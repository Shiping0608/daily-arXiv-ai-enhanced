<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 7]
- [math.AP](#math.AP) [Total: 20]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [math.OC](#math.OC) [Total: 1]
- [math.MG](#math.MG) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [stat.ML](#stat.ML) [Total: 1]
- [hep-ex](#hep-ex) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Analysis of a Discontinuous Galerkin Method for Diffusion Problems on Intersecting Domains](https://arxiv.org/abs/2512.11111)
*Miroslav Kuchta,Rami Masri,Beatrice Riviere*

Main category: math.NA

TL;DR: Interior penalty discontinuous Galerkin method applied to elliptic equations on networks of segments/surfaces with bifurcations, with stability via discrete Poincaré inequality and convergence analysis for different regularity regimes.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods for solving elliptic equations on complex network structures (segments or surfaces with bifurcations) that commonly appear in applications like blood vessels, neural networks, or infrastructure networks.

Method: Interior penalty discontinuous Galerkin method applied to networks with arbitrary bifurcations. Uses discrete Poincaré inequality on hypergraphs for stability, and employs generalized lifting operators for weak consistency in low regularity cases.

Result: Proves stability via discrete Poincaré inequality, convergence for H^r regularity with 1 < r ≤ 2, and weak consistency for low regularity (r ≤ 3/2) using generalized lifting operators. Numerical experiments confirm theoretical results.

Conclusion: The interior penalty discontinuous Galerkin method is effective for solving elliptic equations on complex network structures with bifurcations, with rigorous stability and convergence analysis for different regularity regimes, validated by numerical experiments.

Abstract: The interior penalty discontinuous Galerkin method is applied to solve elliptic equations on either networks of segments or networks of planar surfaces, with arbitrary but fixed number of bifurcations. Stability is obtained by proving a discrete Poincaré's inequality on the hypergraphs. Convergence of the scheme is proved for $H^r$ regularity solution with $1 < r \leq 2$. In the low regularity case ($r \leq 3/2$), a weak consistency result is obtained via generalized lifting operators for Sobolev spaces defined on hypergraphs. Numerical experiments confirm the theoretical results.

</details>


### [2] [An Optimal Weighted Least-Squares Method for Operator Learning](https://arxiv.org/abs/2512.11168)
*John Turnage,Matthew Lowery,John Jakeman,Zachary Morrow,Akil Narayan,Varun Shankar*

Main category: math.NA

TL;DR: The paper proposes a framework for learning nonlinear operators between Hilbert spaces using weighted least squares with optimal sampling measures based on operator-level Christoffel functions, achieving near-optimal sample complexity O(N log N).


<details>
  <summary>Details</summary>
Motivation: Learning unknown operators from data is fundamental in scientific computing and machine learning, but existing methods often suffer from poor conditioning or high sample complexity. The paper aims to develop a theoretically grounded framework for operator learning with provable stability and optimal sample efficiency.

Method: The method uses weighted least squares estimators in finite-dimensional approximation spaces. Key innovations include: 1) Defining optimal sampling measures and weights via operator-level Christoffel functions to ensure well-conditioned Gram matrices, 2) Constructing explicit operator approximation spaces (rank-one linear and polynomial operators), and 3) Developing implementable procedures for sampling from optimal measures.

Result: Theoretical results show that with optimal sampling measures, the method achieves uniformly well-conditioned Gram matrices and near-optimal sample complexity with M ∼ N log N training samples. The framework is demonstrated on benchmark PDE problems (Poisson, viscous Burgers', incompressible Navier-Stokes) with effective performance.

Conclusion: The paper presents a rigorous framework for operator learning with provable stability and sample efficiency. By leveraging operator-level Christoffel functions and optimal sampling measures, the method achieves near-optimal sample complexity and demonstrates practical effectiveness on challenging PDE operator learning problems.

Abstract: We consider the problem of learning an unknown, possibly nonlinear operator between separable Hilbert spaces from supervised data. Inputs are drawn from a prescribed probability measure on the input space, and outputs are (possibly noisy) evaluations of the target operator. We regard admissible operators as square-integrable maps with respect to a fixed approximation measure, and we measure reconstruction error in the corresponding Bochner norm. For a finite-dimensional approximation space $V$ of dimension $N$, we study weighted least squares estimators in $V$ and establish probabilistic stability and accuracy bounds in the Bochner norm. We show that there exist sampling measures and weights - defined via an operator-level Christoffel function - that yield uniformly well-conditioned Gram matrices and near-optimal sample complexity, with a number of training samples $M$ on the order of $N \log N$. We complement the analysis by constructing explicit operator approximation spaces in cases of interest: rank-one linear operators that are dense in the class of bounded linear operators, and rank-one polynomial operators that are dense in the Bochner space under mild assumptions on the approximation measure. For both families we describe implementable procedures for sampling from the associated optimal measures. Finally, we demonstrate the effectiveness of this framework on several benchmark problems, including learning solution operators for the Poisson equation, viscous Burgers' equation, and the incompressible Navier-Stokes equations.

</details>


### [3] [On the Jacobi formula for Bivariate Pade Approximants of Rectangular Type](https://arxiv.org/abs/2512.11238)
*Gareth Hegarty*

Main category: math.NA

TL;DR: A recursive algorithm for evaluating multivariate Padé approximants is presented, analogous to Jacobi's formula for univariate case, and applied to solve a singular Riccati differential equation.


<details>
  <summary>Details</summary>
Motivation: To develop efficient computational methods for multivariate Padé approximants (rectangular type) and apply them to solve challenging differential equations like singular Riccati equations.

Method: A recursive algorithm analogous to Jacobi's formula for univariate Padé approximants is developed for evaluating multivariate Padé approximants of the rectangular type described by Lutterodt.

Result: The algorithm successfully generates fast and accurate approximate solutions when applied to a singular Riccati differential equation.

Conclusion: The recursive algorithm provides an effective computational approach for multivariate Padé approximants and demonstrates practical utility in solving difficult differential equations.

Abstract: In this paper a recursive algorithm is presented for evaluating multivariate Padé approximants (of the rectangular type described in the work of Lutterodt) which is analogous to the Jacobi formula for univariate Padé approximants. This algorithm is then applied to a (singular) Riccati differential equation to generate fast and accurate approximate solutions.

</details>


### [4] [Deconvolution of inclined channel elutriation data to infer particle size distribution](https://arxiv.org/abs/2512.11318)
*Jeffrey A. Hogan,Simon Iveson,Jason Mackellar,Kevin Galvin*

Main category: math.NA

TL;DR: The paper applies optimization techniques with regularization to deconvolve mineral fractionation data from a fluidized bed model, successfully recovering feed size distributions from bag weights with accuracy improving as fluidization rate acceleration decreases.


<details>
  <summary>Details</summary>
Motivation: Deconvolution of mineral fractionation data from fluidized bed operations is an ill-posed problem that requires regularization to obtain feasible solutions from the collected bag weights.

Method: Used optimization techniques with regularization to deconvolve data from a mathematical model of a fluidized bed with inclined parallel channels, involving transport equations with stochastic source functions and linearly increasing fluidization rates.

Result: Successfully deconvolved feed size distribution from bag weights, with accuracy improving as fluidization rate acceleration decreased. Deconvolution error grew linearly with measurement error in bag masses, and combining data from two different liquids improved accuracy.

Conclusion: Regularized deconvolution techniques can effectively solve the ill-posed problem of recovering mineral feed distributions from fluidized bed fractionation data, with performance dependent on operational parameters and enhanced by multi-liquid data combination.

Abstract: In this paper we investigate the application of optimisation techniques in the deconvolution of mineral fractionation data obtained from a mathematical model for the operation of a fluidised bed with a set of inclined parallel channels mounted above. The model involved the transport equation with a stochastic source function and a linearly increasing fluidisation rate, with the overflow solids being collected in a finite number of increments (bags). Deconvolution of this data is an ill-posed problem and regularisation is required to provide feasible solutions. Deconvolution with regularisation is applied to a synthetic feed consisting of particles of constant density that vary in size only. It was found that the feed size distribution could be successfully deconvolved from the bag weights, with an accuracy that improved as the rate acceleration of the fluidisation rate was decreased. The deconvolution error only grew linearly with error in the measured bag masses. It was also shown that combining data from two different liquids can improve the accuracy.

</details>


### [5] [Projected Sobolev Natural Gradient Descent for Neural Variational Monte Carlo Solution of the Gross-Pitaevskii Equation](https://arxiv.org/abs/2512.11339)
*Chenglong Bao,Chen Cui,Kai Jiang,Shi Shu*

Main category: math.NA

TL;DR: Neural variational Monte Carlo method using deep neural networks solves Gross-Pitaevskii equation via projected Sobolev natural gradient descent, achieving high accuracy and accelerated convergence.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for solving the Gross-Pitaevskii equation (GPE) that can handle strong nonlinearities and complex geometric constraints while overcoming stiffness issues in optimization.

Method: Uses deep neural networks with projected Sobolev natural gradient descent, employing an "optimize-then-discretize" strategy with constraint-preserving continuous Riemannian gradient flow on infinite-dimensional manifolds, mapped to neural network parameters via Galerkin projection. Includes hybrid sampling strategy combining integration stream and MCMC for precise estimation.

Result: Demonstrates high accuracy on benchmark cases including harmonic oscillator potential in strong interaction limit and multi-scale optical lattice potentials. Achieves order-of-magnitude acceleration in convergence compared to standard optimizers like Adam, with superior robustness for strong nonlinearities and complex constraints.

Conclusion: The proposed neural variational Monte Carlo method with projected Sobolev natural gradient descent is an effective approach for solving GPE, offering significant improvements in convergence speed, accuracy, and robustness compared to conventional optimization methods.

Abstract: This paper proposes a neural variational Monte Carlo method based on deep neural networks to solve the Gross-Pitaevskii equation (GPE) via projected Sobolev natural gradient descent (NGD). Adopting an "optimize-then-discretize" strategy, we first apply a constraint-preserving continuous Riemannian gradient flow on an infinite-dimensional Riemannian manifold, which is subsequently mapped to the neural network parameter space via Galerkin projection. This process naturally induces a Sobolev energy metric that incorporates physical information, effectively mitigating stiffness during optimization. To address the explicit dependence on the normalization constant caused by the nonlinear interaction term in the GPE, we design a hybrid sampling strategy combining an integration stream and a MCMC stream to achieve precise estimation of the generalized Gram matrix and energy gradients. Numerical experiments on benchmark cases, including the harmonic oscillator potential in the strong interaction limit and multi-scale optical lattice potentials, demonstrate the high accuracy of the proposed method. Furthermore, it achieves an order-of-magnitude acceleration in convergence compared to standard optimizers like Adam, exhibiting superior robustness in handling strong nonlinearities and complex geometric constraints.

</details>


### [6] [A meshless MUSCL method for the BGK-Boltzmann equation](https://arxiv.org/abs/2512.11598)
*Klaas Willems,Axel Klar,Giovanni Russo,Giovanni Samaey,Sudarshan Tiwari*

Main category: math.NA

TL;DR: A numerical method for simulating rarefied gases with moving boundaries using BGK equation in Lagrangian form with moving grid and meshless spatial discretization.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method capable of simulating rarefied gases interacting with moving boundaries and rigid bodies, addressing challenges with time-dependent domains and irregular grids.

Method: Uses BGK equation in Lagrangian form solved with Arbitrary Lagrangian-Eulerian method where grid points move with local mean velocity. Employs meshless Moving Least Squares Method (MLS) for spatial discretization, higher-order Implicit-Explicit Runge-Kutta method, and MOOD method for discontinuity handling with adapted criteria.

Result: Achieves fourth-order accuracy in 1D and second-order in 2D for simulations with moving boundaries. Successfully demonstrated on classical test cases including driven square cavity, shear layer, and shock tube.

Conclusion: The method effectively handles rarefied gas simulations with moving boundaries using a moving grid approach with meshless discretization and novel boundary condition implementation without iterative procedures.

Abstract: We present a numerical method for simulating rarefied gases that interact with moving boundaries and rigid bodies. The gas is described by the BGK equation in Lagrangian form and solved using an Arbitrary Lagrangian-Eulerian method, in which grid points move with the local mean velocity of the gas. The main advantage of the moving grid is that the algorithm can deal well with cases where the domain boundaries are time-dependent and the simulation domain contains rigid objects. Due to the irregular nature of the grid, we use a novel meshless MUSCL-like Moving Least Squares Method (MLS) for spatial discretisation coupled with a higher-order Implicit-Explicit Runge-Kutta method. To avoid spurious oscillations at discontinuities, we use the so-called Multi-dimensional Optimal Order Detection (MOOD) method with an adapted criterion to relax the discrete maximum property. Finally, we employ a new implementation of the boundary conditions that requires no iterative or extrapolation procedure. The method achieves fourth-order in 1D and second-order in 2D for simulations with moving boundaries. We demonstrate the method's effectiveness on classical test cases such as the driven square cavity, shear layer, and shock tube.

</details>


### [7] [A Fully Discrete Surface Finite Element Method for the Navier--Stokes equations on Evolving Surfaces with prescribed Normal Velocity](https://arxiv.org/abs/2512.11737)
*Charles M. Elliott,Achilleas Mavrakis*

Main category: math.NA

TL;DR: This paper analyzes two fully discrete numerical schemes for incompressible Navier-Stokes equations on evolving surfaces using ESFEM with Taylor-Hood elements, establishing stability and optimal error bounds for different approximation orders.


<details>
  <summary>Details</summary>
Motivation: To develop and analyze numerical methods for solving incompressible Navier-Stokes equations on evolving surfaces, which is important for modeling fluid flow on moving interfaces in applications like biological membranes or fluid-structure interaction.

Method: Uses evolving surface finite element method (ESFEM) with generalized Taylor-Hood finite elements (P_k_u-P_k_pr-P_k_λ) for spatial discretization, backward Euler for time-stepping, and Lagrange multiplier for normal velocity constraint. Analyzes two schemes with different geometric information requirements.

Result: Establishes optimal velocity error bounds in L²_a_h-norm for both schemes when k_λ=k_u, but only for the more information-intensive scheme when k_λ=k_u-1. Also proves optimal pressure convergence in L²_L²×L²_H_h⁻¹-norm when k_λ=k_u, and optimal L²_L²×L²_L²-norm pressure bounds for the more intensive scheme with k_λ=k_u-1 under additional regularity.

Conclusion: The paper successfully develops and analyzes two numerical schemes for Navier-Stokes on evolving surfaces with rigorous stability and convergence results, verified by simulations and comparison with penalty methods, providing reliable computational tools for this class of problems.

Abstract: We analyze two fully time-discrete numerical schemes for the incompressible Navier-Stokes equations posed on evolving surfaces in $\mathbb{R}^3$ with prescribed normal velocity using the evolving surface finite element method (ESFEM). We employ generalized Taylor-Hood finite elements $\mathrm{\mathbf{P}}_{k_u}$-- $\mathrm{P}_{k_{pr}}$-- $\mathrm{P}_{k_λ}$, $k_u=k_{pr}+1 \geq 2$, $k_λ\geq 1$, for the spatial discretization, where the normal velocity constraint is enforced weakly via a Lagrange multiplier $λ$, and a backward Euler discretization for the time-stepping procedure. Depending on the approximation order of $λ$ and weak formulation of the Navier-Stokes equations, we present stability and error analysis for two different discrete schemes, whose difference lies in the geometric information needed. We establish optimal velocity $L^{2}_{a_h}$-norm error bounds ($a_h$ an energy norm) for both schemes when $k_λ=k_u$, but only for the more information intensive one when $k_λ=k_u-1$, using iso-parametric and super-parametric discretizations, respectively, with the help of a newly derived surface Ritz-Stokes projection. Similarly, stability and optimal convergence for the pressures is established in an $L^2_{L^2}\times L^2_{H_h^{-1}}$-norm ($H_h^{-1}$ a discrete dual space) when $k_λ=k_u$, using a novel Leray time-projection to ensure weakly divergence conformity for our discrete velocity solution at two different time-steps (surfaces). Assuming further regularity conditions for the more information intensive scheme, along with an almost weak divergence conformity result at two different time-steps, we establish optimal $L^2_{L^2}\times L^2_{L^2}$-norm pressure error bounds when $k_λ=k_u-1$, using super-parametric approximation. Simulations verifying our results are provided, along with a comparison test against a penalty approach.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [8] [Uniqueness of solutions in high-energy x-ray based `eigenstrain tomography' and other inverse eigenstrain problems: Counter examples and necessary conditions for well-posedness](https://arxiv.org/abs/2512.10993)
*Christopher Wensrich,Sean Holman,William Lionheart,Matias Courdurier,Roxanne Jackson*

Main category: math.AP

TL;DR: Eigenstrain tomography reconstructions are not unique with single strain component measurements; uniqueness requires at least three strain components (either shear or diagonal) for well-posed reconstruction.


<details>
  <summary>Details</summary>
Motivation: To establish uniqueness conditions for eigenstrain tomography reconstructions, as current implementations using single strain component measurements lack clear uniqueness guarantees.

Method: Analyze the inverse problem mathematically, construct explicit counterexamples for single-component reconstructions, explore minimum conditions for well-posedness, and prove key theoretical results about eigenstrain generation.

Result: Found non-uniqueness for single-component reconstructions; proved uniqueness requires three measured strain components (either shear or diagonal); established that any residual stress can be generated by diagonal eigenstrain, but not all can be generated by isotropic eigenstrain.

Conclusion: Established rigorous minimum requirements for well-posed eigenstrain tomography: at least three strain components must be measured, providing essential guidance for experimental design and computational methods.

Abstract: Eigenstrain tomography combines diffraction-based strain measurement with elasticity theory to reconstruct full three-dimensional residual stress fields within solids. Notwithstanding a number of recent examples, the uniqueness of such reconstructions has not yet been clearly established. In this paper, we examine the underlying inverse problem in detail and construct explicit counterexamples demonstrating non-uniqueness for a recent implementation of x-ray eigenstrain tomography involving reconstruction from a single measured component of strain. We follow on to explore minimum conditions for well-posedness and conclude that the full elastic strain tensor within an isotropic sample can be uniquely reconstructed from three measured components; specifically the three shear components, or the three diagonal components. We further prove two key results related to eigenstrain reconstruction in a general sense; 1. That any possible residual stress field can be generated by a diagonal eigenstrain and 2. That residual stress fields exist that cannot be generated by isotropic eigenstrains. Together, these findings establish rigorous minimum experimental and computational requirements for well-posed eigenstrain tomography techniques and inverse eigenstrain problems in general.

</details>


### [9] [Two phase micropolar fluid flow with nonlocal energies: Existence theory, nonpolar limits and nonlocal-to-local convergence](https://arxiv.org/abs/2512.11124)
*Kin Shing Chan,Kei Fong Lam*

Main category: math.AP

TL;DR: Nonlocal thermodynamically consistent phase field model for binary micropolar fluid mixtures with global 3D weak existence, 2D strong well-posedness, and convergence to local model.


<details>
  <summary>Details</summary>
Motivation: To extend nonlocal variants of phase field models for binary Newtonian fluid mixtures to micropolar fluids (fluids with internal rotations) and establish mathematical foundations.

Method: Develop a nonlocal Navier-Stokes-Cahn-Hilliard system for binary micropolar fluid mixtures, analyze global weak existence in 3D and strong well-posedness in 2D, study convergence to local model as nonlocal kernel approaches Dirac delta.

Result: Proved global 3D weak existence and global 2D strong well-posedness for the nonlocal micropolar model. Established weak convergence to local counterpart. Provided consistency estimates between strong solutions of nonlocal micropolar model and nonlocal variants of Abels-Garcke-Grün model and Model H in 2D.

Conclusion: The nonlocal micropolar fluid mixture model is mathematically well-founded with rigorous existence and convergence results, extending previous Newtonian fluid mixture models to include internal rotation effects.

Abstract: We study a nonlocal variant of a thermodynamically consistent phase field model for binary mixtures of micropolar fluids, i.e., fluids exhibiting internal rotations. The model is described by a Navier--Stokes--Cahn--Hilliard system that extends the earlier nonlocal variants of the model introduced by Abels, Garcke and Grün for binary Newtonian fluid mixtures with unmatched densities. We establish the global 3D weak existence and global 2D strong well-posedness, followed by the weak convergence of the nonlocal model to its local counterpart as the nonlocal interaction kernel approaches the Dirac delta distribution. In the two dimensional setting we provide consistency estimates between strong solutions of the nonlocal micropolar model and strong solutions of nonlocal variants of the Abels--Garcke--Grün model and Model H.

</details>


### [10] [The pinning effect of dilute defects](https://arxiv.org/abs/2512.11152)
*William M Feldman,Inwon C Kim*

Main category: math.AP

TL;DR: The paper studies pinning effects in Bernoulli free boundary problems with periodic defects, computing asymptotic expansions of pinned slope intervals as defect size approaches zero.


<details>
  <summary>Details</summary>
Motivation: Motivated by contact angle hysteresis in capillary contact lines, the research aims to understand how small periodic defects affect free boundary solutions and cause pinning phenomena.

Method: Analyzes Bernoulli free boundary problems with compact support defects, studies capacity-like pinning effects of single defects, and computes asymptotic expansions for pinned slope intervals as defect size approaches zero for lattice-aligned normal directions.

Result: Shows that when defects are small and periodically arranged, plane-like solutions exist with large-scale slopes slightly different from background field values (pinning). Provides asymptotic expansion of the interval of pinned slopes as defect size goes to zero.

Conclusion: The study successfully quantifies pinning effects in Bernoulli free boundary problems with defects, providing mathematical understanding relevant to contact angle hysteresis phenomena in capillary systems.

Abstract: We consider the Bernoulli free boundary problem with ``defects", inhomogeneities in the coefficients of compact support. When the defects are small and arrayed periodically there exist plane-like solutions with a range of large-scale slopes slightly different from the background field value. This is known as pinning. By studying the capacity-like pinning effect of a single defect in the Bernoulli free boundary problem, we can compute the asymptotic expansion of the interval of pinned slopes as the defect size goes to zero for lattice aligned normal directions. Our work is motivated by the issue of contact angle hysteresis in capillary contact lines.

</details>


### [11] [Scattering for the $2d$ NLS with inhomogeneous nonlinearities](https://arxiv.org/abs/2512.11205)
*Luke Baker*

Main category: math.AP

TL;DR: Proves large-data scattering in H¹ for 2D inhomogeneous nonlinear Schrödinger equations for all powers p>0 using concentration-compactness and contradiction methods.


<details>
  <summary>Details</summary>
Motivation: To establish scattering results for inhomogeneous nonlinear Schrödinger equations in two dimensions, which extends previous results and handles the challenging case of all positive powers p>0.

Method: Uses concentration-compactness and contradiction approach with Morawetz estimates in the style of Nakanishi to preclude existence of compact solutions.

Result: Proves large-data scattering in H¹ for 2D inhomogeneous NLS for all p>0 under conditions: inhomogeneity is nonnegative and repulsive, with decay at infinity required for 0<p≤2.

Conclusion: Successfully establishes scattering theory for inhomogeneous nonlinear Schrödinger equations in two dimensions across the full range of positive powers, overcoming technical challenges through concentration-compactness methods and Morawetz estimates.

Abstract: We prove large-data scattering in $H^1$ for inhomogeneous nonlinear Schrödinger equations in two space dimensions for all powers $p>0$. We assume the inhomogeneity is nonnegative and repulsive; we additionally require decay at infinity in the case $0<p\leq 2$. We use the method of concentration-compactness and contradiction. We preclude the existence of compact solutions using a Morawetz estimate in the style of Nakanishi.

</details>


### [12] [Pseudomeasure distributions for nonseparable, nonlocal mean field games](https://arxiv.org/abs/2512.11210)
*David M. Ambrose,Milton C. Lopes Filho,Anna L. Mazzucato,Helena J. Nussenzveig Lopes*

Main category: math.AP

TL;DR: Existence, uniqueness, and continuous dependence results for mean field games with non-local, non-separable Hamiltonians, allowing pseudomeasure data including Dirac masses for initial distributions.


<details>
  <summary>Details</summary>
Motivation: Many important mean field game models have non-local Hamiltonians where the agent distribution appears only through spatial integrals, requiring new theoretical tools to handle singular initial data like Dirac masses.

Method: Prove existence of solutions for MFG systems with pseudomeasure data, requiring smallness condition on terminal data or Hamiltonian size (but not on initial data or time horizon). Also prove uniqueness and continuous dependence under two convergence hypotheses for initial data.

Result: Established existence theorem allowing Dirac mass initial distributions, with uniqueness and continuous dependence results under smallness conditions on terminal data/Hamiltonian.

Conclusion: The paper provides rigorous mathematical foundations for mean field games with non-local Hamiltonians and singular initial data, extending applicability to important practical models.

Abstract: For a number of important mean field games models, the Hamiltonian is non-local and not additively separable. This means that the distribution of agents appears in the Hamiltonian only in an integral over the whole spatial domain. For mean field games with a class of such Hamiltonians, we prove existence of solutions for the mean field games system of partial differential equations, allowing pseudomeasure data for the distribution of agents. Specifically, this allows the initial distribution of agents to be a sum of Dirac masses. The existence theorem requires a smallness condition on the size of the terminal data for the value function (or, alternatively, on the size of the Hamiltonian); no smallness condition on the size of the initial data or on the size of the time horizon is required. We also prove uniqueness and continuous dependence results under the same type of smallness conditions. We prove continuous dependence under two complementary hypotheses on the initial data: strong convergence of a sequence of pseudomeasures, and weak-$*$ convergence of a sequence of bounded measures.

</details>


### [13] [The incompressible inhomogeneous Navier-Stokes-Vlasov-Fokker-Planck equations: global well-posedness and inviscid limit](https://arxiv.org/abs/2512.11220)
*Fucai Li,Jinkai Ni,Ling-Yun Shou,Dehua Wang*

Main category: math.AP

TL;DR: Global well-posedness and inviscid limit analysis for fluid-particle interaction system (Navier-Stokes + Vlasov-Fokker-Planck) with density-dependent friction in 3D, establishing uniform regularity, optimal convergence rates, and global strong convergence.


<details>
  <summary>Details</summary>
Motivation: To address the challenging problem of establishing inviscid limit over large time periods for incompressible Euler equations under weak dissipative friction force, and to understand global behavior of fluid-particle interaction systems.

Method: Prove global stability of equilibrium using Besov spatial regularity, establish uniform regularity estimates with respect to viscosity coefficient, construct global solutions via vanishing viscosity limit, and capture dissipation from two-phase interactions using novel analytical techniques.

Result: Global well-posedness and uniform regularity estimates for strong solutions, optimal convergence rates to equilibrium uniformly in Navier-Stokes, global solutions to Euler-Fokker-Planck equations via vanishing viscosity, and rigorous justification of global-in-time strong convergence with sharp convergence rates.

Conclusion: The paper successfully establishes global well-posedness and inviscid limit for fluid-particle interaction systems, developing novel analytical techniques that can be applied to other significant problems in multi-phase flow analysis.

Abstract: The global well-posedness and inviscid limit are investigated for the fluid-particle interaction system, described by the Navier-Stokes equations for the inhomogeneous incompressible viscous flows coupled with the Vlasov-Fokker-Planck equation for particles through a density-dependent nonlinear friction force in three-dimensional space. It is challenging to establish the inviscid limit over large time periods for the incompressible Euler equations under the influence of the weak dissipative mechanism generated by the friction force. We first prove the global stability of the equilibrium, in the sense that initial perturbations with appropriate Besov spatial regularity lead to global well-posedness and uniform regularity estimates with respect to the viscosity coefficient for strong solutions of the inhomogeneous Navier-Stokes-Vlasov-Fokker-Planck equations. In particular, we establish the optimal rates of convergence to equilibrium uniformly in Navier-Stokes. Then, we construct global solutions to the inhomogeneous Euler-Fokker-Planck equations via the vanishing viscosity limit. Furthermore, by capturing the dissipation arising from two-phase interactions, we rigorously justify the global-in-time strong convergence of the inviscid limit process, with a convergence rate that is in sharp contrast to that in the pure incompressible fluid case. To achieve this global convergence, novel ideas and new techniques are developed in the analysis and may be applied to other significant problems.

</details>


### [14] [Gradient higher integrability of bounded solutions to parabolic double-phase systems](https://arxiv.org/abs/2512.11294)
*Iwona Chlebicka,Prashanta Garain,Wontae Kim*

Main category: math.AP

TL;DR: Bounded solutions to degenerate parabolic double-phase equations have locally higher integrable gradients for sharp exponent range p<q≤p+α.


<details>
  <summary>Details</summary>
Motivation: The paper studies regularity properties of solutions to degenerate parabolic double-phase problems, which combine p-growth and q-growth terms with a weight function. These equations model various physical phenomena where the diffusion properties change depending on spatial and temporal variables.

Method: The authors prove regularity results using analytical techniques for degenerate parabolic equations. They work with bounded solutions to the double-phase problem where the weight function a(x,t) is α-Hölder continuous in space and α/2-Hölder continuous in time.

Result: The main result shows that bounded solutions have locally higher integrable gradients for the sharp range of exponents p<q≤p+α. This establishes optimal regularity conditions for this class of equations.

Conclusion: The paper provides sharp regularity results for degenerate parabolic double-phase problems, establishing that bounded solutions gain higher integrability of gradients under optimal conditions on the exponents and Hölder continuity of the weight function.

Abstract: We prove that bounded solutions to degenerate parabolic double-phase problem modelled upon \[u_t-\dv(|\na u|^{p-2}\na u+a(x,t)|\na u|^{q-2}\na u)=-\dv(|F|^{p-2}F+a(x,t)|F|^{q-2}F)\,, \] where a nonnegative weight $a$ is $α$-Hölder continuous in space and $\tfrac α2$-Hölder continuous in time, have locally higher integrable gradients for the sharp range of exponents $p<q\le p+α$.

</details>


### [15] [A variational approach to nonlocal heat equations](https://arxiv.org/abs/2512.11370)
*Edoardo Mainini*

Main category: math.AP

TL;DR: Weighted variational integral approach for nonlocal linear diffusion with forcing term, providing solution selection for elliptic-in-time regularizations.


<details>
  <summary>Details</summary>
Motivation: To address solution selection problems in nonlocal linear diffusion models with forcing terms, particularly for elliptic-in-time regularizations where multiple solutions may exist.

Method: A weighted variational integral approach that provides a selection principle for choosing appropriate solutions among possible candidates.

Result: The approach establishes a framework for systematically selecting solutions in nonlocal diffusion models with forcing terms, particularly for elliptic-in-time regularizations.

Conclusion: The weighted variational integral method offers a principled approach to solution selection in nonlocal diffusion problems with forcing terms, addressing regularization challenges.

Abstract: We discuss a weighted variational integral approach for nonlocal linear diffusion models with forcing term, providing a selection principle for solutions of elliptic in time regularizations.

</details>


### [16] [Conformal composition operators with applications to Dirichlet eigenvalues](https://arxiv.org/abs/2512.11380)
*C. Deneche,V. Pchelintsev*

Main category: math.AP

TL;DR: Spectral estimates for first Dirichlet eigenvalue of degenerate p-Laplace operator in bounded simply connected domains in complex plane using conformal analysis approach.


<details>
  <summary>Details</summary>
Motivation: To develop spectral estimates for the first Dirichlet eigenvalue of degenerate p-Laplace operators in bounded simply connected domains, particularly addressing domains with non-rectifiable boundaries where traditional methods may fail.

Method: Uses conformal analysis of elliptic operators to obtain spectral estimates. The approach leverages conformal mapping techniques to handle domains with complex boundaries, including those that are non-rectifiable.

Result: Obtains spectral estimates for the first Dirichlet eigenvalue of degenerate p-Laplace operators in bounded simply connected domains, with the capability to handle domains having non-rectifiable boundaries.

Conclusion: Conformal analysis provides an effective approach for spectral estimation of degenerate p-Laplace operators in complex domains, extending results to domains with irregular boundaries that are not rectifiable.

Abstract: This paper is concerned with spectral estimates for the first Dirichlet eigenvalue of the degenerate $p$-Laplace operator in bounded simply connected domains $Ω\subset \mathbb C$. The proposed approach relies on the conformal analysis of the elliptic operators, which allows us to obtain spectral estimates in domains with non-rectifiable boundaries.

</details>


### [17] [Bubbling analysis of bimeron configurations](https://arxiv.org/abs/2512.11400)
*Glal Bacho,Christof Melcher*

Main category: math.AP

TL;DR: Analysis of chiral symmetry breaking in magnetic thin films reveals new topological solitons like chiral bimerons in easy-plane systems, studied using blow-up methods and Möbius group rigidity.


<details>
  <summary>Details</summary>
Motivation: To understand how chiral symmetry breaking in magnetic thin films enables new families of topological solitons beyond classical chiral skyrmions, particularly in easy-plane systems where dipolar configurations called chiral bimerons emerge.

Method: Combines blow-up methods with quantitative rigidity for the Möbius group, inspired by Sacks-Uhlenbeck theory for approximate harmonic maps, to analyze soliton structure, scaling behavior, and asymptotic limits.

Result: Reveals that chiral bimerons appear as localized energy concentrations in easy-plane backgrounds on compact domains, with detailed descriptions of their structure and behavior in both conformal and large-domain regimes.

Conclusion: Chiral symmetry breaking in magnetic thin films enables novel topological solitons like chiral bimerons, whose mathematical structure can be systematically analyzed using geometric methods, expanding our understanding of magnetic textures beyond conventional skyrmions.

Abstract: Chiral symmetry breaking in magnetic thin films stabilizes new families of topological solitons that are absent in conventional anisotropic ferromagnets. Beyond the classical chiral skyrmion, which arises in uniaxial systems through the Dzyaloshinskii--Moriya interaction, dipolar configurations known as chiral bimerons emerge in easy--plane situations. On compact domains, these solitonic states appear as localized concentrations of energy embedded in an easy--plane background. The analysis, inspired by the Sacks--Uhlenbeck theory for approximate harmonic maps, combines blow--up methods with quantitative rigidity for the Möbius group to describe the structure, scaling behaviour, and asymptotic limits of such magnetic solitons in both the conformal and large--domain regimes.

</details>


### [18] [Stratification of the Helffer-Nourrigat cone](https://arxiv.org/abs/2512.11434)
*Clément Cren*

Main category: math.AP

TL;DR: The paper proposes a desingularization method for the Helffer-Nourrigat cone in subriemannian geometry by extending Puckansky-Pedersen stratification to this phase space, enabling better geometric analysis and revealing solvable structures in related C*-algebras.


<details>
  <summary>Details</summary>
Motivation: The Helffer-Nourrigat cone serves as a phase space in subriemannian geometry but has singular topology that prevents geometric analysis. There's a need to desingularize this space to enable proper geometric understanding and analysis of elliptic regularity problems in singular filtrations.

Method: Extends Puckansky and Pedersen's stratification of unitary spectrum of nilpotent groups (which yields locally compact Hausdorff strata) to the entire Helffer-Nourrigat cone, providing a desingularization approach for this singular phase space.

Result: Successfully desingularizes the Helffer-Nourrigat cone by stratifying it into locally compact Hausdorff strata. As a byproduct, shows that both the C*-algebra of principal symbols and the C*-algebra of pseudodifferential operators of order 0 are solvable with explicit subquotients.

Conclusion: The proposed stratification method effectively desingularizes the Helffer-Nourrigat cone, enabling geometric analysis in subriemannian settings and revealing solvable structures in related operator algebras, advancing the understanding of elliptic regularity in singular filtrations.

Abstract: Given a singular filtration on a manifold, e.g. a subriemannian setting, one can understand the elliptic regularity problems through a special kind of calculus. The principal symbol in this calculus involves the unitary representations of a family of graded nilpotent groups. Not all the irreducible representations of these groups have to be taken into account however, the ones that should be considered form the Helffer-Nourrigat cone. This space thus plays the role of a phase space in subriemannian geometry. Its topology is however very singular, preventing any kind of geometry on it. We propose a way to desingularize it. The unitary spectrum of a nilpotent group can be stratified into strata that are locally compact Hausdorff, following Puckansky and Pedersen. We show how this stratification extends to the whole Helffer-Nourrigat cone. As a byproduct, we show that the C*-algebra of principal symbols and the one of pseudodifferential operators of order 0 are solvable with explicit subquotients.

</details>


### [19] [A deterministic particle approximation for a fourth-order equation](https://arxiv.org/abs/2512.11441)
*Charles Elbar,Alejandro Fernández-Jiménez*

Main category: math.AP

TL;DR: Deterministic particle approximation for a fourth-order PDE modeling cell-cell adhesion, derived via nonlocal PDE limit and 2-Wasserstein gradient flow stability.


<details>
  <summary>Details</summary>
Motivation: Develop deterministic particle methods for fourth-order PDEs, particularly for cell-cell adhesion modeling, where such approximations were previously unavailable.

Method: First show the fourth-order equation emerges as asymptotic limit from well-posed nonlocal PDEs, then use stability of 2-Wasserstein gradient flow of these nonlocal equations to derive deterministic particle approximation.

Result: First deterministic particle approximation for a fourth-order PDE, with numerical simulations demonstrating the particle-level model.

Conclusion: Successfully derived novel deterministic particle approximation for fourth-order PDEs, enabling particle-based simulations of cell-cell adhesion models with potential applications in computational biology.

Abstract: We provide a deterministic particle approximation to a fourth order equation with applications in cell-cell adhesion. In order to do that, first we show that the equation can be asymptotically obtained as a limit from a class of well-posed nonlocal partial differential equations. These latter have the advantage that the particles' empirical measure naturally satisfies the equation. Afterwards, we obtain stability of the 2-Wasserstein gradient flow of this family of nonlocal equations that we use in order to recover a deterministic particle approximation of the fourth order equation. Up to our knowledge, in this manuscript we derive the first deterministic particle approximation for a fourth-order partial differential equation. Finally, we give some numerical simulations of the model at the particles level.

</details>


### [20] [Mixed local-nonlocal $p$-Laplace equation with variable singular nonlinearity in the Heisenberg group](https://arxiv.org/abs/2512.11442)
*Prashanta Garain*

Main category: math.AP

TL;DR: First study of mixed local-nonlocal p-Laplace equations with variable singular exponent on Heisenberg group, proving existence, uniqueness, and regularity of weak solutions.


<details>
  <summary>Details</summary>
Motivation: To extend the theory of mixed local-nonlocal equations to non-commutative settings (Heisenberg group), addressing gaps in existing literature where such problems haven't been studied even in simpler linear cases with constant exponents.

Method: Analysis of mixed local-nonlocal p-Laplace equations on Heisenberg group with variable singular exponent, using appropriate functional analytic framework and establishing weak solution theory under structural assumptions.

Result: Proves existence, uniqueness, and regularity of weak solutions for the mixed local-nonlocal p-Laplace equation with variable singular exponent on Heisenberg group.

Conclusion: Provides foundational results for mixed local-nonlocal problems in non-commutative settings, establishing solution theory that extends beyond commutative Euclidean spaces to Heisenberg group geometry.

Abstract: We investigate a mixed local-nonlocal $p$-Laplace equation on the Heisenberg group, where the nonlinear term features a variable singular exponent. Our analysis establishes the existence, uniqueness, and regularity of weak solutions under suitable structural assumptions. To the best of our knowledge, this work provides the first treatment of such mixed local-nonlocal problems in a non-commutative setting, even in the linear case $p=2$ with a constant singular exponent.

</details>


### [21] [On mixed local-nonlocal Sobolev-type inequalities and their connection with singular equations in the Heisenberg group](https://arxiv.org/abs/2512.11449)
*Prashanta Garain*

Main category: math.AP

TL;DR: Mixed local-nonlocal Sobolev inequality in Heisenberg group links to singular p-Laplace equations, with extremals as solutions and inequality as necessary/sufficient condition for existence.


<details>
  <summary>Details</summary>
Motivation: To establish a unified framework connecting existence theory for singular equations across local, nonlocal, and mixed regimes in the Heisenberg group setting.

Method: Develop mixed local-nonlocal Sobolev-type inequality in Heisenberg group, analyze extremals, relate to singular p-Laplace equations, and prove equivalence between inequality and existence of weak solutions.

Result: Extremals of the inequality coincide with solutions to mixed local-nonlocal singular p-Laplace equations; inequality serves as necessary and sufficient condition for existence of weak solutions; characterization holds for purely local, purely nonlocal, and mixed settings.

Conclusion: Provides unified framework linking existence theory for singular equations across local, nonlocal, and mixed regimes in Heisenberg group, with consistent characterization across all settings.

Abstract: In this work, we establish a mixed local--nonlocal Sobolev-type inequality in the Heisenberg group and demonstrate that its extremals coincide with solutions to the corresponding mixed local--nonlocal singular $p$-Laplace equations. We further show that these inequalities serve as a necessary and sufficient condition for the existence of weak solutions to the associated singular problems. Notably, the same characterization remains valid in both the purely local and purely nonlocal settings. Our results thus provide a unified framework linking the existence theory for singular equations across local, nonlocal, and mixed regimes.

</details>


### [22] [Long-time behavior of free energy in the nonlinear Fokker-Planck equation](https://arxiv.org/abs/2512.11455)
*Kouta Araki,Masashi Mizuno*

Main category: math.AP

TL;DR: Extends entropy dissipation method to analyze long-time behavior of Fokker-Planck equations with spatially inhomogeneous nonlinear diffusion, focusing on porous-medium-type diffusion with large coefficients.


<details>
  <summary>Details</summary>
Motivation: To understand asymptotic behavior of Fokker-Planck equations with spatially inhomogeneous nonlinear diffusion, which extends classical homogeneous diffusion models to more realistic spatially varying scenarios.

Method: Extends entropy dissipation method to handle inhomogeneous diffusion by introducing spatial inhomogeneity into free energy, then analyzes long-time behavior of dissipation function for sufficiently large diffusion coefficients.

Result: Obtains results on long-time behavior of dissipation function for Fokker-Planck equations with porous-medium-type nonlinear diffusion when diffusion coefficients are sufficiently large.

Conclusion: The entropy dissipation method can be successfully extended to analyze spatially inhomogeneous nonlinear diffusion in Fokker-Planck equations, providing insights into their asymptotic behavior for large diffusion coefficients.

Abstract: We study the asymptotic behavior of Fokker-Planck equations with spatially inhomogeneous nonlinear diffusion, based on the energy dissipation law. First, we consider the Fokker-Planck equation with porous-medium-type nonlinear diffusion that satisfies the energy dissipation law by introducing spatial inhomogeneity into the free energy. We obtain a result on the long-time behavior of the dissipation function for sufficiently large diffusion coefficients by extending the entropy dissipation method to the case of inhomogeneous diffusion.

</details>


### [23] [Effective transmission through an interface with evolving microstructure](https://arxiv.org/abs/2512.11489)
*Lucas M. Fix,Gianna Götzmann,Malte A. Peter,Jan-F. Pietschmann*

Main category: math.AP

TL;DR: Homogenization of nonlinear reaction-diffusion-advection equations in a domain with thin membrane containing microscopic channels, deriving effective interface conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the asymptotic behavior of complex transport phenomena in domains with thin membranes containing microscopic channels, which is relevant for biological systems, filtration processes, and porous media applications.

Method: Extend homogenization methods to evolving microstructures in thin layers using two-scale convergence and unfolding techniques in thin layers, with nonlinear flux boundary conditions and critical diffusion scaling.

Result: Derived an effective model where the membrane reduces to a lower-dimensional interface with jump conditions involving solutions of local, space-time-dependent cell problems in reference channels.

Conclusion: Successfully developed homogenization framework for thin membranes with evolving microstructure, providing effective interface conditions for complex transport phenomena in multi-scale systems.

Abstract: We study the asymptotic behaviour of a system of nonlinear reaction--diffusion--advection equations in a domain consisting of two bulk regions connected via microscopic channels distributed within a thin membrane. Both the width of the channels and the thickness of the membrane are of order $\varepsilon \ll 1$, and the geometry evolves in time in an a priori known way.
  We consider nonlinear flux boundary conditions at the lateral boundaries of the channels and critical scaling of the diffusion inside the layer. Extending the method of homogenisation in domains with evolving microstructure to thin layers, we employ two-scale convergence and unfolding techniques in thin layers to derive an effective model in the limit $\varepsilon \to 0$, in which the membrane is reduced to a lower-dimensional interface. We obtain jump conditions for the solution and the total fluxes, which involve the solutions of local, space--time-dependent cell problems in the reference channel.

</details>


### [24] [Existence and dependency results for coupled Schrödinger equations with critical exponent on waveguide manifold](https://arxiv.org/abs/2512.11491)
*Jun Wang,Zhaoyang Yin*

Main category: math.AP

TL;DR: Existence and properties of solutions for coupled Schrödinger equations with critical exponent on ℝ³ × 𝕋 using scaling arguments and semivirial-vanishing techniques


<details>
  <summary>Details</summary>
Motivation: To study coupled Schrödinger equations with critical exponent on product spaces ℝ³ × 𝕋 (3D Euclidean space times torus), which extends previous work to more general geometric settings

Method: Uses scaling arguments and semivirial-vanishing technology to analyze the equations, with techniques applicable to 1-dimensional compact Riemannian manifolds

Result: Obtains existence and y-dependence of solutions, with results extendable to systems with any number of components

Conclusion: The approach successfully establishes solution properties on ℝ³ × 𝕋 and can be generalized to more complex systems and manifold settings

Abstract: We study the coupled Schrödinger equations with critical exponent on $\mathbb{R}^3 \times \mathbb{T}$. With the help of scaling argument and semivirial-vanishing technology, we obtain the existence and $y$-dependence of solution, the tori can be generalized to $1$-dimensional compact Riemannian manifold. Moreover, the conclusion of this paper can be extended to systems with any number of components.

</details>


### [25] [Weak local Gagliardo-Nirenberg type inequalities with a BMO term](https://arxiv.org/abs/2512.11576)
*Dung Le*

Main category: math.AP

TL;DR: The paper improves a global Gagliardo-Nirenberg inequality by incorporating a BMO term.


<details>
  <summary>Details</summary>
Motivation: To enhance the classical Gagliardo-Nirenberg inequality by including a bounded mean oscillation (BMO) term, which allows for better control of functions with less regularity.

Method: The authors develop mathematical analysis techniques to modify the standard Gagliardo-Nirenberg inequality, incorporating BMO norms and establishing new estimates.

Result: A refined version of the global Gagliardo-Nirenberg inequality with a BMO term is proven, providing sharper estimates for functions in appropriate function spaces.

Conclusion: The improved inequality with BMO term offers better interpolation results and extends the applicability of Gagliardo-Nirenberg type estimates to functions with weaker regularity conditions.

Abstract: An improvement of a global Gagliardo-Nienberg inequality with a BMO term is established.

</details>


### [26] [Stability of stationary reaction diffusion-degenerate Nagumo fronts I: spectral analysis](https://arxiv.org/abs/2512.11721)
*Raffaele Folino,César A. Hernández Melo,Luis F. López Ríos,Ramón G. Plaza*

Main category: math.AP

TL;DR: Spectral stability analysis of monotone stationary fronts for degenerate Nagumo-type reaction-diffusion equations, showing real spectrum with spectral gap and exponential decay of analytic semigroup.


<details>
  <summary>Details</summary>
Motivation: To establish spectral stability of monotone stationary fronts in reaction-diffusion equations with degenerate diffusion coefficients that vanish at one equilibrium point. The degeneracy prevents application of standard spectral analysis techniques, requiring new methods.

Method: Uses spectral partition analysis, singular sequences, generalized operator convergence techniques, and refined energy estimates to overcome difficulties from degenerate diffusion. Analyzes the linearized operator around the front in L^2 space.

Result: The L^2-spectrum of the linearized operator is real with a spectral gap (positive distance from imaginary axis except at origin). Origin is a simple isolated eigenvalue corresponding to translation invariance. The linearization generates an analytic semigroup with exponential decay outside the one-dimensional eigenspace of zero eigenvalue.

Conclusion: Monotone stationary fronts connecting degenerate and non-degenerate equilibria in Nagumo-type reaction-diffusion equations with degenerate diffusion are spectrally stable, with well-behaved spectral properties despite the degeneracy.

Abstract: This paper establishes the spectral stability of monotone, stationary front solutions for reaction-diffusion equations where the reaction function is of Nagumo (or bistable) type and with diffusion coefficients which are density dependent and degenerate at zero (one of the equilibrium points of the reaction). These stationary profiles connect the non-degenerate equilibrium point with the degenerate state at zero, they are monotone, and arrive to the degenerate state at a finite point. They are neither sharp nor smooth. The degeneracy of the diffusion precludes the application of standard techniques to locate the essential spectrum of the linearized operator around the wave in the energy space $L^2$. This difficulty is overcome with a suitable partition of the spectrum, the analysis of singular sequences, a generalized convergence of operators technique and refined energy estimates. It is shown that the $L^2$-spectrum of the linearized operator around the front is real and with a spectral gap, that is, a positive distance between the imaginary axis and the rest of the spectrum, with the exception of the origin. Moreover, the origin is a simple isolated eigenvalue, associated to the derivative of the profile as eigenfunction (the translation eigenvalue). Finally, it is shown that the linearization generates an analytic semigroup that decays exponentially outside a one-dimensional eigenspace associated to the zero eigenvalue.

</details>


### [27] [The Gevrey class of the Euler-Bernoulli beam model with singularities](https://arxiv.org/abs/2512.11789)
*Jaime E. Munoz Rivera,Maria Grazia Naso,Bruna T. Silva Sozzo*

Main category: math.AP

TL;DR: Euler-Bernoulli beam with singularities and localized Kelvin-Voigt viscoelastic damping yields immediately differentiable semigroup of Gevrey class 4, ensuring exponential stability and smoothing effects.


<details>
  <summary>Details</summary>
Motivation: To analyze the dynamic behavior of composite beams with material discontinuities (singularities) and localized viscoelastic damping, which are common in engineering applications where different materials are joined or where damping treatments are applied only to specific regions.

Method: Study the Euler-Bernoulli beam model with singularities at points x=ξ₁ and x=ξ₂, composed of elastic and Kelvin-Voigt viscoelastic materials. Use semigroup theory to analyze the system's evolution operator properties.

Result: The corresponding semigroup is immediately differentiable and belongs to Gevrey class 4. This implies exponential stability, linear stability property, and smoothing effect on initial data.

Conclusion: The composite beam model with localized Kelvin-Voigt damping exhibits strong regularity properties (immediate differentiability, Gevrey class 4) and excellent stability characteristics (exponential stability with smoothing effects), making it mathematically well-behaved for engineering applications.

Abstract: We study the Euler-Bernoulli beam model with singularities at the points $x=ξ_1$, $x=ξ_2$ and with localized viscoelastic dissipation of Kelvin-Voigt type. We assume that the beam is composed by two materials; one is an elastic material and the other one is a viscoelastic material of Kelvin-Voigt type.
  Our main result is that the corresponding semigroup is immediately differentiable and also of Gevrey class $4$.
  In particular, our result implies that the model is exponentially stable, has the linear stability property, and the smoothing effect property over the initial data.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [28] [HPRMAT: A high-performance R-matrix solver with GPU acceleration for coupled-channel problems in nuclear physics](https://arxiv.org/abs/2512.11590)
*Jin Lei*

Main category: physics.comp-ph

TL;DR: HPRMAT is a high-performance linear solver library for R-matrix nuclear physics calculations that replaces traditional matrix inversion with optimized direct solving, offering 4 solver backends including GPU acceleration and mixed-precision strategies, achieving up to 18× speedup over legacy codes.


<details>
  <summary>Details</summary>
Motivation: Existing R-matrix coupled-channel scattering codes in nuclear physics use inefficient matrix inversion methods that limit performance, especially for large-scale calculations. There's a need for optimized solvers that can leverage modern hardware (including consumer GPUs) while maintaining physics accuracy.

Method: HPRMAT provides four solver backends: 1) double-precision LU factorization, 2) mixed-precision arithmetic with iterative refinement, 3) Woodbury formula exploiting kinetic-coupling matrix structure, and 4) GPU acceleration. It replaces matrix inversion with direct linear equation solving using optimized libraries.

Result: GPU solver achieves up to 9× speedup over optimized CPU direct solvers and 18× over legacy inversion-based codes for large matrices (N=25600). Mixed-precision strategy effectively uses consumer GPUs despite poor FP64 performance. All solvers maintain physics accuracy with relative errors below 10⁻⁵.

Conclusion: HPRMAT enables large-scale CDCC and coupled-channel calculations on standard desktop workstations without expensive data-center GPUs, providing significant performance improvements while maintaining accuracy, with interfaces for Fortran, C, Python, and Julia.

Abstract: I present HPRMAT, a high-performance solver library for the linear systems arising in R-matrix coupled-channel scattering calculations in nuclear physics. Designed as a drop-in replacement for the linear algebra routines in existing R-matrix codes, HPRMAT employs direct linear equation solving with optimized libraries instead of traditional matrix inversion, achieving significant performance improvements. The package provides four solver backends: (1) double-precision LU factorization, (2) mixed-precision arithmetic with iterative refinement, (3) a Woodbury formula approach exploiting the kinetic-coupling matrix structure, and (4) GPU acceleration. Benchmark calculations demonstrate that the GPU solver achieves up to 9$\times$ speedup over optimized CPU direct solvers, and 18$\times$ over legacy inversion-based codes, for large matrices ($N=25600$). The mixed-precision strategy is particularly effective on consumer GPUs (e.g., NVIDIA RTX 3090/4090), where single-precision throughput exceeds double-precision by a factor of 64:1; by performing factorization in single precision with iterative refinement, HPRMAT overcomes the poor FP64 performance of consumer hardware while maintaining double-precision accuracy. This makes large-scale CDCC and coupled-channel calculations accessible to researchers using standard desktop workstations, without requiring expensive data-center GPUs. CPU-only solvers provide 5--7$\times$ speedup through optimized libraries and algorithmic improvements. All solvers maintain physics accuracy with relative errors below $10^{-5}$ in cross-section calculations, validated against Descouvemont's reference code (Comput.\ Phys.\ Commun.\ 200, 199--219 (2016)). HPRMAT provides interfaces for Fortran, C, Python, and Julia.

</details>


### [29] [Stable spectral neural operator for learning stiff PDE systems from limited data](https://arxiv.org/abs/2512.11686)
*Rui Zhang,Han Wan,Yang Liu,Hao Sun*

Main category: physics.comp-ph

TL;DR: SSNO is a spectral neural operator that learns stiff PDE dynamics from limited data without knowing governing equations, achieving 10-100x lower errors than existing methods with only 2-5 training trajectories.


<details>
  <summary>Details</summary>
Motivation: Modeling spatiotemporal dynamics is crucial but challenging when governing equations are unknown and data are sparse. System stiffness (multiple time-scales) further complicates long-term prediction. Existing methods fail: data-driven approaches need massive datasets, while physics-aware methods require known equations and fine time steps.

Method: SSNO (Stable Spectral Neural Operator) uses spectrally inspired architecture with inductive biases for physics learning. It learns local/global spatial interactions in frequency domain and handles stiffness with integrating factor time-stepping scheme. It's equation-free and doesn't encode specific PDE terms.

Result: SSNO achieves prediction errors 1-2 orders of magnitude lower than leading models across 2D/3D benchmarks in Cartesian and spherical geometries. Shows remarkable data efficiency, requiring only 2-5 training trajectories for robust generalization to out-of-distribution conditions.

Conclusion: SSNO provides a robust, generalizable approach to learning stiff spatiotemporal dynamics from limited data without explicit a priori knowledge of PDE terms, overcoming limitations of both purely data-driven and physics-aware methods.

Abstract: Accurate modeling of spatiotemporal dynamics is crucial to understanding complex phenomena across science and engineering. However, this task faces a fundamental challenge when the governing equations are unknown and observational data are sparse. System stiffness, the coupling of multiple time-scales, further exacerbates this problem and hinders long-term prediction. Existing methods fall short: purely data-driven methods demand massive datasets, whereas physics-aware approaches are constrained by their reliance on known equations and fine-grained time steps. To overcome these limitations, we introduce an equation-free learning framework, namely, the Stable Spectral Neural Operator (SSNO), for modeling stiff partial differential equation (PDE) systems based on limited data. Instead of encoding specific equation terms, SSNO embeds spectrally inspired structures in its architecture, yielding strong inductive biases for learning the underlying physics. It automatically learns local and global spatial interactions in the frequency domain, while handling system stiffness with a robust integrating factor time-stepping scheme. Demonstrated across multiple 2D and 3D benchmarks in Cartesian and spherical geometries, SSNO achieves prediction errors one to two orders of magnitude lower than leading models. Crucially, it shows remarkable data efficiency, requiring only very few (2--5) training trajectories for robust generalization to out-of-distribution conditions. This work offers a robust and generalizable approach to learning stiff spatiotemporal dynamics from limited data without explicit \textit{a priori} knowledge of PDE terms.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [30] [Charge transport and mode transition in dual-energy electron beam diodes](https://arxiv.org/abs/2512.11290)
*Chubin Lin,Jiandong Chen,Huihui Wang,Yangyang Fu*

Main category: physics.plasm-ph

TL;DR: Study reveals five distinct charge transport modes in dual-energy electron beam diodes, governed by interplay between beam energy and current density, with theoretical model matching PIC simulations.


<details>
  <summary>Details</summary>
Motivation: To understand the complex charge transport mechanisms in dual-energy electron beam diodes and provide mechanistic insights for designing high-performance vacuum electronic devices.

Method: Used fully kinetic particle-in-cell (PIC) simulations to analyze charge transport, conducted generalized analysis for n-component electron beams, and proposed a theoretical piecewise function.

Result: Discovered five distinct charge transport modes and their transitions, with theoretical model showing good agreement with PIC simulation results under designed conditions.

Conclusion: The findings provide a mechanistic understanding of multiple electron beam transport in diodes, enabling novel designs for high-performance modern vacuum electronic devices.

Abstract: This Letter uncovers five distinct charge transport modes and their transitions in dual-energy electron beam diodes. We, via fully kinetic particle-in-cell (PIC) simulations, establish that the specific mode (e.g., space charge oscillations) and the current transport characteristics are essentially governed by the interplay between the electron beam energy and injected current density. A more generalized analysis is conducted for n-component electron beams, and a theoretical piecewise function is proposed, which agrees well with the PIC results under designed conditions. The discovery provides a mechanistic picture of multiple electron beam transport in diodes, paving the way for novel designs of high-performance modern vacuum electronic devices.

</details>


### [31] [$T_i/T_e$ Dependence of Core Turbulence and Transport in DIII-D QH-Mode Plasmas](https://arxiv.org/abs/2512.11328)
*Abhishek Tiwari,Kshitish Barada,Jaya Kumar Alageshan,Santanu Banerjee,Tanmay Macwan,Terry L. Rhodes,Sarveshwar Sharma,Zhihong Lin,Animesh Kuley*

Main category: physics.plasm-ph

TL;DR: Investigates how ion-to-electron temperature ratio affects microturbulence transport in QH-mode plasmas, showing TEM/ITG transition depends on Ti/Te ratio and helium plasmas may offer confinement benefits.


<details>
  <summary>Details</summary>
Motivation: To understand how the ion-to-electron temperature ratio (Ti/Te) influences microturbulence-driven transport in Quiescent H-mode (QH-mode) plasmas, which is crucial for optimizing plasma confinement in tokamak fusion devices.

Method: Uses Gyrokinetic Toroidal Code (GTC) with QH-mode equilibrium to perform linear and nonlinear simulations, analyzing transport properties and instability dynamics under variations of Ti and Te, including impurity addition and helium plasma studies.

Result: Decreasing Ti/Te destabilizes TEM over ITG modes; higher Te increases transport saturation; lower Ti modestly enhances transport; impurity addition doesn't significantly alter transport; helium plasmas show higher growth rates but lower saturation levels than deuterium.

Conclusion: Temperature ratio Ti/Te critically determines turbulence regime transitions (TEM vs ITG), with helium plasmas potentially offering confinement benefits; temperature profiles and zonal flows play key roles in plasma confinement optimization.

Abstract: This study investigates the effect of the ion-to-electron temperature ratio ($T_i/T_e$) on microturbulence driven transport in Quiescent H-mode (QH-mode) plasmas in the DIII-D tokamak. Utilizing the Gyrokinetic Toroidal Code (GTC) and the QH-mode equilibrium, we perform linear and nonlinear simulations to analyze transport properties and instability dynamics under variations of $T_i$ and $T_e$. Our results demonstrate that decreasing $T_i/T_e$ leads to a relative destabilization of trapped electron modes (TEM) over ion temperature gradient (ITG) modes, with the transition between these regimes dictated by $T_i/T_e$. When the electron temperature is increased at fixed ion temperature, we observe an increase in transport saturation levels. In contrast, decreasing the ion temperature at fixed electron temperature results in more modest transport enhancement. The radial correlation length, which characterizes eddy size, increases with rising $T_e$ and decreases with falling $T_i$, consistent with the observed trends in turbulent transport. Additionally, we examine the impact of impurity addition on turbulence and growth rates, finding that impurity presence does not significantly alter transport quantities compared to the impurity-free case. Finally, investigating helium as an alternative main ion species, we find that helium plasmas exhibit higher linear growth rates but result in lower transport saturation levels than deuterium plasmas, suggesting potential confinement benefits. These findings provide quantitative insights into the temperature ratio dependence in QH-mode plasmas and highlight the role of temperature profiles and zonal flows in influencing plasma confinement.

</details>


### [32] [Numerical investigation of kinetic instabilities in BGK equilibria under collisional effects](https://arxiv.org/abs/2512.11478)
*Sofia Zanelli,Gabriele Celebre,Sergio Servidio,Francesco Valentini*

Main category: physics.plasm-ph

TL;DR: Numerical study of unstable BGK modes shows electron acoustic wave instability triggered by density noise, with growth rate determined by distribution function slope and onset time affected by collisions.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of unstable Bernstein-Greene-Kruskal (BGK) modes in plasma physics, particularly how electron acoustic waves become unstable and how collisions affect instability development.

Method: High-precision numerical simulations of Vlasov-Poisson system with thermalized electrons and external electric field to trigger EAWs; study instability triggered by large-scale density noise; analyze dependence on collision rates and grid resolution; use Hermite spectral analysis for saturation stage.

Result: Growth rate depends only on distribution function slope in resonant region (consistent with Landau theory); onset time delayed by collisions; collisionless simulations show power-law Hermite spectrum (constant enstrophy flux), while collisional cases show cutoff at high Hermite modes.

Conclusion: BGK mode instability follows Landau theory predictions for growth rates, but collision effects significantly delay instability onset and modify saturation dynamics, with Hermite spectrum revealing different turbulent regimes depending on collisionality.

Abstract: An unstable one-dimensional Bernstein-Greene-Kruskal (BGK) mode has been studied through high-precision numerical simulations. The initial turbulent, periodic equilibrium state is obtained by solving a Vlasov-Poisson system for initially thermalized electrons, with the addition of an external electric field able to trigger undamped, high-amplitude electron acoustic waves (EAWs). Once the external field is turned off, resonant particles are trapped in a stationary two-hole phase-space configuration. This equilibrium scenario is perturbed by some large-scale density noise, leading to an electrostatic instability with the merging of vortices into a final one-hole state. Numerical runs investigate several features of this regime, focusing on the dependence of the instability trigger time and growth rate on the rate of short-range collisions and grid resolution. According to Landau theory for weakly inhomogeneous equilibria, we observe that the growth rate of the instability depends only on the slope of the distribution function in the resonant region. Conversely, the onset time of the instability is affected by the collisional rate, which is able to postpone the onset of the instability. Moreover, by extending the simulations to a long-time scale, we investigate the saturation stage of the instability, which can be analyzed through the Hermite spectral analysis. In collisionless simulations where grid effects are negligible, the Hermite spectrum follows a power law typical of a constant enstrophy flux scenario. Otherwise, if collisional effects become significant, a cutoff is observed at high Hermite modes, leading to a decaying trend.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [33] [What is the optimal way to lie? From microscopic to kinetic descriptions of consensus control](https://arxiv.org/abs/2512.11617)
*Sasha Glendinning,Susana N. Gomes,Marie-Therese Wolfram*

Main category: math.OC

TL;DR: A framework for consensus control in opinion dynamics using a strategic liar who manipulates population opinions through calculated deception to achieve desired consensus.


<details>
  <summary>Details</summary>
Motivation: To develop a systematic approach for controlling opinion dynamics by introducing a strategic agent (liar) who can manipulate population consensus through deception, addressing how best to steer opinions toward a desired outcome while considering social constraints.

Method: Formulates the problem as an optimal control problem where a liar strategically presents 'apparent opinions' (lies) to influence the population. Analyzes various regularizations reflecting social conventions (e.g., staying close to true opinion). Uses instantaneous controls, Boltzmann-type kinetic descriptions, and analyzes resulting Boltzmann and Fokker-Planck equations with numerical simulations.

Result: Develops a mathematical framework for consensus manipulation through deception, demonstrates effects of different control strategies with various regularizations, and provides analysis and numerical results for the kinetic system equations.

Conclusion: Introduces a novel approach to opinion dynamics control using strategic deception, providing both theoretical analysis and computational methods for understanding how a liar can optimally manipulate population consensus while respecting social constraints.

Abstract: We establish an approach for consensus control of opinion dynamics by introducing a liar to the classical system. The liar's aim is to steer the population towards consensus at their goal opinion by showing 'apparent opinions', or 'lies', to members of the population. We analyse this as an optimal control problem for how best to lie to a population in order to guarantee the consensus that the liar desires. We consider a range of regularisations, each motivated by some social convention, such as the liar wanting to present an opinion close to their true opinion. For each regularisation, we demonstrate the effect of instantaneous controls. Furthermore, we introduce a Boltzmann-type description for the corresponding kinetic system and present analysis and numerical results for the resulting Boltzmann and Fokker-Planck equations.

</details>


<div id='math.MG'></div>

# math.MG [[Back]](#toc)

### [34] [The distance to the boundary with respect to the Minkowski functional of a polytope](https://arxiv.org/abs/2512.10013)
*Mohammad Safdari*

Main category: math.MG

TL;DR: Analysis of distance function regularity using Minkowski functional of convex polytopes, with explicit computations and observed new phenomena.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity properties of distance functions defined using Minkowski functionals of convex polytopes, which generalize Euclidean distance and have applications in geometry and analysis.

Method: Study the distance function to domain boundaries using Minkowski functional of convex polytopes, analyze regularity in specific cases, and perform explicit computations on examples.

Result: Obtained regularity results for the distance function in certain cases, computed explicit distance functions in examples, and observed new interesting phenomena specific to these distance functions.

Conclusion: Minkowski functionals of convex polytopes yield distance functions with distinct regularity properties and interesting phenomena compared to Euclidean distance, warranting further investigation.

Abstract: We study the regularity of the distance function to the boundary of a domain in $\mathbb{R}^n$, with respect to the Minkowski functional of a convex polytope. We obtain the regularity of the distance function in certain cases. We also explicitly compute the distance function in a collection of examples and observe the new interesting phenomena that arise for such distance functions.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [35] [Temporal Substepping Scheme for Magnetohydrodynamics with Cell-based Adaptive Mesh Refinement on Staggered Grid](https://arxiv.org/abs/2512.11365)
*Ilja Honkonen,Riku Jarvinen,David Phillips*

Main category: physics.space-ph

TL;DR: New constrained transport algorithm for MHD on staggered meshes that preserves ∇·B=0, supports AMR and temporal substepping without interpolation between refinement levels.


<details>
  <summary>Details</summary>
Motivation: Need for robust numerical MHD methods that maintain the divergence-free constraint on magnetic fields while supporting adaptive mesh refinement and efficient time integration without complex interpolation between refinement levels.

Method: Constrained transport method on staggered meshes, handling resolution changes directly on logically Cartesian grids without interpolation or projection between nested/neighboring grids, and without coupling solutions between refinement levels.

Result: Algorithm preserves ∇·B=0 exactly, supports both cell-based adaptive mesh refinement and temporal substepping, and avoids the computational overhead of interpolation between refinement levels.

Conclusion: The method provides an efficient and accurate approach for MHD simulations with AMR, maintaining the divergence-free constraint while simplifying the handling of resolution changes.

Abstract: We present a new algorithm for numerical magnetohydrodynamics on staggered meshes preserving $\nabla \cdot B = 0$. Our algorithm is based on the constrained transport method and supports both cell-based adaptive mesh refinement and temporal substepping. We handle resolution changes directly on the logically Cartesian grid without needing interpolation or projection between nested or neighboring grids, nor coupling the solution between refinement levels.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [36] [Uplink Rate Maximization for Pinching Antenna- Assisted Covert Backscatter Communication](https://arxiv.org/abs/2512.10970)
*Yulei Wang,Yalin Liu,Yaru Fu,Yuanwei Liu*

Main category: eess.SP

TL;DR: PA-assisted backscatter communication improves covertness and mitigates double near-far problem by optimizing antenna positioning and transmit power.


<details>
  <summary>Details</summary>
Motivation: Pinching antenna technology enables flexible positioning for LoS links, offering potential for ambient signal-based backscatter communication. Need to enhance communication and covertness against randomly distributed eavesdroppers while addressing the double near-far problem where energy harvesting and backscatter transmission degrade simultaneously due to distance disparities.

Method: Formulated optimization problem to maximize uplink covert transmission rate by jointly optimizing transmit power and antenna positions while satisfying communication reliability and covertness constraints. Proposed an alternative optimization (AO)-based framework to solve this problem.

Result: Numerical results show PA-BSC effectively mitigates double near-far problem, improving downlink energy harvesting and uplink data transmission while maintaining covertness performance under practical deployment scenarios.

Conclusion: PA-assisted BSC provides enhanced communication and covertness by optimizing antenna positioning and power allocation, offering practical solution for secure backscatter communication systems.

Abstract: The emerging pinching antenna (PA) technology enables flexible antenna positioning for creating line-of-sight (LoS) links, thus offering substantial potential to facilitate ambient signal-based backscatter communication (BSC). This paper investigates PA-assisted BSC for enhanced communication and covertness in the presence of a randomly distributed eavesdropper. An optimization problem is formulated to maximize the uplink covert transmission rate by jointly optimizing the transmit power and antenna positions while satisfying both communication reliability and covertness constraints. An alternative optimization (AO)-based framework is proposed to solve this problem. Numerical results demonstrate that the proposed PA-BSC effectively mitigates the double near-far problem, where energy harvesting and backscatter transmission degrade simultaneously due to distance disparities, thereby improving downlink energy harvesting and uplink data transmission while maintaining covertness performance under practical deployment scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Parametric Numerical Integration with (Differential) Machine Learning](https://arxiv.org/abs/2512.11530)
*Álvaro Leitao,Jonatan Ráfales*

Main category: cs.LG

TL;DR: Differential machine learning approach for parametric integrals outperforms standard methods across multiple problem classes including statistical functionals, Chebyshev expansions, and differential equation integrals.


<details>
  <summary>Details</summary>
Motivation: To develop more effective machine learning methods for solving parametric integrals by incorporating derivative information during training, addressing limitations of classical approaches.

Method: Differential learning framework that incorporates derivative information during training, applied to three problem classes: statistical functionals (moments, CDFs), Chebyshev expansions for function approximation, and integrals from differential equations.

Result: Differential machine learning consistently outperforms standard architectures with lower mean squared error, enhanced scalability, and improved sample efficiency across all tested cases from smooth benchmarks to challenging numerical integrals.

Conclusion: Differential machine learning is a superior approach for parametric integrals, offering significant performance advantages over traditional methods across diverse application domains.

Abstract: In this work, we introduce a machine/deep learning methodology to solve parametric integrals. Besides classical machine learning approaches, we consider a differential learning framework that incorporates derivative information during training, emphasizing its advantageous properties. Our study covers three representative problem classes: statistical functionals (including moments and cumulative distribution functions), approximation of functions via Chebyshev expansions, and integrals arising directly from differential equations. These examples range from smooth closed-form benchmarks to challenging numerical integrals. Across all cases, the differential machine learning-based approach consistently outperforms standard architectures, achieving lower mean squared error, enhanced scalability, and improved sample efficiency.

</details>


### [38] [Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration](https://arxiv.org/abs/2512.11587)
*Alexander Tyurin*

Main category: cs.LG

TL;DR: GD for neural networks reduces to generalized perceptron algorithms, revealing implicit acceleration: nonlinear models achieve $\tilde{O}(\sqrt{d})$ complexity vs linear models' $Ω(d)$.


<details>
  <summary>Details</summary>
Motivation: Understanding optimization dynamics of gradient descent in neural networks is challenging, especially regarding convergence rates, trajectories, oscillations, and implicit acceleration phenomena.

Method: Analyze nonlinear models with logistic loss, showing GD reduces to generalized perceptron algorithms. Use classical linear algebra tools to analyze simplified algorithmic steps on minimalistic examples.

Result: Nonlinear two-layer models provably achieve $\tilde{O}(\sqrt{d})$ iteration complexity compared to $Ω(d)$ for linear models, explaining implicit acceleration. Results supported by extensive numerical experiments.

Conclusion: The reduction to perceptron algorithms provides a new perspective on neural network optimization dynamics and helps explain implicit acceleration, advancing research in this area.

Abstract: Even for the gradient descent (GD) method applied to neural network training, understanding its optimization dynamics, including convergence rate, iterate trajectories, function value oscillations, and especially its implicit acceleration, remains a challenging problem. We analyze nonlinear models with the logistic loss and show that the steps of GD reduce to those of generalized perceptron algorithms (Rosenblatt, 1958), providing a new perspective on the dynamics. This reduction yields significantly simpler algorithmic steps, which we analyze using classical linear algebra tools. Using these tools, we demonstrate on a minimalistic example that the nonlinearity in a two-layer model can provably yield a faster iteration complexity $\tilde{O}(\sqrt{d})$ compared to $Ω(d)$ achieved by linear models, where $d$ is the number of features. This helps explain the optimization dynamics and the implicit acceleration phenomenon observed in neural networks. The theoretical results are supported by extensive numerical experiments. We believe that this alternative view will further advance research on the optimization of neural networks.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [39] [Data-Driven Model Reduction using WeldNet: Windowed Encoders for Learning Dynamics](https://arxiv.org/abs/2512.11090)
*Biraj Dahal,Jiahui Cheng,Hao Liu,Rongjie Lai,Wenjing Liao*

Main category: stat.ML

TL;DR: WeldNet: A windowed autoencoder framework for nonlinear model reduction of complex time-dependent systems, breaking long-horizon dynamics into manageable segments with transcoders for consistency.


<details>
  <summary>Details</summary>
Motivation: Many scientific and engineering problems involve costly simulations of time-dependent, high-dimensional datasets from complex physical processes. There's a need for efficient data-driven surrogate models to reduce computational costs while capturing nonlinear dynamics.

Method: Windowed Encoders for Learning Dynamics (WeldNet) splits time domain into overlapping windows, uses autoencoders for nonlinear dimension reduction within each window, trains propagator networks for latent code evolution, and uses transcoders to connect latent codes between adjacent windows.

Result: WeldNet successfully captures nonlinear latent structures and underlying dynamics in various differential equations, outperforming both traditional projection-based approaches and recently developed nonlinear model reduction methods.

Conclusion: The windowed decomposition simplifies propagator training by breaking long-horizon dynamics into manageable segments, while transcoders ensure consistency across windows. Mathematical theory establishes representation power under manifold hypothesis, justifying deep autoencoder-based nonlinear model reduction.

Abstract: Many problems in science and engineering involve time-dependent, high dimensional datasets arising from complex physical processes, which are costly to simulate. In this work, we propose WeldNet: Windowed Encoders for Learning Dynamics, a data-driven nonlinear model reduction framework to build a low-dimensional surrogate model for complex evolution systems. Given time-dependent training data, we split the time domain into multiple overlapping windows, within which nonlinear dimension reduction is performed by auto-encoders to capture latent codes. Once a low-dimensional representation of the data is learned, a propagator network is trained to capture the evolution of the latent codes in each window, and a transcoder is trained to connect the latent codes between adjacent windows. The proposed windowed decomposition significantly simplifies propagator training by breaking long-horizon dynamics into multiple short, manageable segments, while the transcoders ensure consistency across windows. In addition to the algorithmic framework, we develop a mathematical theory establishing the representation power of WeldNet under the manifold hypothesis, justifying the success of nonlinear model reduction via deep autoencoder-based architectures. Our numerical experiments on various differential equations indicate that WeldNet can capture nonlinear latent structures and their underlying dynamics, outperforming both traditional projection-based approaches and recently developed nonlinear model reduction methods.

</details>


<div id='hep-ex'></div>

# hep-ex [[Back]](#toc)

### [40] [Molecular Dynamics Simulations of Bubble Nucleation in a Liquid-Noble Scintillator](https://arxiv.org/abs/2512.11257)
*Jack Walker,Emma Wallace,Ken Clark,Greg van Anders,Alex Wright*

Main category: hep-ex

TL;DR: Simulations show scintillation in liquid argon bubble chambers increases bubble formation energy threshold by factor of 2.16, as excited molecular states with long lifetimes don't contribute to nucleation.


<details>
  <summary>Details</summary>
Motivation: Existing bubble chamber simulations don't account for scintillation effects (photon creation, ionization, atomic de-excitation) which are crucial for accurate threshold predictions in WIMP detection experiments.

Method: Used HOOMD-blue molecular dynamics framework to simulate bubble formation in liquid argon including photon creation, ionization, and direct nuclear recoils, comparing thresholds with and without scintillation effects.

Result: Scintillation raises average energy required for bubble formation by factor of 2.16; excited molecular states with lifetimes longer than ~250ps don't contribute significantly to bubble nucleation.

Conclusion: Scintillation effects significantly impact bubble chamber thresholds for WIMP detection, and energy stored in long-lived excited states doesn't contribute to bubble formation, requiring higher energy deposits for nucleation.

Abstract: The Scintillating Bubble Chamber collaboration is searching for Weakly Interacting Massive Particles using a novel bubble chamber with intended thresholds as low as 100eV. Existing molecular dynamics simulations of bubble formation in bubble chambers were conducted with non-scintillating target materials and therefore do not account for the energy transfer to photons or time-delayed releases that occur in atomic de-excitation. In this study, we use the HOOMD-blue molecular dynamics framework to simulate bubble formation in liquid argon, including photon creation, ionization, and direct nuclear recoils. A multi-stage bubble growth process similar to that reported in the literature was observed. When comparing simulated thresholds with and without scintillation effects, we found that scintillation raises the average energy required to form a bubble by a factor of 2.16. This is larger than the fraction of energy lost to photon creation, and demonstrates that energy stored in excited molecular states with lifetimes longer than the rapid growth phase of nucleation (~250 ps) does not contribute significantly to bubble formation. This conclusion was further supported by simulations showing increased bubble nucleation thresholds when the excited molecular state lifetimes were increased, even under identical thermodynamic conditions.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [41] [UK White Paper on Magnetic Reconnection](https://arxiv.org/abs/2512.11631)
*Alexander J. B. Russell,James A. McLaughlin,Philippa Browning,Jennifer Carter,Luca Franci,Heli Hietala,Andrew Hillier,Gunnar Hornig,David MacTaggart,Sarah Matthews,James McKevitt,Eric Priest,Jack Reid,Ben Snow,Julia Stawarz,Anthony Yeates,Jeffersson Andres Agudelo Rueda,William Bate,Giulio Del Zanna,Jonathan Eastwood,Lucie Green,Anshu Kumari,Mike Lockwood,Thomas Neukirch,David Pontin,Andy Smith,Maria-Theresia Walach,Peter Wyper*

Main category: astro-ph.IM

TL;DR: UK white paper outlining priority science objectives and recommendations for magnetic reconnection research over the next decade to maintain UK's world-class position in this field.


<details>
  <summary>Details</summary>
Motivation: Magnetic reconnection is a universal plasma process critical to understanding solar phenomena, space weather, and planetary magnetospheres. It underpins multiple future space mission science objectives, and the UK currently has a leading international role in this field through measurements, observations, and simulations.

Method: White paper analysis identifying nine priority science objectives for reconnection research, providing recommendations for theory/simulation investments and infrastructure, and outlining mission priorities with required measurements.

Result: Identified nine key science objectives for the next decade, developed investment guidance for theory/simulations/infrastructure, and established mission priorities with specific measurement requirements to maintain UK's world-class status.

Conclusion: Strategic planning through this white paper will ensure the UK maintains and enhances its leading international position in magnetic reconnection research, supporting future space missions and advancing understanding of this fundamental plasma process throughout the Heliosphere.

Abstract: Magnetic reconnection powers explosive releases of magnetic energy, heating and particle acceleration throughout the plasma universe. Knowledge of this universal process is vital to understanding the Heliosphere, as it plays a key role in solar flares, coronal mass ejections, coronal heating, solar wind acceleration, geomagnetic storms, and interactions between the solar wind and planetary magnetospheres. As such, reconnection underpins multiple science objectives of multiple future space missions. The UK plays a leading role in this international field, through a combination of in situ measurements from Earth's magnetosphere and the solar wind, observations of the solar corona and chromosphere, and world-class numerical simulations and theory. This white paper identifies: Nine priority science objectives for reconnection research in the next decade; Recommendations to guide investment in theory, simulations and infrastructure; Mission priorities and required measurements to ensure the UK maintains and improves its world-class credentials in reconnection science.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [42] [Defect-Engineered Multifunctionality in Cu-Doped Bi2Te2: Interplay of Thermoelectric, Piezoelectric, and Optoelectronic Properties from First-Principles Insights](https://arxiv.org/abs/2512.11347)
*Muhammad Usman Javed,Sikander Azam,Qaiser Rafiq,Hamdy Khamees Thabet*

Main category: cond-mat.mtrl-sci

TL;DR: Cu doping in Bi₂Te₃ enhances thermoelectric, piezoelectric, and optical properties through structural stabilization, increased carrier concentration, and symmetry breaking.


<details>
  <summary>Details</summary>
Motivation: To improve the coupled charge, spin, and lattice behavior of thermoelectric topological insulators through defect engineering, specifically by studying how Cu doping affects Bi₂Te₃'s multifunctional properties for hybrid energy harvesting applications.

Method: Used density functional theory with spin orbit coupling to analyze structural, electronic, optical, thermoelectric, piezoelectric, and charge density features of both pristine and Cu-doped Bi₂Te₃ systems.

Result: Cu doping expands lattice, stabilizes structure, creates sharp states near Fermi level, increases Seebeck coefficient from 180 to 220 μV/K at 300K, maintains electrical conductivity, enhances piezoelectric coefficient (e₃₃ increases from 0.19 to 0.51 C/m²), and shows strong low-energy optical absorption with large dielectric constants (>600).

Conclusion: Cu doping transforms Bi₂Te₃ into a multifunctional material with coupled thermoelectric, piezoelectric, and optical responses suitable for hybrid energy harvesting, infrared detection, and spin-based devices.

Abstract: Defect engineering can improve the linked charge, spin, and lattice behavior of thermoelectric topological insulators. Using density functional theory with spin orbit coupling, we study structural, electronic, optical, thermoelectric, piezoelectric, and charge density features of pristine and Cu doped Bi2Te3. Cu substitution slightly expands the lattice and lowers the total energy minimum, which stabilizes the structure. The density of states shows that Cu d and Te p hybridization creates sharp states near the Fermi level, raising the carrier concentration and supporting higher Seebeck coefficient and power factor. Transport calculations show an increase in the Seebeck coefficient from about 180 microvolts per kelvin in pristine Bi2Te3 to about 220 microvolts per kelvin at 300 K while keeping the electrical conductivity nearly unchanged. Optical spectra reveal strong low energy absorption and very large static dielectric constants (greater than 600), indicating tunable light matter coupling. The piezoelectric coefficient e33 rises from 0.19 C/m2 in pristine Bi2Te3 to 0.38 C/m2 at 5 percent Cu and 0.51 C/m2 at 10 percent Cu, reflecting symmetry breaking and strain driven polarization. Charge density difference maps show anisotropic redistribution, with Cu donating about 0.8 electrons mainly to Te sites, which enhances p type behavior and phonon scattering. Overall, Cu doping reshapes Bi2Te3 into a multifunctional material with coupled thermoelectric, piezoelectric, and optical responses suitable for hybrid energy harvesting, infrared detection, and spin based devices.

</details>
