<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 18]
- [math.AP](#math.AP) [Total: 38]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [math.NT](#math.NT) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [astro-ph.GA](#astro-ph.GA) [Total: 1]
- [math.OC](#math.OC) [Total: 3]
- [math.CA](#math.CA) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [math.PR](#math.PR) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 2]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 5]
- [math.FA](#math.FA) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Discrete-to-continuum convergence of the density of states for Mathieu's equation](https://arxiv.org/abs/2512.12039)
*Peter Hofhansel,Alexander B. Watson*

Main category: math.NA

TL;DR: Convergence of density of states from discrete tight-binding model to continuum Mathieu-type equation for slowly-varying periodic potentials


<details>
  <summary>Details</summary>
Motivation: To establish rigorous connection between discrete quantum models (tight-binding) and their continuum approximations, showing that fundamental spectral properties converge in the appropriate limit

Method: Analyze density of states for self-adjoint operators in tight-binding models with slowly-varying periodic potentials, prove convergence to continuum Mathieu-type equation using mathematical analysis techniques

Result: Proved convergence of density of states from discrete tight-binding model to its continuum approximation, establishing rigorous connection between discrete and continuous quantum systems

Conclusion: The density of states for tight-binding models with slowly-varying periodic potentials converges to that of continuum Mathieu-type equations, validating continuum approximations for such quantum systems

Abstract: The density of states of a self-adjoint operator generalizes the eigenvalue distribution of a Hermitian matrix. We prove convergence of the density of states for a tight-binding model with a slowly-varying periodic potential to the density of states of its continuum approximation, a Mathieu-type equation.

</details>


### [2] [An unfitted divergence-free higher order finite element method for the Stokes problem](https://arxiv.org/abs/2512.12050)
*Michael Neilan,Maxim Olshanskii,Henry von Wahl*

Main category: math.NA

TL;DR: Higher-order unfitted finite element method for Stokes equations producing strongly divergence-free velocity fields using isoparametric Scott-Vogelius elements with stabilized Nitsche/Lagrange multiplier formulation.


<details>
  <summary>Details</summary>
Motivation: To develop a method that yields strongly divergence-free velocity fields up to physical boundaries while handling complex geometries through unfitted meshes, addressing the loss of pressure robustness typically associated with weak boundary condition enforcement.

Method: Combines isoparametric Scott-Vogelius velocity-pressure pair on cut background mesh with stabilized Nitsche/Lagrange multiplier formulation for Dirichlet boundary conditions. Uses higher-order Lagrange multiplier space for stability and pressure robustness.

Result: Provides complete stability and convergence theory in 2D with optimal-order velocity convergence in H¬π and L¬≤ norms, optimal H¬π-convergence and nearly optimal L¬≤-convergence for post-processed pressure. Numerical experiments confirm theoretical findings.

Conclusion: The method successfully achieves strongly divergence-free velocity fields on unfitted meshes with robust implementation, overcoming geometric approximation errors and maintaining pressure robustness through careful formulation and analysis.

Abstract: The paper develops and analyzes a higher-order unfitted finite element method for the incompressible Stokes equations, which yields a strongly divergence-free velocity field up to the physical boundary. The method combines an isoparametric Scott--Vogelius velocity-pressure pair on a cut background mesh with a stabilized Nitsche/Lagrange multiplier formulation for imposing Dirichlet boundary conditions. We construct finite element spaces that admit robust numerical implementation using standard elementwise polynomial mappings and produce exactly divergence-free discrete velocities. The key components of the analysis are a new inf-sup stability result for the isoparametric Scott--Vogelius pair on unfitted meshes and a combined inf-sup stability result for the bilinear forms associated with the pressure and the Lagrange multiplier. The finite element formulation employs a higher-order Lagrange multiplier space, which ensures stability and mitigates the loss of pressure robustness typically associated with the weak enforcement of boundary conditions for the normal velocity component.
  The paper provides a complete stability and convergence theory in two dimensions, accounting for the geometric errors introduced by the isoparametric approximation. The analysis demonstrates optimal-order velocity convergence in both the $H^1$ and $L^2$ norms and establishes optimal $H^1$-convergence and nearly optimal $L^2$-convergence of a post-processed pressure. Numerical experiments illustrate and confirm the theoretical findings.

</details>


### [3] [Numerical Simulation of Beam Network Models](https://arxiv.org/abs/2512.12062)
*Morgan G√∂rtz,Moritz Hauck,Axel M√•lqvist,Andreas Rupp,Lucia Swoboda*

Main category: math.NA

TL;DR: Two-level additive domain decomposition method for efficient simulation of beam network materials, with applications to stationary elasticity and time-dependent wave propagation problems.


<details>
  <summary>Details</summary>
Motivation: Network models efficiently represent materials with complex 1D structures (fibers, porous media, vascular networks) but require efficient solvers for large linear systems in both stationary and time-dependent formulations.

Method: Proposes a two-level additive domain decomposition method to solve linear systems from stationary elastic deformation and time-dependent wave propagation (via implicit time discretization) in beam networks.

Result: Rigorous convergence analysis shows method's convergence rate depends on network connectivity and heterogeneity. Numerical simulations on commercial paperboard demonstrate efficiency and robustness.

Conclusion: The domain decomposition method provides an efficient, robust solver for network material simulations, enabling accurate mechanical property prediction with reduced computational cost compared to full 3D resolution.

Abstract: Network models are used as efficient representation of materials with complex, interconnected locally one-dimensional structures. They typically accurately capture the mechanical properties of a material, while substantially reducing computational cost by avoiding full three-dimensional resolution. Applications include the simulation of fiber-based materials, porous media, and biological systems such as vascular networks. This article focuses on two representative problems: a stationary formulation describing the elastic deformation of beam networks, and a time-dependent formulation modeling elastic wave propagation in such materials. We propose a two-level additive domain decomposition method to efficiently solve the linear system associated with the stationary problem, as well as the linear systems that arise at each time step of the time-dependent problem through implicit time discretization. We present a rigorous convergence analysis of the domain decomposition method when used as a preconditioner, quantifying the convergence rate with respect to network connectivity and heterogeneity. The efficiency and robustness of the proposed approach are demonstrated through numerical simulations of the mechanical properties of commercial-grade paperboard.

</details>


### [4] [An explicit integrator uniform in the true anomaly and exactly preserving all integrals of motion in the three-dimensional Kepler problem](https://arxiv.org/abs/2512.12099)
*Jan L. Cie≈õli≈Ñski,Maciej Jurgielewicz*

Main category: math.NA

TL;DR: A numerical scheme for Kepler problem that exactly preserves all first integrals (angular momentum, energy, Laplace-Runge-Lenz vector), eliminating spurious precession through adaptive time stepping based on constant angular increments.


<details>
  <summary>Details</summary>
Motivation: Standard numerical methods for the Kepler problem often produce spurious precession in orbital trajectories over long times, failing to preserve the exact shape and orientation of orbits. This paper aims to develop a scheme that maintains all conserved quantities exactly.

Method: The scheme uses an adaptive time step derived from a constant angular increment, ensuring exact preservation of angular momentum, total energy, and the Laplace-Runge-Lenz vector. This approach maintains orbital geometry precisely.

Result: The algorithm demonstrates high accuracy and long-term stability in numerical experiments, with orbital trajectories retaining their precise shape and orientation without spurious precession.

Conclusion: The developed numerical scheme successfully preserves all first integrals of the Kepler problem exactly, providing a stable and accurate method for long-term orbital simulations without the artifacts common in standard approaches.

Abstract: We develop a numerical scheme for the Kepler problem that preserves exactly all first integrals: angular momentum, total energy, and the Laplace-Runge-Lenz vector. This property ensures that orbital trajectories retain their precise shape and orientation over long times, avoiding the spurious precession typical of many standard methods. The scheme uses an adaptive time step derived from a constant angular increment. Analytical considerations and numerical experiments demonstrate that the algorithm combines high accuracy with long-term stability.

</details>


### [5] [$C^1$-$Q_k$ serendipity finite elements on rectangular meshes](https://arxiv.org/abs/2512.12144)
*Shangyou Zhang*

Main category: math.NA

TL;DR: A new C¬π-Q‚Çñ serendipity finite element is developed as a minimal Q‚Çñ-bubble enriched P‚Çñ element that maintains C¬π continuity and includes all P‚Çñ polynomials.


<details>
  <summary>Details</summary>
Motivation: To create more efficient C¬π-continuous finite elements by developing serendipity versions that reduce the number of degrees of freedom while maintaining accuracy and polynomial completeness.

Method: Develop C¬π-Q‚Çñ serendipity elements as sub-elements of C¬π-Q‚Çñ BFS elements. For k=4,5: enrich P‚ÇÑ/P‚ÇÖ with 9/11 Q‚Çñ bubble functions. For k‚â•6: enrich P‚Çñ with exactly 12 Q‚Çñ bubble functions. Prove uni-solvence and quasi-optimality.

Result: Successfully defined C¬π-Q‚Çñ serendipity elements for k‚â•4 with proven uni-solvence and quasi-optimality. Numerical experiments conducted for k=4 to 8 demonstrate practical performance.

Conclusion: The new C¬π-Q‚Çñ serendipity elements provide efficient C¬π-continuous finite elements with reduced degrees of freedom while maintaining polynomial completeness and optimal approximation properties.

Abstract: A $C^1$-$Q_k$ serendipity finite element is a sub-element of $C^1$-$Q_k$ BFS finite element such that the element remains $C^1$-continuous and includes all $P_k$ polynomials. In other words, it is a minimum of $Q_k$ bubbles enriched $P_k$ finite element. We enrich the $P_4$ and $P_5$ spaces by $9$ $Q_4$ and $11$ $Q_5$-bubble functions, respectively. For all $k\ge 6$, we enrich the $P_k$ spaces exactly by $12$ $Q_k$ bubble functions. We show the uni-solvence and quasi-optimality of the newly defined $C^1$-$Q_k$ serendipity elements. Numerical experiments by the $C^1$-$Q_k$ serendipity elements, $4\le k\le 8$, are performed.

</details>


### [6] [Rectangular $C^1$-$P_k$ finite elements with $Q_k$-bubble enrichment](https://arxiv.org/abs/2512.12152)
*Shangyou Zhang*

Main category: math.NA

TL;DR: A family of C¬π-Pk (k‚â•4) finite elements on rectangular meshes is constructed by enriching Pk polynomial space with Qk bubble functions, achieving quasi-optimal convergence.


<details>
  <summary>Details</summary>
Motivation: To develop C¬π-continuous finite elements on rectangular meshes for higher-order polynomial spaces (k‚â•4) that maintain optimal convergence properties.

Method: Enrich Pk polynomial space with Qk bubble functions (5 for k=4, 7 for k=5, 8 for k‚â•6) to create C¬π-Pk finite elements, prove uni-solvency and C¬π-continuity.

Result: Successfully constructed C¬π-Pk finite elements for k=4,5,6,7,8 with proven uni-solvency, C¬π-continuity, and quasi-optimal convergence properties.

Conclusion: The new C¬π-Pk elements provide effective higher-order finite elements with C¬π continuity on rectangular meshes, validated through numerical tests.

Abstract: We enrich the $P_k$ polynomial space by $5$ ($k=4$), or $7$ ($k=5$), or 8 (all $k\ge 6$) $Q_k$ bubble functions to obtain a family of $C^1$-$P_k$ ($k\ge 4$) finite elements on rectangular meshes. We show the uni-solvency, the $C^1$-continuity and the quasi-optimal convergence. Numerical tests on the new $C^1$-$P_k$, $k=4,5,6,7$ and $8$, elements are performed.

</details>


### [7] [Local discontinuous Galerkin method for the integral fractional Laplacian](https://arxiv.org/abs/2512.12200)
*Rubing Han,Shuonan Wu,Hao Zhou*

Main category: math.NA

TL;DR: LDG method for fractional Laplacian on bounded domains using mixed formulation with primal variable, gradient, and Riesz potential, with analysis of regularity and optimal error estimates.


<details>
  <summary>Details</summary>
Motivation: To develop an effective numerical method for solving integral fractional Laplacian problems on bounded Lipschitz domains, addressing the challenges of nonlocal interactions and boundary singularities.

Method: Local discontinuous Galerkin (LDG) method based on three-field mixed formulation (primal variable, gradient, Riesz potential). Analysis includes weighted H√∂lder/Sobolev regularity study of Riesz potential. LDG schemes on quasi-uniform and graded meshes with stabilization for graded case.

Result: Established optimal a priori error estimates. Numerical experiments confirm theoretical results.

Conclusion: The LDG method successfully handles fractional Laplacian problems with proper treatment of boundary singularities through rigorous regularity analysis and appropriate mesh strategies.

Abstract: We develop and analyze a local discontinuous Galerkin (LDG) method for solving integral fractional Laplacian problems on bounded Lipschitz domains. The method is based on a three-field mixed formulation involving the primal variable, its gradient, and the corresponding Riesz potential, yielding a flux-based structure well suited for LDG discretizations while retaining the intrinsic nonlocal interaction. A key ingredient of our analysis is a rigorous study of the weighted H√∂lder and Sobolev regularity of the Riesz potential, which enables accurate characterization of boundary singularities. Guided by these regularity results, we propose LDG schemes on quasi-uniform and graded meshes, with additional stabilization in the graded case to reconcile the discrepancy between the discrete spaces for the Riesz potential and flux fields. Optimal a priori error estimates are established, and numerical experiments corroborate the theoretical results.

</details>


### [8] [A boundary integral equation method for wave scattering in periodic structures via the Floquet-Bloch transform](https://arxiv.org/abs/2512.12414)
*Wangtao Lu,Kuanrong Shen,Ruming Zhang*

Main category: math.NA

TL;DR: A boundary integral equation method using periodic Green's functions for acoustic wave scattering in locally perturbed periodic structures, with efficient algorithms for computing background Green's functions and spectrally accurate quadrature.


<details>
  <summary>Details</summary>
Motivation: The paper addresses acoustic wave scattering in locally perturbed periodic structures where the total wavefield is non-quasi-periodic, requiring effective truncation techniques for high-accuracy numerical solvers since traditional methods struggle with non-quasi-periodic wavefields.

Method: Uses Green's function for background periodic structure to construct boundary integral equation on artificial curve enclosing perturbation as transparent boundary condition; develops efficient algorithms based on Floquet-Bloch transform to compute background Green's functions; implements spectrally accurate quadrature rules for BIE discretization; creates leap and pullback procedures to compute total wavefield throughout structure.

Result: Numerical experiments demonstrate efficiency and accuracy of new solver; method for non-quasi-periodic problem achieves time complexity comparable to single quasi-periodic problem, showing significant computational advantage.

Conclusion: The developed boundary integral equation approach with transparent boundary conditions provides an efficient and accurate solver for acoustic wave scattering in locally perturbed periodic structures, achieving computational performance comparable to simpler quasi-periodic problems while handling more complex non-quasi-periodic wavefields.

Abstract: This paper is concerned with the problem of an acoustic wave scattering in a locally perturbed periodic structure. As the total wavefield is non-quasi-periodic, effective truncation techniques are pursued for high-accuracy numerical solvers. We adopt the Green's function for the background periodic structure to construct a boundary integral equation (BIE) on an artificial curve enclosing the perturbation. It serves as a transparent boundary condition (TBC) to truncate the unbounded domain. We develop efficient algorithms to compute such background Green's functions based on the Floquet-Bloch transform and its inverse. Spectrally accurate quadrature rules are developed to discretize the BIE-based TBC. Effective algorithms based on leap and pullback procedures are further developed to compute the total wavefield everywhere in the structure. A number of numerical experiments are carried out to illustrate the efficiency and accuracy of the new solver. They exhibit that our method for the non-quasi-periodic problem has a time complexity that is even comparable to that of a single quasi-periodic problem.

</details>


### [9] [Hierarchical Coarse Basis by Randomised SVD: the Helmholtz Problem](https://arxiv.org/abs/2512.12538)
*Martin J. Gander,Yao-Lin Jiang,Hui Zhang*

Main category: math.NA

TL;DR: New Schwarz method with hierarchical coarse correction for Helmholtz problems reduces coarse problem size using randomized SVD and hierarchical domain decomposition.


<details>
  <summary>Details</summary>
Motivation: Oscillatory waves require high degrees of freedom, making coarse problems in Schwarz methods too large and computationally expensive.

Method: Combines randomized SVD of interface iteration with hierarchical domain decomposition to create a hierarchical coarse problem that can be solved decoupled at each level.

Result: The proposed method creates a hierarchical coarse problem that can be solved efficiently in a decoupled manner at each hierarchical level.

Conclusion: New Schwarz method with hierarchical coarse correction effectively addresses the coarse problem size issue for Helmholtz problems while maintaining computational efficiency.

Abstract: The oscillatory waves require sufficient degrees of freedom to resolve. That restriction usually applies also to coarse problems for Schwarz methods. The resulting coarse problem is then too large. To address the issue, a new form of Schwarz methods with coarse correction is proposed for the Helmholtz problem. There are two components in the proposed form: randomised SVD of interface iteration, and hierarchical domain decomposition. The resulting coarse problem is hierarchical and can be solved in a decoupled way at each level of hierarchy.

</details>


### [10] [Kernel interpolation in Sobolev spaces of hybrid regularity](https://arxiv.org/abs/2512.12684)
*M. Griebel,H. Harbrecht*

Main category: math.NA

TL;DR: Optimized sparse grids in kernel interpolation avoid logarithmic factors in dimension-dependent complexity estimates, preventing curse of dimensionality for Sobolev spaces with hybrid regularity.


<details>
  <summary>Details</summary>
Motivation: Kernel interpolation in high dimensions suffers from the curse of dimensionality, even with sparse grids that typically introduce dimension-dependent logarithmic factors in complexity estimates.

Method: Using optimized sparse grids for kernel interpolation in tensor product reproducing kernel Hilbert spaces, specifically targeting Sobolev spaces with hybrid regularity.

Result: The logarithmic factor in dimension-dependent complexity estimates can be avoided, making kernel interpolation complexity not suffer from the curse of dimensionality for these spaces.

Conclusion: Optimized sparse grids enable dimension-independent complexity for kernel interpolation in Sobolev spaces with hybrid regularity, overcoming the curse of dimensionality.

Abstract: Kernel interpolation in tensor product reproducing kernel Hilbert spaces allows for the use of sparse grids to mitigate the curse of the dimension. Typically, besides the generic constant, only a dimension dependent power of a logarithm term enters here into complexity estimates. We show that optimized sparse grids can avoid this logarithmic factor when the interpolation error is measured with respect to Sobolev spaces of hybrid regularity. Consequently, in such a situation, the complexity of kernel interpolation does not suffer from the curse of dimension.

</details>


### [11] [Newton Methods for Mean Field Games: A Numerical Study](https://arxiv.org/abs/2512.12752)
*Elisabetta Carlini,Ahmad Zorkot*

Main category: math.NA

TL;DR: The paper develops numerical discretization techniques (finite difference and semi-Lagrangian schemes) to implement infinite-dimensional Newton iterations for solving second-order Mean Field Game problems, demonstrating their effectiveness through benchmark tests.


<details>
  <summary>Details</summary>
Motivation: To develop practical computational methods for solving second-order Mean Field Game (MFG) problems using the theoretically established infinite-dimensional Newton iteration approach, which offers quadratic convergence but needs effective numerical implementation.

Method: Develops two numerical discretization schemes: 1) a finite difference scheme, and 2) a semi-Lagrangian scheme, both designed to enable computational implementation of the infinite-dimensional Newton iterations for MFG systems.

Result: The proposed methods demonstrate robustness, accuracy, and efficiency when tested on several benchmark problems. Comparative analysis shows advantages over existing approaches and highlights the potential of Newton-based solvers for MFG systems.

Conclusion: Newton-based solvers with appropriate numerical discretization (finite difference and semi-Lagrangian schemes) provide effective computational tools for solving second-order Mean Field Game problems, offering improved performance compared to existing methods.

Abstract: We address the numerical solution of second-order Mean Field Game problems through Newton iterations in infinite dimensions, introduced in [14], where quadratic convergence of the method was rigorously established. Building upon this theoretical framework, we develop new numerical discretization techniques, including both a finite difference and a semi-Lagrangian scheme, that enable an effective computational implementation of the infinite-dimensional iterations.
  The proposed methods are tested on several benchmark problems, and the resulting numerical experiments demonstrate their robustness, accuracy, and efficiency. A comparative analysis between the two schemes and existing approaches from the literature is also presented, highlighting the potential of Newton-based solvers for MFG systems.

</details>


### [12] [Fast capacity computation for maze-like configurations](https://arxiv.org/abs/2512.12836)
*Harri Hakula,Oona Rainio,Matti Vuorinen*

Main category: math.NA

TL;DR: The paper studies conformal capacity of maze-like condensers using high-order hp-FEM, comparing numerical results to quasihyperbolic length and perimeter estimates.


<details>
  <summary>Details</summary>
Motivation: Conformal capacity is difficult to compute exactly, so researchers need simpler estimates using domain functionals. The paper focuses on maze-like structures to understand how estimates perform as structural parameters vary.

Method: Uses high-order hp-finite element method to compute capacity of maze-like condensers numerically, then compares results to estimates based on quasihyperbolic length and perimeter of the compact set.

Result: Quasihyperbolic estimates demonstrate desired asymptotic properties and superior computational efficiency compared to direct numerical computation, especially as maze walls approach the compact set.

Conclusion: Quasihyperbolic estimates provide reliable and efficient alternatives to direct numerical computation of conformal capacity for maze-like structures, with good asymptotic behavior.

Abstract: We study the conformal capacity ${\rm cap}(Œ©,K)$ where $Œ©$ is a bounded domain of $\mathbb{R}^2$ and $K$ is a compact connected set in $Œ©$. Because the exact numerical value of the capacity is known only in a handful of special cases, it is important to find estimates for the capacity in terms of domain functionals, simpler than the capacity itself. Here, we study condensers of maze-like structure and compute their capacity by means of a high-order $hp$- finite element method. We compare these numerical results to the estimates given by the quasihyperbolic length and perimeter of the compact set. In particular, we consider the behaviour of these value pairs, numerical results and estimates, when the structure parameters vary and the walls of the maze approach the compact set. Over the configurations covered in the numerical experiments, the quasihyperbolic estimates are shown to have the desired asymptotic properties and superior computational efficiencies once the case-specific analysis is completed.

</details>


### [13] [Sharp convergence bounds for sums of POD and SPOD weights](https://arxiv.org/abs/2512.13068)
*Zexin Pan*

Main category: math.NA

TL;DR: The paper analyzes convergence of sums with POD weights, establishes equivalence conditions for convergence, characterizes growth rates for specific weight families, and generalizes results to SPOD weights.


<details>
  <summary>Details</summary>
Motivation: To understand the convergence behavior of sums involving product and order dependent (POD) weights, which appear in high-dimensional numerical analysis and approximation theory, particularly in quasi-Monte Carlo methods and function spaces.

Method: Mathematical analysis using combinatorial and analytic techniques to establish convergence criteria and asymptotic growth rates for sums with POD weights, then extending the analysis to smoothness-driven POD (SPOD) weights.

Result: Proved that for nonnegative sequences, the sum converges for all m>0 if and only if the sum of Œ•_j converges. For specific weights Œ≥_v=(|v|!)^œÉ‚àè_{j‚ààv}j^{-œÅ}, showed that log S_Œ≥(m) grows asymptotically as m^{1/(œÅ-œÉ)} when œÅ>œÉ.

Conclusion: The paper provides complete characterization of convergence and growth behavior for sums with POD weights, with generalizations to SPOD weights, offering theoretical foundations for applications in high-dimensional approximation and integration.

Abstract: This work analyzes the convergence of sums of the form $S_{\boldsymbolŒ≥}(m)=\sum_{v\subseteq \mathbb{N}}Œ≥_v m^{|v|}$, where $Œ≥_v$ are product and order dependent (POD) weights. We establish that for nonnegative sequence $\{Œ•_j\mid j\in \mathbb{N}\}$, $$\sum_{v\subseteq \mathbb{N}} |v|! m^{|v|}\prod_{j\in v} Œ•_j<\infty \text{ for } m>0 \text{ if and only if } \sum_{j=1}^\infty Œ•_j<\infty.$$ We further characterize the growth of $S_{\boldsymbolŒ≥}(m)$ when $Œ≥_v=(|v|!)^œÉ\prod_{j\in v}j^{-œÅ}$ and prove that $\log S_{\boldsymbolŒ≥}(m)$ exhibits asymptotic order $m^{1/(œÅ-œÉ)}$ when $œÅ>œÉ$. All results are subsequently generalized to smoothness-driven product and order dependent (SPOD) weights.

</details>


### [14] [Mathematical modelling and simulation of HIV dynamics](https://arxiv.org/abs/2512.13171)
*Abdul Rab*

Main category: math.NA

TL;DR: Analysis of HIV dynamics using ODE models with treatment effects, equilibrium analysis, and numerical simulations showing therapy impact on viral suppression.


<details>
  <summary>Details</summary>
Motivation: To understand within-host HIV dynamics and how antiretroviral therapy affects viral load and CD4+ T cell populations over time.

Method: Three-component nonlinear ODE model for healthy CD4+ T cells, infected CD4+ T cells, and free virus. Two treatment extensions: (i) separate efficacy terms for Reverse Transcriptase and Protease inhibitors, (ii) single combined efficacy parameter. Equilibrium analysis with Jacobian matrices and local stability conditions. Numerical simulations using 4th-order Runge-Kutta method.

Result: Determined equilibrium points and stability conditions for each model. Numerical simulations illustrate how therapy strength and timing affect cell populations and viral load evolution, showing potential for sustained viral suppression.

Conclusion: The study provides mathematical framework for understanding HIV dynamics under treatment, demonstrating how therapy parameters influence transient behavior and long-term viral suppression outcomes.

Abstract: We study within-host HIV dynamics using a three--component nonlinear ordinary differential equation model for healthy CD4$^{+}$ T cells, infected CD4$^{+}$ T cells, and free virus. In addition to the baseline model without treatment, we consider two treatment extensions that incorporate antiretroviral therapy: (i) separate efficacy terms for Reverse Transcriptase inhibitors and Protease inhibitors acting on infection and virus production, and (ii) a simplified formulation using a single combined efficacy parameter. For each model we determine equilibrium points and apply linearization to obtain the Jacobian matrix and local stability conditions near equilibrium. We perform numerical simulations using the classical fourth--order Runge--Kutta method to illustrate the evolution of cell populations and viral load under different therapy levels and treatment start times, including continuous treatment scenarios. The simulations highlight how therapy strength and timing shape transient behavior and can lead to sustained viral suppression.

</details>


### [15] [q-Analogue of Hamiltonian Monte Carlo method](https://arxiv.org/abs/2512.13246)
*Xiaomei Yang,Zhiliang Deng*

Main category: math.NA

TL;DR: The paper proposes q-HMC, a novel Hamiltonian Monte Carlo sampler based on q-deformed Hamiltonian dynamics from Lagrangian mechanics on q-commutative spaces, which effectively explores stiff energy landscapes and is applied to Bayesian inverse problems.


<details>
  <summary>Details</summary>
Motivation: To develop a Hamiltonian Monte Carlo sampler that can better explore stiff energy landscapes by leveraging q-deformed Hamiltonian dynamics from Wess's q-commutative spaces, addressing limitations of traditional HMC in challenging sampling scenarios.

Method: Builds upon Lagrangian mechanics on Wess's q-commutative spaces to derive q-deformed Hamiltonian dynamics, then develops a computationally tractable scheme to create the q-HMC sampler that satisfies detailed balance principle.

Result: Numerical experiments show q-HMC's efficacy in exploring distributions with explicit potential functions, particularly stiff energy landscapes. When applied to Bayesian posterior distributions of inverse problems with stiff potentials, q-HMC demonstrates advantages over traditional methods while maintaining identical computational implementation to HMC for functional reconstruction problems.

Conclusion: The proposed q-HMC method successfully extends Hamiltonian dynamics using q-deformation, providing an effective sampler for challenging distributions with stiff energy landscapes while maintaining computational tractability and detailed balance properties.

Abstract: Building upon Lagrangian mechanics on Wess's $q$-commutative spaces, we derive the $q$-deformed Hamiltonian dynamics as formulated by Lavagno et al. (2006). We then develop a computationally tractable scheme and propose a novel Hamiltonian Monte Carlo sampler ($q$-HMC). The proposed $q$-HMC method is shown to satisfy the detailed balance principle. Numerical experiments on distributions with explicit potential functions demonstrate its efficacy, particularly in exploring stiff energy landscapes. This method is also applied to draw samples from the Bayesian posterior distribution of inverse problems. The numerical test for the posterior distribution with stiff potential further shows the advantage of $q$-HMC. And it yields the identical computational implementation process to that of HMC when used to deal with functional reconstruction problems.

</details>


### [16] [A homogeneous geometry of low-rank tensors](https://arxiv.org/abs/2512.13594)
*Simon Jacobsson*

Main category: math.NA

TL;DR: Analysis of tensor sets with fixed CP, multilinear, and TT ranks, showing conditions under which they form smooth homogeneous manifolds, and deriving efficient Riemannian metrics with complete geodesics.


<details>
  <summary>Details</summary>
Motivation: To understand the geometric structure of tensor sets with fixed ranks (CP, multilinear, TT) and establish when these sets form smooth manifolds, enabling the development of efficient Riemannian optimization methods.

Method: Analyze sets of tensors with fixed CP, multilinear, and TT ranks, derive conditions for when their smooth parts form smooth homogeneous manifolds (particularly requiring sufficiently low rank for CP and TT), then use these homogeneous structures to construct Riemannian metrics.

Result: Established conditions for CP and TT rank tensor sets to be smooth homogeneous manifolds (essentially requiring sufficiently low rank), and derived Riemannian metrics with complete geodesics that are computationally efficient.

Conclusion: Tensor sets with fixed ranks can form smooth homogeneous manifolds under appropriate conditions, enabling the development of efficient Riemannian optimization algorithms with complete geodesics for tensor computations.

Abstract: We consider sets of fixed CP, multilinear, and TT rank tensors, and derive conditions for when (the smooth parts of) these sets are smooth homogeneous manifolds. For CP and TT ranks, the conditions are essentially that the rank is sufficiently low. These homogeneous structures are then used to derive Riemannian metrics whose geodesics are both complete and efficient to compute.

</details>


### [17] [Preconditioning Techniques for Hybridizable Discontinuous Galerkin Discretizations on GPU Architectures](https://arxiv.org/abs/2512.13619)
*Andrew Welter,Ngoc Cuong Nguyen*

Main category: math.NA

TL;DR: GPU-optimized iterative solvers and preconditioners for Hybridizable Discontinuous Galerkin methods, using batched dense operations to avoid sparse structures and maximize performance on NVIDIA and AMD GPUs.


<details>
  <summary>Details</summary>
Motivation: To develop scalable, high-performance iterative solvers for HDG discretizations that can efficiently leverage GPU architectures, overcoming limitations of sparse data structures and achieving high arithmetic intensity for complex PDE problems.

Method: GPU-tailored HDG implementation with parallel local element elimination, direct assembly of condensed systems on device using dense-block operations, block matrix storage, and batched iterative solver kernels. Combines Newton's method with preconditioned GMRES using block-Jacobi, additive Schwarz, and polynomial smoothers, all optimized with dense linear algebra kernels and memory-coalesced operations.

Result: Successfully implemented scalable solvers that avoid sparse data structures, increase arithmetic intensity, and sustain high memory throughput across various meshes and polynomial orders. Demonstrated comprehensive performance on multiple PDEs (Poisson, Burgers, elasticity, Euler, Navier-Stokes, RANS) using structured/unstructured meshes on NVIDIA and AMD GPUs.

Conclusion: The GPU-optimized HDG framework with batched dense operations and architecture-aware preconditioners provides scalable, high-performance solutions for complex PDE problems, effectively leveraging modern GPU architectures while maintaining algorithmic efficiency.

Abstract: We present scalable iterative solvers and preconditioning strategies for Hybridizable Discontinuous Galerkin (HDG) discretizations of partial differential equations (PDEs) on graphics processing units (GPUs). The HDG method is implemented using GPU-tailored algorithms in which local element degrees of freedom are eliminated in parallel, and the globally condensed system is assembled directly on the device using dense-block operations. The global matrix is stored in a block format that reflects the natural HDG structure, enabling all iterative solver kernels to be executed with strided batched dense matrix-vector multiplications. This implementation avoids sparse data structures, increases arithmetic intensity, and sustains high memory throughput across a range of meshes and polynomial orders. The nonlinear solver combines Newton's method with preconditioned GMRES, integrating scalable preconditioners such as block-Jacobi, additive Schwarz domain decomposition, and polynomial smoothers. All preconditioners are implemented in batched form with architecture-aware optimizations--including dense linear algebra kernels, memory-coalesced vector operations, and shared-memory acceleration--to minimize memory traffic and maximize parallel occupancy. Comprehensive studies are conducted for a variety of PDEs (including Poisson equation, Burgers equation, linear and nonlinear elasticity, Euler equations, Navier-Stokes equations, and Reynolds-Averaged Navier-Stokes equations) using structured and unstructured meshes with different element types and polynomial orders on both NVIDIA and AMD GPU architectures.

</details>


### [18] [Torus Time-Spectral Method for Quasi-Periodic Problems](https://arxiv.org/abs/2512.13631)
*Sicheng He,Hang Li,Kivanc Ekici*

Main category: math.NA

TL;DR: A torus time-spectral method for analyzing quasi-periodic systems with multiple incommensurate frequencies, overcoming limitations of classical Fourier methods tied to strictly periodic responses.


<details>
  <summary>Details</summary>
Motivation: Classical Fourier-based time-spectral methods are limited to strictly periodic responses, but quasi-periodic trajectories with multiple incommensurate frequencies are common in nonlinear dynamics across many fields (fluid mechanics, plasma physics, celestial mechanics).

Method: Lifts governing equations to an extended angular phase space, applies double-Fourier collocation on the invariant torus, and solves for the state. The method exhibits spectral convergence for quasi-periodic problems.

Result: Demonstrated on Duffing oscillators and nonlinear Klein-Gordon system, showing spectral error decay on the torus and tight agreement with time-accurate integrations using modest frequency grids. Method extends naturally to higher-dimensional tori.

Conclusion: Provides a computationally efficient framework for analyzing quasi-periodic phenomena across various domains where multi-frequency dynamics arise, with rigorous mathematical proof of spectral convergence.

Abstract: Quasi-periodic trajectories with two or more incommensurate frequencies are ubiquitous in nonlinear dynamics, yet the classical Fourier-based time-spectral method is tied to strictly periodic responses. We introduce a torus time-spectral method that lifts the governing equations to an extended angular phase space, applies double-Fourier collocation on the invariant torus, and solves for the state. The formulation exhibits spectral convergence for quasi-periodic problem which we give a rigorous mathematical proof and also verify numerically. We demonstrate the approach on Duffing oscillators and a nonlinear Klein-Gordon system, documenting spectral error decay on the torus and tight agreement with time-accurate integrations while using modest frequency grids. The method extends naturally to higher-dimensional tori and offers a computationally efficient framework for analyzing quasi-periodic phenomena in fluid mechanics, plasma physics, celestial mechanics, and other domains where multi-frequency dynamics arise.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [19] [The energy scaling behavior of a class of incompatible two-well problems](https://arxiv.org/abs/2512.12014)
*Noah Piemontese-Fischer*

Main category: math.AP

TL;DR: The paper studies scaling laws for singularly perturbed two-well energies with incompatible boundary conditions, showing different energy scaling exponents (Œµ^{4/5} vs Œµ^{2/3}) depending on whether wells differ by rank-one or rank-two matrices.


<details>
  <summary>Details</summary>
Motivation: To understand energy scaling behavior in geometrically linear two-well problems when wells and/or boundary data are incompatible, which is important for modeling phase transformations and microstructure formation in materials science.

Method: Uses an ùíú-free framework for incompatible two-well problems to derive lower scaling bounds, and constructs branching patterns adapted to incompatible settings for upper bounds, with matching arguments to establish exact scaling exponents.

Result: For geometrically linear two-well problems in 2D: when boundary data enforces oscillations and Œµ is small, minimal energy scales as Œµ^{4/5} for rank-one matrix differences between wells, and as Œµ^{2/3} for rank-two matrix differences. Similar Œµ^{2/3}-scaling found for gradient and divergence-free two-well problems.

Conclusion: The paper establishes precise scaling laws for incompatible two-well energies, showing different exponents based on matrix rank differences between wells, with general ùíú-free framework providing tools for analyzing such problems and branching constructions demonstrating optimal energy scaling.

Abstract: In this article, we study scaling laws for singularly perturbed two-well energies with prescribed Dirichlet boundary data in settings where the wells and/or the boundary data are incompatible. Our main focus is the geometrically linear two-well problem, for which we characterize the energy scaling in two dimensions for nearly all combinations of linear boundary data and stress-free strains. In particular, we prove that if the boundary data enforces oscillations and the weight $Œµ$ of the surface energy is small, the minimal energy upon subtracting the zeroth-order contribution scales either as $Œµ^{{4}/{5}}$ or as $Œµ^{{2}/{3}}$, depending on whether the wells differ by a rank-one or a rank-two matrix, respectively. For the gradient and divergence-free two-well problem, we obtain analogous results, showing an $Œµ^{{2}/{3}}$-scaling behavior in two dimensions whenever oscillations are energetically favored. These results follow by deriving matching upper and lower scaling bounds. The lower scaling bounds are established in a general $\mathcal{A}$-free framework for incompatible two-well problems, which allows us to compute the excess energy and characterize boundary data which enforce oscillations. The upper scaling bounds are obtained by branching constructions which are adapted to the incompatible setting.

</details>


### [20] [Robust series linearization of nonlinear advection-diffusion equations](https://arxiv.org/abs/2512.12019)
*T. Forrest Kieffer,Jakob Cupp,John S. Van Dyke,Paraj Titum,Michael L. Wall*

Main category: math.AP

TL;DR: Nonlinear PDE series expansions with infinite radius of convergence for Burgers' equation and applications to p-Laplacian models


<details>
  <summary>Details</summary>
Motivation: To develop rigorous series expansion techniques for solving nonlinear advection-diffusion PDEs by deforming them from linear counterparts, enabling systematic analysis beyond perturbative regimes

Method: Introduce auxiliary parameter Œ¥ that interpolates between linear and nonlinear PDEs; derive hierarchical system of linear forced PDEs; prove convergence properties for Burgers' equation; analyze Dirac-delta and periodic initial conditions; extend to p-Laplacian models with numerical validation

Result: Proved infinite radius of convergence for Burgers' equation series expansions; demonstrated convergence outside perturbative regime for p-Laplacian models; showed deformation choice affects convergence rate and radius; provided rigorous foundation for series techniques

Conclusion: Established rigorous framework for series expansion methods in nonlinear advection-diffusion PDEs, enabling new analytical approaches and potential applications in quantum-assisted computational fluid dynamics

Abstract: We consider nonlinear partial differential equations (PDEs) for advection-diffusion processes which are augmented by an auxiliary parameter $Œ¥$ such that $Œ¥=0$ corresponds to linear advection-diffusion. We derive potentially non-perturbative series expansions in $Œ¥$ that provide a process to obtain the solution of the nonlinear PDE through solving a hierarchical system of linear, forced PDEs with the forcing terms dependent on solutions at lower orders in the hierarchy. We rigorously detail our approach for a particular deformation that interpolates between linear advection-diffusion and the canonical Burgers' equation modeling nonlinear advection. In this case, we prove that the series has infinite radius of convergence for arbitrary integrable initial data, analyze the cases of a Dirac-delta initial condition (IC) (i.e., the fundamental solution) in an infinite domain and arbitrary IC in a periodic domain, and demonstrate the approach to turbulent behavior in a scenario with periodic forcing. We then treat models of nonlinear diffusion involving the $p$-Laplacian operator, including generalizations of the Poisson equation in $1$ and $2$ dimensions, and the heat equation in $1+1$ dimensions. We detail series expansions for two different deformations of these equations about their linear (ordinary Laplacian) counterparts, providing numerical evidence for the convergence of the series outside of a perturbative regime and demonstrating that the rate and radius of convergence are affected by choice of deformation. Our results provide a rigorous foundation for using series expansion techniques to study nonlinear advection-diffusion PDEs, opening new pathways for analysis and potential applications for quantum-assisted computational fluid dynamics.

</details>


### [21] [Local Well-Posedness of the Motion of Inviscid Liquid Crystals with a Free Surface Boundary](https://arxiv.org/abs/2512.12150)
*Chenyun Luo,Hang Yu*

Main category: math.AP

TL;DR: Local well-posedness of free-boundary Lin-Liu equations for inviscid nematic liquid crystals with surface tension in Lagrangian coordinates


<details>
  <summary>Details</summary>
Motivation: To address the challenge that a priori energy estimates alone are insufficient for establishing local existence in free-boundary problems involving inviscid fluid equations due to loss of symmetry in linearized equations

Method: Develop an effective approximate system of equations that is asymptotically consistent with the free-boundary Lin-Liu model in Lagrangian coordinates, capturing coupling between fluid motion and harmonic heat flows, and boundary regularity

Result: Prove local well-posedness of the free-boundary Lin-Liu equations describing motion of inviscid nematic liquid crystals with surface tension

Conclusion: Successfully establish local existence for this free-boundary problem by developing an appropriate approximate system that handles the coupling between fluid dynamics and harmonic heat flows while maintaining boundary regularity

Abstract: In this article, we prove the local well-posedness of the free-boundary Lin-Liu equations describing the motion of inviscid nematic liquid crystals in the presence of surface tension in Lagrangian coordinates. It is well known that a priori energy estimates alone are insufficient for establishing local existence in free-boundary problems involving inviscid fluid equations, primarily due to the loss of symmetry in the linearized equations. The main challenge is to develop an effective approximate system of equations that is asymptotically consistent with the free-boundary Lin-Liu model expressed in the Lagrangian coordinates. This system must accurately capture the coupling between the fluid motion and the harmonic heat flows within the interior, as well as the regularity of the moving boundary.

</details>


### [22] [Taylor polynomials on left-quotients of Carnot groups](https://arxiv.org/abs/2512.12239)
*Alessandro Ottazzi*

Main category: math.AP

TL;DR: The paper proves classical Taylor polynomial theorems for sub-Riemannian manifolds that are submetric images of Carnot groups, including conditions for real analyticity and L-harmonicity results.


<details>
  <summary>Details</summary>
Motivation: To extend classical Taylor polynomial theorems from Riemannian geometry to the sub-Riemannian setting, specifically for manifolds that can be represented as submetric images of Carnot groups.

Method: The authors prove Taylor polynomial theorems for sub-Riemannian manifolds by leveraging their representation as submetric images of Carnot groups, establishing conditions for real analyticity and analyzing L-harmonic properties.

Result: The paper establishes Taylor polynomial theorems in sub-Riemannian geometry, provides sufficient conditions for real analyticity of these expansions, and proves results about the L-harmonicity of Taylor polynomials.

Conclusion: The work successfully extends classical Taylor polynomial theory to sub-Riemannian manifolds derived from Carnot groups, with applications to analyticity and harmonic analysis in this geometric setting.

Abstract: We prove classical Taylor polynomial theorems for sub-Riemannian manifolds that are obtained as the submetric image of a Carnot group. For these theorems we also prove a sufficient condition for real analyticity and a result on L-harmonicity of Taylor polynomials.

</details>


### [23] [From cohesive to brittle debonding: the quasistatic framework](https://arxiv.org/abs/2512.12261)
*Filippo Riva*

Main category: math.AP

TL;DR: Cohesive debonding models with steep cohesive profiles converge to brittle debonding solutions in quasistatic peeling of elastic adhesive membranes.


<details>
  <summary>Details</summary>
Motivation: To validate the approximation of brittle fracture laws using increasingly steep cohesive zone models in the context of adhesive membrane debonding.

Method: Uses quasistatic energetic solutions to a rescaled cohesive debonding problem, with convergence analysis to brittle counterpart via free-boundary reformulation.

Result: Proves that solutions to cohesive debonding problems converge to limit evolutions solving the brittle debonding model as cohesive profiles become steeper.

Conclusion: The steep cohesive profile approximation provides a rigorous mathematical validation for bridging cohesive zone models to brittle fracture in adhesive debonding problems.

Abstract: The approximation of brittle laws via steeper and steeper cohesive profiles is validated within the mechanical setting of debonding models, which describe the detachment process of a peeled elastic adhesive membrane. In a quasistatic framework, energetic solutions to a suitably rescaled cohesive debonding problem, formulated in terms of displacements, are proved to converge to a limit evolution of shapes solving its brittle counterpart. The proposed approach relies on an equivalent and recently introduced free-boundary reformulation of this latter model.

</details>


### [24] [Lower Bound of Nodal Sets in Elliptic Homogenization and Functions with Strong Maximum Principle](https://arxiv.org/abs/2512.12305)
*Jiahuan Li,Zhichen Ying*

Main category: math.AP

TL;DR: The paper proves a uniform lower bound for nodal volume in elliptic homogenization, with a constant lower bound achievable in 2D, and extends this to general continuous functions with strong maximum principle.


<details>
  <summary>Details</summary>
Motivation: To establish uniform lower bounds for nodal volumes in elliptic homogenization problems, addressing the gap between existing results and optimal bounds, particularly focusing on two-dimensional cases.

Method: First proves a uniform lower bound for nodal volume in elliptic homogenization setting, then extends the approach to more general settings by considering continuous functions with strong maximum principle.

Result: Achieves a constant lower bound for nodal volume in dimension two, and extends this to general continuous functions with strong maximum principle, working beyond solutions to elliptic PDEs.

Conclusion: The proof technique for elliptic homogenization can be generalized to establish constant lower bounds for nodal volumes of continuous functions satisfying strong maximum principle, expanding applicability beyond elliptic PDE solutions.

Abstract: In this note, we first try to prove a uniform lower bound of nodal volume in elliptic homogenization setting. This lower bound is far from optimal. But, we can prove a constant lower bound in dimension two. Motivated by the proof, we extend this results to more general settings. To be more specific, we prove that the nodal volume has a constant lower bound for all continuous functions with strong maximum princple. Our result works for general functions beyond solutions to elliptic PDEs.

</details>


### [25] [Nontrivial solutions for nonlinear problems driven by a superposition of fractional p-Laplacians with Neumann boundary conditions](https://arxiv.org/abs/2512.12351)
*Yergen Aikyn*

Main category: math.AP

TL;DR: Existence results for nonlinear nonlocal problems with superposition of fractional p-Laplacians under Neumann boundary conditions using variational methods.


<details>
  <summary>Details</summary>
Motivation: To investigate existence of solutions for nonlinear nonlocal problems governed by operators that are superpositions of fractional p-Laplacians with Neumann boundary conditions, which have wide applications in various specific situations.

Method: Spectral analysis of the main operator followed by application of variational methods: either mountain pass method or technique of linking over cones.

Result: Established existence results for nonlinear nonlocal problems through variational approaches applied to the spectral properties of the superposition operator.

Conclusion: The developed theory applies to a wide range of specific situations due to the generality of the setting with superposition of fractional p-Laplacians and Neumann boundary conditions.

Abstract: In this paper, we investigate existence results for nonlinear nonlocal problems governed by an operator obtained as a superposition of fractional $p$-Laplacians, subject to Neumann boundary conditions. A spectral analysis of the main operator leads us to apply different variational tools to establish our results. Specifically, we will use either the mountain pass method or the technique of linking over cones. Due to the generality of the setting, the resulting theory applies to a wide range of specific situations.

</details>


### [26] [A third-order conservation law for the Kirchhoff-Pokhozhaev equation](https://arxiv.org/abs/2512.12380)
*Chiara Boiti,Renato Manfrin*

Main category: math.AP

TL;DR: The paper proves that Pokhozhaev's special Kirchhoff equation has a third-order conservation law and establishes uniform time-boundedness of L¬≤-norms for derivatives up to third order under small energy conditions.


<details>
  <summary>Details</summary>
Motivation: To investigate conservation properties and long-time behavior of solutions to Pokhozhaev's special Kirchhoff equation, particularly establishing higher-order conservation laws and boundedness results for solution derivatives.

Method: Analytical proof techniques to demonstrate existence of a third-order conservation law for the special Kirchhoff equation, combined with energy methods to establish uniform boundedness of L¬≤-norms of derivatives under small energy conditions.

Result: 1) Existence of a third-order conservation law for Pokhozhaev's special Kirchhoff equation. 2) Uniform boundedness with respect to time of L¬≤-norms of derivatives up to third order when solution energy is sufficiently small.

Conclusion: The special Kirchhoff equation possesses richer conservation structure than previously known, and solutions exhibit controlled long-time behavior in terms of derivative boundedness under appropriate energy conditions.

Abstract: We prove that the special Kirchhoff equation studied by Pokhozhaev admits a third-order conservation law. We further show that if the energy of the solution is sufficiently small, then the $L^2$-norms of the derivatives up to third order of the solution remain uniformly bounded with respect to time.

</details>


### [27] [Existence and stability for traveling waves of fourth order semilinear wave and Schrodinger equations](https://arxiv.org/abs/2512.12390)
*Vishnu Iyer,Ross Parker,Atanas G. Stefanov*

Main category: math.AP

TL;DR: Existence and spectral stability analysis of traveling waves for fourth-order beam equations using variational methods and VK stability criterion.


<details>
  <summary>Details</summary>
Motivation: To understand wave propagation phenomena in structural mechanics, particularly suspension bridge models, by analyzing traveling wave solutions for fourth-order semilinear wave equations (beam equations).

Method: Variational methods based on constrained maximization problems to establish existence of smooth traveling waves; spectral analysis of linearized operators; Vakhitov-Kolokolov (VK) type stability criterion; extension to fourth-order nonlinear Schr√∂dinger equations; numerical verification.

Result: Existence of smooth, exponentially decaying traveling waves for wavespeeds in (0, ‚àö2); complete spectral stability characterization via VK criterion; sharp exponential decay rates matching Green's function decay; analogous results for fourth-order NLS; numerical confirmation of stability predictions and regime transitions.

Conclusion: Provides comprehensive mathematical framework for understanding wave propagation in structural mechanics, with complete existence and stability analysis of traveling waves for beam equations and fourth-order NLS, validated by numerical computations.

Abstract: We investigate the existence and spectral stability of traveling wave solutions for a class of fourth-order semilinear wave equations, commonly referred to as beam equations. Using variational methods based on a constrained maximization problem, we establish the existence of smooth, exponentially decaying traveling wave profiles for wavespeeds in the interval $(0, \sqrt{2})$. We derive precise spectral properties of the associated linearized operators and prove a Vakhitov-Kolokolov (VK) type stability criterion that completely characterizes spectral stability. Furthermore, we determine the sharp exponential decay rate of the traveling waves and demonstrate that it matches the decay rate of the Green's function for the linearized operator. Our analysis extends to fourth-order nonlinear Schrodinger equations, for which we establish analogous existence and stability results. The theoretical findings are complemented by numerical computations that verify the stability predictions and reveal the transition from unstable to stable regimes as the wavespeed varies. These results provide a comprehensive mathematical framework for understanding wave propagation phenomena in structural mechanics, particularly suspension bridge models.

</details>


### [28] [Lifespan of the Non-resistive Hall-MHD System with Small Magnetic Gradient](https://arxiv.org/abs/2512.12524)
*Linbin Yang,Taoran Zhou*

Main category: math.AP

TL;DR: The paper proves that strong solutions to the non-resistive axially symmetric Hall-MHD system can have arbitrarily long lifespans when initial magnetic gradients are sufficiently small, with explicit lifespan lower bounds for both viscous and inviscid cases.


<details>
  <summary>Details</summary>
Motivation: To understand the long-time behavior and stability of solutions to the non-resistive axially symmetric Hall-MHD system, particularly how small initial magnetic gradients affect solution lifespan.

Method: Analysis of the non-resistive axially symmetric Hall-MHD system, establishing lifespan estimates through mathematical analysis of the governing equations and initial conditions.

Result: Strong solutions can have arbitrarily large lifespans when initial magnetic gradients are sufficiently small, with precise lower bounds provided for both viscous and inviscid cases.

Conclusion: Small initial magnetic gradients in the non-resistive axially symmetric Hall-MHD system lead to extended solution lifespans, with explicit quantitative bounds that apply to both viscous and inviscid scenarios.

Abstract: In this paper, we consider the non-resistive axially symmetric Hall-MHD system. We show that the lifespan of their strong solutions can be arbitrarily large if their initial magnetic gradient are small enough. Precise lifespan lower bounds for both viscid and inviscid cases are given.

</details>


### [29] [Adiabatic approximation of Abelian Higgs models](https://arxiv.org/abs/2512.12525)
*Amirmasoud Geevechi,Robert L Jerrard*

Main category: math.AP

TL;DR: Constructs novel vortex filament solutions in d‚â•3 dimensions for critical hyperbolic Abelian Higgs model, relating vortex dynamics to wave maps into moduli space, with applications to vortex reconnection in 3D.


<details>
  <summary>Details</summary>
Motivation: To understand the dynamics of multiple vortex filaments in higher-dimensional Abelian Higgs models, particularly the poorly-understood phenomenon of vortex reconnection in 3D superconductors.

Method: Constructs solutions for N‚â•1 slowly-moving, nearly parallel vortex filaments in d‚â•3 dimensions, showing leading-order dynamics are described by wave maps from ‚Ñù^{d-2} into the Abelian Higgs moduli space (parametrizing stationary 2D solutions).

Result: Establishes correspondence between critical hyperbolic AHM dynamics and wave maps into moduli space, and between critical AHM heat flow and harmonic map heat flow into moduli space, with parallel results for near-critical equations.

Conclusion: Provides rigorous framework for studying vortex filament dynamics and reconnection in 3D Abelian Higgs models by relating them to geometric flows on moduli spaces, enabling analysis of previously poorly-understood phenomena.

Abstract: We construct novel solutions in $d\ge 3$ space dimensions of a family of nonlinear evolutions equations that includes the critical hyperbolic Abelian Higgs model (AHM). For the AHM, these solutions exhibit an ensemble of $N\ge 1$ slowly-moving, nearly parallel vortex filaments, whose leading-order dynamics are described by a wave map from ${\mathbb R}^{d-2}$ into the Abelian Higgs moduli space, a manifold carrying a natural Riemannian structure that parametrizes stationary 2d solutions of the AHM. We also prove extremely similar results that relate the critical Abelian Higgs heat flow, modeling certain superconductors, to the harmonic map heat flow into the Moduli space, as well as some parallel results for near-critical equations. When $d=3$, these results allow for the study of the poorly-understood phenomenon of vortex reconnection in this setting.

</details>


### [30] [Steady Solutions to the Relativistic Boltzmann Equation in a Slab](https://arxiv.org/abs/2512.12540)
*Jin Woo Jang,Seok-Bae Yun*

Main category: math.AP

TL;DR: Existence and uniqueness of steady solutions to relativistic Boltzmann equation with hard-sphere interactions in a slab geometry, with exponential momentum decay and no smallness assumption on slab width.


<details>
  <summary>Details</summary>
Motivation: To study steady-state solutions of the relativistic Boltzmann equation in bounded domains, which is important for understanding particle transport in relativistic contexts like astrophysics and high-energy physics.

Method: Use weighted $L^1_p L^\infty_{x_1}$ framework with spatial symmetry in transverse variables, establish sharp coercivity/continuity estimates for collision frequency, weighted convolution bounds for nonlinear gain term, and leverage $(-\Delta_p)^{-1}$-type regularity.

Result: Prove existence and uniqueness of stationary solution with exponential momentum decay, uniform weighted integrability over arbitrary 2D hyperplanes through origin, without smallness assumption on slab width.

Conclusion: The paper establishes rigorous mathematical framework for steady relativistic Boltzmann solutions in bounded domains with hard-sphere interactions, providing important analytical tools for studying relativistic transport phenomena.

Abstract: We study steady solutions to the relativistic Boltzmann equation with hard-sphere interactions in a slab geometry. Under a spatial symmetry assumption in the transverse variables $x_2$ and $x_3$, the problem reduces to a one-dimensional spatial slab $x_1 \in [0,1]$ while retaining full three-dimensional momentum dependence. For non-negative inflow boundary conditions prescribed at $x_1=0$ and $x_1=1$, we prove the existence and uniqueness of a stationary solution in a weighted $L^1_p L^\infty_{x_1}$ framework, together with exponential decay in momentum.
  Our analysis treats the full slab domain and does not rely on any smallness assumption on the slab width. We establish sharp coercivity and continuity estimates for the collision frequency, together with weighted convolution and pointwise bounds for the nonlinear gain term. These estimates generate and propagate a $(-Œî_p)^{-1}$-type regularity within the solution framework, which plays a crucial role in the existence and uniqueness argument. In addition, we obtain uniform weighted integrability of the solution over arbitrary two-dimensional hyperplanes through the origin. This hyperplane estimate is derived as a genuinely a posteriori regularity property, without imposing any a priori hyperplane bounds, and follows from a Lorentz-invariant geometric reduction.

</details>


### [31] [Global controllability of the Cahn-Hilliard equation](https://arxiv.org/abs/2512.12562)
*V√≠ctor Hern√°ndez-Santamar√≠a,Subrata Majumdar,Luz de Teresa*

Main category: math.AP

TL;DR: The paper establishes global null controllability of the Cahn-Hilliard equation on the d-dimensional torus using a two-phase control strategy combining Fourier mode localization and spatial localization.


<details>
  <summary>Details</summary>
Motivation: To study control properties of the Cahn-Hilliard equation, a fundamental model in phase separation and pattern formation, with applications to materials science and fluid dynamics.

Method: 1. Geometric control theory for small-time global approximate controllability using Fourier mode controls. 2. Quantitative propagation of smallness estimates for linearized null controllability with localized spatial controls. 3. Fixed-point argument for local null controllability in dimensions 1-3. 4. Two-phase strategy combining Fourier and spatial localization.

Result: 1. Small-time global approximate controllability with Fourier mode controls. 2. Linearized null controllability with controls on arbitrary positive measure sets. 3. Local null controllability for nonlinear system in dimensions 1-3. 4. Global null controllability of Cahn-Hilliard equation via combined approach.

Conclusion: The Cahn-Hilliard equation is globally null controllable on the d-dimensional torus using a two-phase control strategy: first with Fourier-localized controls, then with spatially localized controls on positive measure sets.

Abstract: This paper deals with the global control properties of the Cahn-Hilliard equation posed on the $d$-dimensional flat torus $\mathbb{T}^d$. We first prove that the system is small-time globally approximately controllable using a control supported on finitely many Fourier modes, following an approach based on geometric control theory techniques. Next, we show that the corresponding linearized problem is null-controllable with a localized control, where the control region is an arbitrary measurable set of positive Lebesgue measure. Our analysis is based on quantitative propagation of smallness estimates for the free solution. Furthermore, when $d\in \{1,2,3\},$ we ensure the local null controllability for the nonlinear system via a fixed-point argument. Finally, by combining these two results, we establish the global null controllability of the Cahn-Hilliard equation. In the first phase, the control is localized in Fourier modes, whereas in the second phase, it is spatially localized on a set of positive Lebesgue measure.

</details>


### [32] [Parabolic Equations with Singular Coefficients and Boundary Data: Analysis and Numerical Simulations](https://arxiv.org/abs/2512.12612)
*Arshyn Altybay,Alibek Yeskermessuly*

Main category: math.AP

TL;DR: Very weak solution framework for parabolic equations with singular coefficients and distributional data using regularization and moderate nets.


<details>
  <summary>Details</summary>
Motivation: Classical and weak solution concepts fail for parabolic equations when coefficients or boundary data are distributions, due to ill-posed products involving distributions.

Method: Introduce very weak solutions based on regularization techniques and theory of moderate nets, using negligibility arguments for uniqueness.

Result: Existence established under minimal regularity, consistency with classical solutions when data are smooth, and uniqueness via negligibility arguments.

Conclusion: Very weak solution framework robustly handles highly singular inputs including delta-type potentials and distributional boundary traces, as shown numerically.

Abstract: We investigate linear parabolic equations in divergence form with singular coefficients and non-smooth boundary data. When the diffusion, drift, or potential terms, as well as the initial or boundary conditions, are distributions rather than functions, classical and weak solution concepts become inadequate due to the ill-posedness of products involving distributions. To overcome this, we introduce a framework of very weak solutions based on regularization techniques and the theory of moderate nets. Existence of very weak solutions is established under minimal regularity assumptions. We further prove consistency with classical solutions when the data are smooth and demonstrate uniqueness via negligibility arguments. Finally, we present numerical computations that illustrate the robustness of the very weak solution framework in handling highly singular inputs, including delta-type potentials and distributional boundary traces.

</details>


### [33] [Estimates for the wave equation on $Œ≤$-dimensional spaces of measures](https://arxiv.org/abs/2512.12618)
*Riju Basak,Daniel Spector*

Main category: math.AP

TL;DR: Fixed-time estimates for wave multipliers on Œ≤-dimension stable measure spaces, refining Hardy space estimates and deriving wave equation estimates with measure data.


<details>
  <summary>Details</summary>
Motivation: To establish refined fixed-time estimates for wave multipliers acting on Œ≤-dimension stable spaces of measures, improving upon known Hardy space estimates.

Method: Develop Miyachi-Peral-type fixed-time estimates for wave multipliers on Œ≤-dimension stable measure spaces, using techniques from harmonic analysis and measure theory.

Result: Obtained refined estimates that improve known Hardy space bounds, and derived corresponding estimates for the wave equation with measure data.

Conclusion: The paper establishes improved fixed-time estimates for wave multipliers on measure spaces and successfully applies them to wave equations with measure data.

Abstract: In this paper, we establish Miyachi-Peral-type fixed-time estimates for wave multipliers acting on $Œ≤$-dimension stable spaces of measures. Our estimates give a refinement of known estimates for the Hardy space. From these bounds, we deduce corresponding estimates for the wave equation with measure data.

</details>


### [34] [Existence and nonexistence results for a nonlocal isoperimetric problem on $\mathbb{H}^n$](https://arxiv.org/abs/2512.12621)
*Haizhong Li,Bo Yang*

Main category: math.AP

TL;DR: Geodesic balls are unique minimizers for small volumes and nonexistent for large volumes in hyperbolic space for nonlocal isoperimetric problems with distance-based nonlocal terms.


<details>
  <summary>Details</summary>
Motivation: Extend the study of nonlocal isoperimetric functionals from Euclidean space to hyperbolic space, where the geometry differs significantly and may yield different minimization behaviors.

Method: Investigate the nonlocal isoperimetric problem in hyperbolic space $\mathbb{H}^n$ with a functional combining perimeter and a nonlocal term derived from negative power of distance function.

Result: Prove geodesic balls are unique minimizers (up to hyperbolic isometries) for small volumes, and show nonexistence of minimizers for large volumes under certain exponent ranges.

Conclusion: The geometry of hyperbolic space significantly affects the minimization behavior compared to Euclidean space, with volume thresholds determining existence and uniqueness of minimizers.

Abstract: In Euclidean space $\mathbb{R}^n$, the minimization problem of a nonlocal isoperimetric functional with a competition between perimeter and a nonlocal term derived from the negative power of the distance function, has been extensively studied. In this paper, we investigate this nonlocal isoperimetric problem in hyperbolic space $\mathbb{H}^n$, we prove that the geodesic balls are unique minimizers (up to hyperbolic isometries) for small volumes $m$ and obtain nonexistence results for large volumes $m$ under certain ranges of the exponent in the nonlocal term.

</details>


### [35] [Uniformity of Maximal Hypoellipticity on Graded Lie Groups: From Pointwise to Global](https://arxiv.org/abs/2512.12646)
*Shiqi Liu,Edward McDonald,Fedor Sukochev,Dmitriy Zanin*

Main category: math.AP

TL;DR: Develops a "freeze-unfreeze" mechanism to transfer maximal hypoellipticity from frozen coefficients to full differential operators on graded Lie groups, enabling symbol-level properties to yield global elliptic estimates without pseudodifferential calculus.


<details>
  <summary>Details</summary>
Motivation: To establish a transparent framework for lifting hypoelliptic properties from symbol-level to global estimates on graded Lie groups, bringing the classical "freeze-unfreeze" strategy into hypoelliptic analysis without relying on complex pseudodifferential techniques.

Method: Develops a mechanism that transfers uniformity of maximal hypoellipticity from frozen coefficients principal parts to full differential operators using a "freeze-unfreeze" strategy adapted to graded Lie groups.

Result: Provides a framework for obtaining global elliptic estimates from symbol-level hypoelliptic properties without pseudodifferential calculus, and proves that symmetric operators of hypoelliptic type on graded Lie groups are self-adjoint.

Conclusion: The approach offers a transparent and flexible alternative to pseudodifferential methods for hypoelliptic analysis on graded Lie groups, with applications to self-adjointness of symmetric hypoelliptic operators.

Abstract: On graded Lie groups, we develop a mechanism that transfers the uniformity of maximal hypoellipcity from the frozen coefficients principal part of a differential operator to the full operator. Our approach brings the century-old "freeze-unfreeze" strategy into the hypoelliptic setting, and offers a transparent and flexible framework for lifting symbol-level hypoelliptic properties to global elliptic estimates, without relying on pseudodifferential calculus. In addition, we prove that symmetric operators of hypoelliptic type on a graded Lie group are self-adjoint.

</details>


### [36] [Sharp Time Estimates for Some Nonlocal Evolution Equations](https://arxiv.org/abs/2512.12700)
*Xiaolei Yang*

Main category: math.AP

TL;DR: New method proves e^{(d-1)t} is sharp time bound for nonlocal evolution equation u_t = d(J*u) - u in ‚Ñù


<details>
  <summary>Details</summary>
Motivation: Analyze the Cauchy problem for nonlocal evolution equations, which model various physical and biological phenomena where spatial interactions are important. The equation u_t = d(J*u) - u involves convolution with kernel J, representing nonlocal diffusion or interaction.

Method: Develops a novel analytical approach to establish sharp time bounds for solutions. The method likely involves careful analysis of the convolution operator, spectral properties, and comparison techniques to prove optimal growth/decay rates.

Result: Proves that e^{(d-1)t} is the sharp time bound for solutions to the nonlocal evolution equation. This establishes the precise exponential growth/decay rate depending on parameter d.

Conclusion: The new method successfully determines the optimal time behavior for this class of nonlocal evolution equations, providing important quantitative information about solution dynamics and stability properties.

Abstract: In this paper, we consider the Cauchy problem for the nonlocal evolution equation \(u_t = d(J*u) - u\) in \(\R\). We present a new method to prove that \(e^{(d-1)t}\) is the sharp time bound.

</details>


### [37] [Hyperbolic equations with fifth-order symmetries](https://arxiv.org/abs/2512.12789)
*Rustem N. Garifullin*

Main category: math.AP

TL;DR: Classification of hyperbolic equations based on existence of higher fifth-order symmetries yields four specific equations.


<details>
  <summary>Details</summary>
Motivation: To systematically classify hyperbolic partial differential equations of a specific form by requiring the existence of higher-order symmetries, which is important for integrability and solvability properties.

Method: Study equations of form ‚àÇ¬≤u/‚àÇx‚àÇy = F(‚àÇu/‚àÇx, ‚àÇu/‚àÇy, u) and impose condition that they admit higher fifth-order symmetries to classify them.

Result: Obtained a list of four equations that satisfy the required conditions for existence of higher fifth-order symmetries.

Conclusion: The classification based on symmetry requirements successfully identifies four specific hyperbolic equations with integrability properties.

Abstract: This paper examines the classification of hyperbolic equations. We study a class of equations of the form $$\frac{\partial^2 u}{\partial x\partial y}=F\left(\frac{\partial u}{\partial x},\frac{\partial u}{\partial y},u\right),$$ where $u(x,y)$ is the unknown function and $x,y$ are independent variables. The classification is based on the requirement for the existence of higher fifth-order symmetries. As a result, a list of four equations with the required conditions was obtained.

</details>


### [38] [Directional Spectral Analysis: Dimension Reduction for Periodic Elliptic Operators](https://arxiv.org/abs/2512.12848)
*Ruming Zhang*

Main category: math.AP

TL;DR: A new approach introduces direction into spectral analysis to solve the limiting absorption principle for elliptic equations with periodic structures in higher dimensions, overcoming previous dimensional barriers.


<details>
  <summary>Details</summary>
Motivation: The study of limiting absorption principle for elliptic equations with periodic structures faces challenges in dimensions greater than 1 due to mismatch between directional physical reality and direction-independent classic spectral analysis.

Method: Introduces a new approach that incorporates direction into classic spectral analysis, allowing for semi-analytic formulation of solutions obtained through the limiting absorption principle.

Result: The new approach resolves the mathematics-physics mismatch, breaks dimensional barriers, provides explicit solution representations, and reflects physical phenomena accurately.

Conclusion: The directional spectral analysis approach opens doors for further possibilities in solution analysis and numerical simulations for elliptic equations with periodic structures.

Abstract: The study of the limiting absorption principle for elliptic equations with periodic structures is very challenging when the dimension is greater than 1. The fundamental reason for the dimensional barrier is the mismatch between directional physical reality and the direction-independent classic spectral analysis. In this paper, we introduce a new approach which introduce the direction into classic spectral analysis. With the new approach, the solution obtained by the limiting absorption principle can be formulated in a semi-analytic form, which not only gives an explicit representation of the solutions, but also reflects the phenomenon in physics.
  The new approach resolves the mismatch between mathematics and physics, and also breaks the dimensional barriers. It also opens a door to a lot of further possibilities, ranging from the analysis of solutions and numerical simulations for the solutions.

</details>


### [39] [On the variational dual formulation of the Nash system and an adaptive convex gradient-flow approach to nonlinear PDEs](https://arxiv.org/abs/2512.12878)
*Dmitry Vorotnikov,Amit Acharya*

Main category: math.AP

TL;DR: The paper studies how base states affect consistency in dual variational formulations for quadratic PDE systems, including non-conservative cases like noise-free Nash systems. It establishes conditions for consistency over long time intervals and proves existence of variational dual solutions.


<details>
  <summary>Details</summary>
Motivation: To understand the role of base states in ensuring consistency of dual variational formulations for quadratic PDE systems, particularly for non-conservative systems like the noise-free Nash system with quadratic Hamiltonians and multiple players.

Method: The authors identify a sufficient condition for consistency over large time intervals, prove existence of variational dual solutions for arbitrary base states, and propose a Hilbertian gradient flow scheme that generates sequences of base states converging to PDE solutions.

Result: In the single-player case, there exists a sequence of fully consistent base states converging in mean to zero. The paper proves existence of variational dual solutions to the noise-free Nash system for arbitrary base states.

Conclusion: Base states play a crucial role in dual variational formulations for quadratic PDE systems, with consistency achievable under certain conditions. The proposed Hilbertian gradient flow scheme offers a promising approach for generating solutions from arbitrary initial base states.

Abstract: We investigate the influence of base states on the consistency of the dual variational formulation for quadratic systems of PDEs, which are not necessarily conservative (typical examples include the noise-free Nash system with a quadratic Hamiltonian and multiple players). We identify a sufficient condition under which consistency holds over large time intervals. In particular, in the single-player case, there exists a sequence of base states (each exhibiting full consistency) that converges in mean to zero. We also prove existence of variational dual solutions to the noise-free Nash system for arbitrary base states. Furthermore, we propose a scheme based on Hilbertian gradient flows that, starting from an arbitrary base state, generates a sequence of new base states that is expected to converge to a solution of the original PDE.

</details>


### [40] [Conservation laws of nonlinear PDEs arising in elasticity and acoustics in Cartesian, cylindrical, and spherical geometries](https://arxiv.org/abs/2512.13062)
*Willy Hereman,Rehana Naz*

Main category: math.AP

TL;DR: The paper computes conservation laws for various nonlinear PDEs in elasticity and acoustics using scaling homogeneity and multiplier methods.


<details>
  <summary>Details</summary>
Motivation: To establish conservation laws for nonlinear PDEs that arise in elasticity and acoustics, which are important for understanding wave propagation phenomena in these fields.

Method: Uses two main approaches: 1) scaling homogeneity method for shear wave propagation models in circular cylinders and cylindrical annuli, and 2) multiplier method for parameterized systems of constitutive equations in cylindrical coordinates with general Cauchy stress expressions.

Result: Derived conservation laws for: shear wave propagation models in circular geometries; parameterized constitutive equation systems; Khokhlov-Zabolotskaya-Kuznetsov equation; and Westervelt-type equations in various coordinate systems.

Conclusion: Successfully established conservation laws for important nonlinear PDEs in elasticity and acoustics using systematic mathematical approaches, providing valuable tools for analyzing wave propagation phenomena in these physical systems.

Abstract: Conservation laws are computed for various nonlinear partial differential equations that arise in elasticity and acoustics. Using a scaling homogeneity approach, conservation laws are established for two models describing shear wave propagation in a circular cylinder and a cylindrical annulus. Next, using the multiplier method, conservation laws are derived for a parameterized system of constitutive equations in cylindrical coordinates involving a general expression for the Cauchy stress. Conservation laws for the Khokhlov-Zabolotskaya-Kuznetsov equation and Westervelt-type equations in various coordinate systems are also presented.

</details>


### [41] [Stability analysis for a plate-membrane system without geometric condition](https://arxiv.org/abs/2512.13087)
*Bienvenido Barraza Mart√≠nez,Robert Denk,Jonathan Gonz√°lez Ospino,Jairo Hern√°ndez Monz√≥n*

Main category: math.AP

TL;DR: Analysis of thermoelastic plate-membrane transmission problem shows lack of exponential stability but polynomial stability without geometric constraints.


<details>
  <summary>Details</summary>
Motivation: To study stability properties of coupled thermoelastic plate and membrane systems without mechanical damping, addressing stability challenges in such transmission problems.

Method: Mathematical analysis of transmission problem describing thermoelastic plate surrounding membrane without mechanical damping, using stability theory approaches.

Result: The system lacks exponential stability but achieves polynomial stability without requiring the usual geometric conditions typically needed for such problems.

Conclusion: While exponential stability is unattainable for this thermoelastic plate-membrane transmission problem without mechanical damping, polynomial stability can be achieved without geometric restrictions, providing important stability characterization for such coupled systems.

Abstract: In this work, we consider a transmission problem describing a thermoelastic plate surrounding a membrane without any mechanical damping. The main results consist of the lack of exponential stability for this problem and the polynomial stability without the usual geometric condition.

</details>


### [42] [Almost sure global nonlinear smoothing for the 2D NLS](https://arxiv.org/abs/2512.13088)
*Chenmin Sun,Nikolay Tzvetkov*

Main category: math.AP

TL;DR: Proves almost-sure global nonlinear smoothing effect for NLS on 2D torus using quantitative quasi-invariance of Gaussian measures.


<details>
  <summary>Details</summary>
Motivation: Extend nonlinear smoothing phenomenon from 1D (circle) to 2D (torus), where deterministic case remains unknown. Address probabilistic approach to overcome deterministic limitations.

Method: Uses quantitative quasi-invariance of Gaussian measures with covariance operator (1-Œî)^{-s} for s>2. Probabilistic approach with measure-theoretic techniques.

Result: Establishes almost-sure global in time nonlinear smoothing effect for NLS on two-dimensional torus. Provides probabilistic extension beyond deterministic results.

Conclusion: Demonstrates probabilistic smoothing effects can be achieved in higher dimensions where deterministic results are unavailable, using measure quasi-invariance techniques.

Abstract: In this article, we prove an almost-sure global in time nonlinear smoothing effect for NLS on the two-dimensional torus. For deterministic data, this phenomenon was proved for the NLS on the circle by Erdoƒüan--Tzirakis, which remains unknown on multidimensional torus.
  Our argument is based on a quantitative quasi-invariance of Gaussian measures with covariance operator $(1-Œî)^{-s}$ for $s>2$.

</details>


### [43] [Convection Effects and Optimal Insulation: Modelling and Analysis](https://arxiv.org/abs/2512.13098)
*Harbir Antil,Alex Kaltenbach,Keegan L. A. Kirk*

Main category: math.AP

TL;DR: This paper studies optimal insulation distribution for a thermally conducting body with convective heat transfer, using Œì-convergence to analyze heat loss as insulation thickness approaches zero.


<details>
  <summary>Details</summary>
Motivation: The motivation is to determine the optimal distribution of insulating material on a thermally conducting body to minimize heat loss through convective heat transfer, which has practical applications in thermal engineering and energy efficiency.

Method: The authors use Œì-convergence in L¬≤(‚Ñù·µà) to analyze the heat loss formulation as Œµ‚Üí0‚Å∫, where Œµ represents insulation conductivity. They consider a bounded Lipschitz domain Œ© with C¬π,¬π-regular or piece-wise flat insulated boundary Œì_I, modeling the insulation layer thickness via Œµd(x) where d is the material distribution function.

Result: The main result establishes Œì-convergence of the heat loss formulation as the insulation conductivity Œµ approaches zero, providing a rigorous mathematical framework for analyzing optimal insulation distribution problems in the thin insulation limit.

Conclusion: The paper provides a mathematical foundation for studying optimal insulation distribution problems using Œì-convergence techniques, enabling analysis of heat loss minimization in the limit of thin insulating layers with convective boundary conditions.

Abstract: In this paper, we study an insulation problem that seeks to determine the optimal distribution of a given amount $m>0$ of insulating material coating an insulated boundary part $Œì_I\subseteq \partialŒ©$ of a thermally conducting body $Œ©\subseteq \mathbb{R}^d$, $d\in \mathbb{N}$, subject to convective heat transfer. The `$\textit{thickness}$' of the insulating layer $Œ£_{I}^{\varepsilon}\subseteq \mathbb{R}^d$ is given locally via $\varepsilon \mathtt{d}$, where $\varepsilon>0$ denotes the (arbitrarily small) conductivity and $\mathtt{d}\colon Œì_{I}\to [0,+\infty)$ the (to be determined) distribution of the insulating material. Then, the physical process is modelled by the stationary heat equation in the insulated thermally conducting body $Œ©_{I}^{\varepsilon}:= Œ©\cupŒ£_{I}^{\varepsilon}$ with Robin-type boundary conditions on the interacting insulation boundary $Œì_I^{\varepsilon}\subseteq \partialŒ©_{I}^{\varepsilon}$ (reflecting convective heat transfer between the thermally conducting body $Œ©$ and its surrounding medium) as well as Dirichlet and Neumann boundary conditions at the remaining boundary parts, $\textit{i.e.}$, $\partialŒ©_{I}^{\varepsilon}\setminus Œì_I^{\varepsilon}$.
  More precisely, we establish $Œì(L^2(\mathbb{R}^d))$-convergence of the heat loss formulation (as ${\varepsilon \to 0^+}$), in the case that the thermally conducting body $Œ©$ is a bounded Lipschitz domain having a $C^{1,1}$-regular or piece-wise flat insulated boundary $Œì_I$.

</details>


### [44] [Quasi invariant Gaussian measures for the nonlinear Schr√∂dinger equation on $\mathbb T^2$](https://arxiv.org/abs/2512.13113)
*Leonardo Tolomeo,Nicola Visciglia*

Main category: math.AP

TL;DR: The paper proves quasi-invariance of Gaussian measures under the 2D defocusing Schr√∂dinger equation flow, showing Radon-Nikodym derivatives belong to all L^p spaces locally.


<details>
  <summary>Details</summary>
Motivation: To understand the statistical behavior of solutions to nonlinear Schr√∂dinger equations and establish measure-theoretic properties of Gaussian measures under Hamiltonian flows in infinite-dimensional settings.

Method: Uses physical-space energies from previous work combined with a new abstract quasi-invariance argument that integrates space-time estimates along the flow with probabilistic bounds on the measure's support.

Result: Shows Gaussian measures with inverse covariance ||u||_H^s^2 are quasi-invariant under the flow for s>2, and the Radon-Nikodym density belongs to every L^p space locally in space.

Conclusion: The paper establishes rigorous measure-theoretic properties for Gaussian measures under nonlinear Schr√∂dinger flows, providing tools for statistical analysis of such PDEs in two dimensions.

Abstract: We study the transport of Gaussian measures under the flow of the 2-dimensional defocusing Schr√∂dinger equation $i \partial_t u + Œîu = |u|^{2k} u$ posed on $\mathbb T^2$. In particular, we show that the Gaussian measures with inverse covariance $\|u\|_{H^s}^2$, are quasi-invariant under the flow for $s>2$. Moreover, we show that the Radon-Nykodim density belongs to every $L^p$ space, locally in space. The proof relies on the physical-space energies introduced in [52], as well as a new abstract quasi-invariance argument that allows us to combine space-time estimates, along the flow with probabilistic bounds on the support of the measure.

</details>


### [45] [PFEM-GP-dpHs : a finite element framework for combining Gaussian processes and infinite-dimensional port-Hamiltonian systems](https://arxiv.org/abs/2512.13163)
*Florian Courteville,Iain Henderson,Denis Matignon,Sylvain Dubreuil*

Main category: math.AP

TL;DR: Combines partitioned finite element method with Gaussian processes to learn distributed port-Hamiltonian systems, using late lumping approach to reduce complexity and focusing on nonlinear parts.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for learning distributed port-Hamiltonian systems (dpHs) using Gaussian processes, addressing the challenge of numerical complexity in modeling such systems.

Method: Combines partitioned finite element method (PFEM) with Gp-dpHs method using late lumping approach, discretizing functional hyperparameters independently from dpHs discretization, and models GP prior mean as quadratic form to focus on nonlinear parts.

Result: Demonstrates the method on a nonlinear one-dimensional wave equation with unknown physical parameters (tension and linear mass), showing reduced numerical complexity.

Conclusion: The proposed approach successfully combines PFEM with GP learning for dpHs, enabling efficient modeling with reduced complexity and focusing on nonlinear system components.

Abstract: In order to learn distributed port-Hamiltonian systems (dpHs) using Gaussian processes (GPs), the partitioned finite element method (PFEM) is combined with the Gp-dpHs method. By following a late lumping approach, the discretization of the functional hyperparameters of the GP prior over the Hamiltonian functional is chosen independently from the discretization of the dpHs, thus reducing the numerical complexity of our method. We next model the mean of the GP prior of the Hamiltonian as a quadratic form, enabling the GP kernel to focus on the nonlinear part of a given dpHs. We illustrate our method on a nonlinear one dimensional wave equation with unknown physical parameters (tension and linear mass).

</details>


### [46] [Rigidity of weighted manifolds via classification results for semilinear equations](https://arxiv.org/abs/2512.13181)
*Giulio Ciraolo,Alberto Farina,Troy Petitt*

Main category: math.AP

TL;DR: The paper studies semilinear equations on weighted Riemannian manifolds with non-negative Bakry-√âmery Ricci curvature, focusing on classification of positive solutions at Sobolev-critical exponent and proving rigidity results.


<details>
  <summary>Details</summary>
Motivation: To understand the relationship between existence of positive solutions to semilinear equations and geometric/topological properties of weighted Riemannian manifolds, particularly how solutions imply rigidity of the manifold and triviality of the weight function.

Method: Analyzes model semilinear equations on complete non-compact weighted Riemannian manifolds with non-negative Bakry-√âmery Ricci curvature. Uses geometric analysis techniques to classify positive solutions at Sobolev-critical exponent and prove rigidity theorems under various curvature conditions (finite vs infinite dimensional Bakry-√âmery Ricci curvature). Constructs counterexamples to demonstrate sharpness of conditions.

Result: 1) Classification of positive solutions at Sobolev-critical exponent shows existence implies manifold rigidity and weight triviality. 2) Results hold under non-negative finite dimensional Bakry-√âmery Ricci curvature, and with additional conditions for infinite dimensional case. 3) Constructed non-trivial positive solution on weighted manifold with positive infinite dimensional curvature demonstrates sharpness. 4) Corresponding rigidity result for Liouville equation on weighted Riemannian surfaces. 5) Non-existence theorems for sub-critical nonlinearities and under volume growth conditions, ruling out positive solutions on shrinking gradient Ricci solitons.

Conclusion: The existence of positive solutions to semilinear equations at Sobolev-critical exponent imposes strong geometric constraints on weighted Riemannian manifolds, leading to rigidity results. The conditions are sharp, as demonstrated by counterexamples. The work establishes deep connections between analysis of PDEs and geometric properties of manifolds with Bakry-√âmery curvature.

Abstract: We study model semilinear equations on complete and non-compact weighted Riemannian manifolds with non-negative Bakry-√âmery Ricci curvature. Our main goal is to classify positive solutions of the equation at the Sobolev-critical exponent, and furthermore to prove that the existence of such solutions implies rigidity of the manifold and triviality of the weight.
  This is possible when the weighted manifold has non-negative finite dimensional Bakry-√âmery Ricci curvature, and even under the weaker condition of non-negative infinite dimensional Bakry-√âmery Ricci curvature, up to imposing some additional conditions in the latter case. To exhibit the sharpness of these additional conditions, we construct a non-trivial positive solution of the critical problem on a weighted manifold with positive infinite dimensional curvature.
  We also obtain a corresponding rigidity result for solutions of the Liouville equation on weighted Riemannian surfaces. Finally, we prove some non-existence theorems when the nonlinearity is sub-critical or simply under certain volume growth conditions. In particular, the latter rules out all positive solutions on shrinking gradient Ricci solitons.

</details>


### [47] [An abstract framework for a class of nonlocal structured population models: existence, uniqueness and stability of steady states](https://arxiv.org/abs/2512.13232)
*J√©r√¥me Coville,L√©o Girardin*

Main category: math.AP

TL;DR: Study of nonlinear nonlocal functional evolution problems in Banach algebras, with applications to structured population models. Analysis of well-posedness, stationary solutions, and stability conditions with counterexamples.


<details>
  <summary>Details</summary>
Motivation: To develop a unified abstract framework for analyzing structured population models in biomathematics, addressing the need for rigorous mathematical treatment of nonlinear nonlocal functional evolution problems in Banach algebras.

Method: Introduces an abstract functional setting in Banach algebras that encompasses various structured population models. Analyzes Cauchy problem well-posedness, existence of stationary solutions in positive cones, and derives stability conditions through review of multiple approaches.

Result: Establishes conditions for local and global stability of stationary solutions, provides explicit counterexamples to test limits of these conditions. For mutation-selection models with symmetric mutation operators, identifies sufficient conditions for existence, uniqueness, stability, and presents counterexamples to existence or stability.

Conclusion: The abstract framework successfully unifies analysis of structured population models, providing rigorous mathematical foundations for well-posedness, stationary solutions, and stability analysis, while identifying both sufficient conditions and limitations through counterexamples.

Abstract: This paper is concerned with the study of a class of nonlinear nonlocal functional evolution problems defined in an abstract Banach algebra. We introduce an abstract functional setting that encompasses a wide range of structured population models appearing in biomathematical literature. Within this framework, we analyze the well-posedness of the Cauchy problem and the existence of stationary solutions in the positive cone of the Banach algebra. By reviewing a large number of approaches, we also derive conditions for the local and global stability of these stationary solutions. Additionally, we explore the limits of these conditions by exhibiting explicit counterexamples. In particular, for mutation--selection models with symmetric mutation operators, we uncover both sufficient conditions for existence, uniqueness and stability, and counterexamples to existence or stability.

</details>


### [48] [The principal eigenvalue of an age-structured operator with diffusion and advection: qualitative analysis and an application](https://arxiv.org/abs/2512.13234)
*Hao Kang,Rui Peng,Maolin Zhou*

Main category: math.AP

TL;DR: Study of eigenvalue problem for age-structured operator with random diffusion and advection, focusing on asymptotic behaviors of principal eigenvalue with respect to large advection and extreme diffusion rates, applied to nonlinear age-structured model.


<details>
  <summary>Details</summary>
Motivation: To understand how diffusion and advection influence spatial distribution of species in age-structured populations, particularly examining asymptotic behaviors of principal eigenvalues under extreme parameter regimes.

Method: Construct various types of super- and sub-solutions to handle nonlocal terms in age-structured operator problems, analyze eigenvalue asymptotics with respect to large advection and small/large diffusion rates.

Result: Derived asymptotic behaviors of principal eigenvalue for large advection and extreme diffusion rates, applied results to nonlinear age-structured model to reveal how diffusion and advection affect species spatial distribution.

Conclusion: The analysis provides better understanding of spatial dynamics in age-structured populations, demonstrating how diffusion and advection parameters influence species distribution patterns through eigenvalue asymptotics.

Abstract: In this paper, we investigate an eigenvalue problem associated with an age-structured operator incorporating random diffusion and advection. Our primary focus is on examining the asymptotic behaviors of the principal eigenvalue with respect to large advection and small or large diffusion rates. We subsequently apply these results to a nonlinear age-structured model, providing a better understanding of how diffusion and advection influence the spatial distribution of species. Among other ingredients, our approach involves constructing various types of super- and sub-solutions to tackle the novel challenges posed by the nonlocal terms in the problems under consideration.

</details>


### [49] [A non-local quenching system with coupled and uncoupled singular absorption terms](https://arxiv.org/abs/2512.13291)
*Sergio Junquera*

Main category: math.AP

TL;DR: Study of non-local diffusion system with singular absorption terms, establishing conditions for existence of stationary/quenching solutions and characterizing simultaneous vs non-simultaneous quenching with rates.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of non-local diffusion systems with coupled and uncoupled singular absorption terms, particularly focusing on when solutions exist and how they evolve over time, including quenching phenomena.

Method: Mathematical analysis of a non-local diffusion system with absorption terms of type u^{-p}, using analytical techniques to prove existence conditions and characterize solution behavior.

Result: Established necessary and sufficient conditions for existence of stationary and quenching solutions. Characterized when quenching is simultaneous or non-simultaneous based on absorption exponents, and obtained quenching rates.

Conclusion: The paper provides a complete theoretical framework for understanding non-local diffusion systems with singular absorption, including precise conditions for solution existence and detailed characterization of quenching behavior.

Abstract: In this paper we study a non-local diffusion system of two equations with both coupled and uncoupled singular absorption terms of the type $u^{-p}$. We prove that there exist necessary and sufficient conditions for the existence of both stationary and quenching solutions. We also characterize in terms of the exponents of the absorption terms when the quenching is simultaneous or non-simultaneous and obtain the quenching rates.

</details>


### [50] [Generic regularity and Lipschitz metric for a two-component Novikov system](https://arxiv.org/abs/2512.13305)
*Kenneth H. Karlsen,Yan Rybalko*

Main category: math.AP

TL;DR: The paper analyzes the Cauchy problem for a two-component Novikov equation with cubic nonlinearity, studying global conservative solutions and constructing a Lipschitz metric for solution continuity.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity of global conservative solutions for an integrable system exhibiting strong nonlinear phenomena like gradient blow-up and peakon interactions, and to establish Lipschitz continuity of the solution flow.

Method: Builds on Bressan and Chen's geometric framework for quasilinear second-order wave equations. Uses transformed Bressan-Constantin variables and introduces a Finsler norm on tangent vectors to construct a Lipschitz metric representing minimal energy transportation cost between solutions.

Result: Proves that solutions retain C^k regularity away from a finite number of piecewise C^{k-1} characteristic curves, and provides description of solution behavior near these curves. Constructs a Lipschitz metric that guarantees continuity of the solution flow.

Conclusion: The paper successfully analyzes regularity properties of the two-component Novikov equation and constructs a metric framework that ensures Lipschitz continuity of the solution flow, advancing understanding of integrable systems with strong nonlinear phenomena.

Abstract: We investigate the Cauchy problem for a two-component generalization of the Novikov equation with cubic nonlinearity -- an integrable system whose solutions may develop strong nonlinear phenomena such as gradient blow-up and interactions between peakon-like structures. Our study has two main objectives: first, to analyze the generic regularity of global conservative solutions; and second, to construct a new metric that guarantees the Lipschitz continuity of the flow. Building on the geometric framework developed by Bressan and Chen for quasilinear second-order wave equations, we prove that the solution retains $C^k$ regularity away from a finite number of piecewise $C^{k-1}$ characteristic curves. Furthermore, we provide a description of the solution behavior in the vicinity of these curves. By introducing a Finsler norm on tangent vectors in the space of solutions, expressed in the transformed Bressan-Constantin variables, we introduce a Lipschitz metric representing the minimal energy transportation cost between two solutions.

</details>


### [51] [Fractional and Integer Order Sobolev Spaces for Compact Metric Graphs](https://arxiv.org/abs/2512.13308)
*Elsiddig Awadelkarim,David Bolin,Alexandre B. Simas*

Main category: math.AP

TL;DR: The paper introduces new Sobolev spaces for metric graphs that respect the unique regularity structure of fractional elliptic PDEs, where even-order derivatives are continuous but odd-order derivatives can be discontinuous at vertices.


<details>
  <summary>Details</summary>
Motivation: Standard Sobolev spaces fail to capture the distinctive regularity structure of solutions to fractional elliptic PDEs on metric graphs, where even-order derivatives are continuous across vertices but odd-order derivatives may be discontinuous. This prevents direct application of classical functional analysis tools.

Method: The authors define new families of Sobolev spaces W^{Œ±,p}(Œì) and H^Œ±(Œì) tailored to metric graphs, respecting continuity constraints on even-order derivatives while permitting discontinuities in odd-order derivatives. They systematically study their properties including characterizations, embedding theorems, and compactness results.

Result: The paper establishes fundamental properties of the new Sobolev spaces, derives uniform bounds on eigenfunction supremum norms, and demonstrates these spaces provide a natural framework for analyzing regularity of fractional elliptic PDEs and SPDEs on metric graphs. They characterize domains of fractional powers of Laplacians and improve regularity results to sharp counterparts.

Conclusion: The introduced Sobolev spaces are fundamental for analyzing fractional PDEs on metric graphs, extending all previously known characterizations, improving regularity results to sharp versions, and providing a framework for studying Gaussian free fields on metric graphs.

Abstract: Given a compact metric graph $Œì$ and the Laplacian $Œî_Œì$ coupled with standard (Kirchhoff) vertex conditions, solutions to fractional elliptic partial differential equations of the form $(Œ∫^2 - Œî_Œì)^{Œ±/2}u=f$ on $Œì$ exhibit a distinctive regularity structure: even-order derivatives are continuous across vertices, while odd-order derivatives may be discontinuous. This non-standard smoothness property precludes the direct application of classical tools from real functional analysis. Because of this, we introduce and systematically study new families of Sobolev spaces tailored to this setting. We define these spaces, denoted $W^{Œ±,p}(Œì)$ and $H^Œ±(Œì)$, to respect the continuity constraints on even-order derivatives at vertices, while permitting discontinuities in odd-order derivatives. We establish their fundamental properties, including characterizations, embedding theorems into H√∂lder and Lebesgue spaces, and compactness results. A central contribution in this investigation is the derivation of uniform bounds on the supremum norm of eigenfunctions for a class of Laplacians on metric graphs, a result of independent interest. Finally, we demonstrate that these spaces provide a natural framework for analyzing the regularity of solutions to fractional elliptic PDEs and SPDEs driven by Gaussian white noise on metric graphs, in particular, establishing a general characterization of the domain of the fractional powers of $(Œ∫^2-Œî_Œì)$ and $(Œ∫^2-\nabla(a\nabla))$ in terms of the Sobolev spaces we introduce, thereby extending all previously known characterizations in the literature, and improving the regularity results previously obtained to their sharp counterparts (with general fractional powers). We also show that these spaces are fundamental to the characterization of Gaussian free fields on metric graphs.

</details>


### [52] [Estimating parameters of the diffusion model via asymptotic expansions](https://arxiv.org/abs/2512.13419)
*Konstantinos Kalimeris,Leonidas Mindrinos*

Main category: math.AP

TL;DR: The paper presents a method for estimating diffusion parameters in heat equation models from single measurements using asymptotic analysis of integral equations derived via the Fokas method.


<details>
  <summary>Details</summary>
Motivation: Inverse problems for determining parameters in PDE models from measurement data are important in various applications. The paper focuses on estimating diffusion parameters in the heat equation from limited measurements, which has practical applications in fields like soil science.

Method: The approach uses the Fokas method to formulate an integral equation from the direct problem solution. Asymptotic evaluation of the associated integrals yields approximate solutions. The method extends to estimating additional parameters like interval length and time to achieve specific states.

Result: The asymptotic approximations provide effective solutions supported by numerical verifications. When applied to soil science problems, the method shows clear improvement over existing approaches.

Conclusion: The proposed method successfully estimates diffusion parameters and other related quantities in heat equation models from single measurements, demonstrating practical utility and improved performance in real-world applications like soil science.

Abstract: A broad class of inverse problems deals with determining certain parameters, from measurement data, in models which are associated to certain partial differential equations. In this work we focus on the heat equation on a finite interval and we determine the dimensionless diffusion parameter from a single measurement. Our results extend to estimating additional parameters of the initial-boundary value problem, such as the length of the interval and/or the time required for the solution to achieve a specific state. Our approach relies on the asymptotic solution of an integral equation: The formulation of this integral equation is based on the solution of the direct problem via the Fokas method; the solution of this equation is achieved through the asymptotic evaluation of the associated integrals which yield an effective approximate solution, supported by numerical verifications. We apply these approximations to well-established problems in soil science and we compare our results with existing ones, displaying clear improvement.

</details>


### [53] [Growth estimates for axisymmetric Euler equations without swirl](https://arxiv.org/abs/2512.13456)
*Khakim Egamberganov,Yao Yao*

Main category: math.AP

TL;DR: The paper establishes upper and lower bounds for growth of solutions to axisymmetric Euler equations without swirl in ‚Ñù¬≥, proving optimal upper bound t¬≤ for radial moment and at least t/log t growth for certain initial data.


<details>
  <summary>Details</summary>
Motivation: To understand the growth behavior of solutions to the 3D axisymmetric Euler equations without swirl, particularly establishing optimal growth rates for the radial moment and L^p norms, which addresses conjectures about potential finite-time singularity formation.

Method: Analyzes axisymmetric Euler equations in ‚Ñù¬≥ without swirl, uses radial moment ‚à´‚Ñù¬≥ rœâ^Œ∏dx as key quantity, establishes upper bounds via mathematical analysis techniques, and proves lower bounds for initial data with specific symmetry and sign conditions.

Result: Proves optimal upper bound t¬≤ for radial moment growth (matching Childress conjecture), shows at least t/log t growth for radial moment under certain conditions, establishes at least t^{1/4} growth for L^p norms in limsup sense for all 1‚â§p‚â§‚àû, and demonstrates vorticity escapes to infinity in time-integral sense.

Conclusion: This provides the first rigorous power-law L^p-norm growth results for smooth, compactly supported initial vorticity in ‚Ñù¬≥, confirming significant growth behavior in axisymmetric Euler equations and supporting theoretical understanding of potential singularity formation.

Abstract: We consider the axisymmetric Euler equations in $\mathbb{R}^3$ without swirl, and establish several upper and lower bounds for the growth of solutions. On the one hand, we obtain an upper bound $t^2$ for the radial moment $\int_{\mathbb{R}^3} rœâ^Œ∏dx$, which is the conjectured optimal rate by Childress (Phys. D 237(14-17):1921-1925, 2008). On the other hand, for all initial data satisfying certain symmetry and sign conditions, we prove that the radial moment grows at least like $t/\log t$ as time goes to infinity, and $\|œâ(\cdot,t)\|_{L^p(\mathbb{R}^3)}$ exhibits at least $t^{1/4}$ growth in the limsup sense for all $1\leq p\leq \infty$. To the best of our knowledge, this is the first result to establish power-law $L^p$-norm growth for smooth, compactly supported initial vorticity in $\mathbb{R}^3$. For these initial data, we also show that nearly all vorticity must eventually escape to $r\to\infty$ in the time-integral sense.

</details>


### [54] [Evolution equation with fractional Schr√∂dinger operators: monotonicity and exponential decay of solutions in Morrey spaces](https://arxiv.org/abs/2512.13499)
*Jan W. Cholewa,Anibal Rodriguez-Bernal*

Main category: math.AP

TL;DR: Study of evolution equations with fractional Schr√∂dinger operators in Morrey spaces, focusing on semigroup properties, monotonicity with respect to potentials, and exponential growth/decay conditions.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of evolution equations with fractional Schr√∂dinger operators in the more general setting of Morrey spaces, which extend beyond classical Lebesgue spaces, and to understand how semigroup properties are affected by Morrey-scale potentials.

Method: Using semigroup theory in Morrey spaces, proving order preserving properties of the semigroup, establishing monotonicity with respect to Morrey potentials, and analyzing exponential growth/decay through precise estimates and conditions on potentials.

Result: Proved order preserving properties in Morrey scale, monotonicity with respect to Morrey potentials, precise exponential growth estimates, and showed that Arendt-Batty type condition is necessary for exponential decay, identifying a large class of dissipative potentials where it's also sufficient.

Conclusion: The paper establishes fundamental properties of fractional Schr√∂dinger semigroups in Morrey spaces, providing necessary and sufficient conditions for exponential decay and identifying classes of potentials that ensure dissipative behavior in this generalized functional setting.

Abstract: We consider evolution equation with fractional Schr√∂dinger operators in Morrey spaces. We prove order preserving properties of the associated semigroup in Morrey scale. We prove monotonicity of the semigroup with respect to Morrey's potentials and give some precise estimates of its exponential growth. We show that Arendt and Batty's type condition on the potential is necessary for exponential decay of Morrey's norms of the semigroup and find a large class of dissipative potentials for which it is also sufficient.

</details>


### [55] [Well-posedness of multidimensional nonlocal conservation laws with nonlinear mobility and bounded force](https://arxiv.org/abs/2512.13535)
*Antonin Chodron de Courcel*

Main category: math.AP

TL;DR: Local existence and uniqueness for nonlocal conservation laws with nonlinear mobility in multiple dimensions, with bounded finite-variation kernels. Solutions can develop shocks even with smooth kernels. Entropy solutions constructed via vanishing viscosity with convergence rate.


<details>
  <summary>Details</summary>
Motivation: Study nonlocal conservation laws with nonlinear mobility, which differ from linear mobility cases where shocks may form even with smooth kernels. Address the need for existence/uniqueness results under weak kernel assumptions in multiple dimensions.

Method: Vanishing viscosity method to construct entropy solutions. Assumes kernels are bounded and have finite total variation. Provides convergence rate for the approximation scheme.

Result: Establishes local-in-time existence and uniqueness for solutions. Shows solutions may develop shocks in finite time even with smooth kernels (unlike linear mobility case). Provides convergence rate for vanishing viscosity approximation.

Conclusion: Nonlocal conservation laws with nonlinear mobility exhibit different shock formation behavior than linear cases. The vanishing viscosity method successfully constructs entropy solutions with quantified convergence rates under weak kernel assumptions.

Abstract: We establish local-in-time existence and uniqueness results for nonlocal conservation laws with a nonlinear mobility, in several space dimensions, under weak assumptions on the kernel, which is assumed to be bounded and of finite total variation. Contrary to the linear mobility case, solutions may develop shocks in finite time, even when the kernel is smooth. We construct entropy solutions via a vanishing viscosity method, and provide a rate of convergence for this approximation scheme.

</details>


### [56] [Exponential Absolute Minimizing extension and biased infinity Laplacian](https://arxiv.org/abs/2512.13664)
*Yang Chu*

Main category: math.AP

TL;DR: The paper introduces Œ≤-Exponential Absolute Minimizing Extension (Œ≤-AM) on length spaces, generalizing classical absolute minimizing Lipschitz extensions to include a bias term Œ≤. This corresponds to biased infinity Laplacian equations and arises from biased tug-of-war games.


<details>
  <summary>Details</summary>
Motivation: To extend the theory of absolute minimizing Lipschitz extensions and infinity Laplacian equations to include a bias parameter Œ≤, creating a more general framework that includes classical results as special cases (when Œ≤=0).

Method: Introduces Œ≤-Exponential Absolute Minimizing Extension (Œ≤-AM) on arbitrary length spaces using exponential slope functional L^Œ≤_u(E). Defines Exponential McShane-Whitney-type extension and Œ≤-biased convexity as equivalent characterizations. Shows connection to biased tug-of-war games and studies properties of these extensions.

Result: Establishes that Œ≤-AM generalizes classical absolute minimizing Lipschitz extensions, corresponds to viscosity solutions of Œî^Œ≤_‚àû u = 0 (biased infinity Laplacian), arises as continuum limit of biased tug-of-war games, and satisfies linear blow-up property for biased infinity harmonic functions.

Conclusion: The Œ≤-AM framework provides a natural generalization of absolute minimizing Lipschitz extensions that incorporates bias, connects to biased infinity Laplacian equations and tug-of-war games, and preserves key properties while extending the theory to more general settings.

Abstract: We study the variational structure of the biased infinity Laplacian by introducing a notion of the $Œ≤$\textit{-Exponential Absolute Minimizing Extension} ($Œ≤$--AM) on arbitrary length space, which absolutely minimizing the exponential slope
  $$ L^Œ≤_u (E) := Œ≤\sup_{x,y \in E} \frac{u(y) - e^{-Œ≤|x-y|} u(x)}{1- e^{-Œ≤|x-y|}}. $$We also define the corresponding Exponential McShane-Whitney-type extension, and $Œ≤$-biased convexity, which equivalently characterize $Œ≤$-AM and may be of independent interest. These generalize the classical Absolute Minimizing Lipschitz Extension as a special case when $Œ≤= 0$. In Euclidean space with Euclidean norm, this corresponds to the Aronsson equation with Hamiltonian \[ H(u, \nabla u) = |\nabla u| + Œ≤u, \] equivalently viscosity solutions of $Œî_{\infty}^Œ≤ u = 0$. We show that $Œ≤$-AM arises as the continuum value of a biased tug-of-war game. Analogous to the unbiased case, we derive various properties of this extension. As an application, we further show that the linear blow-up property holds for biased infinity harmonic functions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [57] [HWF-PIKAN: A Multi-Resolution Hybrid Wavelet-Fourier Physics-Informed Kolmogorov-Arnold Network for solving Collisionless Boltzmann Equation](https://arxiv.org/abs/2512.12001)
*Mohammad E. Heravifard,Kazem Hejranfar*

Main category: physics.comp-ph

TL;DR: Proposed HWF-PIKAN: a multi-resolution hybrid wavelet-Fourier-enhanced physics-informed KAN for solving advection problems and collisionless Boltzmann equations with improved accuracy and convergence.


<details>
  <summary>Details</summary>
Motivation: Physics-informed neural networks (PINNs) and physics-informed KANs (PIKANs) show promise for solving PDEs without extensive labeled data, but need enhancement for handling both continuous and discontinuous features in advection problems and high-dimensional phase-space settings.

Method: Developed a hybrid wavelet-Fourier-enhanced PIKAN (HWF-PIKAN) that combines multi-resolution spectral feature embeddings. Applied to advection equations in 1D/2D and extended to high-dimensional phase-space for solving collisionless Boltzmann equation using Hamiltonian phase-space dynamics.

Result: HWF-PIKAN accurately captures both smooth and abrupt features in advection problems. Outperforms vanilla PINN, vanilla PIKAN, and single-modality Fourier/wavelet-enhanced variants in solution accuracy and convergence speed for complex kinetic equations.

Conclusion: Multi-resolution spectral feature embeddings significantly advance physics-informed deep learning for complex kinetic equations in both space-time and phase-space domains, demonstrating the power of hybrid wavelet-Fourier enhancements in PIKAN frameworks.

Abstract: Physics-Informed Neural Networks (PINNs) and more recently Physics-Informed Kolmogorov-Arnold Networks (PIKANs) have emerged as promising approaches for solving partial differential equations (PDEs) without reliance on extensive labeled data. In this work, we propose a novel multi-resolution Hybrid Wavelet-Fourier-Enhanced Physics-Informed Kolmogorov-Arnold Network (HWF-PIKAN) for solving advection problems based on collisionless Boltzmann equation (CBE) with both continuous and discontinuous initial conditions. To validate the effectiveness of the proposed model, we conduct systematic benchmarks on classical advection equations in one and two dimensions. These tests demonstrate the model's ability to accurately capture smooth and abrupt features. We then extend the application of HWF-PIKAN to the high-dimensional phase-space setting by solving the CBE in a continuous-velocity manner. This leverages the Hamiltonian concept of phase-space dynamics to model the statistical behavior of particles in a collisionless system, where advection governs the evolution of a probability distribution function or number density. Comparative analysis against Vanilla PINN, Vanilla PIKAN, as well as Fourier-enhanced and Wavelet-enhanced PIKAN variants, shows that the proposed hybrid model significantly improves solution accuracy and convergence speed. This study highlights the power of multi-resolution spectral feature embeddings in advancing physics-informed deep learning frameworks for complex kinetic equations in both space-time and phase-space.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [58] [JAX-in-Cell: A Differentiable Particle-in-Cell Code for Plasma Physics Applications](https://arxiv.org/abs/2512.12160)
*Longyu Ma,Rogerio Jorge,Hongke Lu,Aaron Tran,Christopher Woolford*

Main category: physics.plasm-ph

TL;DR: JAX-in-Cell is a modern, fully electromagnetic 1D3V Particle-in-Cell framework implemented in JAX that bridges educational scripts and production codes with auto-differentiation capabilities.


<details>
  <summary>Details</summary>
Motivation: To create a modern Python-based alternative to traditional PIC frameworks that leverages JAX's capabilities for performance on CPUs/GPUs/TPUs and enables differentiable physics and AI integration.

Method: Implements a fully electromagnetic, multispecies, relativistic 1D3V PIC framework in JAX using Just-In-Time compilation and automatic vectorization. Solves Vlasov-Maxwell system on staggered Yee lattice with various boundary conditions, offering both explicit Boris solver and implicit Crank-Nicolson method via Picard iteration.

Result: Achieves performance comparable to traditional compiled codes while providing a testbed for differentiable physics and AI integration with end-to-end gradient-based optimization capabilities.

Conclusion: JAX-in-Cell successfully bridges the gap between educational PIC scripts and production codes, offering a modern framework that combines high performance with auto-differentiation capabilities for advanced physics and AI applications.

Abstract: JAX-in-Cell is a fully electromagnetic, multispecies, and relativistic 1D3V Particle-in-Cell (PIC) framework implemented entirely in JAX. It provides a modern, Python-based alternative to traditional PIC frameworks. It leverages Just-In-Time compilation and automatic vectorization to achieve the performance of traditional compiled codes on CPUs, GPUs, and TPUs. The resulting framework bridges the gap between educational scripts and production codes, providing a testbed for differentiable physics and AI integration that enables end-to-end gradient-based optimization. The code solves the Vlasov-Maxwell system on a staggered Yee lattice with either periodic, reflective, or absorbing boundary conditions, allowing both an explicit Boris solver and an implicit Crank-Nicolson method via Picard iteration to ensure energy conservation. Here, we detail the numerical methods employed, validate against standard benchmarks, and showcase the use of its auto-differentiation capabilities.

</details>


### [59] [Large Errors in Kinetic Temperature Measurements Using Particle Tracking Velocimetry](https://arxiv.org/abs/2512.12163)
*Anton Kananovich,Parth Mehrotra,Surabhi Jaiswal*

Main category: physics.plasm-ph

TL;DR: Random errors in kinetic temperature measurements from particle tracking velocimetry due to position uncertainty, with spatial resolution being more critical than frame rate.


<details>
  <summary>Details</summary>
Motivation: To understand and quantify how position uncertainty in particle tracking velocimetry affects kinetic temperature measurements, particularly the relative importance of spatial resolution versus frame rate.

Method: Used simulated data with particles following Maxwellian distribution at known temperature. Particle positions were randomly assigned and roughened to match prescribed spatial resolution. Velocities were restored using two-frame tracking method, and kinetic temperature was calculated. Procedure repeated to obtain discrepancy as function of spatial resolution and frame rate.

Result: Under typical experimental conditions, restored kinetic temperature can deviate significantly from true value, with spatial resolution playing a more dominant role than frame rate in causing measurement errors.

Conclusion: Position uncertainty in particle tracking velocimetry introduces significant errors in kinetic temperature measurements, with spatial resolution being the primary factor affecting accuracy rather than frame rate.

Abstract: We report on random errors in kinetic temperature measurements due to position uncertainty in particle tracking velocimetry. Using simulated data, we isolate the effects of spatial resolution and the frame rate on particle velocity calculations. A sample of particle velocities is generated from a Maxwellian distribution at a known temperature. Particle positions are assigned randomly and roughened to match a prescribed spatial resolution. Velocities are restored using the two-frame tracking method, and the kinetic temperature is calculated. By repeating this procedure, we obtain the discrepancy as a function of the spatial resolution and frame rate. Results show that, under typical experimental conditions, the restored kinetic temperature can deviate significantly from the true value, with spatial resolution playing a more dominant role than the frame rate.

</details>


### [60] [Charged particle energization by low-amplitude electrostatic waves at cyclotron harmonics](https://arxiv.org/abs/2512.13184)
*F. Sattin. L. Martinelli*

Main category: physics.plasm-ph

TL;DR: Charged particles in perpendicular electrostatic waves below stochastic threshold can still gain energy through non-adiabatic dynamics, not just through stochastic heating.


<details>
  <summary>Details</summary>
Motivation: Previous studies focused on stochastic heating above threshold potential, but sub-threshold dynamics were overlooked despite periodic oscillations always occurring.

Method: Analytical and numerical analysis of charged particle dynamics in perpendicular electrostatic waves with frequency above cyclotron frequency.

Result: Particle motion is non-adiabatic - particles don't return to initial state when wave is slowly turned off, enabling energy gain even below stochastic threshold.

Conclusion: Sub-threshold electrostatic waves can energize particles through non-adiabatic dynamics, expanding understanding of particle heating mechanisms in magnetized plasmas.

Abstract: The system made by a charged particle interacting with a single electrostatic wave which propagates perpendicularly to the magnetic field, at a frequency larger than the cyclotron one, has been extensively studied in literature due to its implications with ion heating in magnetized plasmas. It is known that a threshold in the electrostatic potential must be exceeded in order for stochastic particle motion and heating to occur. Regardless its amplitude, however, the electrostatic wave induces a periodic oscillation in the particle motion. We show, by analytical and numerical arguments, that this dynamics is non-adiabatic, meaning that the particle does not land back to its initial state when the wave is slowly turned off. This way, particle energization (although, not rigorously heating) occurs even under sub-threshold conditions.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [61] [DoNOF 2.0: A modern Open-Source Electronic Structure Program for Natural Orbital Functionals](https://arxiv.org/abs/2512.13550)
*Juan Felipe Huan Lew-Yee,Ion Mitxelena,Jorge M. del Campo,and Mario Piris*

Main category: physics.chem-ph

TL;DR: DoNOF 2.0 is an open-source natural orbital functional software with improved optimization, excited-state calculations, molecular dynamics, and enhanced property evaluation including nonlinear optical responses.


<details>
  <summary>Details</summary>
Motivation: To provide an enhanced, open-source computational chemistry tool for natural orbital functional calculations with broader capabilities for excited states, molecular dynamics, and property evaluation.

Method: Natural orbital functional theory implemented in Fortran with Python and Julia interfaces, using improved optimization algorithms, finite-field Romberg-Richardson scheme for nonlinear optical properties, and hybrid OpenMPI/OpenMP parallelization.

Result: Release of DoNOF 2.0 with expanded capabilities including excited-state computations, ab initio molecular dynamics, integration with libcint library, and evaluation of static polarizabilities and higher-order hyperpolarizabilities.

Conclusion: DoNOF 2.0 represents a significant upgrade to the natural orbital functional software, providing researchers with enhanced computational tools for electronic structure calculations and property evaluation in an open-source framework.

Abstract: In this work, we present the second version of the Donostia Natural Orbital Functional Software, an open-source program for natural orbital functional calculations. The new release incorporates improved optimization algorithms, capabilities for excited-state computations, support for ab initio molecular dynamics, and integration with the libcint library. DoNOF 2.0 also extends its property toolbox by enabling the evaluation of nonlinear optical responses, including static polarizabilities and higher-order hyperpolarizabilities via a finite-field Romberg-Richardson scheme. Program Summary [Title: DoNOF; Developer's repository link: http://github.com/DoNOF/; Program's Manual link: https://donof.readthedocs.io/; Licensing provisions: GPLv3; Programming language: Fortran; additional implementations available in Python (PyNOF) and Julia (DoNOF.jl); Multinode capability: Support for distributed execution through a hybrid OpenMPI and OpenMP implementation]

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [62] [Large Deviation Properties of Minimum Spanning Trees for Random Graphs](https://arxiv.org/abs/2512.13418)
*Mahdi Sarikhani,Alexander K. Hartmann*

Main category: cond-mat.dis-nn

TL;DR: Large-deviation analysis of minimum spanning tree weight distributions for complete graphs and connected Erd≈ës-R√©nyi random graphs, revealing distribution changes at percolation threshold.


<details>
  <summary>Details</summary>
Motivation: To understand the statistical properties and extreme-value behavior of minimum spanning trees in random graph ensembles, particularly how their weight distributions behave in the large-deviation regime and whether they follow the large deviation principle.

Method: Used large-deviation Markov chain sampling to obtain distribution P(W) of spanning-tree weight W down to extremely small probability densities (10^{-300}). Studied two ensembles: complete graphs and Erd≈ës-R√©nyi random graphs with edge probability p=c/N conditioned to be connected.

Result: For complete graphs, confirmed analytical predictions for expectation values. For both ensembles, the large deviation principle is fulfilled. For connected ER graphs, observed a remarkable change in distributions at c=1, which corresponds to the percolation threshold of the original ER ensemble.

Conclusion: Minimum spanning tree weight distributions exhibit large deviation behavior that follows the large deviation principle, with ER graphs showing a phase transition-like change at the percolation threshold, revealing connections between spanning tree properties and graph connectivity transitions.

Abstract: We study the large-deviation properties of minimum spanning trees for two ensembles of random graphs with $N$ nodes. First, we consider complete graphs. Second, we study Erd≈ës-R√©nyi (ER) random graphs with edge probability $p=c/N$ conditioned to be connected. By using large-deviation Markov chain sampling, we are able to obtain the distribution $P(W)$ of the spanning-tree weight $W$ down to probability densities as small as $10^{-300}$. For the complete graph, we confirm analytical predictions with respect to the expectation value. For both ensembles, the large deviation principle is fulfilled. For the connected ER graphs, we observe a remarkable change of the distributions at the value of $c=1$, which is the percolation threshold for the original ER ensemble.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [63] [Irregular Stanley sequences plausibly do not have growth $Œò(n^2/\log n)$](https://arxiv.org/abs/2512.11983)
*Nat Sothanaphan*

Main category: math.NT

TL;DR: Numerical evidence challenges the conjectured Œò(n¬≤/log n) growth rate for Stanley sequences starting from {0,4}, suggesting instead O(n¬≤/log n) upper bound but Œ©(n^{2-Œ¥}) lower bound.


<details>
  <summary>Details</summary>
Motivation: To investigate the long-standing conjecture about Stanley sequences starting from {0,n}, which are hypothesized to have either regular (Œò(n^{log‚ÇÇ(3)})) or irregular (Œò(n¬≤/log n)) growth rates. The n=4 case has been considered a paradigmatic candidate for irregular type, but no n has been proven to have such growth rate.

Method: The paper uses numerical methods to analyze the growth rate of Stanley sequences starting from {0,4}. The authors provide strong numerical evidence against the conjectured Œò(n¬≤/log n) growth rate for this specific case.

Result: Numerical evidence suggests that for n=4, the upper bound might be O(n¬≤/log n) but the lower bound appears to be Œ©(n^{2-Œ¥}) for some Œ¥>0, contradicting the conjectured Œò(n¬≤/log n) growth rate. This indicates the sequence is not as "random" as previously assumed.

Conclusion: The conjectured Œò(n¬≤/log n) growth rate for Stanley sequences starting from {0,4} is likely incorrect. The actual growth appears to have different upper and lower bounds, suggesting the sequence exhibits more structure than previously thought. The paper also discusses limitations of the numerical approach used.

Abstract: Stanley sequences starting from the set $\{0, n\}$ where $n$ is a positive integer have long been conjectured to be divided into two types: the "regular" type where the growth rate is $Œò(n^{\log_2(3)})$, and the "irregular" type where the growth rate is thought to be $Œò(n^2/\log n)$. A paradigmatic case of a candidate irregular type is $n=4$, although to date no value of $n$ has been proven to have such a growth rate. Here, we provide strong numerical evidence against this conjectured growth rate for $n=4$. Specifically, for $n=4$, it seems plausible that the upper bound is $O(n^2/\log n)$ but that the lower bound is in fact $Œ©(n^{2-Œ¥})$ for some $Œ¥> 0$. This appears to be because the sequence is not totally "random" as has been assumed. Limitations of the numerical method here is discussed.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [64] [What are Switchbacks?](https://arxiv.org/abs/2512.12585)
*Zesen Huang,Marco Velli,Yuliang Ding*

Main category: physics.space-ph

TL;DR: A 3D Alfv√©n wave model produces switchback-like field reversals through curved magnetic field lines, matching Parker Solar Probe observations.


<details>
  <summary>Details</summary>
Motivation: To explain the "switchbacks" (sudden magnetic field reversals) observed by Parker Solar Probe in the solar wind, which appear as one-dimensional profiles but likely originate from three-dimensional magnetic field structures.

Method: Developed a solitary Alfv√©n wave model with nontrivial 3D twisting of open magnetic field lines while maintaining constant magnetic field magnitude. The model uses embedded rotational discontinuities to sharply deflect otherwise uniform field lines.

Result: The model produces localized, large-amplitude field reversals in one-dimensional profiles that closely resemble the switchbacks observed by Parker Solar Probe. This shows that switchbacks in spacecraft time series arise from traversals through strongly curved segments of open magnetic field lines.

Conclusion: Switchbacks observed in one-dimensional spacecraft data are manifestations of three-dimensional magnetic field line curvature, specifically from traversals through sharply curved segments of open magnetic field lines in the inner heliosphere.

Abstract: We present a solitary Alfv√©n wave model that exhibits nontrivial three-dimensional twisting of open magnetic field lines while preserving constant $|B|$. Embedded rotational discontinuities sharply deflect the otherwise uniform field lines, producing localized, large-amplitude field reversals in one-dimensional profiles that closely resemble the ``switchbacks'' observed by the Parker Solar Probe in the inner heliosphere. This indicates that switchbacks, as seen in one-dimensional spacecraft time series, arise from traversals through strongly curved segments of open magnetic field lines.

</details>


<div id='astro-ph.GA'></div>

# astro-ph.GA [[Back]](#toc)

### [65] [Reconnection-Driven Turbulent Fluctuations in the Magnetically Dominated Collisionless Regime](https://arxiv.org/abs/2512.12516)
*Yue Hu,Luca Comisso,Lorenzo Sironi,Siyao Xu*

Main category: astro-ph.GA

TL;DR: 3D particle-in-cell simulations reveal turbulence statistics in collisionless magnetic reconnection: velocity fluctuations show Kolmogorov-like scaling (~1/3), magnetic fluctuations are steeper (~0.6-0.8), with guide fields increasing magnetic intermittency and local anisotropies.


<details>
  <summary>Details</summary>
Motivation: Despite magnetic reconnection's fundamental importance in converting magnetic energy to plasma energy, the statistical properties of turbulent fluctuations generated by collisionless reconnection remain poorly understood, hindering our understanding of energy conversion processes.

Method: Used large-scale 3D particle-in-cell simulations to investigate turbulence characteristics in magnetically dominated plasmas. Computed structure functions along different directions (inflow, outflow, guide-field) within the reconnection layer to characterize statistical properties.

Result: Velocity fluctuations show Kolmogorov-like power-law scaling (~1/3 slope) across all directions. Magnetic fluctuations exhibit steeper slopes (~0.6-0.8). Guide fields don't affect velocity scaling but steepen magnetic scaling in guide-field and inflow directions. Strong magnetic intermittency found along outflow direction, with increased local anisotropies for stronger guide fields.

Conclusion: This study provides the first systematic characterization of multiscale turbulence in collisionless reconnection layers, revealing distinct statistical properties for velocity and magnetic fluctuations, with important implications for understanding plasma heating and particle acceleration mechanisms.

Abstract: Magnetic reconnection is a fundamental plasma process that converts magnetic energy into bulk flow energy, thermal energy, and nonthermal particle acceleration. Despite its importance, the statistical properties of the turbulent fluctuations generated by collisionless reconnection, which are essential for understanding how this energy conversion proceeds, remain poorly understood. Here, we employ large-scale 3D particle-in-cell simulations to investigate the turbulence characteristics of velocity and magnetic field fluctuations generated by collisionless reconnection in a magnetically dominated plasma. We characterize their statistical properties by computing structure functions along different directions within the reconnection layer. We find that the square root of the second-order velocity structure function follows a power-law scaling with a slope near $\sim1/3$ at intermediate to large scales, consistent with Kolmogorov-like turbulence, a behavior robust along the inflow, outflow, and guide-field directions. The square root of the second-order magnetic structure function consistently exhibits a steeper slope, in the range $\sim 0.6 - 0.8$. The presence of a finite guide field does not systematically modify the slope of the velocity fluctuations, while it progressively steepens the scaling of the magnetic fluctuations in the guide-field and inflow directions. We also measure higher-order structure functions, which reveal strong magnetic intermittency along the outflow direction and weaker intermittency in the inflow and guide-field directions. In addition, the local anisotropies of both velocity and magnetic field fluctuations are greater for stronger guide fields. These results provide a first systematic characterization of the multiscale nature of turbulence in collisionless reconnection layers, with important implications for plasma heating and particle acceleration.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [66] [Structure versus regularity of set-valued maps in convex generalized Nash equilibrium problems in Banach spaces](https://arxiv.org/abs/2512.12831)
*Marcelo Bongarti,Michael Hinterm√ºller*

Main category: math.OC

TL;DR: This paper addresses existence of generalized Nash equilibria in Banach spaces, replacing the standard lower semicontinuity assumption with graph convexity or KKM properties, which are easier to verify in PDE-constrained settings.


<details>
  <summary>Details</summary>
Motivation: The standard assumption of lower semicontinuity for constraint maps in GNEPs is difficult to verify in function spaces and PDE-constrained settings, even in convex cases. There's a need for alternative, more verifiable conditions that can ensure equilibrium existence.

Method: The authors replace lower semicontinuity requirements with graph convexity or Knaster-Kuratowski-Mazurkiewicz (KKM) properties for constraint maps. They develop an analytic framework using these alternative conditions and extend Rosen's uniqueness condition to Banach spaces via multiplier bias. They also present a complementary geometric approach using preference maps.

Result: The paper shows that equilibrium existence can be established without lower semicontinuity by using graph convexity or KKM properties instead. These alternative conditions are often easier to verify in practical applications, particularly in function spaces and PDE-constrained problems. The results unify existing existence theorems and clarify the structural role of constraint maps.

Conclusion: The paper provides more practical conditions for equilibrium existence in GNEPs in Banach spaces, particularly valuable for applications in optimal control and PDE-constrained settings where verifying lower semicontinuity is challenging. The approach offers a unified framework that simplifies verification while maintaining theoretical rigor.

Abstract: A generalized Nash equilibrium problem (GNEP) in Banach space consists of $N>1$ optimal control problems with couplings in both the objective functions and, most importantly, in the feasible sets. We address the existence of equilibria for convex GNEPs in Banach space. We show that the standard assumption of lower semicontinuity of the set-valued constraint maps - foundational in the current literature on GNEPs - can be replaced by graph convexity or the so-called Knaster-Kuratowski-Mazurkiewicz (KKM) property. Lower semicontinuity is often essential for obtaining upper semicontinuity of best response maps, crucial for the existence theory based on Kakutani-Fan fixed-point arguments. However, in function spaces or PDE-constrained settings, verifying lower semicontinuity becomes much more challenging (even in convex cases), whereas graph convexity, for example, is often straightforward to check. Our results unify several existence theorems in the literature and clarify the structural role of constraint maps. We also extend Rosen's uniqueness condition to Banach spaces using a multiplier bias framework. Additionally, we present a geometric counterpart to our analytic framework using preference maps. This geometric is intended as a complement to, rather than a replacement for, the analytic theory developed in the main body of the paper.

</details>


### [67] [A bilinear pointwise tracking optimal control problem for a semilinear elliptic PDE](https://arxiv.org/abs/2512.12854)
*Enrique Otarola,Daniel Quero,Matias Sasso*

Main category: math.OC

TL;DR: The paper analyzes a bilinear optimal control problem for semilinear elliptic PDEs with pointwise tracking, establishing existence of optimal solutions, optimality conditions, and regularity results for controls.


<details>
  <summary>Details</summary>
Motivation: To study optimal control problems where the control enters as a reaction coefficient in semilinear elliptic PDEs and the cost functional involves point evaluations of the state, which leads to challenging mathematical analysis due to Dirac measures in the adjoint problem.

Method: Mathematical analysis of bilinear optimal control problems using variational methods, deriving existence results, analyzing first and second order optimality conditions, and proving regularity properties for optimal controls in Lipschitz and convex polygonal domains.

Result: Proved existence of optimal solutions, established first and necessary/sufficient second order optimality conditions, showed that locally optimal controls belong to H¬π(Œ©), and for convex polygons in ‚Ñù¬≤, proved that optimal controls are Lipschitz continuous.

Conclusion: The paper provides a comprehensive mathematical analysis of bilinear optimal control problems with pointwise tracking, establishing important theoretical foundations including existence, optimality conditions, and regularity results for optimal controls in various domain settings.

Abstract: We consider a bilinear optimal control problem with pointwise tracking for a semilinear elliptic PDE in two and three dimensions. The control variable enters the PDE as a (reaction) coefficient and the cost functional contains point evaluations of the state variable. These point evaluations lead to an adjoint problem with a linear combination of Dirac measures as a forcing term. In Lipschitz domains, we derive the existence of optimal solutions and analyze first and necessary and sufficient second order optimality conditions. We also prove that every locally optimal control $\bar u$ belongs to $H^1(Œ©)$. Finally, assuming that the domain $Œ©\subset \mathbb{R}^2$ is a convex polygon, we prove that $\bar u \in C^{0,1}(\bar Œ©)$.

</details>


### [68] [Local controllability in finite time and the controllable time of the Korteweg-De Vries equation using the right Neumann controls](https://arxiv.org/abs/2512.13066)
*Hoai-Minh Nguyen*

Main category: math.OC

TL;DR: The paper proves that the KdV equation with right Neumann boundary controls is not locally null-controllable in small time for critical lengths where the linearized system's unreachable subspace has dimension ‚â•2, extending previous results.


<details>
  <summary>Details</summary>
Motivation: To investigate the local boundary controllability of the KdV equation at critical lengths, extending previous work by Coron, Koenig, and Nguyen who established non-controllability for only a subclass of these lengths.

Method: Analysis of the KdV system with right Neumann boundary controls, focusing on the unreachable subspace of the linearized system at critical lengths where controllability issues arise.

Result: 1) KdV is not locally null-controllable in small time for all critical lengths where the unreachable subspace has dimension ‚â•2. 2) A new controllability time is obtained for all but two critical lengths, updating results from Cerpa (2007) and Cerpa-Crepeau (2009).

Conclusion: The work extends previous non-controllability results to all critical lengths with sufficient unreachable subspace dimension and provides updated controllability times, advancing understanding of KdV boundary control limitations.

Abstract: We investigate the local boundary controllability of the Korteweg-de Vries (KdV) equation with right Neumann boundary controls at critical lengths. We show that the KdV system is not locally null-controllable in small time for all critical lengths for which the unreachable subspace of the linearized system has dimension at least two. This result extends the work of Coron, Koenig, and Nguyen, who established it for a subclass of these lengths. We also obtain a new controllability time for such systems for all but two critical lengths. It is worth noting that the latest results on the controllability time prior to this work date back to the work of Cerpa (2007) and Cerpa and Crepeau (2009).

</details>


<div id='math.CA'></div>

# math.CA [[Back]](#toc)

### [69] [Poisson Kernels and Hilbert Transforms for Trigonometric Heckman-Opdam Polynomials of type $A_1$](https://arxiv.org/abs/2512.12659)
*B. Amri,A. Guesmi*

Main category: math.CA

TL;DR: The paper connects trigonometric Heckman-Opdam polynomials of type A‚ÇÅ to ultraspherical polynomials, derives explicit Poisson kernel, develops convolution structure via product formula, defines fractional integrals, and establishes boundedness of generalized Hilbert transform on L^p spaces.


<details>
  <summary>Details</summary>
Motivation: To develop harmonic analysis for trigonometric Heckman-Opdam polynomials of type A‚ÇÅ, providing an alternative approach to the classical theory of B. Muckenhoupt and E.M. Stein for ultraspherical polynomials.

Method: Establishes connections with ultraspherical polynomials, derives explicit Poisson kernel expression, uses product formula to define convolution structure, develops fractional integral theory, and defines generalized Hilbert transform in Cherednik operator framework.

Result: Explicit expression for Poisson kernel, natural convolution structure via product formula, theory of fractional integrals, and proof of boundedness of generalized Hilbert transform on L^p spaces.

Conclusion: Provides comprehensive harmonic analysis framework for trigonometric Heckman-Opdam polynomials of type A‚ÇÅ, offering alternative perspective to classical ultraspherical polynomial theory of Muckenhoupt and Stein.

Abstract: In this paper, we investigate the trigonometric Heckman-Opdam polynomials of type $A_1$. We establish connections with ultraspherical polynomials and derive an explicit expression for the associated Poisson kernel. Using the product formula, we introduce a natural convolution structure and develop a theory of fractional integrals associated with these polynomials. We also define a generalized Hilbert transform in the framework of the Cherednik operator and prove its boundedness on $L^p$-spaces.
  This work provides an alternative perspective on the approach of B. Muckenhoupt and E.M. Stein \cite{MS}.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [70] [Convergence of the Cumulant Expansion and Polynomial-Time Algorithm for Weakly Interacting Fermions](https://arxiv.org/abs/2512.12010)
*Hongrui Chen,Cambyse Rouz√©,Jielun Chen,Jiaqing Jiang,Samuel O. Scalet,Yongtao Zhan,Garnet Kin-Lic Chan,Lexing Ying,Yu Tong*

Main category: quant-ph

TL;DR: A randomized algorithm with polynomial runtime for computing log-partition functions of weakly interacting fermions, using importance sampling with belief propagation instead of traditional MCMC.


<details>
  <summary>Details</summary>
Motivation: While weakly interacting fermionic systems are considered tractable for methods like diagrammatic quantum Monte Carlo, there has been no mathematically rigorous proof of polynomial runtime for these computations.

Method: Extends cumulant expansion proof techniques from periodic to non-periodic systems, uses tree-determinant expansion to reveal underlying tree structure in Feynman diagrams, and designs a randomized algorithm combining importance sampling with belief propagation.

Result: Develops a new algorithm with provable polynomial runtime in both system size and precision, overcoming limitations of traditional Markov chain Monte Carlo methods whose efficiency is hard to guarantee.

Conclusion: The approach provides a mathematically rigorous polynomial-time algorithm for computing log-partition functions of weakly interacting fermions, offering guaranteed efficiency where previous methods lacked provable runtime bounds.

Abstract: We propose a randomized algorithm to compute the log-partition function of weakly interacting fermions with polynomial runtime in both the system size and precision. Although weakly interacting fermionic systems are considered tractable for many computational methods such as the diagrammatic quantum Monte Carlo, a mathematically rigorous proof of polynomial runtime has been lacking. In this work we first extend the proof techniques developed in previous works for proving the convergence of the cumulant expansion in periodic systems to the non-periodic case. A key equation used to analyze the sum of connected Feynman diagrams, which we call the tree-determinant expansion, reveals an underlying tree structure in the summation. This enables us to design a new randomized algorithm to compute the log-partition function through importance sampling augmented by belief propagation. This approach differs from the traditional method based on Markov chain Monte Carlo, whose efficiency is hard to guarantee, and enables us to obtain a algorithm with provable polynomial runtime.

</details>


### [71] [A Joint Quantum Computing, Neural Network and Embedding Theory Approach for the Derivation of the Universal Functional](https://arxiv.org/abs/2512.13138)
*Martin J. Uttendorfer,Daniel Barragan-Yani,Matthias Sperl,Marc Landmann*

Main category: quant-ph

TL;DR: A novel approach combining quantum computing, machine learning, and reduced density matrix functional theory to improve quantum particle simulations by obtaining universal functionals via neural networks trained with quantum algorithms.


<details>
  <summary>Details</summary>
Motivation: To leverage quantum computing's potential for improving simulations of interacting quantum particles by developing a reusable universal functional that can be applied across multiple systems without additional quantum resources.

Method: Uses deep neural networks trained with quantum algorithms to obtain the universal functional, and employs fragment-bath systems from density matrix embedding theory to expand the space of applicable Hamiltonians.

Result: Demonstrates a way to potentially achieve cumulative quantum advantage in quantum chemistry and condensed matter physics applications by creating reusable universal functionals.

Conclusion: The approach enables reusable universal functionals that can be applied to any system with identical fragment interactions, offering a pathway to cumulative quantum advantage in quantum simulations.

Abstract: We introduce a novel approach that exploits the intersection of quantum computing, machine learning and reduced density matrix functional theory to leverage the potential of quantum computing to improve simulations of interacting quantum particles. Our method focuses on obtaining the universal functional using a deep neural network trained with quantum algorithms. We also use fragment-bath systems defined by density matrix embedding theory to strengthen our approach by substantially expanding the space of Hamiltonians for which the obtained functional can be applied without the need for additional quantum resources. Given the fact that once obtained, the same universal functional can be reused for any system where the interactions within the embedded fragment are identical, our work demonstrates a way to potentially achieve a cumulative quantum advantage within quantum computing applications for quantum chemistry and condensed matter physics.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [72] [A Corrected Open Boundary Framework for Lattice Boltzmann Immiscible Pseudopotential Models](https://arxiv.org/abs/2512.12934)
*Yizhong Chen,Zhibin Wang*

Main category: physics.flu-dyn

TL;DR: Proposes a corrected open boundary framework for immiscible pseudopotential LBM with MRT to address spurious currents and boundary stability issues in multi-component immiscible fluid systems.


<details>
  <summary>Details</summary>
Motivation: Existing immiscible pseudopotential methods for dynamic multi-component systems with open boundaries face challenges with spurious currents affecting interface formation/breakup and boundary configuration effects on simulation stability.

Method: Three key improvements: 1) Correction coefficients to reconstruct distribution function for accurate macroscopic quantity recovery at inlet; 2) Outlet velocity adjustment based on real-time mass flow rates to ensure global mass conservation; 3) Relaxation coefficient adjustment based on two-phase fluid viscosity to reduce spurious currents.

Result: Validated through four benchmark cases: Laplace tests and Taylor deformation, two-phase Poiseuille flow, droplet migration in microchannels, and droplet generation in T-shaped and co-flow devices. The corrected approach accurately captures various dynamic complex immiscible multiphase flows.

Conclusion: The proposed corrected open boundary framework based on MRT for immiscible pseudopotential model successfully addresses boundary stability issues and spurious currents, enabling reliable simulation of dynamic multi-component immiscible fluid systems with open boundaries.

Abstract: The pseudopotential lattice Boltzmann method (LBM) is a prominent approach for simulating multiphase flows, valued for its physical intuitiveness and computational tractability. However, existing immiscible pseudopotential methods for modeling dynamic multi-component immiscible fluid systems involving open boundaries face persistent challenges, notably the influence of spurious currents on interface formation and breakup, as well as the effects of inlet and outlet boundary configurations on simulation stability. Therefore, this paper proposes a corrected open boundary framework based on Multiple-relaxation-time (MRT) for the immiscible pseudopotential model. Our method includes three key improvements: firstly, introducing correction coefficients to reconstruct the distribution function, in order to accurately recover the macroscopic quantities at the inlet boundary. Secondly, based on real-time mass flow rates at the inlet and outlet, the outlet boundary velocity is adjusted to ensure global mass conservation in the computational domain. Finally, the relaxation coefficient related to numerical stability is adjusted based on the viscosity of two-phase fluids to reduce spurious currents. To validate the reliability of the proposed corrected method, four benchmark cases were simulated: Laplace tests and Taylor deformation, two-phase Poiseuille flow, migration of droplets in microchannels, as well as droplet generation in T-shaped and co-flow devices. The results demonstrate that the corrected approach accurately captures various dynamic complex immiscible multiphase flows.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [73] [Ergodicity for the Dean--Kawasaki Equation with Dirichlet Boundary Conditions: Taming the Square-Root](https://arxiv.org/abs/2512.12861)
*Shyam Popat,Zhengyan Wu*

Main category: math.PR

TL;DR: Establishes ergodicity for generalized Dean-Kawasaki equations with correlated noise and Dirichlet boundary conditions, accommodating irregular square-root type noise coefficients. Shows exponential convergence for classical equations and polynomial convergence for porous medium type, with regularization by noise effect improving polynomial to exponential convergence for regular coefficients.


<details>
  <summary>Details</summary>
Motivation: Previous ergodicity results (Fehrman, Gess, Gvalani) didn't accommodate irregular, square-root type noise coefficients. This paper aims to extend ergodicity analysis to handle such irregular coefficients in Dean-Kawasaki equations with correlated noise and Dirichlet boundary conditions.

Method: Relies on establishing a supercontraction property in a suitably weighted Lebesgue space using a refined doubling of variables argument. The weight function construction crucially exploits the specific structure of the Dean-Kawasaki-type correlated noise.

Result: 1) For irregular coefficients, classical Dean-Kawasaki equation converges exponentially fast to equilibrium. 2) Porous medium type Dean-Kawasaki equation converges at polynomial rate. 3) Regularization by noise effect: polynomial convergence improves to exponential when noise coefficient is sufficiently regular, including conservative multiplicative linear noise case.

Conclusion: Successfully establishes ergodicity for generalized Dean-Kawasaki equations with irregular noise coefficients, demonstrating different convergence rates based on equation type and noise regularity, with a novel supercontraction approach in weighted spaces.

Abstract: In this paper, we establish the ergodicity of generalized Dean--Kawasaki equations with correlated noise and Dirichlet boundary conditions. In contrast to the ergodicity results of Fehrman, Gess, and Gvalani arXiv:2206.14789, our analysis accommodates irregular, square-root type noise coefficients. For such irregular coefficients, we prove that the law of the classical Dean--Kawasaki equation converges exponentially fast to equilibrium, while for the porous medium type Dean--Kawasaki equation, the convergence occurs at a polynomial rate. Furthermore, we obtain a regularization by noise effect, showing that the polynomial convergence rate improves to an exponential one whenever the noise coefficient is sufficiently regular, including the case of conservative multiplicative linear noise. Our approach relies on establishing a supercontraction property in a suitably weighted Lebesgue space, achieved through a refined doubling of variables argument. The construction of the weight function crucially exploits the specific structure of the Dean--Kawasaki-type correlated noise.

</details>


### [74] [Heat kernel estimates for Markov processes in bounded sets with jump kernels decaying at the boundary](https://arxiv.org/abs/2512.12991)
*Soobin Cho,Panki Kim,Renming Song,Zoran Vondraƒçek*

Main category: math.PR

TL;DR: The paper establishes sharp two-sided heat kernel estimates for symmetric Markov jump processes with boundary-decaying jump kernels in bounded smooth domains.


<details>
  <summary>Details</summary>
Motivation: To understand the heat kernel behavior of purely discontinuous symmetric Markov processes with jump kernels that decay at the boundary, which is important for studying boundary effects in jump processes and their probabilistic properties.

Method: Study two types of processes: conservative processes and processes killed at boundaries or by killing potentials. Analyze jump kernels of form J(x,y)=B(x,y)|x-y|^{-d-Œ±} where B decays at boundary and is described by O-regularly varying and slowly varying functions.

Result: Establish sharp two-sided estimates on the heat kernel: in Lipschitz sets for conservative processes, and in C^{1,1} open sets for killed processes, under conditions on B and killing potential Œ∫.

Conclusion: The paper provides precise heat kernel estimates for symmetric Markov jump processes with boundary-decaying jump kernels, extending understanding of boundary effects in discontinuous processes.

Abstract: In this paper, we study two types of purely discontinuous symmetric Markov processes $X$ in bounded smooth subsets of $\mathbb R^d$: conservative processes and processes killed either upon approaching the boundary of the set or by a killing potential $Œ∫$. The jump kernel of $X$ is of the form $J(x,y)={\cal B}(x,y)|x-y|^{-d-Œ±}$, $Œ±\in (0,2)$, where the function ${\cal B}(x,y)$ decays to 0 at the boundary and is described in terms of two $O$-regularly varying functions and one slowly varying function. Under the conditions, introduced in \cite{CKSV24}, on ${\cal B}(x,y)$ and on the killing potential $Œ∫$, we establish sharp two-sided estimates on the heat kernel of $X$: in Lipschitz sets when $X$ is conservative, and in $C^{1,1}$ open sets for the killed process.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [75] [Predicting the Thermal Conductivity Collapse in SWCNT Bundles: The Interplay of Symmetry Breaking and Scattering Revealed by Machine-Learning-Driven Quantum Transport](https://arxiv.org/abs/2512.12940)
*Feng Tao,Xiaoliang Zhang,Dawei Tang,Shigeo Maruyama,Ya Feng*

Main category: cond-mat.mes-hall

TL;DR: ML-based neuroevolution potentials combined with anharmonic lattice dynamics and Boltzmann transport equation enable quantitative thermal transport analysis in carbon nanotube bundles, revealing dual suppression mechanisms.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between theoretical models and experimental measurements of thermal transport in nanoscale materials, specifically single-walled carbon nanotubes and their bundles, by developing a predictive framework.

Method: Combines machine learning-based neuroevolution potentials (NEP) with anharmonic lattice dynamics and Boltzmann transport equation (ALD-BTE), incorporating quantum Bose-Einstein statistics for accurate phonon scattering calculations.

Result: Reveals dual mechanism for thermal conductivity suppression in bundles: 1) breaking of rotational symmetry enhances scattering of symmetry-sensitive phonon modes (like twist mode), 2) emergence of inter-tube phonon modes creates additional scattering channels across frequencies. Approach quantitatively reproduces experimental observations.

Conclusion: Establishes ML-driven interatomic potentials combined with ALD-BTE as a predictive framework for nanoscale thermal transport, effectively bridging theory-experiment gap and enabling quantitative, mode-resolved analysis.

Abstract: We combine machine learning (ML)-based neuroevolution potentials (NEP) with anharmonic lattice dynamics and the Boltzmann transport equation (ALD-BTE) to achieve a quantitative and mode-resolved description of thermal transport in individual (10, 0) zigzag single-walled carbon nanotubes (SWCNTs) and their bundles. Our analysis reveals a dual mechanism behind the drastic suppression of thermal conductivity in bundles: first, the breaking of rotational symmetry in isolated SWCNTs dramatically enhances the scattering rates of symmetry-sensitive phonon modes, such as the twist (TW) mode. Second, the emergence of new inter-tube phonon modes introduces abundant additional scattering channels across the entire frequency spectrum. Crucially, the incorporation of quantum Bose-Einstein (BE) statistics is essential to accurately capture these phenomena, enabling our approach to quantitatively reproduce experimental observations. This work establishes the combination of ML-driven interatomic potentials and ALD-BTE as a predictive framework for nanoscale thermal transport, effectively bridging the gap between theoretical models and experimental measurements.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [76] [3D lattice Monte Carlo modeling of morphology formation of Si/SiOx nanocomposites during phase separation of nonstoichiometric Si oxide films](https://arxiv.org/abs/2512.13071)
*Ivan Oliinyk,Andrey Sarikov*

Main category: cond-mat.mtrl-sci

TL;DR: 3D Monte Carlo lattice model simulates phase separation in nonstoichiometric SiOx films, showing how initial stoichiometry and film thickness control Si nanoparticle vs. network formation.


<details>
  <summary>Details</summary>
Motivation: To understand the kinetics of morphology change during phase separation in nonstoichiometric silicon oxide (SiOx, x < 2) films, which is important for controlling Si nanoparticle or network formation in thin film applications.

Method: Developed a three-dimensional lattice model using Monte Carlo approach that incorporates SiOx local atomic structure and probabilistic oxygen atom migration driven by free energy minimization.

Result: Initial stoichiometry x critically determines morphology: isolated Si nanoparticles form at x ‚â• 1.4, interconnected Si networks appear at x ‚â§ 0.8. Film thickness imposes geometric constraints - percolation threshold shifts from xp ‚âà 1.35 (bulk) to xp ‚âà 0.85 (quasi-2D films). Transition to bulk behavior occurs at ~4.2 nm thickness.

Conclusion: Both initial stoichiometry and film thickness are crucial parameters controlling Si phase morphology during phase separation in SiOx films, with thickness-dependent geometric constraints significantly affecting percolation thresholds and network formation.

Abstract: In this paper, a three-dimensional lattice model based on the Monte Carlo approach is presented. This model is developed to investigate the kinetics of morphology change during phase separation in nonstoichiometric Si oxide (SiOx, x < 2) films. The model takes into account the SiOx local atomic structure and probabilistic migration of oxygen atoms driven by the tendency of free energy minimization. The influence of the initial SiOx stoichiometry index x and film thickness on the morphology of the precipitated Si phase in the Si oxide matrix is analyzed. The morphology of the Si phase is shown to critically depend on the initial SiOx stoichiometry. Namely, isolated Si nanoparticles form at low excess Si content (x >= 1.4), while interconnected Si networks always appear at x <= 0.8. A dimensional effect on the morphology of the Si phase is revealed. Namely, reducing the film thickness imposes geometric constraints on the Si network formation. The percolation threshold is found to shift from xp ~= 1.35 for the bulk-like SiOx layers to xp ~= 0.85 for the quasi-two-dimensional films. The transition to the bulk material behavior is observed at a SiOx thickness of approximately 4.2 nm.

</details>


### [77] [Electronic and optical properties of native point defects in CuInS$_2$ and CuGaS$_2$](https://arxiv.org/abs/2512.13567)
*Henry Phillip Fried,Daniel Barragan-Yani,Ludger Wirtz*

Main category: cond-mat.mtrl-sci

TL;DR: HSE hybrid functional study of intrinsic defects in CuInS2 and CuGaS2, investigating band gap tuning, charge-transition levels, and lattice relaxation effects on photoluminescence predictions.


<details>
  <summary>Details</summary>
Motivation: To understand the electronic properties of intrinsic defects in CuInS2 and CuGaS2 materials, particularly how HSE functional parameters affect band gap calculations and defect characterization, and to improve the connection between theoretical predictions and experimental photoluminescence measurements.

Method: Used Heyd-Scuseria-Ernzerhof (HSE) hybrid functional scheme to study intrinsic defects. Investigated impact of HSE parameters (Œ± and œâ) on band gap and Koopmans' theorem compliance. Applied formation energy formalism and calculated thermodynamic charge-transition levels. Analyzed connection between charge-transition levels and optical-transition levels, and calculated Franck-Condon shifts for emission to account for lattice relaxation effects.

Result: The study shows that including lattice relaxation effects (Franck-Condon shifts) brings theoretical predictions closer to experimental photoluminescence measurements. The investigation of HSE parameters provides insights into band gap tuning and defect characterization accuracy.

Conclusion: Lattice relaxation is crucial for accurate defect attribution to luminescence peaks in CuInS2 and CuGaS2. Proper treatment of HSE parameters and inclusion of Franck-Condon shifts improves agreement between theoretical defect predictions and experimental photoluminescence data.

Abstract: We present a detailed study of common intrinsic defects in CuInS$_2$ and CuGaS$_2$ using the Heyd, Scuseria and Ernzerhof (HSE) hybrid functional scheme. The impact of the two HSE parameters, $Œ±$ and $œâ$ on the band gap and compliance with the generalized Koopmans' theorem is investigated. Using the formation energy formalism and calculated thermodynamic charge-transition levels, we assess the electronic properties of the defects and explore the connection of charge-transition levels with optical-transition levels. Calculated Franck-Condon shifts for emission highlight the importance of lattice relaxation for the attribution of defects to luminescence peaks. Our results show that once these effects are included, predictions become closer to photoluminescence measurements available in literature.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [78] [Exploring the energy landscape of the logarithmic potential: local minima and stationary states](https://arxiv.org/abs/2512.12416)
*Paolo Amore,Victor Figueroa,Raymundo Ramos*

Main category: cond-mat.soft

TL;DR: Exponential growth of distinct energy-minimizing configurations and stationary states for logarithmic potential on sphere up to N=160.


<details>
  <summary>Details</summary>
Motivation: To understand the complexity and growth patterns of energy-minimizing configurations on a sphere with logarithmic potential interactions, similar to the Thomson problem but with different potential.

Method: Detailed exploration of energy landscape using techniques from previous work, analyzing local minima configurations up to N=160 and stationary states up to N=24.

Result: Number of distinct configurations (N_conf) grows exponentially with N, though slower than Thomson problem. Number of stationary states also grows exponentially for N‚â§24.

Conclusion: Logarithmic potential on sphere exhibits exponential growth in both distinct energy-minimizing configurations and stationary states, indicating complex energy landscape similar to but distinct from Thomson problem.

Abstract: We have performed a detailed exploration of the energy landscape for configurations of points on the sphere, interacting via the logarithmic potential, and corresponding to local minima of the total energy, up to $N = 160$. The growth of $N_{\rm conf}$ (number of distinct configurations) is exponential, as for the Thomson problem, although weaker. Using the techniques described in our previous paper~\cite{Amore25} we have also explored the solution landscape of this problem for $N \leq 24$, and found that the number of stationary states is growing exponentially.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [79] [Fredholm properties of the jacobi Operator of minimal conical hypersurfaces](https://arxiv.org/abs/2512.11804)
*Oscar Ivan Agudelo Rico,Matteo Rizzi*

Main category: math.DG

TL;DR: The paper studies non-degeneracy properties of minimal hypersurfaces asymptotic to cones via the Jacobi operator, and constructs a right inverse to solve the Jacobi equation under certain non-degeneracy assumptions.


<details>
  <summary>Details</summary>
Motivation: To understand the non-degeneracy properties of minimal hypersurfaces that approach cones at infinity, and to develop tools for solving the Jacobi equation on such surfaces, which is important for studying stability and deformation properties.

Method: Analyzes the Jacobi operator J_Œ£ = Œî_Œ£ + |A_Œ£|¬≤ of minimal hypersurfaces asymptotic to cones, studies its non-degeneracy properties, and constructs a right inverse operator to solve J_Œ£œÜ = f under suitable assumptions about Œ£ and the asymptotic behavior of f.

Result: Establishes non-degeneracy properties of minimal hypersurfaces via their Jacobi operators, proves existence of a right inverse for the Jacobi operator, and demonstrates solvability of the Jacobi equation under appropriate conditions on the hypersurface and forcing term.

Conclusion: The paper provides analytical tools for studying minimal hypersurfaces asymptotic to cones by establishing non-degeneracy results and constructing right inverses for their Jacobi operators, with applications to various examples in minimal surface theory.

Abstract: In this paper we study non-degeneracy properties of $Œ£$ via the Jacobi operator $J_Œ£:=Œî_Œ£+|A_Œ£|^2$ of a given minimal hypersurface $Œ£$ asymptotic to a cone $C\subset \mathbb{R}^{N+1}$ of co-dimension one. Here $Œî_Œ£$ is the Laplace Beltrami operator of $Œ£$ and $|A_Œ£|$ is the norm of the second fundamental form of $Œ£$. We also construct a right inverse of $J_Œ£$, that is, we prove that the Jacobi equation $J_Œ£œÜ=f$ is solvable in $Œ£$, at least under some suitable non-degeneracy assumptions about $Œ£$ and about the asymptotic behavior of $f$ at infinity. We also discuss some examples where our results can be applied.

</details>


### [80] [The quermassintegral inequalities for horo-convex domains in the sphere](https://arxiv.org/abs/2512.12565)
*Shujing Pan,Julian Scheuer*

Main category: math.DG

TL;DR: The paper introduces horo-convexity for subsets of the unit sphere (analogous to hyperbolic horo-convexity), studies horo-convex hypersurfaces, proves smooth convergence of the Guan/Li inverse flow, and establishes quermassintegral inequalities for these hypersurfaces.


<details>
  <summary>Details</summary>
Motivation: To extend the concept of horo-convexity from hyperbolic space to the unit sphere, creating a new geometric framework for studying convexity properties on spherical domains and establishing fundamental geometric inequalities.

Method: Introduces horo-convexity for spherical subsets, studies horo-convex hypersurfaces, applies the classical Guan/Li flow of inverse type, and proves smooth convergence of this flow for horo-convex hypersurfaces.

Result: Proves smooth convergence of the Guan/Li inverse flow for horo-convex hypersurfaces of the unit sphere, and uses this to establish the full set of quermassintegral inequalities for such hypersurfaces.

Conclusion: The paper successfully extends horo-convexity to spherical geometry, demonstrates the applicability of inverse curvature flows to this new setting, and establishes fundamental geometric inequalities that complete the theory for horo-convex hypersurfaces on the unit sphere.

Abstract: We study a new notion of convexity for subsets of the unit sphere, which closely resembles the horo-convexity for subsets of the hyperbolic space. We call this notion, accordingly, horo-convexity. For horo-convex hypersurfaces of the unit sphere, we prove the smooth convergence of the classical Guan/Li flow of inverse type and use this result to prove the full set of quermassintegral inequalities for horo-convex hypersurfaces of the unit sphere.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [81] [Laser Wakefield Acceleration in a Capillary Gas Cell Producing GeV-Scale High-Quality Electron Beams](https://arxiv.org/abs/2512.13118)
*Srimanta Maity,Francesco Massimo,Alex Whitehead,Pavel Sasorov,Alexander Molodozhentsev*

Main category: physics.acc-ph

TL;DR: Computational study of Laser Wakefield Acceleration in a two-section capillary gas cell produces GeV-class electron beams with reduced energy spread using tailored gas density profiles.


<details>
  <summary>Details</summary>
Motivation: LWFA offers compact high-brightness electron beam sources for next-generation accelerators, but needs optimization for high-quality GeV beams with low energy spread.

Method: Two-section capillary design: short injection region with He-N2 mixture for electron injection, followed by pure He acceleration section. Hydrodynamic simulations optimize gas profiles, then Particle-In-Cell simulations study LWFA with 100 TW-class laser parameters.

Result: Electron acceleration to mean energies >1.0 GeV with high-quality beam properties. Tailored density profiles reduce energy spread by limiting continuous ionization injection. Self-injected He electrons observed and evaluated.

Conclusion: The study demonstrates effective LWFA beam optimization using two-section capillary design, providing valuable insights for upcoming EuPRAXIA Project experiments at ELI Beamlines Facility.

Abstract: Laser Wakefield Acceleration (LWFA) is a promising approach for producing high-brightness electron beams in the GeV energy range, offering significant potential for compact next-generation accelerator facilities. In this work, we present a computational study of LWFA in a specially designed single-stage capillary gas-cell target aimed at producing high-quality, GeV-class electron beams. The capillary cell includes a short (~2 mm) injection region at the entrance filled with a helium (He) and nitrogen (N2 ) gas mixture. This is followed by a longer (~12 mm) pure He section, which provides the required acceleration length and limits continuous ionization injection, thereby significantly reducing the energy spread of the accelerated beam. Hydrodynamic simulations are performed to optimize the capillary geometry and generate the required two-section gas-pressure profile. The resulting gas-density distributions for various cases are then directly incorporated in Particle-In-Cell (PIC) simulations to study LWFA. In particular, our hydrodynamic simulations demonstrate how tailored density profiles with longitudinal density tapering in the acceleration section can be realized in a capillary gas cell, while the corresponding PIC simulations reveal how these profiles influence the acceleration process and the resulting beam quality. Using a 100 TW-class laser system with parameters relevant to the L2-DUHA laser at the ELI Beamlines Facility, the PIC results demonstrate electron acceleration to mean energies exceeding 1.0 GeV with high-quality beam properties. Self-injected He electrons are also observed, and their impact on the main beam quality is evaluated. The findings of this study provide valuable insights for upcoming LWFA experiments planned within the EuPRAXIA Project at the ELI Beamlines Facility.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [82] [Residual energy in weakly compressible turbulence with a mean guide field](https://arxiv.org/abs/2512.11973)
*R. Skalidis,A. Tritsis,J. R. Beattie,P. F. Hopkins*

Main category: astro-ph.SR

TL;DR: Study of residual energy (E_r = E_kin - E_mag) in weakly compressible MHD turbulence with strong guide field, showing different spectral scalings depending on driving mechanism and plasma beta.


<details>
  <summary>Details</summary>
Motivation: Residual energy distribution in MHD turbulence shows different behaviors in incompressible (E_r < 0) vs highly compressible (E_r > 0) regimes, but weakly compressible regime with strong guide field is less explored. Need to understand how driving mechanisms and field strength affect E_r cascade.

Method: Direct numerical simulations using PENCIL code with sonic Mach numbers ~0.1. Vary Alfv√©n Mach number (plasma beta Œ≤) and driving mechanism (velocity vs magnetic fluctuations at large scales). Analyze power spectra of kinetic, magnetic, density, and residual energy.

Result: Magnetically-driven simulations show locally imbalanced Alfv√©nic fluctuations with k^{-3/2} cascade (dynamic alignment theory). Kinetically-driven simulations show k^{-1} scaling (reflection-driven turbulence). Residual energy is positive with spectral slope Œ± depending on Œ≤: Œ≤=4.0: -2‚â≤Œ±‚â≤-5/3; Œ≤=1.0: -5/3‚â≤Œ±‚â≤-3/2; Œ≤=0.3: Œ±‚âà-1.

Conclusion: Driving mechanism and plasma beta significantly influence residual energy cascade in weakly compressible MHD turbulence. Different scalings reveal distinct physical mechanisms: dynamic alignment for magnetic driving vs reflection-driven turbulence for kinetic driving.

Abstract: The energy distribution is a fundamental property of magnetohydrodynamic (MHD) turbulence. In strongly magnetized turbulence energy imbalances can arise, quantified by the so-called residual energy: $E_r~=~(E_{kin}~ - ~E_{mag})$; $E_{kin}$ and $E_{mag}$ stand for the volume-averaged kinetic and magnetic energy, respectively. Numerical simulations of incompressible turbulence yield $E_r < 0$, which is consistent with Solar wind observations, while in highly compressible turbulence simulations $E_r > $ 0. Differences arise in the cascade of $E_r$ between the two regimes. We explore the properties of $E_r$ in weakly compressible MHD turbulence in the presence of an initially strong (guide) magnetic field. We study the influence of different driving mechanisms and field strengths on the cascade of $E_r$. We run a suite of direct numerical simulations with the PENCIL code. All simulations are maintained through forcing in a quasi-static regime with sonic Mach numbers close to 0.1. We solely change the Alfv√©n Mach number, or equivalently the plasma beta ($Œ≤$) of the simulations. We drive turbulence by either injecting velocity or magnetic fluctuations at large scales and study the power spectra of kinetic, magnetic, density, and $E_r$. Magnetically-driven simulations show locally imbalanced Alfv√©nic fluctuations and a $\propto k^{-3/2}$ cascade, consistent with the dynamic alignment theory. Kinetically-driven simulations give rise to a $\propto k^{-1}$ scaling, consistent with interactions between Alfv√©n waves scattered by density inhomogeneities -- a hallmark of reflection-driven turbulence. Residual energy is positive with a spectral slope ($Œ±$) depending on $Œ≤$ as: for $Œ≤= 4.0$, $-2 \lesssim Œ±\lesssim -5/3$, for $Œ≤= 1.0$, $-5/3 \lesssim Œ±\lesssim -3/2$, and for $Œ≤= 0.3$, $Œ±\approx -1$.

</details>


### [83] [The Maximum Particle Energy Gain During Magnetic Reconnection](https://arxiv.org/abs/2512.13394)
*Zhiyu Yin,Harry Arnold,James F Drake,Marc Swisdak*

Main category: astro-ph.SR

TL;DR: The paper investigates how system size affects maximum particle energy gain during magnetic reconnection, finding that multiple flux rope mergers through Fermi reflection drive energy gain, with larger systems enabling more mergers and higher maximum energies.


<details>
  <summary>Details</summary>
Motivation: Previous work showed that maximum particle energy gain increases with system size during magnetic reconnection, but the physical basis for this relationship was not understood. The authors aim to investigate why larger systems produce higher maximum energies.

Method: The researchers used analytical investigation and large-scale simulations with the kglobal model, varying the effective system size over a large range to isolate processes determining maximum energy gain. They tracked magnetic-island mergers and flux rope formation.

Result: Maximum energy gain (W_max) is regulated by the number of magnetic-island mergers that occur. Larger systems produce more flux ropes and more mergers, with Fermi reflection during these repeated mergers dominating particle energy gain. The number of mergers determines the maximum attainable energy.

Conclusion: The link between maximum particle energy and number of flux rope mergers explains why particle-in-cell simulations produce powerlaw distributions with limited energy ranges. System size controls the number of mergers, which in turn regulates maximum energy gain during magnetic reconnection.

Abstract: The factors that control the maximum energy attained by protons and electrons during magnetic reconnection are investigated analytically and using large-scale simulations with the \textit{kglobal} model. Previous work revealed that a strong ambient guide field strongly impacts particle energy gain during reconnection, suppressing energy gain from Fermi reflection by increasing the radius of curvature of reconnected field lines. However, previous simulations have also shown that the maximum energy gain increases with the system size. The physical basis for this result has not been explored. We perform simulations that vary the effective system size over a large range to isolate the processes determining the maximum energy gain. The maximum energy $W_{max}$ is regulated by the number of magnetic-island mergers that occur, as multiple flux ropes that form at early time repeatedly merge until the largest approaches the system scale. Fermi reflection in these repeated mergers dominates particle energy gain. The number of mergers is linked to the effective system size -- larger systems produce a larger number of flux ropes and more mergers. That $W_{max}$ is linked to the number of flux rope mergers has implications for understanding why particle-in-cell simulations only produce powerlaw distributions of energetic particles with a limited range in energy.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [84] [Numerical Assessment of Advective and Diffusive Dynamics of Interacting and Isolated Prototypical Convectively Initiated Circulations](https://arxiv.org/abs/2512.11828)
*Matthew R. Igel,Joseph A. Biello,Adele L. Igel*

Main category: physics.ao-ph

TL;DR: KRoNUT model effectively represents full convective circulation including updrafts, compensating descent, and horizontal motions, outperforming plume models and accurately simulating dry dynamics of isolated/interacting convective circulations.


<details>
  <summary>Details</summary>
Motivation: Existing plume models only represent updraft regions of convective clouds, missing the complete circulation that includes compensating descent, cloud-free air, and horizontal motions. A more comprehensive representation is needed to understand full convective dynamics.

Method: Developed Kinematic Representation of Non-rotating Updraft Tori (KRoNUT) model to represent entire convective flow. Compared KRoNUT's skill against plume models using high-resolution marine tropical convection simulations. Used KRoNUT to analyze dry dynamics of isolated and interacting convective circulations under advection and diffusion only.

Result: KRoNUT outperforms plume representations. Vertical advection of vertical wind is most important advective tendency in clouds, but horizontal circulation components play crucial role in evolution without buoyancy. Strong flow curvature near surface/updraft core creates scale-dependent diffusive tendencies. KRoNUT tendencies match simulation results well. Interacting circulations show diverse dynamics including unique stability of geometric properties and clustering of circulation centers.

Conclusion: KRoNUT provides superior representation of complete convective circulation compared to plume models, capturing essential dynamics of both isolated and interacting convective systems under dry conditions, with implications for understanding convective organization and stability.

Abstract: The bulk circulation associated with convective clouds includes not only a region of updraft and cloudy air but also a region of compensating descent and cloud-free air and horizontal motions coupling these regions. The Kinematic Representation of Non-rotating Updraft Tori (KRoNUT) model is a simple representation of this entire flow. First, the skill of the KRoNUT in representing flows from a high resolution full-physics simulation of marine tropical convection is compared to various plume representations of convection. Then the KRoNUT is used to construct bulk descriptions of the dry dynamics of isolated and interacting convective circulations under the influence of advection and diffusion (only). Cross sections of advective and diffusive tendencies show that while vertical advection of the vertical wind is the most important advective tendency in clouds, the horizontal component of the convective circulation and advection thereof plays a crucial role in the evolution of circulations in the absence of buoyancy. Strong curvature of the flow near the surface and near the updraft core results in locally strong diffusive tendencies that depend on scale. Cross sections of tendencies from the KRoNUT compare favourably to results from the simulation. Interacting circulations are shown to exhibit a wide range of dynamics with some cases of interactions leading to unique stability of geometric properties of otherwise evolving flows and some leading to geometric clustering of circulation centers.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [85] [Noise-robust Contrastive Learning for Critical Transition Detection in Dynamical Systems](https://arxiv.org/abs/2512.12523)
*Wenqi Fang,Ye Li*

Main category: cs.LG

TL;DR: A lightweight neural network with SVD architecture and semi-orthogonality constraints improves contrastive learning for detecting critical transitions in noisy time-series data.


<details>
  <summary>Details</summary>
Motivation: Critical transitions in complex systems are hard to detect due to noise masking order parameters, and existing contrastive learning methods are overparameterized and noise-sensitive.

Method: Propose a neural network architecture using singular value decomposition with strictly semi-orthogonality-constrained training algorithm to enhance contrastive learning.

Result: The method matches traditional contrastive learning performance in identifying critical transitions while being more lightweight and significantly more noise-resistant.

Conclusion: The proposed SVD-based architecture with orthogonality constraints provides an effective, efficient solution for critical transition detection in noisy time-series data.

Abstract: Detecting critical transitions in complex, noisy time-series data is a fundamental challenge across science and engineering. Such transitions may be anticipated by the emergence of a low-dimensional order parameter, whose signature is often masked by high-amplitude stochastic variability. Standard contrastive learning approaches based on deep neural networks, while promising for detecting critical transitions, are often overparameterized and sensitive to irrelevant noise, leading to inaccurate identification of critical points. To address these limitations, we propose a neural network architecture, constructed using singular value decomposition technique, together with a strictly semi-orthogonality-constrained training algorithm, to enhance the performance of traditional contrastive learning. Extensive experiments demonstrate that the proposed method matches the performance of traditional contrastive learning techniques in identifying critical transitions, yet is considerably more lightweight and markedly more resistant to noise.

</details>


### [86] [On the Approximation Power of SiLU Networks: Exponential Rates and Depth Efficiency](https://arxiv.org/abs/2512.12132)
*Koffi O. Ayena*

Main category: cs.LG

TL;DR: SiLU activation networks achieve exponential approximation rates for smooth functions with better complexity than ReLU networks, using a novel hierarchical construction starting from efficient x¬≤ approximation.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that SiLU (Sigmoid Linear Unit) activation networks can achieve superior approximation capabilities compared to classical ReLU networks, with explicit and improved complexity control for smooth function approximation.

Method: Develop a novel hierarchical construction beginning with an efficient approximation of the square function x¬≤ that is more compact in depth and size than comparable ReLU realizations. Extend this approach through functional composition to establish sharp approximation bounds for deep SiLU networks approximating Sobolev-class functions.

Result: SiLU networks achieve approximation error decaying as O(œâ^{-2k}) using networks of depth O(1). For Sobolev-class functions, they achieve total depth O(1) and size O(Œµ^{-d/n}), demonstrating exponential approximation rates with improved complexity control.

Conclusion: SiLU activation networks provide a theoretically superior alternative to ReLU networks for smooth function approximation, offering exponential approximation rates with explicit and improved complexity bounds through a novel hierarchical construction methodology.

Abstract: This article establishes a comprehensive theoretical framework demonstrating that SiLU (Sigmoid Linear Unit) activation networks achieve exponential approximation rates for smooth functions with explicit and improved complexity control compared to classical ReLU-based constructions. We develop a novel hierarchical construction beginning with an efficient approximation of the square function $x^2$ more compact in depth and size than comparable ReLU realizations, such as those given by Yarotsky. This construction yields an approximation error decaying as $\mathcal{O}(œâ^{-2k})$ using networks of depth $\mathcal{O}(1)$. We then extend this approach through functional composition to establish sharp approximation bounds for deep SiLU networks in approximating Sobolev-class functions, with total depth $\mathcal{O}(1)$ and size $\mathcal{O}(\varepsilon^{-d/n})$.

</details>


### [87] [Solving a Machine Learning Regression Problem Based on the Theory of Random Functions](https://arxiv.org/abs/2512.12731)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: The paper derives regression methods from first principles using indifference postulates and symmetry properties, showing that generalized polyharmonic splines emerge naturally as optimal kernels without empirical selection.


<details>
  <summary>Details</summary>
Motivation: To establish a theoretical foundation for regression methods by deriving them from first principles rather than empirical selection, connecting machine learning regression to multivariate approximation theory using random function theory.

Method: Uses the theory of random functions and postulates of indifference to derive regression methods analytically. Assumes probability measures on infinite-dimensional function spaces possess natural symmetries (translation, rotation, scaling invariance, and Gaussianity).

Result: The entire regression solution scheme (kernel form, regularization type, noise parameterization) follows analytically from symmetry postulates. The resulting kernel coincides with generalized polyharmonic splines, providing theoretical justification rather than empirical selection.

Conclusion: The indifference principle provides a theoretical foundation for smoothing and interpolation methods, demonstrating their optimality when no a priori information is available, connecting machine learning regression to fundamental mathematical principles.

Abstract: This paper studies a machine learning regression problem as a multivariate approximation problem using the framework of the theory of random functions. An ab initio derivation of a regression method is proposed, starting from postulates of indifference. It is shown that if a probability measure on an infinite-dimensional function space possesses natural symmetries (invariance under translation, rotation, scaling, and Gaussianity), then the entire solution scheme, including the kernel form, the type of regularization, and the noise parameterization, follows analytically from these postulates. The resulting kernel coincides with a generalized polyharmonic spline; however, unlike existing approaches, it is not chosen empirically but arises as a consequence of the indifference principle. This result provides a theoretical foundation for a broad class of smoothing and interpolation methods, demonstrating their optimality in the absence of a priori information.

</details>


### [88] [KD-PINN: Knowledge-Distilled PINNs for ultra-low-latency real-time neural PDE solvers](https://arxiv.org/abs/2512.13336)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

TL;DR: KD-PINN framework transfers high-accuracy teacher model knowledge to compact student via KL divergence adaptation, achieving near-teacher accuracy with 4.8-6.9x speedup and sub-10ms inference latency.


<details>
  <summary>Details</summary>
Motivation: To develop accurate ultra-low-latency neural PDE solvers by reducing inference latency in Physics-Informed Neural Networks while maintaining physical accuracy.

Method: Knowledge distillation framework that transfers predictive accuracy from high-capacity teacher PINN to compact student model through continuous adaptation of Kullback-Leibler divergence.

Result: Student preserved teacher's physical accuracy with mean RMSE increase below 0.64%, achieved 4.8x-6.9x inference speedups, average 5.3ms latency on CPU, and demonstrated regularizing effect.

Conclusion: KD-PINN enables development of accurate ultra-low-latency neural PDE solvers with sub-10ms real-time performance while maintaining high physical accuracy through knowledge distillation.

Abstract: This work introduces Knowledge-Distilled Physics-Informed Neural Networks (KD-PINN), a framework that transfers the predictive accuracy of a high-capacity teacher model to a compact student through a continuous adaptation of the Kullback-Leibler divergence. To confirm its generality for various dynamics and dimensionalities, the framework is evaluated on a representative set of partial differential equations (PDEs). In all tested cases, the student model preserved the teacher's physical accuracy, with a mean RMSE increase below 0.64%, and achieved inference speedups ranging from 4.8x (Navier-Stokes) to 6.9x (Burgers). The distillation process also revealed a regularizing effect. With an average inference latency of 5.3 ms on CPU, the distilled models enter the ultra-low-latency real-time regime defined by sub-10 ms performance. Finally, this study examines how knowledge distillation reduces inference latency in PINNs to contribute to the development of accurate ultra-low-latency neural PDE solvers.

</details>


### [89] [DP-EMAR: A Differentially Private Framework for Autonomous Model Weight Repair in Federated IoT Systems](https://arxiv.org/abs/2512.13460)
*Chethana Prasad Kabgere,Shylaja S S*

Main category: cs.LG

TL;DR: DP-EMAR is a differentially private error model-based autonomous repair framework for Federated IoT that detects and reconstructs transmission-induced distortions during FL aggregation while maintaining privacy guarantees.


<details>
  <summary>Details</summary>
Motivation: In multi-tier Federated IoT systems, unstable connectivity and adversarial interference can silently alter transmitted model parameters during FL training, degrading convergence. Model weight distortion remains a major challenge in resource-constrained IoT networks, necessitating solutions that can detect and repair transmission errors while preserving privacy.

Method: DP-EMAR integrates Differential Privacy (DP) with Secure Aggregation (SA) to distinguish DP noise from genuine transmission errors. It estimates corruption patterns and applies adaptive correction before privacy noise is added, enabling reliable in-network repair without violating confidentiality. The framework uses error model-based autonomous repair to detect and reconstruct transmission-induced distortions during FL aggregation.

Result: Experiments on heterogeneous IoT sensor and graph datasets show that DP-EMAR preserves convergence stability and maintains near baseline performance under communication corruption while ensuring strict (epsilon, delta)-DP guarantees. The framework enhances robustness, communication efficiency, and trust in privacy-preserving Federated IoT learning.

Conclusion: DP-EMAR successfully addresses the challenge of model weight distortion in resource-constrained IoT networks by combining differential privacy with error correction mechanisms. The framework enables reliable FL training in unstable network conditions while maintaining strong privacy guarantees, making it suitable for practical Federated IoT deployments.

Abstract: Federated Learning (FL) enables decentralized model training without sharing raw data, but model weight distortion remains a major challenge in resource constrained IoT networks. In multi tier Federated IoT (Fed-IoT) systems, unstable connectivity and adversarial interference can silently alter transmitted parameters, degrading convergence. We propose DP-EMAR, a differentially private, error model based autonomous repair framework that detects and reconstructs transmission induced distortions during FL aggregation. DP-EMAR estimates corruption patterns and applies adaptive correction before privacy noise is added, enabling reliable in network repair without violating confidentiality. By integrating Differential Privacy (DP) with Secure Aggregation (SA), the framework distinguishes DP noise from genuine transmission errors. Experiments on heterogeneous IoT sensor and graph datasets show that DP-EMAR preserves convergence stability and maintains near baseline performance under communication corruption while ensuring strict (epsilon, delta)-DP guarantees. The framework enhances robustness, communication efficiency, and trust in privacy preserving Federated IoT learning.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [90] [Stability and Regularization of Quasi-Variational Inequalities under Monotone Operator Perturbations](https://arxiv.org/abs/2512.13275)
*M. H. M. Rashid*

Main category: math.FA

TL;DR: This paper establishes stability and convergence results for quasi-variational inequalities under monotone operator perturbations, providing explicit convergence rates and applications to various mathematical and engineering problems.


<details>
  <summary>Details</summary>
Motivation: To develop a unified mathematical framework for robust numerical approximation and sensitivity analysis of quasi-variational problems arising in materials science, physics, and engineering applications, bridging classical monotone operator theory with contemporary computational challenges.

Method: The paper proves strong convergence of minimal and maximal solutions when sequences of operators converge pointwise while preserving key properties (homogeneity, strong monotonicity, Lipschitz continuity, T-monotonicity). The analysis extends to regularization techniques, finite-dimensional approximations, and non-monotone nonlinearities.

Result: Comprehensive stability results for QVIs under monotone perturbations, with explicit convergence rates under appropriate conditions. The theory encompasses applications to p-Laplacian operators, elliptic regularizations, and optimal control problems with QVI constraints.

Conclusion: The work provides essential mathematical foundations for the robust numerical approximation and sensitivity analysis of quasi-variational problems, establishing a unified framework that connects classical monotone operator theory with practical computational applications in science and engineering.

Abstract: This paper establishes comprehensive stability results for quasi-variational inequalities (QVIs) under monotone perturbations of the governing operator. We prove strong convergence of both minimal and maximal solutions when sequences of operators converge pointwise while preserving fundamental properties including homogeneity, strong monotonicity, Lipschitz continuity, and T-monotonicity. Our analysis extends to regularization techniques, finite-dimensional approximations, and non-monotone nonlinearities, providing explicit convergence rates under appropriate conditions. The theory encompasses applications to $p$-Laplacian operators, elliptic regularizations, and optimal control problems with QVI constraints. By developing a unified framework that bridges classical monotone operator theory with contemporary computational challenges, this work provides essential mathematical foundations for the robust numerical approximation and sensitivity analysis of quasi-variational problems arising in materials science, physics, and engineering applications.

</details>
