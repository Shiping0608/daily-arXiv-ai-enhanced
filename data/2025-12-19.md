<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 26]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [cs.LG](#cs.LG) [Total: 4]
- [cond-mat.supr-con](#cond-mat.supr-con) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [math.HO](#math.HO) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 3]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.atom-ph](#physics.atom-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [math.CV](#math.CV) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Make the most of what you have: Resource-efficient randomized algorithms for matrix computations](https://arxiv.org/abs/2512.15929)
*Ethan N. Epperly*

Main category: math.NA

TL;DR: Thesis develops efficient randomized algorithms for matrix computations: RPCholesky for low-rank PSD approximation, leave-one-out methods for implicit matrix attribute estimation, and backward-stable randomized least-squares solvers.


<details>
  <summary>Details</summary>
Motivation: Randomized algorithms are fundamental in computational linear algebra but need to use information efficiently to maximize speed and accuracy given limited data budgets. The thesis addresses designing algorithms that optimally use collected matrix information.

Method: Three-part approach: 1) Randomly pivoted Cholesky (RPCholesky) for low-rank PSD matrix approximation with minimal entry access; 2) Leave-one-out approach for estimating attributes (trace, diagonal, row-norms) of implicit matrices via matrix-vector products; 3) Development of backward-stable randomized algorithms for overdetermined linear least squares problems.

Result: RPCholesky achieves superior speed and reliability for low-rank PSD approximation. Leave-one-out approach yields optimized trace, diagonal, and row-norm estimation algorithms. Randomized least-squares algorithms achieve backward stability, resolving previous floating-point accuracy concerns.

Conclusion: The thesis demonstrates that randomized algorithms can be designed to use matrix information efficiently, achieving both computational speed and numerical reliability across various matrix computation tasks including low-rank approximation, attribute estimation, and least-squares problems.

Abstract: In recent years, randomized algorithms have established themselves as fundamental tools in computational linear algebra, with applications in scientific computing, machine learning, and quantum information science. Many randomized matrix algorithms proceed by first collecting information about a matrix and then processing that data to perform some computational task. This thesis addresses the following question: How can one design algorithms that use this information as efficiently as possible, reliably achieving the greatest possible speed and accuracy for a limited data budget?
  The first part of this thesis focuses on low-rank approximation for positive-semidefinite matrices. Here, the goal is to compute an accurate approximation to a matrix after accessing as few entries of the matrix as possible. This part of the thesis explores the randomly pivoted Cholesky (RPCholesky) algorithm for this task, which achieves a level of speed and reliability greater than other methods for the same problem.
  The second part of this thesis considers the task of estimating attributes of an implicit matrix accessible only by matrix-vector products. This thesis describes the leave-one-out approach to developing matrix attribute estimation algorithms and develops optimized trace, diagonal, and row-norm estimation algorithms.
  The third part of this thesis considers randomized algorithms for overdetermined linear least squares problems. Randomized algorithms for linear-least squares problems are asymptotically faster than any known deterministic algorithm, but recent work has raised questions about the accuracy of these methods in floating point arithmetic. This thesis shows these issues are resolvable by developing fast randomized least-squares problem achieving backward stability, the gold-standard stability guarantee for a numerical algorithm.

</details>


### [2] [Time-Frequency Analysis for Neural Networks](https://arxiv.org/abs/2512.15992)
*Ahmed Abdeljawad,Elena Cordero*

Main category: math.NA

TL;DR: The paper develops a quantitative approximation theory for shallow neural networks using time-frequency analysis, achieving dimension-independent approximation rates in Sobolev norms with explicit constants.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous approximation rates for neural networks that combine standard activations with localized time-frequency windows, providing theoretical guarantees for their performance in Sobolev spaces.

Method: Using tools from time-frequency analysis and working in weighted modulation spaces M^{p,q}_m(R^d), the authors prove approximation rates for networks with units that combine standard activations with localized time-frequency windows.

Result: For functions in M^{p,q}_m(R^d), they achieve dimension-independent approximation rates: ||f - f_N||_{W^{n,r}(Ω)} ≲ N^{-1/2} ||f||_{M^{p,q}_m(R^d)} on bounded domains, with explicit constant control. They also obtain global approximation theorems on R^d and derive consequences for various function spaces.

Conclusion: Modulation-based neural networks provide superior Sobolev approximation compared to standard ReLU networks, with rigorous theoretical guarantees and practical performance confirmed by numerical experiments in 1D and 2D.

Abstract: We develop a quantitative approximation theory for shallow neural networks using tools from time-frequency analysis. Working in weighted modulation spaces $M^{p,q}_m(\mathbf{R}^{d})$, we prove dimension-independent approximation rates in Sobolev norms $W^{n,r}(Ω)$ for networks whose units combine standard activations with localized time-frequency windows. Our main result shows that for $f \in M^{p,q}_m(\mathbf{R}^{d})$ one can achieve \[ \|f - f_N\|_{W^{n,r}(Ω)} \lesssim N^{-1/2}\,\|f\|_{M^{p,q}_m(\mathbf{R}^{d})}, \] on bounded domains, with explicit control of all constants. We further obtain global approximation theorems on $\mathbf{R}^{d}$ using weighted modulation dictionaries, and derive consequences for Feichtinger's algebra, Fourier-Lebesgue spaces, and Barron spaces. Numerical experiments in one and two dimensions confirm that modulation-based networks achieve substantially better Sobolev approximation than standard ReLU networks, consistent with the theoretical estimates.

</details>


### [3] [A divergence-free parametric finite element method for 3D Stokes equations on curved domains](https://arxiv.org/abs/2512.16216)
*Lingxiao Li,Haiyan Su,He Zhang,Weiying Zheng*

Main category: math.NA

TL;DR: A novel divergence-free parametric mixed finite element method for 3D Stokes equations on curved domains using high-order elements and IPDG technique.


<details>
  <summary>Details</summary>
Motivation: The Stokes equations are crucial for incompressible flow simulation, but solving them on domains with piecewise smooth boundaries requires specialized methods that maintain divergence-free properties.

Method: Proposes a divergence-free parametric mixed finite element method using high-order parametric Brezzi-Douglas-Marini elements for velocity and volume elements for pressure on curved tetrahedral meshes, employing interior-penalty discontinuous Galerkin (IPDG) technique.

Result: Proves inf-sup condition for the mixed finite element pair, achieves high-order optimal error estimates in energy norm, and ensures exactly divergence-free discrete velocity (div uh = 0) in curved computational domains. Numerical experiments validate theoretical analyses.

Conclusion: The proposed method successfully solves 3D Stokes equations on curved domains while maintaining exact divergence-free properties and achieving optimal convergence rates, making it suitable for accurate incompressible flow simulations.

Abstract: The Stokes equations play an important role in the incompressible flow simulation. In this paper, a novel divergence-free parametric mixed finite element method is proposed for solving three-dimensional Stokes equations on domains with piecewise smooth boundaries. The flow velocity and pressure are discretized with high-order parametric Brezzi-Douglas-Marini elements and volume elements, respectively, on curved tetrahedral meshes. Utilizing the interior-penalty discontinuous Galerkin (IPDG) technique, we prove the inf-sup condition for the mixed finite element pair, and high-order optimal error estimates in the energy norm, with the help of the extension and transformation of the true solution to computational domain. Moreover, the discrete velocity is exactly divergence-free, meaning that div uh = 0 holds in the curved computational domain. Numerical experiments are conducted to support the theoretical analyses.

</details>


### [4] [Numerical reconstruction of Schrödinger equations with quadratic nonlinearities](https://arxiv.org/abs/2512.16269)
*Khaoula El Maddah,Matti Lassas,Teemu Tyni*

Main category: math.NA

TL;DR: A numerical framework for reconstructing potentials in 2D semilinear elliptic PDEs from Dirichlet-to-Neumann data using higher-order linearization and Fourier inversion.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the inverse problem of recovering unknown potentials in semilinear elliptic PDEs from boundary measurements (Dirichlet-to-Neumann map), which has applications in medical imaging, geophysics, and material science.

Method: Uses higher-order linearization method to compute Fourier data of the unknown potential from the nonlinear Dirichlet-to-Neumann map, then inverts the Fourier data to reconstruct the potential q.

Result: Numerical experiments demonstrate accurate reconstructions for both smooth and discontinuous test cases, validating the effectiveness of the proposed framework.

Conclusion: The proposed numerical framework successfully solves the inverse potential reconstruction problem for 2D semilinear elliptic PDEs with power-type nonlinearities, achieving accurate results even for discontinuous potentials.

Abstract: We introduce a numerical framework for reconstructing the potential in two dimensional semilinear elliptic PDEs with power type nonlinearities from the nonlinear Dirichlet to Neumann map. By applying higher order linearization method, we compute the Fourier data of the unknown potential and then invert it to recover $q$. Numerical experiments show accurate reconstructions for both smooth and discontinuous test cases.

</details>


### [5] [A Locally Divergence-Free Local Characteristic Decomposition Based Path-Conservative Central-Upwind Scheme for Ideal Magnetohydrodynamics](https://arxiv.org/abs/2512.16346)
*Shaoshuai Chu,Alexander Kurganov,Maria Lukacova-Medvidova,Mingye Na*

Main category: math.NA

TL;DR: A new low-dissipation LCD-PCCU scheme for MHD equations that enhances solution resolution by incorporating local characteristic decomposition into the path-conservative central-upwind framework.


<details>
  <summary>Details</summary>
Motivation: To develop a less dissipative numerical method for ideal magnetohydrodynamics equations that improves solution resolution while maintaining desirable properties of existing methods.

Method: Incorporates local characteristic decomposition (LCD) into the path-conservative central-upwind (PCCU) framework, extending the recently proposed locally divergence-free PCCU scheme to reduce numerical dissipation.

Result: The LCD-PCCU method enhances numerical solution resolution as demonstrated through a series of benchmark tests, showing improved performance over the base PCCU scheme.

Conclusion: The proposed LCD-PCCU scheme successfully reduces numerical dissipation while maintaining desirable properties, making it an effective method for solving ideal MHD equations with enhanced resolution.

Abstract: We introduce a locally divergence-free local characteristic decomposition based path-conservative central-upwind (LCD-PCCU) scheme for ideal magnetohydrodynamics (MHD) equations. The proposed method is a low-dissipation extension of the recently proposed locally divergence-free PCCU scheme. To reduce the numerical dissipation, we incorporate the LCD into the PCCU framework. The resulting LCD-PCCU method enhances the resolution of numerical solutions as demonstrated through a series of benchmark tests.

</details>


### [6] [Conserving mass, momentum, and energy for the Benjamin-Bona-Mahony, Korteweg-de Vries, and nonlinear Schrödinger equations](https://arxiv.org/abs/2512.16352)
*Hendrik Ranocha,David I. Ketcheson*

Main category: math.NA

TL;DR: High-order numerical methods that preserve multiple invariants (mass, momentum, energy) while being essentially explicit, applied to nonlinear PDEs with demonstrated long-term stability.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods that preserve important physical invariants (conservation laws) while avoiding the computational cost of solving large nonlinear algebraic systems, enabling accurate long-term simulations of nonlinear PDEs.

Method: Combines Fourier Galerkin methods in space with orthogonal projection and relaxation in time to create arbitrarily high-order discretizations that are essentially explicit (no large system solves needed).

Result: The methods conserve mass, momentum, and energy up to numerical precision for Benjamin-Bona-Mahoney, Korteweg-de Vries, nonlinear Schrödinger, and hyperbolic NLS equations. This conservation leads to reduced error growth in long-term simulations.

Conclusion: The proposed high-order, essentially explicit methods successfully preserve multiple invariants for various nonlinear PDEs, providing improved long-term simulation accuracy through conservation properties.

Abstract: We propose and study a class of arbitrarily high order numerical discretizations that preserve multiple invariants and are essentially explicit (they do not require the solution of any large systems of algebraic equations). In space, we use Fourier Galerkin methods, while in time we use a combination of orthogonal projection and relaxation. We prove and numerically demonstrate the conservation properties of the method by applying it to the Benjamin-Bona-Mahoney, Korteweg-de Vries, and nonlinear Schrödinger (NLS) PDEs as well as a hyperbolic approximation of NLS. For each of these equations, the proposed schemes conserve mass, momentum, and energy up to numerical precision. We show that this conservation leads to reduced growth of numerical errors for long-term simulations.

</details>


### [7] [New Fully Discrete Active Flux Methods with Truly Multi-Dimensional Evolution Operators and WENO Reconstruction](https://arxiv.org/abs/2512.16359)
*Amelie Porfetye,Zhuyan Tang,Shaoshuai Chu,Christiane Helzel,Maria Lukacova-Medvidova*

Main category: math.NA

TL;DR: Third-order accurate Active Flux and WENO methods for 2D acoustic equations using multidimensional evolution operators with improved stability via bicharacteristics method.


<details>
  <summary>Details</summary>
Motivation: To develop more stable and accurate numerical methods for solving two-dimensional acoustic equations, addressing limitations of existing schemes in handling both continuous and discontinuous problems on coarse grids.

Method: Proposes fully discrete third-order accurate Active Flux and WENO methods based on truly multidimensional evolution operators. Uses the method of bicharacteristics to derive approximate evolution operators that improve stability. Performs linear stability analysis to determine maximal CFL numbers.

Result: The schemes demonstrate improved stability and accurate approximation even on coarse grids. Extensive testing on both continuous and discontinuous problems confirms their robustness and third-order accuracy.

Conclusion: The proposed multidimensional evolution operators based on bicharacteristics method successfully enhance stability of third-order accurate Active Flux and WENO schemes for 2D acoustic equations, making them robust for various problem types including discontinuities.

Abstract: We propose new fully discrete third-order accurate Active Flux and WENO methods based on truly multidimensional evolution operators for the two-dimensional acoustic equations. Building on the method of bicharacteristics, several approximate evolution operators are derived that yield an improved stability of the resulting schemes. A linear stability analysis is applied to determine the maximal CFL number. The schemes are tested extensively on both continuous and discontinuous problems, confirming their robustness and accurate approximation even on coarse grids.

</details>


### [8] [An Euler scheme for BSDEs via the Wiener chaos decomposition](https://arxiv.org/abs/2512.16418)
*Pere Díaz Lozano,Giulia Di Nunno*

Main category: math.NA

TL;DR: A Wiener chaos decomposition-based implementation of the Euler scheme for BSDEs that handles non-Markovian terminal conditions without requiring forward-backward structure.


<details>
  <summary>Details</summary>
Motivation: Standard Euler scheme implementations for BSDEs require approximating conditional expectations and martingale terms, typically relying on forward-backward Markovian structure. This limits applicability to Markovian settings.

Method: Uses Wiener chaos decomposition to approximate conditional expectations and martingale terms in the Euler scheme for BSDEs, enabling handling of arbitrary square-integrable terminal conditions without Markovian assumptions.

Result: Provides comprehensive convergence analysis and demonstrates the method's effectiveness through several numerical examples, showing it works for non-Markovian terminal conditions.

Conclusion: The Wiener chaos decomposition approach successfully extends the Euler scheme for BSDEs to handle general terminal conditions beyond Markovian settings, with proven convergence and practical numerical performance.

Abstract: The Euler scheme is a standard time discretization for BSDEs, but its implementation hinges on approximating conditional expectations and the associated martingale terms at each time step. We propose an implementation based on the Wiener chaos decomposition to approximate these quantities. In contrast to many numerical schemes that rely on a forward-backward (Markovian) structure, our approach accommodates arbitrary $\mathcal{F}_T$-measurable square-integrable terminal conditions. We provide a comprehensive convergence analysis and illustrate the method on several numerical examples.

</details>


### [9] [A non-negativity-preserving cut-cell discontinuous Galerkin method for the diffusive wave equation](https://arxiv.org/abs/2512.16525)
*Panasun Manorost,Peter Bastian*

Main category: math.NA

TL;DR: A non-negativity-preserving cut-cell DG method for degenerate parabolic diffusive wave approximation of shallow water equations, with FV comparison on Delaunay triangulations.


<details>
  <summary>Details</summary>
Motivation: To develop accurate numerical methods for shallow water equations that preserve non-negativity (water depth ≥ 0), handle complex bathymetry (continuous/discontinuous), and work on general triangular meshes while accommodating different friction laws.

Method: Two methods: 1) Cut-cell discontinuous Galerkin (DG) method with upwind flux, 2) Finite volume (FV) method on Delaunay triangulations with upwind flux. Both preserve non-negativity and handle Manning's and Chezy's friction laws.

Result: DG method achieves full second-order accuracy for Barenblatt analytical solution on inclined plane, while FV method is only first-order accurate. FV requires 3-4 mesh refinements to match DG solution quality.

Conclusion: The cut-cell DG method is superior to FV method in accuracy and efficiency for solving degenerate parabolic diffusive wave approximation of shallow water equations, while maintaining non-negativity preservation and handling complex geometries.

Abstract: A non-negativity-preserving cut-cell discontinuous Galerkin method for the degenerate parabolic diffusive wave approximation of the shallow water equation is presented. The method can handle continuous and discontinuous bathymmetry as well as general triangular meshes. It is complemented by a finite volume method on Delauney triangulations which is also shown to be non-negativity preserving. Both methods feature an upwind flux and can handle Manning's and Chezy's friction law. By numerical experiment we demonstrate the discontinuous Galerkin method to be fully second-order accurate for the Barenblatt analytical solution on an inclined plane. In constrast, the finite volume method is only first-order accurate. Further numerical experiments show that three to four mesh refinements are needed for the finite volume method to match the solution of the discontinuous Galerkin method.

</details>


### [10] [Landscape Analysis of Excited States Calculation over Quantum Computers](https://arxiv.org/abs/2512.16539)
*Hengzhun Chen,Yingzhou Li,Bichen Lu,Jianfeng Lu*

Main category: math.NA

TL;DR: Three VQE models with built-in orthogonality constraints for excited state calculations are analyzed, showing favorable optimization landscapes where local minima are global minima.


<details>
  <summary>Details</summary>
Motivation: VQE works well for ground states but struggles with excited states due to orthogonality requirements and variational collapse. Current methods need external orthogonality enforcement, which is challenging on NISQ devices.

Method: Analyze three VQE models that embed orthogonality constraints through specially designed cost functions. Conduct rigorous landscape analysis of stationary points and local minimizers to prove favorable optimization properties.

Result: The formulations have the property that any local minimum is also a global minimum, addressing optimization difficulties. Theoretical guarantees are provided, and comprehensive comparison between models considers quantum resource requirements and classical optimization complexity.

Conclusion: These VQE models with built-in orthogonality constraints provide theoretically guaranteed favorable optimization landscapes for excited state calculations, overcoming key algorithmic hurdles in NISQ quantum computing.

Abstract: The variational quantum eigensolver (VQE) is one of the most promising algorithms for low-lying eigenstates calculation on Noisy Intermediate-Scale Quantum (NISQ) computers. Specifically, VQE has achieved great success for ground state calculations of a Hamiltonian. However, excited state calculations arising in quantum chemistry and condensed matter often requires solving more challenging problems than the ground state as these states are generally further away from a mean-field description, and involve less straightforward optimization to avoid the variational collapse to the ground state. Maintaining orthogonality between low-lying eigenstates is a key algorithmic hurdle. In this work, we analyze three VQE models that embed orthogonality constraints through specially designed cost functions, avoiding the need for external enforcement of orthogonality between states. Notably, these formulations possess the desirable property that any local minimum is also a global minimum, helping address optimization difficulties. We conduct rigorous landscape analyses of the models' stationary points and local minimizers, theoretically guaranteeing their favorable properties and providing analytical tools applicable to broader VQE methods. A comprehensive comparison between the three models is also provided, considering their quantum resource requirements and classical optimization complexity.

</details>


### [11] [Obstacle Mean Curvature Flow: Efficient Approximation and Convergence Analysis](https://arxiv.org/abs/2512.16668)
*Fabius Krämer,Tim Laux*

Main category: math.NA

TL;DR: A simple, efficient numerical method for computing mean curvature flow with obstacles that extends the Merriman-Bence-Osher scheme with pointwise constraint enforcement while maintaining computational complexity.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method for obstacle mean curvature flow that is both simple to implement and efficient, while preserving key structural properties of the continuous problem.

Method: Augments the Merriman-Bence-Osher scheme with a pointwise update that enforces obstacle constraints, retaining the original scheme's computational complexity. The method inherits both geometric comparison principle and minimizing movements interpretation.

Result: Proves convergence to viscosity solution of obstacle mean curvature flow using comparison principle, shows convergence of spatially discrete model using minimizing movements interpretation, demonstrates unconditional stability, and presents numerical experiments for physical applications.

Conclusion: The proposed naive scheme successfully computes obstacle mean curvature flow while preserving crucial mathematical properties, offering a practical numerical approach with theoretical guarantees for physical applications.

Abstract: We introduce a simple and efficient numerical method to compute mean curvature flow with obstacles. The method augments the Merrimam-Bence-Osher scheme with a pointwise update that enforces the constraint and therefore retains the computational complexity of the original scheme. Remarkably, this naive scheme inherits both crucial structural properties of obstacle mean curvature flow: a geometric comparison principle and a minimizing movements interpretation. The latter immediately implies the unconditional stability of the scheme. Based on the comparison principle we prove the convergence of the scheme to the viscosity solution of obstacle mean curvature flow. Moreover, using the minimizing movements interpretation, we show convergence of a spatially discrete model. Finally, we present numerical experiments for a physical model that inspired this work.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Fokas-type closed-form solution formulae for Sobolev-type equations with time-dependent coefficients](https://arxiv.org/abs/2512.15937)
*Andreas Chatziafratis*

Main category: math.AP

TL;DR: The paper develops explicit integral representations for solving nonhomogeneous initial-boundary-value problems for evolution PDEs of Sobolev-Galpern type with time-dependent coefficients, using an extension of the Fokas unified transform method.


<details>
  <summary>Details</summary>
Motivation: To solve evolution PDEs with mixed spatiotemporal derivatives and time-dependent coefficients that induce rational dispersion relations, which present challenging technical difficulties in complex-analytic and algebraic aspects.

Method: Extends the Fokas unified transform methodology to handle evolution equations with time-dependent coefficients and mixed derivatives, carefully implementing the technique to derive explicit integral representations for solutions.

Result: Successfully generates closed-form solutions for various equations (Milne-Taylor-Barenblatt-Coleman-Ting-Chen-type, Benjamin-Bona-Mahony-type, and higher-order variants) on the half-line, resolving complex-analytic and algebraic difficulties.

Conclusion: The new explicit integral formulas are useful for investigating qualitative properties and analyzing nonlinear counterparts, with further extensions and implementations to be reported in forthcoming publications.

Abstract: We analytically derive novel explicit integral representations for the solution of nonhomogeneous initial-boundary-value problems for a large category of evolution partial differential equations of Sobolev-Galpern type with generic temporally variable coefficients, satisfying suitable mild conditions, and with arbitrary data in classical function spaces. This work is based on the careful implementation of the pioneering Fokas unified transform methodology alongside its recently-proposed extension for solving a class of linear evolution equations with dispersion relation of specific polynomial type and time-dependent coefficients. We herein effectively extend those techniques to a special collection of evolution equations with time-dependent coefficients and mixed spatiotemporal derivatives, which induce rational dispersion relations. The new approach is exhibited in detail through illustrative generation of closed-form solutions for a multitude of such equations (such as Milne-Taylor-Barenblatt-Coleman-Ting-Chen-type, Benjamin-Bona-Mahony-type, as well as numerous higher-order variants) posed on the half-line. Challenging technical difficulties of complex-analytic and of algebraic flavour naturally emerge due the presence of mixed-derivative terms, and these are appropriately resolved in each case. The new formulas are of utility in subsequent investigation of qualitative properties and analysis of nonlinear counterparts too. Further extensions, generalizations, rigorous aspects and implementations to other types of problems as well will soon be reported in forthcoming publications.

</details>


### [13] [Fundamental Properties and Embedding Results in a Novel $(Φ_x, ψ)$-Fractional Musielak Space with an Application to Nonlocal BVP](https://arxiv.org/abs/2512.15972)
*Ayoub Kasmi,El Houssine Azroul,Mohammed Shimi*

Main category: math.AP

TL;DR: The paper introduces generalized $(Φ_x,ψ)$-fractional Musielak spaces for modeling heterogeneous nonlinear phenomena with memory/nonlocal effects, establishes their properties and embeddings, and applies them to prove existence of solutions to fractional differential problems.


<details>
  <summary>Details</summary>
Motivation: To develop a flexible functional framework that extends classical fractional spaces to handle heterogeneous and nonlinear phenomena with memory and nonlocal effects, particularly relevant for nonlocal boundary value problems in variable-exponent and Musielak-Orlicz settings.

Method: Introduces generalized $(Φ_x,ψ)$-fractional Musielak spaces $\mathcal{K}_{Φ_x}^{α, β, ψ}$, conducts rigorous functional analysis of their structure, establishes new properties and embedding results, and applies the framework to prove existence of nontrivial solutions using mountain pass theorem under Ambrosetti-Rabinowitz conditions.

Result: Establishes detailed functional properties and embedding results for the new fractional Musielak spaces, and proves existence of nontrivial solutions to nonlinear fractional differential problems within this framework, demonstrating its applicability to nonlocal BVPs.

Conclusion: The proposed $(Φ_x,ψ)$-fractional Musielak spaces provide a powerful new framework for analyzing nonlocal and nonhomogeneous equations, offering flexibility for modeling heterogeneous phenomena with memory effects and opening new perspectives in variable-exponent and Musielak-Orlicz settings.

Abstract: In this paper, we introduce and study a novel class of generalized $(Φ_x,ψ)$-fractional Musielak spaces $\mathcal{K}_{Φ_x}^{α, β, ψ}$, which extends classical fractional spaces and offers the flexibility to model heterogeneous and nonlinear phenomena with memory and nonlocal effects. A detailed and rigorous analysis of their functional structure is carried out. Several new properties and embedding results are established, highlighting the originality of the proposed framework and its relevance to nonlocal BVPs. To illustrate the significance of this functional setting, we prove the existence of nontrivial solutions to a nonlinear fractional differential problem under an Ambrosetti--Rabinowitz type condition, using the mountain pass theorem. Our results provide new perspectives for the analysis of nonlocal and nonhomogeneous equations in variable-exponent and Musielak-Orlicz settings.

</details>


### [14] [A Fourier analysis for $(θ,T)$-periodic functions and applications](https://arxiv.org/abs/2512.15974)
*André Pedroso Kowacs,Marielle Aparecida Silva*

Main category: math.AP

TL;DR: Fourier analysis for (θ,T)-periodic functions with applications to global hypoellipticity/solvability of operators


<details>
  <summary>Details</summary>
Motivation: To extend Fourier analysis from classical periodic functions to the more general class of (θ,T)-periodic functions, and apply this theory to study global hypoellipticity and solvability properties of differential operators

Method: Develop Fourier analysis framework for (θ,T)-periodic functions, prove properties including Poincaré-type inequalities, then apply this analysis to study continuous linear operators acting on smooth (θ,T)-periodic functions

Result: Established Fourier transform properties and inequalities for (θ,T)-periodic functions, proved equivalence: operator on (θ,T)-periodic functions is globally hypoelliptic/solvable iff corresponding operator on periodic functions is, characterized global hypoellipticity/solvability for first-order differential operators

Conclusion: Successfully extended Fourier analysis to (θ,T)-periodic functions and used this framework to characterize global hypoellipticity and solvability properties of operators, establishing connections between behavior on generalized periodic functions and classical periodic functions

Abstract: We develop a Fourier analysis for a generalization of the class of periodic functions, often referred to as $(θ, T)$-periodic functions, and prove several properties and inequalities related to the Fourier transform, including a type of Poincaré inequality, which extend the periodic case. As an application, we employ this analysis to show that a continuous linear operator acting on smooth $(θ, T)$-periodic functions is globally hypoelliptic/solvable if and only if the corresponding operator which acts on periodic functions is globally hypoelliptic/solvable, and characterize the global hypoellipticity/solvability of a class of first order differential operators acting on the set of smooth $(θ, T)$-periodic functions.

</details>


### [15] [A Poisson Formula for the Wave Propagator on Schwarzschild-de Sitter Backgrounds](https://arxiv.org/abs/2512.16054)
*Izak Oltman,Ben Pineau*

Main category: math.AP

TL;DR: Proves a Poisson formula for wave propagators in Schwarzschild-de Sitter spacetime, extending previous results to non-compactly supported potentials.


<details>
  <summary>Details</summary>
Motivation: Previous Poisson formulas for wave propagators required compactly supported perturbations, but many physically relevant potentials (like Regge-Wheeler potentials in black hole physics) are non-compactly supported. The paper aims to extend the theory to handle these important cases.

Method: Develops a Poisson formula relating wave propagators and scattering resonances for a class of non-compactly supported potentials on the real line. The approach handles potentials that decay sufficiently at infinity, including Regge-Wheeler potentials obtained from separation of variables in Schwarzschild-de Sitter spacetime.

Result: Successfully proves a Poisson formula for the wave propagator of Schwarzschild-de Sitter metric, overcoming the compact support limitation of previous work by Lax-Phillips, Melrose, and others. The formula connects wave propagation to scattering resonances for non-compactly supported potentials.

Conclusion: The paper extends scattering theory to non-compactly supported potentials, providing a Poisson formula for wave propagators in Schwarzschild-de Sitter spacetime, which has applications in black hole physics and gravitational wave analysis.

Abstract: This paper proposes a Poisson formula for the wave propagator of the Schwarzschild--de Sitter (SdS) metric. That is done by proving a Poisson formula relating wave propagators and scattering resonances for a class of non-compactly supported potentials on the real line. That class includes the Regge--Wheeler potentials obtained from separation of variables for SdS. The novelty lies in allowing non-compact supports -- all exact Poisson formulae of Lax--Phillips, Melrose, and other authors required compactness of the support of the perturbation.

</details>


### [16] [Low Regularity Well-Posedness of Cauchy Problem for Two-Dimensional Relativistic Euler Equation](https://arxiv.org/abs/2512.16090)
*Huali Zhang*

Main category: math.AP

TL;DR: Study of Cauchy problem for 2D relativistic Euler equations in low-regularity setting using reformulated wave-transport system with rescaled velocity, logarithmic enthalpy, and vorticity variables.


<details>
  <summary>Details</summary>
Motivation: To establish well-posedness results for the relativistic Euler equations with minimal regularity requirements on initial data, extending previous results to more general settings.

Method: Introduce rescaled velocity, logarithmic enthalpy, and vorticity variables to reformulate equations as coupled wave-transport system. Use Strichartz estimates and semiclassical analysis to prove existence and uniqueness.

Result: Proved existence/uniqueness for general state function p(ρ)=ρ^A (A≥1) with initial data in specific Sobolev spaces. For special case p(ρ)=ρ, established improved well-posedness results including local well-posedness for irrotational flows and global well-posedness for small data.

Conclusion: The paper successfully establishes low-regularity well-posedness for 2D relativistic Euler equations using novel variable transformations and modern analytical techniques, with results matching or improving upon previous work in related equations.

Abstract: In this article, we initiate the study of the Cauchy problem for the two-dimensional relativistic Euler equations in a low-regularity setting. By introducing good variables--a rescaled velocity, logarithmic enthalpy, and an appropriately defined vorticity, we reformulate the equations into a coupled wave-transport system.
  First, we prove the existence and uniqueness of solutions when the initial logarithmic enthalpy $h_0$, rescaled velocity $\bv_0$, and vorticity $\bw_0$ satisfy $(h_0, \bv_0, \bw_0, \nabla \bw_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac32+}(\mathbb{R}^2) \times L^8(\mathbb{R}^2)$. By using Strichartz estimates and semiclassical analysis, a relaxed well-posedness result holds when $(h_0, \bv_0, \bw_0, \nabla \bw_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac32}(\mathbb{R}^2) \times L^8(\mathbb{R}^2)$. Both results are valid for the general state function $p(\varrho)=\varrho^A$ ($A \geq 1$).
  Secondly, in the special case where $p(\varrho)=\varrho$, the acoustic metric reduces to the standard flat Minkowski metric. We can establish the well-posedness of solutions when $(h_0, \mathbf{v}_0, \mathbf{w}_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{1+}(\mathbb{R}^2)$. The regularity exponents for the log-enthalpy and rescaled velocity correspond to those in Smith and Tataru \cite{ST}, while the vorticity regularity corresponds to Bourgain and Li \cite{BL}. Moreover, if the stiff flow is irrotational, we can prove the local well-posedness for $(h_0, \mathbf{v}_0) \in H^{1+}(\mathbb{R}^2)$, and global well-posedness for small initial data $(h_0, \bv_0) \in \dot{B}^{1}_{2,1}(\mathbb{R}^2)$.

</details>


### [17] [Global weak solutions of 3D compressible magnetohydrodynamic equations subject to large external potential forces with discontinuous initial data and vacuum](https://arxiv.org/abs/2512.16121)
*Geyuan Chen,Xin Zhong*

Main category: math.AP

TL;DR: Global existence of weak solutions for compressible MHD equations with large external forces and discontinuous initial data in 3D bounded domains under Navier-slip boundary conditions, requiring small initial energy.


<details>
  <summary>Details</summary>
Motivation: To establish existence results for compressible magnetohydrodynamic systems with challenging conditions: large external potential forces, discontinuous initial data (including vacuum states and large oscillations), in bounded domains with physical boundary conditions.

Method: Use estimates based on effective viscous flux to overcome difficulties from boundary effects and large external forces. Work with Navier-slip boundary conditions in three-dimensional bounded domains.

Result: Prove global existence of weak solutions when initial energy is suitably small, even with discontinuous initial data containing vacuum states and large oscillations.

Conclusion: The paper establishes existence theory for compressible MHD equations under physically realistic but mathematically challenging conditions, providing new analytical tools for handling boundary effects and large external forces.

Abstract: We investigate the compressible magnetohydrodynamic equations subject to large external potential forces with discontinuous initial data in a three-dimensional bounded domain under Navier-slip boundary conditions. We show the global existence of weak solutions for such an initial-boundary value problem provided the initial energy is suitably small. In particular, the initial data may contain vacuum states and possibly exhibit large oscillations. To overcome difficulties brought by boundary and large external forces, some new estimates based on the effective viscous flux play crucial roles.

</details>


### [18] [Well-Posedness for Low Regularity Solutions to the g-SQG Equation with Regular Level Sets](https://arxiv.org/abs/2512.16128)
*Junekey Jeon,Andrej Zlatos*

Main category: math.AP

TL;DR: Generalized SQG equation is locally well-posed in low regularity spaces with H² level sets; for α≤1/6, solutions exist until level sets lose H² regularity, not just from collisions.


<details>
  <summary>Details</summary>
Motivation: To establish well-posedness for the generalized SQG equation in low regularity settings and understand solution breakdown mechanisms, particularly whether solutions can fail due to level set collisions or other geometric singularities.

Method: Analyze the generalized SQG equation in spaces of Hölder continuous solutions with H² level sets (L² curvatures). Use geometric analysis of level sets to study solution breakdown mechanisms.

Result: Local well-posedness established for Hölder continuous solutions with H² level sets. For α≤1/6, solutions exist until level sets lose H² regularity, showing breakdown is not due to collisions or "pile ups" of level sets.

Conclusion: The generalized SQG equation exhibits robust well-posedness in low regularity settings, and for small α values, solution breakdown is characterized by loss of H² regularity in level sets rather than geometric collisions.

Abstract: We show that the generalized SQG equation on the plane is locally well-posed in spaces of low regularity solutions (essentially Hölder continuous with Hölder exponents depending on the equation parameter $α\in(0,\frac 12)$) that have $H^2$ level sets (i.e., with $L^2$ curvatures). Moreover, for $α\le\frac 16$ and initial data satisfying some additional hypotheses we show that the corresponding solutions can stop existing only when their level sets lose $H^2$-regularity, and hence not just due to level set collisions or "pile ups".

</details>


### [19] [On the existence of full dimensional KAM tori for 1D periodic nonlinear Schrödinger equation](https://arxiv.org/abs/2512.16283)
*Yuan Wu*

Main category: math.AP

TL;DR: Proves existence of full dimensional tori for 1D nonlinear Schrödinger equation with space-dependent nonlinearity and Gevrey smooth coefficients, extending previous results to more general perturbations.


<details>
  <summary>Details</summary>
Motivation: Previous results by Bourgain and Cong established invariant tori for nonlinear Schrödinger equations, but their results didn't cover cases where the nonlinear perturbation explicitly depends on the space variable x. This paper aims to extend those results to more general nonlinear perturbations with space dependence.

Method: Uses KAM (Kolmogorov-Arnold-Moser) theory to prove existence of invariant tori. The analysis deals with a 1D nonlinear Schrödinger equation with Fourier multiplier V* and Gevrey smooth nonlinear coefficient f(x). The approach handles the slower decay condition on the radius of invariant tori.

Result: Proves existence of full dimensional tori with radius decaying as I_n ∼ e^{-2ln^σ|n|} for any σ > 2. This extends Bourgain's and Cong's results to cases where nonlinear perturbation depends explicitly on space variable x.

Conclusion: The paper successfully extends invariant tori results to 1D nonlinear Schrödinger equations with space-dependent nonlinear perturbations, establishing existence under Gevrey smoothness conditions and slower decay rates for the tori radii.

Abstract: In this paper, we will prove the existence of full dimensional tori for 1-dimensional nonlinear Schrödinger equation \begin{eqnarray}\label{maineq0} \mathbf{i}u_{t}-u_{xx}+V*u+εf(x)|u|^{4}u=0,\ x\in\mathbb{T}=\mathbb{R}/2π\mathbb{Z}, \end{eqnarray} with boundary conditions, where $V*$ is the Fourier multiplier, and $f(x)$ is Gevrey smooth. Here the radius of the invariant tori satisfies a slower decay, i.e. \[ I_n\sim e^{-2\ln^σ|n|}, \mbox{as}\ n\rightarrow\infty, \] for any $ σ> 2, $ which extends results of Bourgain \cite{BJFA2005} and Cong \cite{cong2024} to the case that the nonlinear perturbation depends explicitly on the space variable $x$.

</details>


### [20] [Low-Mach-number limit for multiphase flows](https://arxiv.org/abs/2512.16286)
*Cassandre Lebot*

Main category: math.AP

TL;DR: Review paper on low-Mach-number limit analysis for compressible Navier-Stokes/Euler equations in single-phase and two-phase flows.


<details>
  <summary>Details</summary>
Motivation: To systematically study and review mathematical analysis of low-Mach-number limits for compressible fluid equations, particularly extending from single-phase to more complex two-phase flow systems.

Method: Review and analysis approach: First examines existing results for single-phase flows, then focuses on two-phase flow systems with different mathematical formulations (algebraic vs. PDE pressure closure, single vs. dual velocities, with/without entropy).

Result: Provides comprehensive review of mathematical results on low-Mach-number limits, comparing different formulations and their mathematical properties for both single-phase and two-phase compressible flows.

Conclusion: The paper organizes and synthesizes existing mathematical theory on low-Mach-number limits, highlighting differences between single-phase and various two-phase flow formulations, providing a foundation for further analysis in this important asymptotic regime.

Abstract: This paper is devoted to the study of the low-Mach-number limit for solutions of the compressible Navier-Stokes or Euler equations for different types of fluids. We first review the different results obtained in the case of flows consisting of one phase. Then, we focus on the low-Mach-number limit for two-phase flows, considering different types of systems: with an algebraic closure or a PDE closure for the pressure, with one single or two different velocities, without or with entropy.

</details>


### [21] [Nekhoroshev type stability for non-local semilinear Schrödinger equations](https://arxiv.org/abs/2512.16299)
*Bingqi Yu,Li Yong*

Main category: math.AP

TL;DR: First rigorous stability results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters, achieving optimal stability times matching Bourgain's conjecture.


<details>
  <summary>Details</summary>
Motivation: To investigate Nekhoroshev-type stability for solutions of ultra-differentiable regularity in Schrödinger equations with non-local nonlinear terms, addressing the gap in rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters.

Method: Employing the method of rational normal forms with a novel global vector field norm adapted to this framework, which eliminates the need for degree tracking during iteration and enables unified treatment of nonlinear terms.

Result: Established first rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters. Under Gevrey class regularity assumptions, achieved stability times matching Bourgain's conjectured optimal stability time.

Conclusion: The paper successfully extends Nekhoroshev-type stability theory to ultra-differentiable regularity regimes in infinite-dimensional Hamiltonian systems, with the novel vector field norm providing a more efficient framework for handling nonlinear terms in rational normal form methods.

Abstract: This paper investigates Nekhoroshev-type stability for solutions of ultra-differentiable regularity in Schrödinger equations with non-local nonlinear terms, employing the method of rational normal forms. We establish the first rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters. Under Gevrey class regularity assumptions, we achieve the stability times matching Bourgain's conjectured optimal stability time in \cite{B04}. Furthermore, we introduce a novel global vector field norm adapted to the rational normal form framework. This norm eliminate the need for degree tracking during the iteration process, thereby enabling a unified treatment of nonlinear terms.

</details>


### [22] [A unified proof of sharp bounds for the Jacobi heat kernel with trace and estimates of multiplicative constants](https://arxiv.org/abs/2512.16306)
*Adam Nowak,Paweł Plewa,Tomasz Z. Szarek*

Main category: math.AP

TL;DR: Unified proof of sharp Jacobi heat kernel bounds with quantitative constant control


<details>
  <summary>Details</summary>
Motivation: Previous sharp bounds for Jacobi heat kernel were developed gradually across multiple papers; need unified proof with explicit constant tracking

Method: Unified and optimized proof approach that traces and estimates all constants throughout the reasoning process

Result: Quantitative control of multiplicative constants in Jacobi heat kernel bounds in terms of parameters; extends to spherical heat kernel and compact rank one symmetric spaces

Conclusion: Provides explicit constant control for heat kernel bounds across related mathematical contexts, enabling dimension-dependent quantitative estimates

Abstract: We give a unified and optimized proof of the sharp bounds for the Jacobi heat kernel, which were obtained gradually in several papers in recent years. We lay particular emphasis on tracing and estimating all constants appearing throughout the entire reasoning. This allows us to quantitatively control the multiplicative constants in the Jacobi heat kernel bounds in terms of the parameters involved. Consequently, analogous control extends to a number of interrelated heat kernels. In particular, we obtain quantitative control in terms of the associated dimension for the spherical heat kernel and for all other heat kernels on compact rank one symmetric spaces.

</details>


### [23] [Bifurcating domains for an overdetermined eigenvalue problem in cylinders](https://arxiv.org/abs/2512.16319)
*Yuanyuan Lian,Filomena Pacella,Pieralberto Sicbaldi*

Main category: math.AP

TL;DR: The paper studies an overdetermined eigenvalue problem in domains within a half-cylinder, showing that nontrivial solutions bifurcate from trivial bounded cylinders at specific parameter values related to Neumann eigenvalues.


<details>
  <summary>Details</summary>
Motivation: To construct domains beyond simple bounded cylinders where positive eigenfunctions satisfy overdetermined boundary conditions, extending the understanding of such eigenvalue problems in cylindrical geometries.

Method: Using bifurcation theory to show that branches of domains with desired properties emerge from trivial bounded cylinder domains Ω_t at critical values t_j = π/(2√σ_j), where σ_j are simple Neumann eigenvalues of the Laplace operator on the cross-section ω.

Result: Successfully constructed nontrivial domains in the half-cylinder that admit positive eigenfunctions satisfying the overdetermined boundary conditions, with solutions that can be reflected to generate solutions in full cylinders.

Conclusion: The paper demonstrates the existence of nontrivial solutions to the overdetermined eigenvalue problem through bifurcation from trivial domains, providing new examples beyond the obvious bounded cylinder cases.

Abstract: We study an overdetermined eigenvalue problem for domains $Ω$ contained in the half-cylinder $Σ=ω\times (0, +\infty)$, based on a bounded regular domain $ω\subset \mathbb{R}^{N-1}$. It is easy to see that in any bounded cylinder $Ω_{t}=ω\times (0, t)$, $t > 0$, the eigenvalue problem admits a one-dimensional positive eigenfunction which satisfies the overdetermined boundary conditions. The aim of the paper is to construct other domains $Ω\subset Σ$ for which there exists a positive eigenfunction that is a solution of the overdetermined problem. This is achieved by showing that branches of such domains bifurcate from the ``trivial'' domains $Ω_{t_j}$ at the values $t_{j} = \fracπ{2\sqrt{σ_j}}$ where $σ_j$ ($j\geq 1$) is a simple Neumann eigenvalue of the Laplace operator on $ω\subset \mathbb{R}^{N-1}$. The solutions can be reflected with respect to $ω$ to generate nontrivial solutions in a cylinder.

</details>


### [24] [Nekhoroshev type stability for Ultra-differential Hamiltonian in $L^2$ space](https://arxiv.org/abs/2512.16332)
*Bingqi Yu,Li Yong*

Main category: math.AP

TL;DR: The paper establishes sub-exponential stability times for infinite-dimensional Hamiltonian PDEs using a normal form lemma that combines high mode decay with high-order smallness in ultra-differentiable regularity.


<details>
  <summary>Details</summary>
Motivation: To develop a general framework for proving long-time stability results for Hamiltonian PDEs under weaker regularity conditions than previous approaches, aiming to reach optimal stability bounds predicted by Bourgain.

Method: Combines decay of high modes with smallness introduced by high orders to prove a normal form lemma for infinite-dimensional Hamiltonian systems under ultra-differentiable regularity. The approach works within a general framework applicable to the ultra-differential class.

Result: Proves sub-exponential stability time for a wide class of Hamiltonian PDEs including Schrödinger equations with convolution potentials, fractional-order Schrödinger equations, and beam equations with metrics. When conditions match previous ones, the stability time reaches Bourgain's predicted optimal bound, and earlier results are approached under lower conditions.

Conclusion: The paper provides a general framework for establishing long-time stability in Hamiltonian PDEs with ultra-differentiable regularity, achieving optimal bounds in certain cases and extending results to broader classes of equations under weaker conditions.

Abstract: This paper combines the decay of high modes with the smallness introduced by high orders, leading to a normal form lemma for infinite-dimensional Hamiltonian systems under ultra-differentiable regularity. We prove the sub-exponential stability time of a wide class of Hamiltonian PDEs, including the Schrödinger equation with convolution potentials, fractional-order Schrödinger equations, and beam equations with metrics. When the conditions are equivalent to previous ones, the stability time we obtain reaches Bourgain's predicted optimal bound. Furthermore, we approach earlier results under lower conditions. These results are discussed within a general framework we propose, which applies to the ultra-differential class.

</details>


### [25] [Quantitative stratification and optimal regularity for harmonic almost complex structures](https://arxiv.org/abs/2512.16341)
*Chang-Yu Guo,Ming-Lun Liu,Chang-Lin Xiang*

Main category: math.AP

TL;DR: New proof of partial regularity and rectifiability of singularities for energy minimizing harmonic almost complex structures, improving previous results.


<details>
  <summary>Details</summary>
Motivation: To provide simpler proofs and stronger results for the regularity theory of energy minimizing harmonic almost complex structures, building on He's recent work.

Method: 1) New observation on equation structure for simpler partial regularity proof; 2) Quantitative stratification method of Naber-Valtorto to prove rectifiability of singular stratum; 3) Combining these to establish optimal regularity theory.

Result: 1) Easier new proof of partial regularity theorem; 2) Rectifiability of singular stratum; 3) Optimal regularity theory that improves He's result.

Conclusion: The paper provides significant improvements to the regularity theory for energy minimizing harmonic almost complex structures through new methods and stronger results.

Abstract: In a recent interesting work [15], W.Y. He established the important partial regularity theory and the almost optimal higher regularity theory for energy minimizing harmonic almost complex structures. Based on a new observation on the structure of equations, we give an easier new proof of the partial regularity theorem, and adapting the powerful quantitative stratification method of Naber-Valtorta [22], we further prove the rectifiability of singular stratum of energy minimizing harmonic almost complex structures. Based on this, we establish an optimal regularity theory, which improves the corresponding result of He.

</details>


### [26] [Homogenization of a micropolar fluid past a porous media with non-zero spin boundary condition](https://arxiv.org/abs/2512.16353)
*Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: Analysis of micropolar fluid flow through porous media with periodic obstacles, deriving a micropolar Darcy law via homogenization.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of micropolar fluids (fluids with microstructure) flowing through porous media with periodically distributed obstacles, and to derive effective macroscopic equations that describe such flows.

Method: Mathematical analysis of micropolar fluid equations in perforated domains with non-homogeneous boundary conditions for microrotation (proportional to velocity rotation rate). Uses homogenization theory to pass to the limit as obstacle size ε → 0.

Result: Proves existence and uniqueness of solution for the microscopic problem. Derives an analogue of the classical Darcy law for micropolar fluids through homogenization, providing effective macroscopic equations for flow in porous media.

Conclusion: The study successfully extends porous media flow theory to micropolar fluids, establishing both microscopic well-posedness and macroscopic effective equations that generalize Darcy's law to account for microstructure effects.

Abstract: We consider a micropolar fluid flow in a media perforated by periodically distributed obstacles of size $\varepsilon$. A non-homogeneous boundary condition for microrotation is considered: the microrotation is assumed to be proportional to the rotation rate of the velocity on the boundary of the obstacles. The existence and uniqueness of solution is analyzed. Moreover, passing to the limit when $\varepsilon$ tends to zero, an analogue of the classical micropolar Darcy law in the theory of porous media is derived.

</details>


### [27] [Uniform vanishing damping limit for the 2D inviscid Oldroyd-B model with fractional stress tensor diffusion](https://arxiv.org/abs/2512.16436)
*Chen Liang,Zhaonan Luo,Zhaoyang Yin*

Main category: math.AP

TL;DR: The paper studies the uniform vanishing damping limit of 2D inviscid Oldroyd-B model with fractional stress tensor diffusion, establishing optimal time decay rates and uniform damping vanishing rates.


<details>
  <summary>Details</summary>
Motivation: To understand how fractional stress tensor diffusion affects the global regularity and time decay behavior of the 2D Oldroyd-B model with damping, and to establish uniform vanishing damping limits.

Method: Uses improved Fourier splitting method for time decay analysis, spectral analysis methods for improving decay rates of specific components, and combines time decay rates with time integrability to obtain uniform damping vanishing rates.

Result: 1) Fractional stress tensor diffusion reduces global regularity requirements; 2) Optimal time decay rates under critical regularity for a=0; 3) Uniform time decay rates for a∈(0,1]; 4) Uniform damping vanishing rates for the model; 5) Improved decay rates for trτ ensuring sharp uniform damping vanishing rates.

Conclusion: The paper successfully establishes uniform vanishing damping limits for the 2D Oldroyd-B model with fractional diffusion, providing optimal decay rates and demonstrating how fractional diffusion improves regularity and decay properties.

Abstract: This paper is devoted to the uniform vanishing damping limit of the 2D inviscid Oldroyd-B model with fractional stress tensor diffusion. Firstly, we find that fractional stress tensor diffusion helps to reduce the global regularity of the 2D Oldroyd-B model with damping coefficient $a\in[0,1]$. By virtue of improved Fourier splitting method, we then prove the optimal time decay rates under the critical regularity for $a=0$. When $a\in (0,1]$, we establish time decay rates that are uniform with respect to $a$. Combining the time decay rate for $a\in [0,1]$ and the time integrability, we obtain the uniform damping vanishing rates for the 2D Oldroyd-B model. Using spectral analysis methods, we finally improve the time decay rates for $\mathrm{tr}τ$ with $a\in (0,1]$, which ensure the sharp uniform damping vanishing rates of $\mathrm{tr}τ$.

</details>


### [28] [Normalized solutions for a class of fractional Choquard equations with mixed nonlinearities](https://arxiv.org/abs/2512.16438)
*Shaoxiong Chen,Zhipeng Yang,Xi Zhang*

Main category: math.AP

TL;DR: Study of fractional Choquard equation with mixed nonlinearities and mass constraint, establishing existence and multiplicity of normalized solutions including ground states.


<details>
  <summary>Details</summary>
Motivation: To investigate normalized solutions (solutions with prescribed L²-norm) for fractional Choquard equations with competing nonlocal nonlinearities, which arise in quantum physics and have important physical interpretations.

Method: Variational methods combined with constrained minimization techniques, using the fractional Laplacian operator and Riesz potential interactions, with careful analysis of the competing nonlinear terms.

Result: Proved existence and multiplicity of normalized solutions for the fractional Choquard equation with mixed nonlinearities, and established existence of ground state normalized solutions for sufficiently small α parameter.

Conclusion: The fractional Choquard equation with competing nonlocal nonlinearities admits normalized solutions with prescribed mass, including ground states, under appropriate parameter conditions and exponent ranges.

Abstract: In this paper we study the following fractional Choquard equation with mixed nonlinearities:
  \[
  \left\{
  \begin{array}{l}
  (-Δ)^s u = λu + α\left( I_μ* |u|^q \right) |u|^{q-2} u + \left( I_μ* |u|^p \right) |u|^{p-2} u, \quad x \in \mathbb{R}^N, \\[4pt]
  \displaystyle \int_{\mathbb{R}^N} |u|^2 \,\mathrm{d}x = c^2 > 0.
  \end{array}
  \right.
  \]
  Here $N > 2s$, $s \in (0,1)$, $μ\in (0, N)$, and the exponents satisfy
  \[
  \frac{2N - μ}{N} < q < p < \frac{2N - μ}{N - 2s},
  \]
  while $α> 0$ is a sufficiently small parameter, $λ\in \mathbb{R}$ is the Lagrange multiplier associated with the mass constraint, and $I_μ$ denotes the Riesz potential. We establish existence and multiplicity results for normalized solutions and, in addition, prove the existence of ground state normalized solutions for $α$ in a suitable range.

</details>


### [29] [Global existence and stability of near-affine solutions of compressible elastodynamics](https://arxiv.org/abs/2512.16505)
*Xianpeng Hu,Yuanzhi Tu,Changyou Wang,Huanyao Wen*

Main category: math.AP

TL;DR: Global existence and asymptotic behavior of strong solutions for compressible nonlinear elastodynamics under small perturbations of affine solutions in dimensions 2 and 3.


<details>
  <summary>Details</summary>
Motivation: To establish global existence and long-time behavior for compressible nonlinear elastodynamics, which is important for understanding material deformation and wave propagation in elastic media.

Method: Analysis of the Cauchy problem for compressible nonlinear elastodynamics in ℝ^d (d=2,3), considering sufficiently small H^3-perturbations of affine solutions.

Result: Proves unique global strong solution existence for small perturbations and establishes asymptotic behavior of the solution.

Conclusion: The compressible nonlinear elastodynamics system admits global strong solutions with predictable asymptotic behavior for small perturbations of affine states in dimensions 2 and 3.

Abstract: We prove that for sufficiently small $H^3$-perturbations of an affine solution, the Cauchy problem for the compressible nonlinear elastodynamics in $\mathbb{R}^d$, for $d=2,3$, admits a unique global strong solution. Moreover, we establish the asymptotic behavior of the solution.

</details>


### [30] [Liouville-type Theorems for Stable Solutions of the Hénon-Lane-Emden System](https://arxiv.org/abs/2512.16566)
*Long-Han Huang,Wenming Zou*

Main category: math.AP

TL;DR: The paper establishes Liouville-type theorems for the Hénon-Lane-Emden system in ℝ^N\{0}, covering both subcritical and supercritical cases, with applications to solutions stable outside compact sets.


<details>
  <summary>Details</summary>
Motivation: To prove nonexistence (Liouville-type) results for the Hénon-Lane-Emden system, particularly for solutions that are stable outside a compact set, which extends previous work in the field.

Method: Mathematical analysis of the Hénon-Lane-Emden system using PDE techniques, establishing general Liouville-type theorems for subcritical cases, then proving validity of the Hénon-Lane-Emden conjecture under specific parameter conditions.

Result: First Liouville-type theorems for this class of solutions in the Hénon-Lane-Emden system; validity of the conjecture for solutions stable outside compact sets under conditions: 0 < min{p,q} < 1, or 0 ≤ a-b ≤ (N-2)(p-q), or N ≤ 2(p+q+2)/(pq-1) + 10.

Conclusion: The paper provides comprehensive Liouville-type results for the Hénon-Lane-Emden system, refining existing literature and establishing new nonexistence theorems for both subcritical and supercritical cases.

Abstract: We investigate the Hénon-Lane-Emden system defined by $- Δu=|x|^a |v|^{p-1}v$ and $- Δv=|x|^b |u|^{q-1}u$ in $\mathbb{R}^N \!\setminus\! \{0\}$. We begin by establishing a general Liouville-type theorem for the subcritical case. Then we prove that the Hénon-Lane-Emden conjecture is valid for solutions stable outside a compact set, provided that $0 < \min\,\{p, q\} < 1$, or $0 \leq a - b \leq (N-2)(p - q)$, or $N \leq \frac{2(p+q+2)}{pq-1} + 10$. Additional Liouville-type theorems for the subcritical case are also obtained. Furthermore, we address the supercritical case. To our knowledge, these results constitute the first Liouville-type theorems for this class of solutions in the Hénon-Lane-Emden system. As a by-product, several existing results in the literature are refined.

</details>


### [31] [Constructing steering-type solutions for higher order Cauchy-Riemann equations in $\mathbb{R}^{m+1}$](https://arxiv.org/abs/2512.16594)
*Daniel Alfonso Santiesteban,Dixan Peña Peña,Ricardo Abreu Blaya*

Main category: math.AP

TL;DR: The paper constructs explicit solutions to higher-order PDE systems using the multidimensional Cauchy-Riemann operator framework, focusing on polymonogenic and polyharmonic functions, and identifies which solutions satisfy hypercomplex derivative equations.


<details>
  <summary>Details</summary>
Motivation: The multidimensional Cauchy-Riemann operator provides a powerful framework for studying higher-order partial differential equations in ℝ^{m+1}, but there's a need to explicitly construct solutions to such systems, particularly for polymonogenic and polyharmonic functions.

Method: The authors construct solutions from families of complex-valued functions that are closed under both conjugation and the action of the complex Cauchy-Riemann operator. They then analyze which of these solutions satisfy homogeneous linear differential equations involving the hypercomplex derivative.

Result: The work successfully provides explicit constructions of solutions to higher-order PDE systems and proves that precisely some of these solutions also satisfy homogeneous linear differential equations with the hypercomplex derivative.

Conclusion: The paper establishes a systematic approach for constructing explicit solutions to higher-order PDE systems using the multidimensional Cauchy-Riemann framework and characterizes which solutions have additional properties related to hypercomplex derivatives.

Abstract: The multidimensional Cauchy-Riemann operator provides a framework for studying higher order partial differential equations in $\mathbb{R}^{m+1}$, whose solutions include polymonogenic and polyharmonic functions, among others. In this work, we aim to explicitly construct solutions to such systems, generated from families of complex valued functions which are closed under conjugation and under the action of the complex Cauchy-Riemann operator. Moreover, we prove that precisely some of these solutions also satisfy homogeneous linear differential equations involving the so-called hypercomplex derivative.

</details>


### [32] [Regularity for fully nonlinear elliptic equations in generalized Orlicz spaces](https://arxiv.org/abs/2512.16600)
*Sun-Sig Byun,Jeongmin Han,Mikyoung Lee*

Main category: math.AP

TL;DR: Optimal global Calderón-Zygmund estimate for viscosity solutions of fully nonlinear elliptic equations with nonconvex nonlinearities in generalized Orlicz spaces.


<details>
  <summary>Details</summary>
Motivation: To establish optimal regularity estimates for viscosity solutions of fully nonlinear elliptic equations even when the nonlinearities are nonconvex or only asymptotically convex, extending classical Calderón-Zygmund theory to more general settings.

Method: Prove global Calderón-Zygmund type estimates for viscosity solutions to Dirichlet boundary problems, working in generalized Orlicz spaces and handling asymptotically convex nonlinearities with respect to the Hessian.

Result: The Hessian of the solution is shown to be as integrable as the nonhomogeneous term in generalized Orlicz spaces, even for asymptotically convex nonlinearities.

Conclusion: Optimal global regularity estimates can be established for fully nonlinear elliptic equations with nonconvex nonlinearities, extending classical results to more general function spaces and nonlinearity conditions.

Abstract: In this paper, we establish an optimal global Calderón-Zygmund type estimate for the viscosity solution to the Dirichlet boundary problem of fully nonlinear elliptic equations with possibly nonconvex nonlinearities. We prove that the Hessian of the solution is as integrable as the nonhomogeneous term in the setting of a given generalized Orlicz space even when the nonlinearity is asymptotically convex with respect to the Hessian of the solution.

</details>


### [33] [Existence and stability of discretely self-similar blowup for a wave maps type equation](https://arxiv.org/abs/2512.16623)
*Irfan Glogić,David Hilditch,David Wallauch*

Main category: math.AP

TL;DR: Construction and nonlinear stability analysis of discretely self-similar blowup solutions for a geometric wave equation with null-form structure in all dimensions d≥1.


<details>
  <summary>Details</summary>
Motivation: To study finite-time blowup for a nonlinear wave equation mapping from Minkowski space to the 1-sphere, addressing the existence and stability of discretely self-similar blowup solutions for geometric wave equations.

Method: Construct countable family of discretely self-similar blowup solutions for all d≥1, then perform detailed nonlinear stability analysis using similarity variables, Liouville-Green transformations, Volterra-type asymptotics, and spectral analysis of linearized operators.

Result: Successfully constructed discretely self-similar blowup solutions in all dimensions d≥1 and established their nonlinear stability with precise co-dimension determined by unstable spectrum.

Conclusion: First result on existence and stability of discretely self-similar blowup for a geometric wave equation, with comprehensive analysis covering all dimensions and general perturbations in d=1.

Abstract: We study finite-time blowup for a nonlinear wave equation for maps from the Minkowski space $\mathbb{R}^{1+d}$ into the 1-sphere $\mathbb{S}^1$, whose nonlinearity exhibits a null-form structure. We construct, for every dimension $d \geq 1$, a countable family of discretely self-similar blowup solutions, which are even for $d=1$ and radial for $d \geq 2$. The main contribution of the paper is a detailed nonlinear stability analysis of this family of solutions. For $d \geq 2$, we consider radial data, while in $d=1$ we allow for general perturbations. After linearizing around the self-similar profiles in similarity variables, we construct resolvents of the resulting highly non-self-adjoint operators through Liouville-Green transformations and precise Volterra-type asymptotics. The construction itself, which occupies most of the paper, is technically challenging, as it is performed in arbitrary dimensions and for a countable family of operators in each. Combined with a detailed spectral analysis of the linearized operators, this yields sharp semigroup bounds and allows us to establish nonlinear stability of all discretely self-similar profiles in all dimensions, with precise co-dimension determined by the unstable spectrum. To our knowledge, this is the first result on the existence and stability of discretely self-similar blowup for a geometric wave equation.

</details>


### [34] [The capillary Christoffel-Minkowski problem](https://arxiv.org/abs/2512.16655)
*Xinqun Mei,Guofang Wang,Liangjun Weng*

Main category: math.AP

TL;DR: Introduces k-th capillary area measure for capillary convex bodies in Euclidean half-space and solves corresponding Christoffel-Minkowski problem via Hessian-type equation with Robin boundary condition.


<details>
  <summary>Details</summary>
Motivation: To extend classical area measure theory to capillary convex bodies in Euclidean half-space by introducing capillary area measures, and to formulate and solve the corresponding Christoffel-Minkowski problem as a natural boundary counterpart to classical convex geometry problems.

Method: Introduces k-th capillary area measure for capillary convex bodies, formulates Christoffel-Minkowski problem for these measures, reduces problem to solving Hessian-type equation with Robin boundary value condition, then establishes existence and uniqueness of smooth solutions.

Result: Establishes existence and uniqueness of smooth solution to the Christoffel-Minkowski problem for capillary convex bodies under natural sufficient conditions, providing complete solution to the boundary counterpart of classical area measure problems.

Conclusion: Successfully extends classical area measure theory to capillary convex bodies by introducing capillary area measures and solving the corresponding Christoffel-Minkowski problem, establishing a complete theoretical framework for boundary convex geometry in Euclidean half-space.

Abstract: In this article, we introduce a $k$-th capillary area measure for capillary convex bodies in the Euclidean half-space, which serves as a boundary counterpart to the classical concept of area measure (see, e.g., \cite[Chapter 8]{Sch}). We then propose a Christoffel-Minkowski problem for capillary convex bodies, to find a capillary convex body in the Euclidean half-space with a prescribed $k$-th capillary area measure. This problem is equivalent to solving a Hessian-type equation with a Robin boundary value condition. We then establish the existence and uniqueness of a smooth solution under a natural sufficient condition.

</details>


### [35] [Unconditional uniqueness of Hardy--Hénon parabolic equations on Herz spaces](https://arxiv.org/abs/2512.16711)
*Naoya Hatano,Masahiro Ikeda*

Main category: math.AP

TL;DR: The paper proves unconditional uniqueness for Hardy-Hénon parabolic equation solutions in Herz spaces, improving previous results by relaxing endpoint and interpolation exponent conditions.


<details>
  <summary>Details</summary>
Motivation: The Hardy-Hénon parabolic equation (semilinear heat equation with power-type weight |x|^γ|u|^{α-1}u) has weight that can be effectively handled in Herz spaces. Previous results had limitations on endpoint case q=α and large interpolation exponent r≥q that need to be relaxed.

Method: The authors work within Herz spaces $\dot{K}^s_{q,r}({\mathbb R}^n)$ framework. They use the properties of Herz spaces to handle the power-type weight in the nonlinear term more effectively than previous approaches.

Result: The main result establishes unconditional uniqueness of solutions in Herz spaces, specifically relaxing the endpoint case q=α and the large interpolation exponent case r≥q compared to previous results.

Conclusion: Herz spaces provide an effective framework for studying the Hardy-Hénon parabolic equation, allowing for improved uniqueness results with less restrictive conditions on parameters compared to previous approaches.

Abstract: In this paper, we introduce the unconditional uniqueness of solutions in Herz spaces for the Hardy--Hénon parabolic equation, which is a semilinear heat equation with a power-type weight in the nonlinear term $|x|^γ|u|^{α-1}u$. It is expected that the power-type weight in the nonlinear term can be effectively handled within Herz spaces. In fact, our result in Herz spaces $\dot{K}^s_{q,r}({\mathbb R}^n)$ relaxes the endpoint case $q=α$ and the large interpolation exponent case $r\ge q$ compared to previous results.

</details>


### [36] [Stability under lamination and polycrystalline effective conductivity](https://arxiv.org/abs/2512.16787)
*Nathan Albin,Vincenzo Nesi,Mariapia Palombaro*

Main category: math.AP

TL;DR: The paper proves stability under lamination for a set of 3×3 symmetric matrices representing effective conductivities of polycrystals, contributing to the best known inner bound on the G-closure in 3D.


<details>
  <summary>Details</summary>
Motivation: To advance the understanding of effective properties of composite materials, specifically polycrystals, by establishing stability properties of conductivity matrices under lamination operations, which helps characterize the complete set of achievable effective properties (G-closure).

Method: The authors prove mathematical stability under lamination operations for a specific set of real, symmetric 3×3 matrices that represent effective conductivities. This builds upon a construction from a companion paper and combines with previous results.

Result: The paper successfully establishes the stability under lamination of the constructed matrix set, which when combined with previous constructions provides the best known inner bound on the G-closure of three-dimensional polycrystals.

Conclusion: The stability proof represents a significant advancement in characterizing the complete set of achievable effective conductivities for 3D polycrystals, moving closer to a complete description of the G-closure through mathematical analysis of lamination stability.

Abstract: We prove the stability under lamination of a set of real, symmetric 3$\times$3 matrices that can be viewed as a subset of the effective conductivities of a polycrystal. Constructed in a companion paper, such set in combination with several previous constructions provides the best inner bound known so far on the $G$-closure of a three dimensional polycrystal.

</details>


### [37] [On Some Transformations Associated to a Certain Cone](https://arxiv.org/abs/2512.16840)
*Vladimir Vasilyev,Denis Tokarev*

Main category: math.AP

TL;DR: Study of elliptic pseudo-differential equations in 4-faced cones using Sobolev-Slobodetskii spaces, with Bochner kernel evaluation and unique solution formulas under symbol restrictions, plus boundary value problems with integral conditions.


<details>
  <summary>Details</summary>
Motivation: To analyze elliptic pseudo-differential equations in complex geometric settings (4-faced cones) and develop solution methods for such equations with boundary conditions, which have applications in mathematical physics and PDE theory.

Method: Use Sobolev-Slobodetskii spaces for analysis, evaluate Bochner kernel for 4-faced cones, derive explicit solution formulas under symbol restrictions, and consider boundary value problems with additional integral conditions.

Result: Obtained explicit formula for unique solution to the elliptic pseudo-differential equation under certain symbol restrictions, and proved unique solvability for the boundary value problem with integral condition.

Conclusion: The paper successfully develops analytical tools for solving elliptic pseudo-differential equations in 4-faced cones, providing explicit solution formulas and proving unique solvability for boundary value problems with integral conditions.

Abstract: A model elliptic pseudo-differential equation in $4$-faced cone is studied in Sobolev--Slobodetskii space. The Bochner kernel for such a cone is evaluated and explicit formula for unique solution to the considered equation is presented under certain restrictions on the symbol. Boundary value problem with additional integral condition is considered and unique solvability to the boundary value problem is proved.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [38] [Sparse Operator-Adapted Wavelet Decomposition Using Polygonal Elements for Multiscale FEM Problems](https://arxiv.org/abs/2512.16004)
*Furkan Şık,F. L. Teixeira,B. Shanker*

Main category: physics.comp-ph

TL;DR: A sparse multiscale wavelet-based FEM using polygonal mesh hierarchies with adaptive coarsening for memory efficiency and near-linear computational complexity.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient finite element method that can handle complex domains with varying resolution needs while maintaining computational efficiency and memory optimization.

Method: Uses operator-adapted wavelet decomposition on unstructured polygonal mesh hierarchies obtained via geometric coarsening. Starts with triangular elements at finest level, coarsens to convex polygons at coarser levels. Decouples resolution levels for independent solving.

Result: Creates an adaptive method where smooth regions use fewer, larger polygonal elements while high-gradient regions use smaller elements, improving memory efficiency. Achieves nearly linear computational complexity through hierarchical sparse linear-algebra operations.

Conclusion: The proposed method provides an efficient, adaptive FEM framework with decoupled multiscale resolution, memory optimization through adaptive element sizing, and near-linear computational complexity suitable for complex domain problems.

Abstract: We develop a sparse multiscale operator-adapted wavelet decomposition-based finite element method (FEM) on unstructured polygonal mesh hierarchies obtained via a coarsening procedure. Our approach decouples different resolution levels, allowing each scale to be solved independently and added to the entire solution without the need to recompute coarser levels. At the finest level, the meshes consist of triangular elements which are geometrically coarsened at each step to form convex polygonal elements. Smooth field regions of the domain are solved with fewer, larger, polygonal elements, whereas high-gradient regions are represented by smaller elements, thereby improving memory efficiency through adaptivity. The proposed algorithm computes solutions via sequences of hierarchical sparse linear-algebra operations with nearly linear computational complexity.

</details>


### [39] [ClusTEK: A grid clustering algorithm augmented with diffusion imputation and origin-constrained connected-component analysis: Application to polymer crystallization](https://arxiv.org/abs/2512.16110)
*Elyar Tourani,Brian J. Edwards,Bamin Khomami*

Main category: physics.comp-ph

TL;DR: A grid clustering framework using Laplacian-kernel diffusion and origin-constrained connected-component analysis to improve edge handling and topological accuracy while maintaining computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Grid clustering algorithms suffer from parameter sensitivity, loss of structural detail at coarse resolutions, and misclassification of edge/bridge cells at fine resolutions. Existing solutions (adaptive grids, parameter tuning, hybrid methods) offer limited robustness.

Method: Integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid. Features automated preprocessing for data-driven cell size and density thresholds. Diffusion mitigates sparsity and reconstructs missing edge cells without over-smoothing, while OC-CCA constrains component growth to physically consistent origins to reduce false merges.

Result: Method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems (9k, 180k, and 989k atoms) shows atomic-level accuracy, captures physically meaningful morphologies, and delivers accelerated computation with O(n log n) scaling.

Conclusion: The proposed framework overcomes traditional grid clustering limitations by combining diffusion-based reconstruction with constrained component analysis, achieving both high topological accuracy and computational efficiency for large-scale data analysis.

Abstract: Grid clustering algorithms are valued for their efficiency in large-scale data analysis but face persistent limitations: parameter sensitivity, loss of structural detail at coarse resolutions, and misclassifications of edge or bridge cells at fine resolutions. Previous studies have addressed these challenges through adaptive grids, parameter tuning, or hybrid integration with other clustering methods, each of which offers limited robustness. This paper introduces a grid clustering framework that integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid to reconstruct the cluster topology with high accuracy and computational efficiency. During grid construction, an automated preprocessing stage provides data-driven estimates of cell size and density thresholds. The diffusion step then mitigates sparsity and reconstructs missing edge cells without over-smoothing physical gradients, while OC-CCA constrains component growth to physically consistent origins, reducing false merges across narrow gaps. Operating on a fixed-resolution grid with spatial indexing ensures the scaling of O(nlog n). Experiments on synthetic benchmarks and polymer simulation datasets demonstrate that the method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems across scales (9k, 180k, and 989k atoms) shows that optimal preprocessing, combined with diffusion-based clustering, reproduces atomic-level accuracy and captures physically meaningful morphologies while delivering accelerated computation.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [40] [Tensor network approaches for plasma dynamics](https://arxiv.org/abs/2512.15924)
*Ryan J. J. Connor,Preetma Soin,Callum W. Duncan,Andrew J. Daley*

Main category: physics.plasm-ph

TL;DR: Tensor networks, particularly Matrix Product States, show promise for simulating plasma dynamics described by Vlasov-Maxwell and Magnetohydrodynamics systems, with validation against Particle-In-Cell codes.


<details>
  <summary>Details</summary>
Motivation: Plasma dynamics are governed by complex non-linear differential equations that are computationally challenging to solve directly for large 2D and 3D problems, requiring more efficient simulation methods.

Method: The paper investigates applying tensor networks (specifically Matrix Product States) to plasma systems described by Vlasov-Maxwell equations, and extends this approach to Magnetohydrodynamics descriptions.

Result: Matrix Product States perform well for low-dimensional plasma problems, but alternative tensor network geometries may be needed for regimes with strong permanent magnetic fields or high-dimensional problems. The approach was validated against state-of-the-art Particle-In-Cell codes for industrially relevant test cases.

Conclusion: Tensor networks offer a promising approach for efficient plasma simulations, with Matrix Product States working well for simpler cases but requiring alternative geometries for more complex scenarios, and the method can be extended to different plasma descriptions like Magnetohydrodynamics.

Abstract: The dynamics of plasmas are governed by a set of non-linear differential equations which remain challenging to solve directly for large 2D and 3D problems. Here we investigate how tensor networks could be applied to plasmas described by the Vlasov-Maxwell system of equations and investigate parameter regimes which show promise for efficient simulations. We show for low-dimensional problems that the simplest form of tensor networks known as a Matrix Product State performs sufficiently well, however in regimes with a strong permanent magnetic field or high-dimensional problems one may need to consider alternative tensor network geometries. We conclude the study of the Vlasov-Maxwell system with the application of tensor networks to an industrially relevant test case and validate our results against state of the art plasma solvers based on Particle-In-Cell codes. We also extend the application of tensor networks to the alternative plasma description of Magnetohydrodynamics and outline how this can be encoded using Matrix Product States.

</details>


### [41] [Toward the Origins of Binding Energy Shifts and Satellites Formation During Plasma-XPS Measurements](https://arxiv.org/abs/2512.16196)
*J. Trey Diulus,Ashley R. Head,Jorge Anibal Boscoboinik,Carles Corbella Roca,Alexander Tselev,Andrei Kolmakov*

Main category: physics.plasm-ph

TL;DR: Plasma XPS enables real-time chemical analysis during plasma processing, revealing transient surface species and showing how plasma parameters affect binding energy shifts and satellite peaks in conductive, dielectric, and gas phase systems.


<details>
  <summary>Details</summary>
Motivation: To understand the origins of binding energy shifts and satellite peaks in plasma XPS measurements, which occur under conditions relevant to semiconductor processing and plasma technologies, where conventional ultrahigh vacuum XPS cannot access transient chemical states.

Method: Used a standard laboratory ambient pressure XPS apparatus coupled with an AC-driven capacitively coupled plasma source to study conductive (Au), dielectric, and gas phase systems during plasma exposure.

Result: Detected metastable surface species like transient Au oxides; observed pressure- and plasma-dependent BE shifts up to 50 eV in dielectrics due to charging; found spectral broadening and satellite peaks in gas phase species from oscillating plasma potentials; showed mitigation of shifts at higher pressures or with electronegative plasmas.

Conclusion: Plasma XPS is a critical metrological tool for probing transient surface chemistry, revealing complex interplay between plasma parameters, surface charging, and local electric fields, with important implications for semiconductor processing, material synthesis, and plasma diagnostics.

Abstract: In plasma X ray photoelectron spectroscopy emerges as a powerful platform for real time, in situ chemical analysis under conditions relevant to semiconductor processing and other plasma enabled technologies. This study investigates the origins of binding energy shifts and satellite peaks formation observed during plasma XPS measurements across conductive, dielectric, and gas phase systems. Using a standard laboratory based ambient pressure XPS apparatus coupled with an alternating current driven capacitively coupled plasma source, we show that metastable surface species, such as transient Au oxides, can be detected during plasma exposure, revealing chemical states hardly accessible using conventional ultrahigh vacuum XPS. In dielectric samples, we observe pressure- and plasma type dependent BE shifts up to 50 eV, attributed to X ray induced and plasma mediated surface charging. These shifts are mitigated at higher pressures plasmas or in electronegative plasmas, the latter due to enhanced charge compensation mechanisms involving slow negative ions. For gas phase species, AC plasma excitation leads to spectral broadening and the emergence of satellite peaks with a few eV energy separations, linked to oscillating local plasma potentials in the probing volume. These findings highlight the important and complex interplay of plasma parameters, surface charging, and local electric fields in shaping XPS spectra. Overall, plasma XPS emerges as a critical metrological tool for probing transient surface chemistry, with implications for semiconductor processing, material synthesis, and plasma diagnostics.

</details>


### [42] [SCOPE: Simple Coil Optimization for Plasma and Engineering](https://arxiv.org/abs/2512.16546)
*Nathan Welch,Chris Marsden*

Main category: physics.plasm-ph

TL;DR: A combined simulated annealing and constrained optimization method for designing superconducting tokamak coils that handles multiple plasma scenarios and engineering constraints efficiently.


<details>
  <summary>Details</summary>
Motivation: Superconducting coil design for tokamaks is complex due to multiple engineering requirements, HTS cable limits, need to support various plasma scenarios, divertor optimization, and physical space constraints.

Method: Combined simulated annealing for optimal coil sizes/positions with constrained quadratic/quartic optimization for coil currents. Optimizes for multiple scenarios simultaneously to avoid over-optimization of single design points.

Result: Efficient implementation enabling millions of evaluations in hours with modest computational power. Part of larger iterative workflow allowing detailed design feedback.

Conclusion: The method provides an efficient optimization approach for complex tokamak coil design that balances multiple constraints and scenarios while enabling iterative refinement.

Abstract: Designing superconducting coils for a tokamak fusion device is a highly coupled, non-linear design problem. The coils have many disparate engineering requirements from structural to power electronics, as well strict limits placed on the system by the high temperature superconducting (HTS) cables. Simultaneously, the coils must be able to contain multiple plasma scenarios from inception, through ramp up, to flat top, and ramp down, all whilst applying a large, controlled, inductive voltage to drive current. In addition, we wish to optimize divertor separatrices to increase the likelihood of designing a suitable divertor strikepoint. Lastly, the physical limits of the entire tokamak must be taken into account and space reserved for support structures, access for maintenance schemes, and installation limits. The method outlined here uses a combined simulated annealing method to find optimal coil sizes and positions with a constrained quadratic or quartic optimization for the coil currents. The method is designed to optimize coils for multiple scenarios simultaneously, including ramp-ups, to avoid over optimization of a single design point. A key enabler is the efficient implementation that allows millions of evaluations to be performed in a few hours with modest computational power. This optimization method is part of a larger, iterative workflow which enables further, detailed design work to feedback on the optimization.

</details>


### [43] [Disruption Modelling for Engineering and Physics Design of Tokamak Energy ST-E1 Fusion Power Plant](https://arxiv.org/abs/2512.16604)
*M. Scarpari,X. Zhang,K. Borowiec,P. F. Buxton,G. Calabro,S. Carusotti,A. Ciula,V. Godhani,J. D. Lore,E. N. J. Maartensson,S. A. M. McNamara,J. H. Nichols,M. Notazio,M. Robinson,M. Romanelli,J. Willis,ST-E1 Team*

Main category: physics.plasm-ph

TL;DR: Comprehensive disruption modeling approach for ST-E1 tokamak design, integrating physics and engineering analyses to assess electromagnetic and thermal impacts across different configurations.


<details>
  <summary>Details</summary>
Motivation: Plasma disruptions threaten tokamak integrity and availability. While avoidance strategies are essential, complete prevention is impossible, making disruption consequence assessment crucial for next-generation fusion power plant design and qualification.

Method: Integrated physics-engineering methodology analyzing ST-E1 layout options for electromagnetic response under disruption loads, plus exploration of broad disruption scenarios scanning operational parameters, plasma-material interactions, thermal loads, and different equilibria (Double Null to Single Null configurations).

Result: Significant contrasts in plasma dynamics and electromagnetic behavior between configurations, highlighting disruption modeling's importance in guiding design choices. Analyses proved instrumental in shaping ST-E1 development and offering risk mitigation insights.

Conclusion: Disruption modeling is essential for fusion reactor design optimization, providing critical insights for risk mitigation and structural integrity assessment in next-generation power plants like ST-E1.

Abstract: Plasma disruptions represent a critical challenge for high-performance tokamak operations, as they can compromise machine integrity and reduce operational availability. Although future fusion devices essentially need to incorporate strategies to minimise disruption occurrence, complete avoidance remains unattainable. Consequently, assessing and characterising unmitigated disruption consequences is fundamental for the design and qualification of next-generation fusion power plants. This work supports the pre-conceptual design of ST-E1, a low aspect-ratio Tokamak Fusion Power Plant developed by Tokamak Energy Ltd., by presenting a comprehensive disruption modelling approach applied across different design stages. The methodology integrates both physics and engineering considerations to evaluate the impact of disruptions on machine performance and structural integrity. From an engineering perspective, several ST-E1 layout options were analysed to investigate the electromagnetic response of key components under disruption-induced loads, enabling comparison between alternative design solutions. On the physics side, a broad set of disruption scenarios was explored, scanning operational space parameters, plasma-material interactions, and associated thermal loads. Furthermore, the study examined variations in disruption behaviour arising from different reference equilibria, focusing on a range starting from Double Null to Single Null configurations, reflecting the increasing up-down asymmetry consequences. The results reveal significant contrasts in plasma dynamics and structures electromagnetic behaviour between configurations, highlighting the importance of disruption modelling in guiding design choices. These analyses have proven instrumental in shaping ST-E1 development, offering critical insights for mitigating risks and optimising future fusion reactor designs.

</details>


### [44] [Photon Accelerator in Magnetized Plasma](https://arxiv.org/abs/2512.16630)
*Sergei Bulanov,Stepan Bulanov,Timur Esirkepov,Gianluca Gregori,Gabriele Grittani,Brandon Russell,Alec Thomas,Petr Valenta*

Main category: physics.plasm-ph

TL;DR: Magnetic fields enhance photon acceleration in relativistic plasma waves, increasing frequency gain and efficiency.


<details>
  <summary>Details</summary>
Motivation: Magnetic fields fundamentally alter electromagnetic wave propagation and interaction with relativistic plasma waves in both laboratory and space environments, affecting particle and radiation generation processes.

Method: The paper analyzes how magnetic fields modify the relationship between frequency and wave number of electromagnetic waves in plasma, and how they alter wave interaction with relativistic plasma waves for photon acceleration.

Result: Magnetic fields lead to both quantitative and qualitative changes in photon acceleration properties, amplifying the increase in electromagnetic wave frequency and potentially resulting in higher efficiency.

Conclusion: The presence of magnetic fields significantly enhances photon acceleration in relativistic plasma waves, offering improved frequency gain and efficiency compared to field-free cases.

Abstract: Strong magnetic fields and plasmas are intrinsically linked in both terrestrial laboratory experiments and in space phenomena. One of the most profound consequences of that is the change in relationship between the frequency and the wave number of electromagnetic waves propagating in plasma in the presence of such magnetic fields when compared to the case without these fields. Furthermore, magnetic fields alter electromagnetic wave interaction with relativistic plasma waves, resulting in different outcomes for particle and radiation generation. For a relativistic plasma wave-based photon acceleration this leads to an increased frequency gain, and, thus, potentially to higher efficiency. The influence of a magnetic field leads to quantitative and qualitative change in the properties of photon acceleration, amplifying the increase in the electromagnetic wave frequency.

</details>


### [45] [CARONTE: a Physics-Informed Extreme Learning Machine-Based Algorithm for Plasma Boundary Reconstruction in Magnetically Confined Fusion Devices](https://arxiv.org/abs/2512.16689)
*Federico Fiorenza,Sara Dubbioso,Gianmaria De Tommasi,Alfredo Pironti*

Main category: physics.plasm-ph

TL;DR: A physics-informed neural network using Extreme Learning Machine for real-time plasma boundary reconstruction in tokamaks, outperforming traditional methods with better generalization and noise robustness.


<details>
  <summary>Details</summary>
Motivation: Need for accurate real-time plasma boundary reconstruction in tokamak devices to monitor and control plasma evolution during operation. Traditional methods like JET's algorithm require retuning for different plasma equilibria and may not generalize well.

Method: Uses a single Extreme Learning Machine network to solve the homogeneous Grad-Shafranov equation. The network is trained in real-time using available magnetic sensor data, enabling dynamic adaptation to evolving plasma equilibrium without requiring extensive pre-training on large experimental datasets.

Result: The network performs accurate plasma boundary reconstruction for complex configurations, outperforming established methods like JET's algorithm. It better generalizes the poloidal flux function without requiring retuning across different plasma equilibria, and shows greater robustness to noise on magnetic measurements.

Conclusion: The proposed physics-informed neural network approach provides an effective solution for real-time plasma boundary reconstruction that combines neural network generalization power with physics constraints, offers better performance than traditional methods, and is straightforward to implement on existing tokamak devices.

Abstract: In this work, we propose a novel physics informed neural network based algorithm for real time plasma boundary reconstruction in tokamak devices. The approach is based on a single Extreme Learning Machine network used to solve the homogeneous Grad Shafranov equation, which is required to identify the plasma boundary. This architecture enables the real time training of the network parameters using the available magnetic sensor data and, consequently, dynamically adapting the network output to the evolving plasma equilibrium. We demonstrate that, the network performs accurate plasma boundary reconstruction for complex configurations, outperforming well established methods, such as the algorithm used for decades at the Joint European Torus, the world's largest tokamak, until it ceased operation in 2023. Indeed, compared to the latter, the proposed solution better generalizes the poloidal flux function, without requiring algorithm retuning across different plasma equilibria. The proposed neural network reconstructor demonstrates also greater robustness with respect to noise on the magnetic measurements. Moreover, this method takes advantage of the generalization power of neural networks but without the need for extensive, time consuming training based on a huge amount of experimental data, making its implementation on existing devices straightforward.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [46] [Introduction to Symbolic Regression in the Physical Sciences](https://arxiv.org/abs/2512.15920)
*Deaglan J. Bartlett,Harry Desmond,Pedro G. Ferreira,Gabriel Kronberger*

Main category: cs.LG

TL;DR: This is an introductory review for a Special Issue on Symbolic Regression in Physical Sciences, covering foundations, applications, methods, challenges, and future directions.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from a Royal Society discussion meeting (April 2025) recognizing symbolic regression as a powerful tool for scientific discovery and empirical modeling in physical sciences.

Method: The review outlines conceptual foundations of symbolic regression, contrasts it with conventional regression, surveys main use cases, and discusses methodological considerations including search-space design, operator selection, complexity control, feature selection, and integration with modern AI approaches.

Result: The Special Issue collects contributions spanning applications from automated equation discovery and emergent-phenomena modeling to construction of compact emulators for computationally expensive simulations.

Conclusion: The papers illustrate accelerating progress of symbolic regression and its growing relevance across physical sciences, while highlighting ongoing challenges (scalability, robustness, overfitting) and emerging directions (incorporating symmetry constraints, asymptotic behavior, theoretical information).

Abstract: Symbolic regression (SR) has emerged as a powerful method for uncovering interpretable mathematical relationships from data, offering a novel route to both scientific discovery and efficient empirical modelling. This article introduces the Special Issue on Symbolic Regression for the Physical Sciences, motivated by the Royal Society discussion meeting held in April 2025. The contributions collected here span applications from automated equation discovery and emergent-phenomena modelling to the construction of compact emulators for computationally expensive simulations.
  The introductory review outlines the conceptual foundations of SR, contrasts it with conventional regression approaches, and surveys its main use cases in the physical sciences, including the derivation of effective theories, empirical functional forms and surrogate models. We summarise methodological considerations such as search-space design, operator selection, complexity control, feature selection, and integration with modern AI approaches. We also highlight ongoing challenges, including scalability, robustness to noise, overfitting and computational complexity. Finally we emphasise emerging directions, particularly the incorporation of symmetry constraints, asymptotic behaviour and other theoretical information. Taken together, the papers in this Special Issue illustrate the accelerating progress of SR and its growing relevance across the physical sciences.

</details>


### [47] [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](https://arxiv.org/abs/2512.15771)
*Xinjie He,Chenggong Zhang*

Main category: cs.LG

TL;DR: Extends Time-Evolving Natural Gradient (TENG) framework to handle Dirichlet boundary conditions in PDEs using natural gradient optimization with time-stepping schemes, showing Heun method's superior accuracy and Euler's efficiency.


<details>
  <summary>Details</summary>
Motivation: Traditional numerical methods struggle with high-dimensional/complex PDEs, and while PINNs offer an alternative, they face challenges with accuracy and complex boundary conditions. There's a need for improved neural network-based PDE solvers that can handle boundary conditions effectively.

Method: Extends TENG framework to incorporate Dirichlet boundary conditions by adding penalty terms to the loss function. Uses natural gradient optimization combined with numerical time-stepping schemes (Euler and Heun methods) to ensure stability and accuracy.

Result: Experiments on heat equation show Heun method provides superior accuracy due to second-order corrections, while Euler method offers computational efficiency for simpler scenarios. The approach successfully enforces Dirichlet constraints precisely.

Conclusion: Establishes foundation for extending framework to Neumann and mixed boundary conditions, as well as broader PDE classes. Advances applicability of neural network-based solvers for real-world problems by addressing boundary condition challenges.

Abstract: Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient alternative by embedding physics-based constraints into deep learning frameworks, but they face challenges in achieving high accuracy and handling complex boundary conditions. In this work, we extend the Time-Evolving Natural Gradient (TENG) framework to address Dirichlet boundary conditions, integrating natural gradient optimization with numerical time-stepping schemes, including Euler and Heun methods, to ensure both stability and accuracy. By incorporating boundary condition penalty terms into the loss function, the proposed approach enables precise enforcement of Dirichlet constraints. Experiments on the heat equation demonstrate the superior accuracy of the Heun method due to its second-order corrections and the computational efficiency of the Euler method for simpler scenarios. This work establishes a foundation for extending the framework to Neumann and mixed boundary conditions, as well as broader classes of PDEs, advancing the applicability of neural network-based solvers for real-world problems.

</details>


### [48] [Multi-Fidelity Delayed Acceptance: hierarchical MCMC sampling for Bayesian inverse problems combining multiple solvers through deep neural networks](https://arxiv.org/abs/2512.16430)
*Filippo Zacchei,Paolo Conti,Attilio Alberto Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems using neural networks to combine predictions from solvers of varying fidelity, avoiding expensive high-fidelity simulations during online inference.


<details>
  <summary>Details</summary>
Motivation: Traditional inverse uncertainty quantification methods are computationally expensive for physics-based models requiring repeated evaluations of complex numerical solvers. While surrogate models can help, generating high-fidelity training data is costly, and relying solely on low-fidelity data reduces accuracy.

Method: Multi-Fidelity Delayed Acceptance scheme extending Multi-Level Delayed Acceptance framework. Uses multi-fidelity neural networks trained offline with high-fidelity data to combine predictions from varying-fidelity solvers. During online phase, only coarse solvers are evaluated, with neural networks providing corrections, avoiding additional high-fidelity simulations.

Result: The approach improves approximation accuracy of low-fidelity solvers, enables longer sub-chain lengths, better mixing, and accelerated posterior inference. Demonstrated on two benchmark problems (steady isotropic groundwater flow and unsteady reaction-diffusion system) with substantial computational savings.

Conclusion: The proposed Multi-Fidelity Delayed Acceptance scheme provides a flexible, computationally efficient approach for Bayesian inverse problems by leveraging multi-fidelity neural networks to combine predictions from heterogeneous coarse solvers while avoiding expensive high-fidelity simulations during inference.

Abstract: Inverse uncertainty quantification (UQ) tasks such as parameter estimation are computationally demanding whenever dealing with physics-based models, and typically require repeated evaluations of complex numerical solvers. When partial differential equations are involved, full-order models such as those based on the Finite Element Method can make traditional sampling approaches like Markov Chain Monte Carlo (MCMC) computationally infeasible. Although data-driven surrogate models may help reduce evaluation costs, their utility is often limited by the expense of generating high-fidelity data. In contrast, low-fidelity data can be produced more efficiently, although relying on them alone may degrade the accuracy of the inverse UQ solution.
  To address these challenges, we propose a Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems. Extending the Multi-Level Delayed Acceptance framework, the method introduces multi-fidelity neural networks that combine the predictions of solvers of varying fidelity, with high fidelity evaluations restricted to an offline training stage. During the online phase, likelihood evaluations are obtained by evaluating the coarse solvers and passing their outputs to the trained neural networks, thereby avoiding additional high-fidelity simulations.
  This construction allows heterogeneous coarse solvers to be incorporated consistently within the hierarchy, providing greater flexibility than standard Multi-Level Delayed Acceptance. The proposed approach improves the approximation accuracy of the low fidelity solvers, leading to longer sub-chain lengths, better mixing, and accelerated posterior inference. The effectiveness of the strategy is demonstrated on two benchmark inverse problems involving (i) steady isotropic groundwater flow, (ii) an unsteady reaction-diffusion system, for which substantial computational savings are obtained.

</details>


### [49] [Polyharmonic Spline Packages: Composition, Efficient Procedures for Computation and Differentiation](https://arxiv.org/abs/2512.16718)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: Proposes a cascade architecture of polyharmonic spline packages to address scalability and high-dimensionality limitations of previous kernel regression methods.


<details>
  <summary>Details</summary>
Motivation: Previous work showed optimal kernel regression using polyharmonic splines, but had O(N^3) computational cost and theoretical breakdown in high-dimensional spaces. Need scalable solution for problems with unknown intrinsic low dimensionality.

Method: Cascade architecture built from packages of polyharmonic splines, with efficient matrix procedures for forward computation and end-to-end differentiation through the cascade.

Result: Simultaneously addresses scalability (computational efficiency) and provides theoretical justification for problems with unknown intrinsic low dimensionality.

Conclusion: The cascade architecture overcomes limitations of previous polyharmonic spline approach, making it practical for real-world applications with high-dimensional data.

Abstract: In a previous paper it was shown that a machine learning regression problem can be solved within the framework of random function theory, with the optimal kernel analytically derived from symmetry and indifference principles and coinciding with a polyharmonic spline. However, a direct application of that solution is limited by O(N^3) computational cost and by a breakdown of the original theoretical assumptions when the input space has excessive dimensionality. This paper proposes a cascade architecture built from packages of polyharmonic splines that simultaneously addresses scalability and is theoretically justified for problems with unknown intrinsic low dimensionality. Efficient matrix procedures are presented for forward computation and end-to-end differentiation through the cascade.

</details>


<div id='cond-mat.supr-con'></div>

# cond-mat.supr-con [[Back]](#toc)

### [50] [Beyond dpa: an atomistic framework for a quantitative description of radiation damage in YBa2Cu3O7](https://arxiv.org/abs/2512.16249)
*Federico Ledda,Daniele Torsello,Davide Gambino,Flyura Djurabekova,Fabio Calzavara,Niccolò Di Eugenio,Ville Jantunen,Antonio Trotta,Erik Gallo,Kai Nordlund,Francesco Laviano*

Main category: cond-mat.supr-con

TL;DR: Developed multiscale computational framework combining Molecular Dynamics and Binary Collision Approximation to model radiation damage in high-temperature cuprate superconductors like YBa2Cu3O7.


<details>
  <summary>Details</summary>
Motivation: Radiation damage in high-temperature cuprate superconductors is a major technological challenge for deployment in harsh environments (fusion reactors, accelerators), but existing damage models are inadequate due to the materials' complex crystal structures.

Method: Developed atomistic-based approach coupling Molecular Dynamics and Binary Collision Approximation simulations, integrated with Primary Knock-on Atom spectra from Monte Carlo codes for multiscale modeling.

Result: Established framework enabling quantitative estimates of damage descriptors including defect production, defect clustering, and effective damaged volume for irradiation conditions where collision cascades dominate.

Conclusion: The computational approach is suitable for predicting irradiation effects in any complex functional oxide, with applications ranging from aerospace to nuclear fusion and high-energy physics.

Abstract: Radiation damage in high-temperature cuprate superconductors represents one of the main technological challenges for their deployment in harsh environments, such as fusion reactors and accelerator facilities. Their complex crystal structure makes modeling irradiation effects in this class of materials a particularly demanding task, for which existing damage models remain inadequate. In this work, we develop an atomistic-based approach for describing primary radiation damage in YBa2Cu3O7, by coupling Molecular Dynamics and Binary Collision Approximation simulations in a way that makes them complementary. When integrated with Primary Knock-on Atom spectra obtained from Monte Carlo codes, our results establish a framework for multiscale modeling of radiation damage, enabling quantitative estimates of several damage descriptors, such as defect production, defect clustering, and the effective damaged volume for any specific irradiation conditions where collision cascades dominate. This computational approach is suitable for the prediction of irradiation effects in any complex functional oxide, with applications ranging from aerospace to nuclear fusion and high-energy physics.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [51] [Ground states for the Hartree energy functional in the critical case](https://arxiv.org/abs/2512.16513)
*Tommaso Pistillo*

Main category: math-ph

TL;DR: Existence of ground states for Hartree energy functional with convolution potentials in L∞ + L^{3/2,∞} spaces, including Coulomb-type potentials, with global well-posedness and orbital stability results.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the existence of minimizers (ground states) for the Hartree energy functional with convolution potentials that include important physical cases like Coulomb-type potentials (-1/|x|^α for 0<α≤2) and L^{3/2} potentials. These are fundamental in quantum mechanics and nonlinear Schrödinger equations.

Method: The authors work in the Sobolev space H^1(ℝ³) and consider convolution potentials w in L∞(ℝ³) + L^{3/2,∞}(ℝ³) with the L∞ part vanishing at infinity. They prove existence of ground states for a wide range of L² masses using variational methods and establish basic properties like positivity and regularity.

Result: The main results are: (1) existence of ground state minimizers for the Hartree energy functional, (2) basic properties of these ground states (positivity and regularity), (3) global well-posedness of the associated evolution problem, and (4) orbital stability of the set of ground states.

Conclusion: The paper successfully establishes the existence and properties of ground states for Hartree-type equations with broad classes of convolution potentials, including physically relevant Coulomb-type interactions, and proves stability results for the associated evolution problem.

Abstract: We consider the problem of finding a minimizer $u$ in $ H^1(\mathbb{R}^3)$ for the Hartree energy functional with convolution potential $w$ in $L^\infty(\mathbb{R}^3)+L^{3/2,\infty}(\mathbb{R}^3)$ with $L^\infty$ part vanishing at infinity. This class includes sums of potentials of the kind $-\frac{1}{|x|^α}$, $0<α\le2$, together with the case $w$ in $L^{3/2}(\mathbb{R}^3)$. We prove the existence of such groundstates for a wide range of $L^2$ masses. We also establish basic properties of the groundstates, i.e.~positivity and regularity. Lastly, we exploit the estimates we derived for the stationary problem to prove global well-posedness of the associated evolution problem and orbital stability of the set of ground states.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [52] [The Diffusive Behavior of Solutions to the Linear Damped Wave Equation: an Undergraduate D.I.Y. Classnote](https://arxiv.org/abs/2512.15770)
*Gastão Almeida Braga,Antônio Marcos da Silva,Jussara de Matos Moreira*

Main category: math.HO

TL;DR: The paper explains the mathematical relationship between solutions of Damped Wave and Heat equations as time approaches infinity, targeting undergraduate students with calculus background through a hands-on exercise approach.


<details>
  <summary>Details</summary>
Motivation: To help undergraduate students understand the surprising mathematical connection between solutions of two fundamentally different equations (Damped Wave and Heat equations) as time approaches infinity, despite describing distinct physical phenomena.

Method: Uses a "do it yourself" pedagogical strategy with suggested exercises that students are invited to complete, making the mathematical derivation accessible to those with good calculus background.

Result: Provides an accessible explanation of how the relationship between solutions of Damped Wave and Heat equations is established in the limit as t→∞, enabling students to understand this mathematical connection through guided exercises.

Conclusion: The paper successfully creates an educational framework for undergraduates to grasp the mathematical relationship between two distinct PDE solutions through hands-on exercises, bridging the gap between different physical phenomena descriptions.

Abstract: Despite of the fact that the Damped Wave and the Heat equations describe phenomena of distinct nature, it is amazing that their solutions are related in the limit as $t \to \infty$. The aim of this note is to explain to undergraduate students, with a good calculus background, how the relation between these solutions is established. We follow a ``do it yourself'' strategy and the students are invited to do the suggested exercises in order to understand the content of this note.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [53] [Efficient Monte-Carlo sampling of metastable systems using non-local collective variable updates](https://arxiv.org/abs/2512.16812)
*Christoph Schönle,Davide Carbone,Marylou Gabrié,Tony Lelièvre,Gabriel Stoltz*

Main category: cond-mat.stat-mech

TL;DR: Generalized algorithm for non-local Monte Carlo proposals in collective-variable space using non-linear CVs and underdamped Langevin dynamics, with proven reversibility and improved performance over overdamped methods.


<details>
  <summary>Details</summary>
Motivation: Standard Monte Carlo simulations suffer from metastability issues in complex molecular systems. Non-local proposal updates in collective-variable space have shown promise but need generalization to handle non-linear CVs and more realistic dynamics.

Method: Developed a generalized algorithm for non-local proposal updates in CV space that handles non-linear collective variables and underdamped Langevin dynamics. The approach leverages generative machine-learning-based proposal samplers for efficient sampling in intermediate-dimensional CV spaces (tens to hundreds of variables).

Result: Proved reversibility of the resulting scheme. Demonstrated substantial performance increase compared to methods based on overdamped Langevin dynamics through several numerical examples. Extended applicability of generative ML-based proposal samplers to more realistic molecular systems.

Conclusion: The generalized algorithm enables efficient sampling in complex molecular systems by combining non-local CV-space proposals with underdamped Langevin dynamics, overcoming metastability issues and bridging the gap between advanced sampling methods and realistic molecular simulations.

Abstract: Monte-Carlo simulations are widely used to simulate complex molecular systems, but standard approaches suffer from metastability. Lately, the use of non-local proposal updates in a collective-variable (CV) space has been proposed in several works. Here, we generalize these approaches and explicitly spell out an algorithm for non-linear CVs and underdamped Langevin dynamics. We prove reversibility of the resulting scheme and demonstrate its performance on several numerical examples, observing a substantial performance increase compared to methods based on overdamped Langevin dynamics as considered previously. Advances in generative machine-learning-based proposal samplers now enable efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables), and our results extend their applicability toward more realistic molecular systems.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [54] [Self-confinement of relativistic pair beams in magnetized interstellar plasmas: the case of pulsar X-ray filaments](https://arxiv.org/abs/2512.15847)
*Luca Orusa,Lorenzo Sironi*

Main category: astro-ph.HE

TL;DR: Charge-neutral electron-positron beams from pulsar wind nebulae can spontaneously generate net currents via Weibel instability, driving magnetic turbulence that explains suppressed cosmic-ray diffusion and X-ray filament formation.


<details>
  <summary>Details</summary>
Motivation: Observations of filamentary X-ray structures around pulsar wind nebulae and slow-diffusion regions challenge standard cosmic-ray transport models, requiring suppressed diffusion coefficients. The paper aims to explain how initially charge-neutral pair beams can generate the net currents needed to drive magnetic turbulence via streaming instability.

Method: Used fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratios to study the propagation of charge-neutral electron-positron beams through electron-proton plasma. Investigated the nonlinear evolution of the Weibel instability and its role in creating charge asymmetries.

Result: Beam electrons become focused into self-generated magnetic filaments via Weibel instability, while beam positrons remain unconfined. This creates a net positron current that drives the non-resonant streaming instability, amplifying magnetic fields and enabling efficient scattering of beam particles.

Conclusion: The mechanism provides a pathway for charge asymmetry generation in initially neutral pair beams and magnetic fluctuation growth, explaining X-ray filament formation and particle self-confinement in TeV halos around pulsar wind nebulae.

Abstract: The observation of filamentary X-ray structures near bow-shock pulsar wind nebulae (PWNe) -- such as the Guitar, Lighthouse, and PSR J2030$+$4415 nebulae -- and of slow-diffusion regions around pulsars like Geminga, Monogem, and PSR J0622$+$3749, challenges the standard picture of cosmic-ray transport in the interstellar medium, implying a diffusion coefficient two orders of magnitude smaller than the Galactic average. The suppressed diffusion can be attributed to self-generated magnetic turbulence, driven -- via the non-resonant streaming instability -- by electron--positron pairs escaping the PWNe. This instability requires a net current, yet the beam of escaping pairs is expected to be charge-neutral. We show that a charge-neutral pair beam propagating through an electron--proton plasma can spontaneously generate a net current. Using fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratio, we find that beam electrons get focused into self-generated magnetic filaments produced by the nonlinear evolution of the Weibel instability, while beam positrons remain unconfined. The resulting net (positron) current drives the non-resonant streaming instability, further amplifying the magnetic field. This mechanism provides a pathway for the onset of charge asymmetries in initially charge-neutral pair beams and for the growth of magnetic fluctuations that efficiently scatter the beam particles, with implications for the formation of X-ray filaments and, more broadly, for particle self-confinement in TeV halos around PWNe.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [55] [Unveiling the amorphous ice layer during premelting using AFM integrating machine learning](https://arxiv.org/abs/2512.15772)
*Binze Tang,Chon-Hei Lo,Tiancheng Liang,Jiani Hong,Mian Qin,Yizhi Song,Duanyun Cao,Ying Jiang,Limei Xu*

Main category: cond-mat.mtrl-sci

TL;DR: Researchers discovered a novel amorphous ice layer preceding the quasi-liquid layer during ice premelting using a machine learning framework that integrates AFM with molecular dynamics simulations, enabling 3D surface reconstruction and revealing new insights into ice surface dynamics.


<details>
  <summary>Details</summary>
Motivation: Premelting is crucial across multiple scientific disciplines but remains poorly understood at the atomic level due to limitations in surface characterization techniques, particularly AFM's depth and signal constraints.

Method: Developed a machine learning framework that integrates atomic force microscopy (AFM) with molecular dynamics simulations to overcome AFM limitations, enabling 3D surface structure reconstruction from AFM images and exploring premelting interfaces across wide temperature ranges.

Result: Discovered a novel amorphous ice layer (AIL) present between 121-180K that precedes the quasi-liquid layer during ice premelting, featuring disordered two-dimensional hydrogen-bond networks with solid-like dynamics, refining the ice premelting phase diagram.

Conclusion: The study provides new insights into ice surface growth dynamics, dissolution, and interfacial chemical reactivity, while establishing a novel framework for AFM-based 3D structural discovery that enables unprecedented probing of complex disordered interfaces across multiple research domains.

Abstract: Premelting plays a key role across physics, chemistry, materials and biology sciences but remains poorly understood at the atomic level due to surface characterization limitations. We report the discovery of a novel amorphous ice layer (AIL) preceding the quasi-liquid layer (QLL) during ice premelting, enabled by a machine learning framework integrating atomic force microscopy (AFM) with molecular dynamics simulations. This approach overcomes AFM's depth and signal limitations, allowing for three-dimensional surface structure reconstruction from AFM images. It further enables structural exploration of premelting interfaces across a wide temperature range that are experimentally inaccessible. We identify the AIL, present between 121-180K, displaying disordered two-dimensional hydrogen-bond network with solid-like dynamics. Our findings refine the ice premelting phase diagram and offering new insights into the surface growth dynamic, dissolution and interfacial chemical reactivity. Methodologically, this work establishes a novel framework for AFM-based 3D structural discovery, marking a significant leap in our ability to probe complex disordered interfaces with unprecedented precision and paving the way for future disciplinary research, including surface reconstruction, crystallization, ion solvation, and biomolecular recognition.

</details>


### [56] [Atomic forces from correlation energy functionals based on the adiabatic-connection fluctuation-dissipation theorem](https://arxiv.org/abs/2512.16460)
*Damian Contant,Maria Hellgren*

Main category: cond-mat.mtrl-sci

TL;DR: Implementation of analytical atomic forces in random phase approximation (RPA) for plane waves and pseudopotentials, showing excellent numerical quality and systematic improvement over PBE.


<details>
  <summary>Details</summary>
Motivation: To extend correlation energy functionals based on adiabatic-connection fluctuation-dissipation theorem by implementing analytical atomic forces within RPA for more accurate structural and vibrational calculations.

Method: Implemented analytical RPA forces using plane waves and pseudopotentials, calculated forces at self-consistency via optimized effective potential method and Hellmann-Feynman theorem, and evaluated non-self-consistent RPA forces from PBE using density functional perturbation theory.

Result: Forces show excellent numerical quality; self-consistency has negligible impact on geometries and vibrational frequencies for most systems; RPA systematically improves over PBE; RPAx achieves accuracy comparable to advanced wavefunction methods; provides accurate theoretical references for zone-center optical phonons.

Conclusion: RPA and RPAx with analytical forces provide accurate and efficient methods for structural and vibrational calculations, offering systematic improvements over standard DFT approximations with accuracy approaching advanced wavefunction methods.

Abstract: We extend the capabilities of correlation energy functionals based on the adiabatic-connection fluctuation-dissipation theorem by implementing the analytical atomic forces within the random phase approximation (RPA), in the context of plane waves and pseudopotentials. Forces are calculated at self-consistency through the optimized effective potential method and the Hellmann-Feynman theorem. In addition, non-self-consistent RPA forces, starting from the PBE generalized gradient approximation, are evaluated using density functional perturbation theory. In both cases, we find forces of excellent numerical quality. Furthermore, for most molecules and solids studied, self-consistency is found to have a negligible impact on the computed geometries and vibrational frequencies. The RPA is shown to systematically improve over PBE and, by including the exact-exchange kernel within RPA + exchange (RPAx), through finite-difference total energy calculations, we obtain an accuracy comparable to advanced wavefunction methods. Finally, we estimate the anharmonic shift and provide accurate theoretical references based on RPA and RPAx for the zone-center optical phonon of diamond, silicon, and germanium.

</details>


### [57] [Thermodynamical study of N$_2$ clathrate hydrate from DFT calculations](https://arxiv.org/abs/2512.16819)
*L. Martin-Gondre,V. Meko Fotso,C. Métais,A. Patt,J. Ollivier,A. Desmedt*

Main category: cond-mat.mtrl-sci

TL;DR: DFT study shows N₂ clathrate hydrate stability depends on cage occupancy and pressure, with sI stable at lower pressures and sII with double occupancy becoming stable above ~0.8 GPa.


<details>
  <summary>Details</summary>
Motivation: To understand the thermodynamic stability of N₂ clathrate hydrates in different crystal structures (sI and sII) under varying pressure conditions, using first-principles methods to establish a baseline framework.

Method: Density functional theory calculations with various exchange-correlation functionals, explicitly accounting for composition (cage occupancies) and pressure at T = 0 K. revPBE-D3(0) functional was identified as best reproducing experimental lattice parameters and bulk moduli.

Result: revPBE-D3(0) best reproduces experimental data. sI with single occupancy remains thermodynamically stable up to ~0.8 GPa alongside sII with single occupancy. Above this pressure, sII with double occupancy becomes stabilized due to its larger large-cage volume and lower framework strain.

Conclusion: The study provides a coherent first-principles thermodynamic framework for N₂ hydrate stability, showing pressure-dependent structural transitions between sI and sII with different cage occupancies, establishing a baseline for finite-temperature extensions.

Abstract: Thermodynamic stability of N$_2$ clathrate hydrates in the sI and sII structures is investigated using density functional theory with several exchange-correlation functionals, explicitly accounting for composition (cage occupancies) and pressure at T = 0 K. Among the tested functionals, revPBE-D3(0) best reproduces experimental lattice parameters and bulk moduli B$_0$ . Energetic analyses confirm the strong impact of large cage double occupancy on sI, whereas the convex-hull results show that sI with single occupancy remains thermodynamically stable up to $\sim$ 0.8 GPa alongside sII with single occupancy. Increasing pressure then stabilizes sII with double occupancy, consistent with its larger large-cage volume and lower framework strain. These results provide a coherent, first-principles thermodynamic framework for N$_2$ hydrate stability and a baseline for finite-temperature extension.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [58] [QMCkl: A Kernel Library for Quantum Monte Carlo Applications](https://arxiv.org/abs/2512.16677)
*Emiel Slootman,Vijay Gopal Chilkuri,Aurelien Delval,Max Hoffer,Tommaso Gorni,François Coppens,Joris van de Nes,Ramón L. Panadés-Barrueta,Evgeny Posenitskiy,Abdallah Ammar,Edgar Josué Landinez Borda,Kevin Camus,Oto Kohulàk,Emmanuel Giner,Pablo de Oliveira Castro,Cedric Valensi,William Jalby,Claudia Filippi,Anthony Scemama*

Main category: physics.chem-ph

TL;DR: QMCkl is a modular, portable library of high-performance kernels for Quantum Monte Carlo calculations that separates algorithmic development from hardware optimization, enabling consistent, efficient simulations across different codes and architectures.


<details>
  <summary>Details</summary>
Motivation: Quantum Monte Carlo methods are highly accurate but computationally intensive, requiring optimization for different hardware while maintaining reproducibility and consistency across different QMC codes.

Method: Developed QMCkl as a modular library with C-compatible API, TREXIO standard support, and core QMC kernels including atomic/molecular orbitals, cusp corrections, Jastrow factor, and derivatives. Combines human-readable reference implementations with performance-optimized kernels that produce identical numerical results.

Result: Achieves substantial speedups in energy and derivative evaluations, enables consistent and reproducible simulations across different QMC codes and architectures, and can accelerate deterministic quantum chemistry workflows and visualization tools.

Conclusion: QMCkl successfully separates algorithmic development from hardware-specific tuning, promotes cross-code interoperability, simplifies high-performance scientific software development, and extends beyond QMC to benefit broader quantum chemistry applications.

Abstract: Quantum Monte Carlo (QMC) methods deliver highly accurate electronic structure calculations but are computationally intensive. The quantum Monte Carlo kernel library (QMCkl) provides a modular, portable collection of high-performance kernels implementing the core building blocks of QMC calculations. It offers a C-compatible API, supports the TREXIO standard for input, and covers essential QMC kernels including atomic and molecular orbitals, cusp corrections, Jastrow factor, and the necessary derivatives also to perform variational and structural optimization. QMCkl separates algorithmic development from hardware-specific tuning by combining human-readable reference implementations with performance-optimized kernels that produce identical numerical results. The library enables consistent, efficient, and reproducible simulations across different QMC codes and architectures, and achieves substantial speedups in the evaluation of the energy and its derivatives. Beyond QMC, QMCkl can accelerate deterministic quantum chemistry workflows and visualization tools, promoting cross-code interoperability and simplifying high-performance scientific software development.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [59] [An evacuation simulator for pedestrian dynamics based on the Social Force Model](https://arxiv.org/abs/2512.16887)
*Julián López,Virginia Mazzone,M. Leticia Rubio Puzzo,Juan Cruz Moreno*

Main category: physics.soc-ph

TL;DR: SiCoBioNa is an open-source evacuation simulator based on the Social Force Model that provides an intuitive GUI for configuring pedestrian scenarios without requiring numerical modeling expertise.


<details>
  <summary>Details</summary>
Motivation: Pedestrian evacuation from enclosed spaces is a critical safety engineering problem that requires realistic simulation tools to analyze collective dynamics, individual interactions, and spatial constraints.

Method: Developed SiCoBioNa, an open-source simulator using the Social Force Model framework with an intuitive graphical interface for configuring pedestrian properties, spatial geometries, and initial conditions.

Result: The simulator generates both quantitative data and visual outputs for analyzing evacuation dynamics and evaluating different spatial configurations, with modular and extensible design for reproducible research.

Conclusion: SiCoBioNa serves as a practical research tool for pedestrian dynamics studies and evacuation planning, making evacuation simulation accessible without requiring numerical modeling expertise.

Abstract: The evacuation of pedestrians from enclosed spaces represents a key problem in safety engineering and infrastructure design. Analyzing the collective dynamics that emerge during evacuation processes requires simulation tools capable of capturing individual interactions and spatial constraints realistically.
  In this work, we present \textit{SiCoBioNa}, an open-source evacuation simulator based on the Social Force Model (SFM). The software provides an intuitive graphical interface that allows users to configure pedestrian properties, spatial geometries, and initial conditions without requiring prior expertise in numerical modeling techniques. The SFM framework enables the representation of goal-oriented motion, interpersonal interactions, and interactions with fixed obstacles.
  The simulator generates both quantitative data and visual outputs, facilitating the analysis of evacuation dynamics and the evaluation of different spatial configurations. Due to its modular and extensible design, \textit{SiCoBioNa} serves as a reproducible research tool for studies on pedestrian dynamics providing practical support for evacuation planning.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [60] [Manifold submetries from compact homogeneous spaces](https://arxiv.org/abs/2512.16606)
*Samuel Lin,Ricardo A. E. Mendes,Marco Radeschi*

Main category: math.DG

TL;DR: Singular Riemannian foliations on compact normal homogeneous spaces are algebraic, with correspondence between Laplace-Beltrami invariant algebras and manifold submetries.


<details>
  <summary>Details</summary>
Motivation: To establish the algebraic nature of singular Riemannian foliations and manifold submetries on compact normal homogeneous spaces, and to understand the relationship between algebraic function algebras preserved by the Laplace-Beltrami operator and manifold submetries.

Method: The paper uses geometric analysis on compact normal homogeneous spaces, proving that manifold submetries have algebraic structure. A key technical result shows that the mean curvature vector field of fibers is basic (related to a vector field in the base).

Result: 1) Singular Riemannian foliations/manifold submetries on compact normal homogeneous spaces are algebraic. 2) One-to-one correspondence exists between algebras of algebraic functions preserved by Laplace-Beltrami operator and manifold submetries. 3) Mean curvature vector field of fibers is basic for any manifold submetry.

Conclusion: The paper establishes deep connections between geometric structures (manifold submetries) and algebraic structures on compact normal homogeneous spaces, with the Laplace-Beltrami operator playing a crucial role in this correspondence.

Abstract: We show that singular Riemannian foliations, or, more generally, manifold submetries, defined on a compact normal homogeneous space, have algebraic nature. Moreover, in this case there exists a one-to-one correspondence between algebras of algebraic functions preserved by the Laplace--Beltrami operator, and manifold submetries.
  A key intermediate result is that, for any manifold submetry on a compact normal homogeneous space, the vector field given by the mean curvature of the fibers is basic, in the sense that it is related to a vector field in the base.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [61] [A unified MRT-LB framework for Navier-Stokes and nonlinear convection-diffusion equations and beyond: moment equations, auxiliary moments, multispeed lattices, and Hermite matrices](https://arxiv.org/abs/2512.16230)
*Baochang Shi,Xiaolei Yuan,Zhenhua Chai*

Main category: physics.flu-dyn

TL;DR: A unified MRT-LB framework using discrete Hermite polynomials for simulating Navier-Stokes equations and nonlinear convection-diffusion equations with multispeed rectangular lattice models.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive lattice Boltzmann framework that can handle both incompressible/compressible isothermal flows and nonlinear convection-diffusion problems using a unified approach with rectangular lattice structures.

Method: Developed MRT-LB framework based on discrete Hermite polynomials, using multispeed rectangular lattice models (rDdQb). Derived macroscopic moment equations via Taylor expansion, identified critical auxiliary moments for eliminating spurious terms, and established essential relations using weighted orthogonality of Hermite matrices.

Result: Created several multispeed rectangular lattice models including rD2Q25, rD3Q53 with subgroup models, derived generalized third-order equilibrium distribution function, and identified necessary corrections for third-order discrete Hermite polynomials in rectangular lattices.

Conclusion: The proposed unified MRT-LB framework successfully simulates both NSEs and NCDEs using rectangular lattice models, with specific auxiliary moments and corrected Hermite polynomials ensuring accurate recovery of target equations.

Abstract: We develop a unified multi-relaxation-time lattice Boltzmann (MRT-LB) framework based on discrete Hermite polynomials (Hermite matrices) for the Navier-Stokes equations (NSEs) and nonlinear convection-diffusion equations (NCDEs), using multispeed rectangular lattice (rD$d$Q$b$) models. For NSEs, the proposed MRT-LB model simulates incompressible and compressible isothermal flows in both single-phase and multiphase systems. Macroscopic moment equations are derived from the MRT-LB model via the direct Taylor expansion method. By selecting appropriate fundamental moments, the target NSEs and NCDE are recovered from these moment equations. Critically, the elimination of spurious terms and/or the recovery of the desired terms relies on specific auxiliary moments: the second-order auxiliary moment ($\mathbf{M}_{2G}$) of the source term distribution function (SDF) and the third-order auxiliary moment ($\mathbf{M}_{30}$) of the equilibrium distribution function (EDF) for NSEs, as well as the first-order auxiliary moment ($\mathbf{M}_{1G}$) of the SDF and the second-order auxiliary moment ($\mathbf{M}_{20}$) of the EDF for NCDE. Furthermore, using the weighted orthogonality of Hermite matrices, we establish essential relations for weight coefficients and construct several multispeed rectangular lattice models, including rD2Q25 and rD3Q53, with subgroup models rD2Q21, rD2Q17, rD2Q13, rD3Q45, and rD3Q33. A generalized third-order equilibrium distribution function is derived. We emphasize that for rectangular lattices, specific elements of the Hermite matrix corresponding to third-order discrete Hermite polynomials require correction to satisfy weighted orthogonality.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [62] [Electric field diagnostics in a continuous rf plasma using Rydberg-EIT](https://arxiv.org/abs/2512.16867)
*Bineet Dash,Xinyan Xiang,Dingkun Feng,Eric Paradis,Georg Raithel*

Main category: physics.atom-ph

TL;DR: Non-invasive plasma electric field measurement using Rydberg atoms and EIT spectroscopy to determine plasma density and microfield distribution.


<details>
  <summary>Details</summary>
Motivation: Need for non-invasive, precise electric field diagnostics in low-pressure plasmas for applications in plasma sheaths, process plasma, and dusty plasma.

Method: Uses Rydberg atoms' large polarizabilities and Stark shifts measured via Electromagnetically Induced Transparency (EIT) of rubidium vapor seeded into rf plasma. Analyzes rf modulation sidebands and lineshapes to determine plasma properties.

Result: Demonstrated that rf modulation sidebands vanish in plasma due to field screening, and EIT spectra reflect Holtsmark microfield distribution, enabling determination of plasma density and collisional broadening across pressure and power ranges.

Conclusion: The technique enables non-invasive spatio-temporal electric-field diagnostics for various low-pressure plasma applications.

Abstract: We present a non-invasive spectroscopic technique to measure electric fields in plasma, leveraging large polarizabilities and Stark shifts of Rydberg atoms. Rydberg Stark shifts are measured with high precision using narrow-linewidth lasers via Electromagnetically Induced Transparency (EIT) of rubidium vapor seeded into a continuous, inductively coupled radio-frequency (rf) plasma in a few mTorr of argon gas. Without plasma, the Rydberg-EIT spectra exhibit rf modulation sidebands caused by electric- and magnetic-dipole transitions in the rf drive coil. With the plasma present, the rf modulation sidebands vanish due to screening of the rf drive field from the plasma interior. The lineshapes of the EIT spectra in the plasma reflect the plasma's Holtsmark microfield distribution, allowing us to determine plasma density and collisional line broadening over a range of pressures and rf drive powers. The work is expected to have applications in non-invasive spatio-temporal electric-field diagnostics of low-pressure plasma, plasma sheaths, process plasma and dusty plasma.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [63] [Riemannian Stochastic Interpolants for Amorphous Particle Systems](https://arxiv.org/abs/2512.16607)
*Louis Grenioux,Leonardo Galliano,Ludovic Berthier,Giulio Biroli,Marylou Gabrié*

Main category: stat.ML

TL;DR: Equivariant Riemannian stochastic interpolation framework for generating equilibrium configurations of amorphous materials (glasses) with proper geometric and symmetry constraints.


<details>
  <summary>Details</summary>
Motivation: Sampling equilibrium configurations of glass-forming materials is notoriously slow and difficult, creating a need for generative models that can produce equilibrium configurations with well-defined likelihoods to overcome this obstacle.

Method: Leverages an equivariant Riemannian stochastic interpolation framework combining Riemannian stochastic interpolant and equivariant flow matching. Incorporates periodic boundary conditions and symmetries of multi-component particle systems using an equivariant graph neural network operating directly on the torus.

Result: Numerical experiments on model amorphous systems demonstrate that enforcing geometric and symmetry constraints significantly improves generative performance.

Conclusion: The proposed framework successfully addresses the challenge of generating equilibrium configurations for amorphous materials by properly incorporating domain-specific constraints, offering a promising approach for accelerating simulations of glass-forming systems.

Abstract: Modern generative models hold great promise for accelerating diverse tasks involving the simulation of physical systems, but they must be adapted to the specific constraints of each domain. Significant progress has been made for biomolecules and crystalline materials. Here, we address amorphous materials (glasses), which are disordered particle systems lacking atomic periodicity. Sampling equilibrium configurations of glass-forming materials is a notoriously slow and difficult task. This obstacle could be overcome by developing a generative framework capable of producing equilibrium configurations with well-defined likelihoods. In this work, we address this challenge by leveraging an equivariant Riemannian stochastic interpolation framework which combines Riemannian stochastic interpolant and equivariant flow matching. Our method rigorously incorporates periodic boundary conditions and the symmetries of multi-component particle systems, adapting an equivariant graph neural network to operate directly on the torus. Our numerical experiments on model amorphous systems demonstrate that enforcing geometric and symmetry constraints significantly improves generative performance.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [64] [Direct calculation of steady-state hydrodynamic solar wind solutions with newtonian viscosity](https://arxiv.org/abs/2512.16028)
*Roger B. Scott,Stephen J. Bradshaw,Mark G. Linton,Chris Lowder,Leonard Strachan*

Main category: astro-ph.SR

TL;DR: Including viscous stress in solar wind equations eliminates sonic point singularities, enabling efficient computation of complete solar wind profiles from solar surface to heliosphere without special sonic point treatment.


<details>
  <summary>Details</summary>
Motivation: Inviscid solar wind models have singularities at sonic points that require special treatment, creating significant computational challenges for efficient solar wind modeling.

Method: Cast steady-state Navier-Stokes equations with viscous stress, external heating, and radiative losses as five coupled ODEs, solved using conventional methods without special sonic point treatment.

Result: Viscous stress eliminates sonic point singularities, enabling computation of complete solar wind profiles from transition region to outer heliosphere in a single solution with realistic initial conditions.

Conclusion: This viscous approach provides an efficient, realistic method for generating accurate solar wind profiles at much lower computational cost than relaxation-based models.

Abstract: Steady-state solutions to the Navier-Stokes equations are known to admit solutions that are singular at the sonic point. Consequently, inviscid solar wind models require special treatment of the solution near the sonic points, and this has proven to be a significant impediment to efficient modeling of the solar wind. In this paper we revisit the governing hydrodynamic equations for the expanding solar wind, with the inclusion of the classical (Newtonian) viscous stress , and we show how this inclusion eliminates the singularities that emerge from the inviscid equations. This result has been previously reported and used to generate solar wind profiles from initial conditions in the asymptotic limit; however, those studies did not include realistic treatments of the inner corona, and generally rejected the prospect of extrapolating solutions outward from the Sun into the heliosphere. Here, we expand this method to include external heating and optically thin radiative losses and show that solutions can be computed from initial conditions near the solar surface, thereby capturing the entire range of scales from below the transition region to the outer heliosphere in a single solution. Our approach is to cast the steady-state Navier-Stokes equations as a system of five coupled, ordinary differential equations (ODEs), which we solve using conventional methods, without any special treatment of the governing equations in the vicinity of the sonic point. The representative solutions that we present here demonstrate the utility and efficiency of this extrapolation method, which is considerably more realistic than commonly used analytical or empirical models. This method provides a direct approach to generating accurate solar wind profiles subject to observationally motivated initial conditions near the solar surface, at a fraction of the computational cost of comparable relaxation-based models.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [65] [On the distribution kernels of Toeplitz operators on CR manifolds](https://arxiv.org/abs/2512.16506)
*Chin-Yu Hsiao,Ood Shabtai*

Main category: math.CV

TL;DR: Analysis of Toeplitz operators on CR manifolds: diagonal values of kernel symbols and asymptotic expansions on CR orbifolds.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Toeplitz operators on complex-analytic geometric structures (CR manifolds and orbifolds), particularly their kernel properties and asymptotic expansions.

Method: Study distribution kernels of Toeplitz operators associated with classical pseudodifferential operators on compact, embeddable, strictly pseudoconvex CR manifolds. Analyze symbol expansions and establish asymptotic expansions under natural assumptions.

Result: Main result: formula for diagonal values of second coefficient in kernel symbol expansion. Additional result: asymptotic expansions for Toeplitz operators on positive part of compact CR orbifolds (not necessarily strictly pseudoconvex).

Conclusion: The paper provides precise formulas for kernel behavior and extends asymptotic analysis to more general CR orbifold settings, advancing the understanding of Toeplitz operators in complex geometry.

Abstract: We study the distribution kernel of a Toeplitz operator associated with a classical pseudodifferential operator on a compact, embeddable, strictly pseudoconvex CR manifold. The main result consists of a formula for the values at the diagonal of the second coefficient in the expansion of the symbol of the kernel. We also establish asymptotic expansions for Toeplitz operators on the positive part of a compact not necessary strictly pseudoconvex CR orbifold under certain natural assumptions.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [66] [Information theory and discriminative sampling for model discovery](https://arxiv.org/abs/2512.16000)
*Yuxuan Bao,J. Nathan Kutz*

Main category: cs.IT

TL;DR: The paper proposes using Fisher Information Matrix within SINDy framework to analyze dynamical systems, visualize information patterns, and improve data efficiency through principled sampling strategies.


<details>
  <summary>Details</summary>
Motivation: Fisher information and Shannon entropy are fundamental tools for understanding dynamical systems, but there's a need to leverage them within data-driven frameworks like SINDy to improve sampling efficiency and model performance by prioritizing more informative data.

Method: Integrates Fisher Information Matrix (FIM) with sparse identification of nonlinear dynamics (SINDy), visualizes information patterns in chaotic/non-chaotic systems, uses spectral analysis of FIM to understand statistical bagging benefits, and applies information metrics to three data scenarios.

Result: Demonstrates how information-based analysis improves sampling efficiency and enhances model performance by prioritizing informative data, shows benefits of statistical bagging through FIM spectral analysis, and illustrates data efficiency in three practical scenarios.

Conclusion: Principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements in data-driven model discovery.

Abstract: Fisher information and Shannon entropy are fundamental tools for understanding and analyzing dynamical systems from complementary perspectives. They can characterize unknown parameters by quantifying the information contained in variables, or measure how different initial trajectories or temporal segments of a trajectory contribute to learning or inferring system dynamics. In this work, we leverage the Fisher Information Matrix (FIM) within the data-driven framework of {\em sparse identification of nonlinear dynamics} (SINDy). We visualize information patterns in chaotic and non-chaotic systems for both single trajectories and multiple initial conditions, demonstrating how information-based analysis can improve sampling efficiency and enhance model performance by prioritizing more informative data. The benefits of statistical bagging are further elucidated through spectral analysis of the FIM. We also illustrate how Fisher information and entropy metrics can promote data efficiency in three scenarios: when only a single trajectory is available, when a tunable control parameter exists, and when multiple trajectories can be freely initialized. As data-driven model discovery continues to gain prominence, principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements.

</details>
