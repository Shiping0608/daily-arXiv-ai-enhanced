<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 26]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [math.DG](#math.DG) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 3]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [math.CV](#math.CV) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.atom-ph](#physics.atom-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [math.HO](#math.HO) [Total: 1]
- [cond-mat.supr-con](#cond-mat.supr-con) [Total: 1]
- [math-ph](#math-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Make the most of what you have: Resource-efficient randomized algorithms for matrix computations](https://arxiv.org/abs/2512.15929)
*Ethan N. Epperly*

Main category: math.NA

TL;DR: This thesis develops efficient randomized algorithms for computational linear algebra problems, focusing on low-rank approximation, matrix attribute estimation, and stable least-squares solutions with optimal data usage.


<details>
  <summary>Details</summary>
Motivation: Randomized algorithms are fundamental in computational linear algebra but often use data inefficiently. The thesis aims to design algorithms that achieve maximum speed and accuracy with limited data budgets, addressing efficiency gaps in existing methods.

Method: Three-part approach: 1) Randomly pivoted Cholesky (RPCholesky) for low-rank PSD matrix approximation with minimal entry access; 2) Leave-one-out approach for estimating implicit matrix attributes (trace, diagonal, row-norms); 3) Development of fast randomized least-squares algorithms with backward stability guarantees.

Result: RPCholesky outperforms other methods in speed and reliability for low-rank approximation; optimized algorithms for matrix attribute estimation; and backward-stable randomized least-squares algorithms that resolve floating-point accuracy concerns.

Conclusion: The thesis demonstrates that randomized algorithms can be designed to use information efficiently while maintaining reliability, achieving optimal performance for limited data budgets across multiple linear algebra problems.

Abstract: In recent years, randomized algorithms have established themselves as fundamental tools in computational linear algebra, with applications in scientific computing, machine learning, and quantum information science. Many randomized matrix algorithms proceed by first collecting information about a matrix and then processing that data to perform some computational task. This thesis addresses the following question: How can one design algorithms that use this information as efficiently as possible, reliably achieving the greatest possible speed and accuracy for a limited data budget?
  The first part of this thesis focuses on low-rank approximation for positive-semidefinite matrices. Here, the goal is to compute an accurate approximation to a matrix after accessing as few entries of the matrix as possible. This part of the thesis explores the randomly pivoted Cholesky (RPCholesky) algorithm for this task, which achieves a level of speed and reliability greater than other methods for the same problem.
  The second part of this thesis considers the task of estimating attributes of an implicit matrix accessible only by matrix-vector products. This thesis describes the leave-one-out approach to developing matrix attribute estimation algorithms and develops optimized trace, diagonal, and row-norm estimation algorithms.
  The third part of this thesis considers randomized algorithms for overdetermined linear least squares problems. Randomized algorithms for linear-least squares problems are asymptotically faster than any known deterministic algorithm, but recent work has raised questions about the accuracy of these methods in floating point arithmetic. This thesis shows these issues are resolvable by developing fast randomized least-squares problem achieving backward stability, the gold-standard stability guarantee for a numerical algorithm.

</details>


### [2] [Time-Frequency Analysis for Neural Networks](https://arxiv.org/abs/2512.15992)
*Ahmed Abdeljawad,Elena Cordero*

Main category: math.NA

TL;DR: The paper develops a quantitative approximation theory for shallow neural networks using time-frequency analysis, achieving dimension-independent approximation rates in Sobolev norms with explicit constants.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous approximation rates for neural networks that combine standard activations with localized time-frequency windows, providing theoretical guarantees for their performance in Sobolev spaces.

Method: Uses tools from time-frequency analysis and weighted modulation spaces $M^{p,q}_m(\mathbf{R}^{d})$. Networks combine standard activations with localized time-frequency windows. Proves dimension-independent approximation rates in Sobolev norms $W^{n,r}(Ω)$ with explicit constant control.

Result: For $f \in M^{p,q}_m(\mathbf{R}^{d})$, achieves $\|f - f_N\|_{W^{n,r}(Ω)} \lesssim N^{-1/2}\,\|f\|_{M^{p,q}_m(\mathbf{R}^{d})}$ on bounded domains. Also obtains global approximation theorems on $\mathbf{R}^{d}$ using weighted modulation dictionaries, with applications to Feichtinger's algebra, Fourier-Lebesgue spaces, and Barron spaces.

Conclusion: Modulation-based neural networks provide superior Sobolev approximation compared to standard ReLU networks, with theoretical rates confirmed by numerical experiments in 1D and 2D.

Abstract: We develop a quantitative approximation theory for shallow neural networks using tools from time-frequency analysis. Working in weighted modulation spaces $M^{p,q}_m(\mathbf{R}^{d})$, we prove dimension-independent approximation rates in Sobolev norms $W^{n,r}(Ω)$ for networks whose units combine standard activations with localized time-frequency windows. Our main result shows that for $f \in M^{p,q}_m(\mathbf{R}^{d})$ one can achieve \[ \|f - f_N\|_{W^{n,r}(Ω)} \lesssim N^{-1/2}\,\|f\|_{M^{p,q}_m(\mathbf{R}^{d})}, \] on bounded domains, with explicit control of all constants. We further obtain global approximation theorems on $\mathbf{R}^{d}$ using weighted modulation dictionaries, and derive consequences for Feichtinger's algebra, Fourier-Lebesgue spaces, and Barron spaces. Numerical experiments in one and two dimensions confirm that modulation-based networks achieve substantially better Sobolev approximation than standard ReLU networks, consistent with the theoretical estimates.

</details>


### [3] [A divergence-free parametric finite element method for 3D Stokes equations on curved domains](https://arxiv.org/abs/2512.16216)
*Lingxiao Li,Haiyan Su,He Zhang,Weiying Zheng*

Main category: math.NA

TL;DR: A novel divergence-free parametric mixed finite element method for 3D Stokes equations on domains with piecewise smooth boundaries using high-order curved tetrahedral meshes.


<details>
  <summary>Details</summary>
Motivation: The Stokes equations are crucial for incompressible flow simulation, but existing methods may not maintain exact divergence-free properties on curved domains with piecewise smooth boundaries.

Method: Uses high-order parametric Brezzi-Douglas-Marini elements for velocity and volume elements for pressure on curved tetrahedral meshes. Applies interior-penalty discontinuous Galerkin (IPDG) technique to prove inf-sup condition and optimal error estimates.

Result: Proves inf-sup condition for mixed finite element pair, achieves high-order optimal error estimates in energy norm, and ensures exact divergence-free discrete velocity (div uh = 0) in curved computational domain. Numerical experiments support theoretical analyses.

Conclusion: The proposed method successfully solves 3D Stokes equations on curved domains while maintaining exact divergence-free properties and achieving optimal convergence rates, validated by both theoretical proofs and numerical experiments.

Abstract: The Stokes equations play an important role in the incompressible flow simulation. In this paper, a novel divergence-free parametric mixed finite element method is proposed for solving three-dimensional Stokes equations on domains with piecewise smooth boundaries. The flow velocity and pressure are discretized with high-order parametric Brezzi-Douglas-Marini elements and volume elements, respectively, on curved tetrahedral meshes. Utilizing the interior-penalty discontinuous Galerkin (IPDG) technique, we prove the inf-sup condition for the mixed finite element pair, and high-order optimal error estimates in the energy norm, with the help of the extension and transformation of the true solution to computational domain. Moreover, the discrete velocity is exactly divergence-free, meaning that div uh = 0 holds in the curved computational domain. Numerical experiments are conducted to support the theoretical analyses.

</details>


### [4] [Numerical reconstruction of Schrödinger equations with quadratic nonlinearities](https://arxiv.org/abs/2512.16269)
*Khaoula El Maddah,Matti Lassas,Teemu Tyni*

Main category: math.NA

TL;DR: A numerical framework for reconstructing potentials in 2D semilinear elliptic PDEs from Dirichlet-to-Neumann data using higher-order linearization and Fourier inversion.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the inverse problem of recovering unknown potentials in semilinear elliptic PDEs from boundary measurements (Dirichlet-to-Neumann map), which has applications in medical imaging, geophysics, and material science.

Method: Uses higher-order linearization method to compute Fourier data of the unknown potential, then inverts it to recover q. The approach handles power-type nonlinearities in 2D semilinear elliptic PDEs.

Result: Numerical experiments demonstrate accurate reconstructions for both smooth and discontinuous test cases, showing the method's effectiveness across different potential types.

Conclusion: The proposed numerical framework successfully reconstructs potentials in semilinear elliptic PDEs from boundary measurements, with promising results for both smooth and discontinuous potentials.

Abstract: We introduce a numerical framework for reconstructing the potential in two dimensional semilinear elliptic PDEs with power type nonlinearities from the nonlinear Dirichlet to Neumann map. By applying higher order linearization method, we compute the Fourier data of the unknown potential and then invert it to recover $q$. Numerical experiments show accurate reconstructions for both smooth and discontinuous test cases.

</details>


### [5] [A Locally Divergence-Free Local Characteristic Decomposition Based Path-Conservative Central-Upwind Scheme for Ideal Magnetohydrodynamics](https://arxiv.org/abs/2512.16346)
*Shaoshuai Chu,Alexander Kurganov,Maria Lukacova-Medvidova,Mingye Na*

Main category: math.NA

TL;DR: A new low-dissipation numerical scheme (LCD-PCCU) for MHD equations that improves solution resolution by incorporating local characteristic decomposition into a path-conservative central-upwind framework.


<details>
  <summary>Details</summary>
Motivation: To develop a less dissipative extension of the existing locally divergence-free PCCU scheme for ideal magnetohydrodynamics equations, aiming to enhance numerical solution resolution.

Method: Incorporates local characteristic decomposition (LCD) into the path-conservative central-upwind (PCCU) framework, creating the LCD-PCCU scheme that maintains local divergence-free properties while reducing numerical dissipation.

Result: The LCD-PCCU method successfully reduces numerical dissipation and enhances resolution of numerical solutions, as validated through a series of benchmark tests.

Conclusion: The proposed LCD-PCCU scheme provides an effective low-dissipation extension to existing PCCU methods for MHD simulations, offering improved solution accuracy and resolution.

Abstract: We introduce a locally divergence-free local characteristic decomposition based path-conservative central-upwind (LCD-PCCU) scheme for ideal magnetohydrodynamics (MHD) equations. The proposed method is a low-dissipation extension of the recently proposed locally divergence-free PCCU scheme. To reduce the numerical dissipation, we incorporate the LCD into the PCCU framework. The resulting LCD-PCCU method enhances the resolution of numerical solutions as demonstrated through a series of benchmark tests.

</details>


### [6] [Conserving mass, momentum, and energy for the Benjamin-Bona-Mahony, Korteweg-de Vries, and nonlinear Schrödinger equations](https://arxiv.org/abs/2512.16352)
*Hendrik Ranocha,David I. Ketcheson*

Main category: math.NA

TL;DR: High-order numerical methods that preserve multiple invariants (mass, momentum, energy) for PDEs using Fourier Galerkin in space and orthogonal projection with relaxation in time, requiring no large algebraic solves.


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical methods that preserve important physical invariants (mass, momentum, energy) for long-term simulations of PDEs without requiring computationally expensive solutions of large algebraic systems.

Method: Combines Fourier Galerkin methods in space with orthogonal projection and relaxation techniques in time to create essentially explicit schemes that preserve multiple invariants while avoiding large algebraic solves.

Result: The methods successfully conserve mass, momentum, and energy up to numerical precision for Benjamin-Bona-Mahoney, Korteweg-de Vries, nonlinear Schrödinger, and hyperbolic NLS equations, leading to reduced error growth in long-term simulations.

Conclusion: The proposed high-order, essentially explicit numerical schemes effectively preserve multiple physical invariants, improving long-term simulation accuracy for various PDEs while maintaining computational efficiency.

Abstract: We propose and study a class of arbitrarily high order numerical discretizations that preserve multiple invariants and are essentially explicit (they do not require the solution of any large systems of algebraic equations). In space, we use Fourier Galerkin methods, while in time we use a combination of orthogonal projection and relaxation. We prove and numerically demonstrate the conservation properties of the method by applying it to the Benjamin-Bona-Mahoney, Korteweg-de Vries, and nonlinear Schrödinger (NLS) PDEs as well as a hyperbolic approximation of NLS. For each of these equations, the proposed schemes conserve mass, momentum, and energy up to numerical precision. We show that this conservation leads to reduced growth of numerical errors for long-term simulations.

</details>


### [7] [New Fully Discrete Active Flux Methods with Truly Multi-Dimensional Evolution Operators and WENO Reconstruction](https://arxiv.org/abs/2512.16359)
*Amelie Porfetye,Zhuyan Tang,Shaoshuai Chu,Christiane Helzel,Maria Lukacova-Medvidova*

Main category: math.NA

TL;DR: New fully discrete third-order accurate Active Flux and WENO methods for 2D acoustic equations using multidimensional evolution operators with improved stability.


<details>
  <summary>Details</summary>
Motivation: To develop high-order accurate numerical methods for acoustic equations that maintain robustness and accuracy even on coarse grids, addressing stability challenges in multidimensional problems.

Method: Based on method of bicharacteristics, derive several approximate evolution operators to create truly multidimensional third-order accurate Active Flux and WENO schemes with improved stability properties.

Result: Schemes demonstrate third-order accuracy, improved stability determined through linear stability analysis, and robust performance on both continuous and discontinuous problems even on coarse grids.

Conclusion: The proposed multidimensional evolution operators successfully yield stable, third-order accurate methods for 2D acoustic equations that perform well across various problem types including discontinuous cases.

Abstract: We propose new fully discrete third-order accurate Active Flux and WENO methods based on truly multidimensional evolution operators for the two-dimensional acoustic equations. Building on the method of bicharacteristics, several approximate evolution operators are derived that yield an improved stability of the resulting schemes. A linear stability analysis is applied to determine the maximal CFL number. The schemes are tested extensively on both continuous and discontinuous problems, confirming their robustness and accurate approximation even on coarse grids.

</details>


### [8] [An Euler scheme for BSDEs via the Wiener chaos decomposition](https://arxiv.org/abs/2512.16418)
*Pere Díaz Lozano,Giulia Di Nunno*

Main category: math.NA

TL;DR: A Wiener chaos decomposition-based implementation of the Euler scheme for BSDEs that handles arbitrary square-integrable terminal conditions without requiring Markovian structure.


<details>
  <summary>Details</summary>
Motivation: The standard Euler scheme for BSDEs requires approximating conditional expectations and martingale terms, which typically relies on forward-backward Markovian structure. This limits applications to specific types of terminal conditions.

Method: Uses Wiener chaos decomposition to approximate conditional expectations and martingale terms in the Euler scheme for BSDEs. This approach doesn't require Markovian structure and can handle arbitrary $\mathcal{F}_T$-measurable square-integrable terminal conditions.

Result: Provides comprehensive convergence analysis of the proposed method and demonstrates its effectiveness through several numerical examples.

Conclusion: The Wiener chaos decomposition offers a flexible alternative to traditional BSDE numerical methods, extending applicability to non-Markovian settings with arbitrary terminal conditions while maintaining theoretical convergence guarantees.

Abstract: The Euler scheme is a standard time discretization for BSDEs, but its implementation hinges on approximating conditional expectations and the associated martingale terms at each time step. We propose an implementation based on the Wiener chaos decomposition to approximate these quantities. In contrast to many numerical schemes that rely on a forward-backward (Markovian) structure, our approach accommodates arbitrary $\mathcal{F}_T$-measurable square-integrable terminal conditions. We provide a comprehensive convergence analysis and illustrate the method on several numerical examples.

</details>


### [9] [A non-negativity-preserving cut-cell discontinuous Galerkin method for the diffusive wave equation](https://arxiv.org/abs/2512.16525)
*Panasun Manorost,Peter Bastian*

Main category: math.NA

TL;DR: A non-negativity-preserving cut-cell DG method for degenerate parabolic diffusive wave approximation of shallow water equations, with comparison to a finite volume method.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods for shallow water equations that preserve non-negativity (water depth) while handling complex geometries, discontinuous bathymetry, and different friction laws.

Method: Two methods: 1) Cut-cell discontinuous Galerkin method with upwind flux, 2) Finite volume method on Delaunay triangulations with upwind flux. Both preserve non-negativity and handle Manning's and Chezy's friction laws.

Result: DG method achieves full second-order accuracy for Barenblatt solution on inclined plane, while FV method is only first-order accurate. FV method requires 3-4 mesh refinements to match DG solution quality.

Conclusion: The cut-cell DG method is superior in accuracy and efficiency, providing second-order accuracy with fewer mesh refinements needed compared to the first-order FV method.

Abstract: A non-negativity-preserving cut-cell discontinuous Galerkin method for the degenerate parabolic diffusive wave approximation of the shallow water equation is presented. The method can handle continuous and discontinuous bathymmetry as well as general triangular meshes. It is complemented by a finite volume method on Delauney triangulations which is also shown to be non-negativity preserving. Both methods feature an upwind flux and can handle Manning's and Chezy's friction law. By numerical experiment we demonstrate the discontinuous Galerkin method to be fully second-order accurate for the Barenblatt analytical solution on an inclined plane. In constrast, the finite volume method is only first-order accurate. Further numerical experiments show that three to four mesh refinements are needed for the finite volume method to match the solution of the discontinuous Galerkin method.

</details>


### [10] [Landscape Analysis of Excited States Calculation over Quantum Computers](https://arxiv.org/abs/2512.16539)
*Hengzhun Chen,Yingzhou Li,Bichen Lu,Jianfeng Lu*

Main category: math.NA

TL;DR: Three VQE models with built-in orthogonality constraints for excited state calculations are analyzed, showing favorable optimization landscapes where local minima are global minima.


<details>
  <summary>Details</summary>
Motivation: VQE excels at ground state calculations but struggles with excited states due to variational collapse and orthogonality maintenance challenges. Current methods require external orthogonality enforcement, which complicates optimization.

Method: Three VQE models with specially designed cost functions that embed orthogonality constraints intrinsically. These formulations avoid external orthogonality enforcement and are analyzed through rigorous landscape analysis of stationary points and local minimizers.

Result: The models possess the desirable property that any local minimum is also a global minimum, addressing optimization difficulties. Theoretical guarantees of favorable properties are provided, along with analytical tools applicable to broader VQE methods.

Conclusion: The proposed VQE models with built-in orthogonality constraints provide effective solutions for excited state calculations, with comprehensive comparison of quantum resource requirements and classical optimization complexity.

Abstract: The variational quantum eigensolver (VQE) is one of the most promising algorithms for low-lying eigenstates calculation on Noisy Intermediate-Scale Quantum (NISQ) computers. Specifically, VQE has achieved great success for ground state calculations of a Hamiltonian. However, excited state calculations arising in quantum chemistry and condensed matter often requires solving more challenging problems than the ground state as these states are generally further away from a mean-field description, and involve less straightforward optimization to avoid the variational collapse to the ground state. Maintaining orthogonality between low-lying eigenstates is a key algorithmic hurdle. In this work, we analyze three VQE models that embed orthogonality constraints through specially designed cost functions, avoiding the need for external enforcement of orthogonality between states. Notably, these formulations possess the desirable property that any local minimum is also a global minimum, helping address optimization difficulties. We conduct rigorous landscape analyses of the models' stationary points and local minimizers, theoretically guaranteeing their favorable properties and providing analytical tools applicable to broader VQE methods. A comprehensive comparison between the three models is also provided, considering their quantum resource requirements and classical optimization complexity.

</details>


### [11] [Obstacle Mean Curvature Flow: Efficient Approximation and Convergence Analysis](https://arxiv.org/abs/2512.16668)
*Fabius Krämer,Tim Laux*

Main category: math.NA

TL;DR: A simple, efficient numerical method for computing mean curvature flow with obstacles that extends the Merriman-Bence-Osher scheme with constraint enforcement while maintaining computational complexity.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method for obstacle mean curvature flow that is both simple to implement and efficient, while preserving key structural properties of the continuous problem.

Method: Augments the Merriman-Bence-Osher scheme with a pointwise update that enforces obstacle constraints, retaining the original scheme's computational complexity while inheriting geometric comparison principle and minimizing movements interpretation.

Result: The scheme inherits both crucial structural properties (comparison principle and minimizing movements interpretation), provides unconditional stability, proves convergence to viscosity solution, shows convergence of spatially discrete model, and demonstrates effectiveness through numerical experiments.

Conclusion: The proposed naive scheme successfully computes obstacle mean curvature flow with preserved structural properties, proven convergence, and practical effectiveness demonstrated through numerical experiments for physical models.

Abstract: We introduce a simple and efficient numerical method to compute mean curvature flow with obstacles. The method augments the Merrimam-Bence-Osher scheme with a pointwise update that enforces the constraint and therefore retains the computational complexity of the original scheme. Remarkably, this naive scheme inherits both crucial structural properties of obstacle mean curvature flow: a geometric comparison principle and a minimizing movements interpretation. The latter immediately implies the unconditional stability of the scheme. Based on the comparison principle we prove the convergence of the scheme to the viscosity solution of obstacle mean curvature flow. Moreover, using the minimizing movements interpretation, we show convergence of a spatially discrete model. Finally, we present numerical experiments for a physical model that inspired this work.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Fokas-type closed-form solution formulae for Sobolev-type equations with time-dependent coefficients](https://arxiv.org/abs/2512.15937)
*Andreas Chatziafratis*

Main category: math.AP

TL;DR: The paper develops explicit integral representations for solving nonhomogeneous initial-boundary-value problems for evolution PDEs of Sobolev-Galpern type with time-dependent coefficients, using an extension of the Fokas unified transform method.


<details>
  <summary>Details</summary>
Motivation: To solve evolution PDEs with mixed spatiotemporal derivatives and time-dependent coefficients that induce rational dispersion relations, which present complex analytical and algebraic challenges not addressed by existing methods.

Method: Extension of the Fokas unified transform methodology to handle evolution equations with time-dependent coefficients and mixed derivatives, carefully implementing complex-analytic techniques to overcome technical difficulties arising from rational dispersion relations.

Result: Novel explicit integral representations for solutions of nonhomogeneous initial-boundary-value problems for Sobolev-Galpern type equations with arbitrary data in classical function spaces, demonstrated through closed-form solutions for various equations on the half-line.

Conclusion: The developed approach successfully solves challenging evolution equations with mixed derivatives and time-dependent coefficients, providing formulas useful for qualitative analysis and nonlinear extensions, with further generalizations to be reported.

Abstract: We analytically derive novel explicit integral representations for the solution of nonhomogeneous initial-boundary-value problems for a large category of evolution partial differential equations of Sobolev-Galpern type with generic temporally variable coefficients, satisfying suitable mild conditions, and with arbitrary data in classical function spaces. This work is based on the careful implementation of the pioneering Fokas unified transform methodology alongside its recently-proposed extension for solving a class of linear evolution equations with dispersion relation of specific polynomial type and time-dependent coefficients. We herein effectively extend those techniques to a special collection of evolution equations with time-dependent coefficients and mixed spatiotemporal derivatives, which induce rational dispersion relations. The new approach is exhibited in detail through illustrative generation of closed-form solutions for a multitude of such equations (such as Milne-Taylor-Barenblatt-Coleman-Ting-Chen-type, Benjamin-Bona-Mahony-type, as well as numerous higher-order variants) posed on the half-line. Challenging technical difficulties of complex-analytic and of algebraic flavour naturally emerge due the presence of mixed-derivative terms, and these are appropriately resolved in each case. The new formulas are of utility in subsequent investigation of qualitative properties and analysis of nonlinear counterparts too. Further extensions, generalizations, rigorous aspects and implementations to other types of problems as well will soon be reported in forthcoming publications.

</details>


### [13] [Fundamental Properties and Embedding Results in a Novel $(Φ_x, ψ)$-Fractional Musielak Space with an Application to Nonlocal BVP](https://arxiv.org/abs/2512.15972)
*Ayoub Kasmi,El Houssine Azroul,Mohammed Shimi*

Main category: math.AP

TL;DR: The paper introduces generalized $(Φ_x,ψ)$-fractional Musielak spaces for modeling heterogeneous nonlinear phenomena with memory/nonlocal effects, establishes their properties and embeddings, and applies them to prove existence of solutions to fractional differential problems.


<details>
  <summary>Details</summary>
Motivation: To develop a flexible functional framework that extends classical fractional spaces to handle heterogeneous and nonlinear phenomena with memory and nonlocal effects, particularly relevant for nonlocal boundary value problems in variable-exponent and Musielak-Orlicz settings.

Method: Introduces and rigorously analyzes generalized $(Φ_x,ψ)$-fractional Musielak spaces $\mathcal{K}_{Φ_x}^{α, β, ψ}$, establishes their functional structure, properties, and embedding results, then applies the framework to prove existence of nontrivial solutions to nonlinear fractional differential problems using mountain pass theorem under Ambrosetti-Rabinowitz conditions.

Result: Establishes new properties and embedding results for the proposed fractional Musielak spaces, and proves existence of nontrivial solutions to nonlinear fractional differential problems, providing new analytical perspectives for nonlocal and nonhomogeneous equations.

Conclusion: The proposed generalized $(Φ_x,ψ)$-fractional Musielak spaces offer a powerful and flexible framework for analyzing heterogeneous nonlinear phenomena with memory and nonlocal effects, with applications to nonlocal boundary value problems and potential for broader applications in variable-exponent and Musielak-Orlicz settings.

Abstract: In this paper, we introduce and study a novel class of generalized $(Φ_x,ψ)$-fractional Musielak spaces $\mathcal{K}_{Φ_x}^{α, β, ψ}$, which extends classical fractional spaces and offers the flexibility to model heterogeneous and nonlinear phenomena with memory and nonlocal effects. A detailed and rigorous analysis of their functional structure is carried out. Several new properties and embedding results are established, highlighting the originality of the proposed framework and its relevance to nonlocal BVPs. To illustrate the significance of this functional setting, we prove the existence of nontrivial solutions to a nonlinear fractional differential problem under an Ambrosetti--Rabinowitz type condition, using the mountain pass theorem. Our results provide new perspectives for the analysis of nonlocal and nonhomogeneous equations in variable-exponent and Musielak-Orlicz settings.

</details>


### [14] [A Fourier analysis for $(θ,T)$-periodic functions and applications](https://arxiv.org/abs/2512.15974)
*André Pedroso Kowacs,Marielle Aparecida Silva*

Main category: math.AP

TL;DR: Fourier analysis for (θ,T)-periodic functions with applications to global hypoellipticity/solvability of differential operators.


<details>
  <summary>Details</summary>
Motivation: To extend Fourier analysis from classical periodic functions to the broader class of (θ,T)-periodic functions, which generalize periodic functions, and apply this analysis to study global hypoellipticity and solvability properties of differential operators.

Method: Develop Fourier analysis for (θ,T)-periodic functions, prove properties and inequalities (including Poincaré-type inequality), then apply this framework to analyze continuous linear operators acting on smooth (θ,T)-periodic functions.

Result: Established Fourier analysis for (θ,T)-periodic functions with extended properties/inequalities; proved equivalence: operator on (θ,T)-periodic functions is globally hypoelliptic/solvable iff corresponding periodic operator is; characterized global hypoellipticity/solvability for first-order differential operators on (θ,T)-periodic functions.

Conclusion: The developed Fourier analysis successfully extends periodic function theory to (θ,T)-periodic functions and provides tools to characterize global hypoellipticity/solvability of differential operators on these function spaces, establishing important equivalences with the classical periodic case.

Abstract: We develop a Fourier analysis for a generalization of the class of periodic functions, often referred to as $(θ, T)$-periodic functions, and prove several properties and inequalities related to the Fourier transform, including a type of Poincaré inequality, which extend the periodic case. As an application, we employ this analysis to show that a continuous linear operator acting on smooth $(θ, T)$-periodic functions is globally hypoelliptic/solvable if and only if the corresponding operator which acts on periodic functions is globally hypoelliptic/solvable, and characterize the global hypoellipticity/solvability of a class of first order differential operators acting on the set of smooth $(θ, T)$-periodic functions.

</details>


### [15] [A Poisson Formula for the Wave Propagator on Schwarzschild-de Sitter Backgrounds](https://arxiv.org/abs/2512.16054)
*Izak Oltman,Ben Pineau*

Main category: math.AP

TL;DR: Proposes a Poisson formula for wave propagator in Schwarzschild-de Sitter spacetime, extending previous results to non-compactly supported potentials.


<details>
  <summary>Details</summary>
Motivation: Previous Poisson formulae for wave propagators required compactly supported perturbations, limiting applications to black hole spacetimes like Schwarzschild-de Sitter where potentials have non-compact support.

Method: Proves a Poisson formula relating wave propagators and scattering resonances for a class of non-compactly supported potentials on the real line, including Regge-Wheeler potentials from separation of variables in SdS.

Result: Establishes a Poisson formula for the wave propagator of SdS metric, overcoming the compact support limitation present in previous work by Lax-Phillips, Melrose, and others.

Conclusion: Extends Poisson formula theory to non-compactly supported potentials, enabling direct application to black hole spacetimes like Schwarzschild-de Sitter where compact support assumptions fail.

Abstract: This paper proposes a Poisson formula for the wave propagator of the Schwarzschild--de Sitter (SdS) metric. That is done by proving a Poisson formula relating wave propagators and scattering resonances for a class of non-compactly supported potentials on the real line. That class includes the Regge--Wheeler potentials obtained from separation of variables for SdS. The novelty lies in allowing non-compact supports -- all exact Poisson formulae of Lax--Phillips, Melrose, and other authors required compactness of the support of the perturbation.

</details>


### [16] [Low Regularity Well-Posedness of Cauchy Problem for Two-Dimensional Relativistic Euler Equation](https://arxiv.org/abs/2512.16090)
*Huali Zhang*

Main category: math.AP

TL;DR: Study of Cauchy problem for 2D relativistic Euler equations in low-regularity settings using reformulated variables and wave-transport system analysis.


<details>
  <summary>Details</summary>
Motivation: To establish well-posedness results for the relativistic Euler equations in low-regularity settings, which is important for understanding relativistic fluid dynamics with minimal smoothness assumptions.

Method: Introduce rescaled velocity, logarithmic enthalpy, and vorticity variables to reformulate equations into coupled wave-transport system. Use Strichartz estimates and semiclassical analysis to prove existence and uniqueness results.

Result: Proved existence/uniqueness for general state functions with specific Sobolev space regularity requirements. For special case p(ρ)=ρ, established well-posedness with lower regularity requirements. Also proved local/global well-posedness for irrotational stiff flows.

Conclusion: Successfully developed low-regularity well-posedness theory for 2D relativistic Euler equations using novel variable transformations and analytical techniques, achieving optimal or near-optimal regularity exponents.

Abstract: In this article, we initiate the study of the Cauchy problem for the two-dimensional relativistic Euler equations in a low-regularity setting. By introducing good variables--a rescaled velocity, logarithmic enthalpy, and an appropriately defined vorticity, we reformulate the equations into a coupled wave-transport system.
  First, we prove the existence and uniqueness of solutions when the initial logarithmic enthalpy $h_0$, rescaled velocity $\bv_0$, and vorticity $\bw_0$ satisfy $(h_0, \bv_0, \bw_0, \nabla \bw_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac32+}(\mathbb{R}^2) \times L^8(\mathbb{R}^2)$. By using Strichartz estimates and semiclassical analysis, a relaxed well-posedness result holds when $(h_0, \bv_0, \bw_0, \nabla \bw_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac32}(\mathbb{R}^2) \times L^8(\mathbb{R}^2)$. Both results are valid for the general state function $p(\varrho)=\varrho^A$ ($A \geq 1$).
  Secondly, in the special case where $p(\varrho)=\varrho$, the acoustic metric reduces to the standard flat Minkowski metric. We can establish the well-posedness of solutions when $(h_0, \mathbf{v}_0, \mathbf{w}_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{1+}(\mathbb{R}^2)$. The regularity exponents for the log-enthalpy and rescaled velocity correspond to those in Smith and Tataru \cite{ST}, while the vorticity regularity corresponds to Bourgain and Li \cite{BL}. Moreover, if the stiff flow is irrotational, we can prove the local well-posedness for $(h_0, \mathbf{v}_0) \in H^{1+}(\mathbb{R}^2)$, and global well-posedness for small initial data $(h_0, \bv_0) \in \dot{B}^{1}_{2,1}(\mathbb{R}^2)$.

</details>


### [17] [Global weak solutions of 3D compressible magnetohydrodynamic equations subject to large external potential forces with discontinuous initial data and vacuum](https://arxiv.org/abs/2512.16121)
*Geyuan Chen,Xin Zhong*

Main category: math.AP

TL;DR: Global existence of weak solutions for compressible magnetohydrodynamic equations with large external forces and discontinuous initial data in 3D bounded domains with Navier-slip boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To establish existence results for compressible MHD equations with challenging conditions: large external potential forces, discontinuous initial data (including vacuum states and large oscillations), in bounded domains with Navier-slip boundary conditions.

Method: Uses new estimates based on effective viscous flux to overcome difficulties from boundary effects and large external forces. Focuses on weak solutions framework with small initial energy assumption.

Result: Proves global existence of weak solutions when initial energy is suitably small, allowing for initial data containing vacuum states and large oscillations.

Conclusion: The paper successfully establishes existence theory for compressible MHD equations under challenging conditions by developing new estimates using effective viscous flux techniques.

Abstract: We investigate the compressible magnetohydrodynamic equations subject to large external potential forces with discontinuous initial data in a three-dimensional bounded domain under Navier-slip boundary conditions. We show the global existence of weak solutions for such an initial-boundary value problem provided the initial energy is suitably small. In particular, the initial data may contain vacuum states and possibly exhibit large oscillations. To overcome difficulties brought by boundary and large external forces, some new estimates based on the effective viscous flux play crucial roles.

</details>


### [18] [Well-Posedness for Low Regularity Solutions to the g-SQG Equation with Regular Level Sets](https://arxiv.org/abs/2512.16128)
*Junekey Jeon,Andrej Zlatos*

Main category: math.AP

TL;DR: Generalized SQG equation is locally well-posed in low regularity Hölder spaces with H² level sets, and for α≤1/6, solutions persist until level sets lose H² regularity, not just from collisions.


<details>
  <summary>Details</summary>
Motivation: To establish local well-posedness for the generalized SQG equation in low regularity settings and understand solution breakdown mechanisms, specifically whether solutions can persist beyond level set collisions if the level sets maintain sufficient regularity.

Method: Analyze the generalized SQG equation on the plane, working in spaces of essentially Hölder continuous solutions with Hölder exponents depending on α∈(0,½), requiring that level sets have H² regularity (L² curvatures). For α≤1/6, impose additional hypotheses on initial data to track solution persistence.

Result: Local well-posedness is proven for low regularity Hölder spaces with H² level sets. For α≤1/6 with additional initial conditions, solutions can only cease to exist when their level sets lose H²-regularity, not merely due to level set collisions or "pile ups".

Conclusion: The generalized SQG equation exhibits robust local well-posedness in low regularity settings, and for sufficiently small α, solution breakdown is tied specifically to loss of H² regularity in level sets rather than geometric collisions, providing insight into solution persistence mechanisms.

Abstract: We show that the generalized SQG equation on the plane is locally well-posed in spaces of low regularity solutions (essentially Hölder continuous with Hölder exponents depending on the equation parameter $α\in(0,\frac 12)$) that have $H^2$ level sets (i.e., with $L^2$ curvatures). Moreover, for $α\le\frac 16$ and initial data satisfying some additional hypotheses we show that the corresponding solutions can stop existing only when their level sets lose $H^2$-regularity, and hence not just due to level set collisions or "pile ups".

</details>


### [19] [On the existence of full dimensional KAM tori for 1D periodic nonlinear Schrödinger equation](https://arxiv.org/abs/2512.16283)
*Yuan Wu*

Main category: math.AP

TL;DR: Proves existence of full dimensional tori for 1D nonlinear Schrödinger equation with space-dependent nonlinearity and Gevrey smooth coefficients, extending previous results to more general perturbations.


<details>
  <summary>Details</summary>
Motivation: Extend previous KAM theory results (Bourgain 2005, Cong 2024) for nonlinear Schrödinger equations to cases where the nonlinear perturbation explicitly depends on the space variable x, which is more general and physically relevant.

Method: Uses KAM (Kolmogorov-Arnold-Moser) theory techniques to construct invariant tori for the infinite-dimensional Hamiltonian system. Handles the explicit x-dependence in the nonlinear term f(x)|u|^4u and deals with Gevrey smooth coefficients rather than analytic ones.

Result: Proves existence of full dimensional invariant tori with radius decaying as I_n ∼ e^{-2ln^σ|n|} for any σ > 2, which is slower decay than previous results, allowing for larger invariant sets in phase space.

Conclusion: Successfully extends KAM theory for 1D nonlinear Schrödinger equations to include explicit space-dependent nonlinear perturbations with Gevrey smooth coefficients, providing existence of invariant tori with slower decay rates than previously known.

Abstract: In this paper, we will prove the existence of full dimensional tori for 1-dimensional nonlinear Schrödinger equation \begin{eqnarray}\label{maineq0} \mathbf{i}u_{t}-u_{xx}+V*u+εf(x)|u|^{4}u=0,\ x\in\mathbb{T}=\mathbb{R}/2π\mathbb{Z}, \end{eqnarray} with boundary conditions, where $V*$ is the Fourier multiplier, and $f(x)$ is Gevrey smooth. Here the radius of the invariant tori satisfies a slower decay, i.e. \[ I_n\sim e^{-2\ln^σ|n|}, \mbox{as}\ n\rightarrow\infty, \] for any $ σ> 2, $ which extends results of Bourgain \cite{BJFA2005} and Cong \cite{cong2024} to the case that the nonlinear perturbation depends explicitly on the space variable $x$.

</details>


### [20] [Low-Mach-number limit for multiphase flows](https://arxiv.org/abs/2512.16286)
*Cassandre Lebot*

Main category: math.AP

TL;DR: Review paper on low-Mach-number limit analysis for compressible Navier-Stokes/Euler equations across single-phase and two-phase flows with various system configurations.


<details>
  <summary>Details</summary>
Motivation: To systematically study and review the mathematical analysis of low-Mach-number limits for compressible fluid equations, bridging single-phase results to more complex two-phase flow scenarios with different physical closures and assumptions.

Method: Theoretical review and analysis approach: first examines existing results for single-phase flows, then extends to two-phase flows with different system configurations including algebraic vs PDE pressure closures, single vs dual velocities, and presence/absence of entropy considerations.

Result: Comprehensive review of mathematical results on low-Mach-number limits, establishing connections between single-phase theory and more complex two-phase systems with various closure models and physical assumptions.

Conclusion: The paper provides a systematic framework for understanding low-Mach-number limits across different fluid systems, highlighting how single-phase results can inform and extend to two-phase flow analysis with varying physical constraints and mathematical formulations.

Abstract: This paper is devoted to the study of the low-Mach-number limit for solutions of the compressible Navier-Stokes or Euler equations for different types of fluids. We first review the different results obtained in the case of flows consisting of one phase. Then, we focus on the low-Mach-number limit for two-phase flows, considering different types of systems: with an algebraic closure or a PDE closure for the pressure, with one single or two different velocities, without or with entropy.

</details>


### [21] [Nekhoroshev type stability for non-local semilinear Schrödinger equations](https://arxiv.org/abs/2512.16299)
*Bingqi Yu,Li Yong*

Main category: math.AP

TL;DR: First rigorous Nekhoroshev-type stability results for ultra-differentiable Schrödinger equations with non-local nonlinearities using rational normal forms, achieving optimal stability times matching Bourgain's conjecture.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous stability results for infinite-dimensional Hamiltonian systems with ultra-differentiable regularity, particularly for logarithmic ultra-differentiable regularity without external parameters, which has been lacking in previous literature.

Method: Employ rational normal forms method with a novel global vector field norm adapted to this framework, eliminating the need for degree tracking during iteration and enabling unified treatment of nonlinear terms.

Result: First rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters; under Gevrey class regularity, stability times match Bourgain's conjectured optimal stability time.

Conclusion: The rational normal form approach with the novel global vector field norm provides a powerful framework for establishing Nekhoroshev-type stability in ultra-differentiable Schrödinger equations, achieving optimal stability bounds and overcoming previous technical limitations.

Abstract: This paper investigates Nekhoroshev-type stability for solutions of ultra-differentiable regularity in Schrödinger equations with non-local nonlinear terms, employing the method of rational normal forms. We establish the first rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters. Under Gevrey class regularity assumptions, we achieve the stability times matching Bourgain's conjectured optimal stability time in \cite{B04}. Furthermore, we introduce a novel global vector field norm adapted to the rational normal form framework. This norm eliminate the need for degree tracking during the iteration process, thereby enabling a unified treatment of nonlinear terms.

</details>


### [22] [A unified proof of sharp bounds for the Jacobi heat kernel with trace and estimates of multiplicative constants](https://arxiv.org/abs/2512.16306)
*Adam Nowak,Paweł Plewa,Tomasz Z. Szarek*

Main category: math.AP

TL;DR: Unified proof of sharp Jacobi heat kernel bounds with explicit constant tracking and quantitative parameter control


<details>
  <summary>Details</summary>
Motivation: Previous sharp bounds for Jacobi heat kernel were developed gradually across multiple papers; need unified proof with explicit constant tracking for quantitative parameter control

Method: Unified and optimized proof approach that traces and estimates all constants throughout the reasoning process

Result: Quantitative control of multiplicative constants in Jacobi heat kernel bounds in terms of parameters; extends to spherical heat kernel and other heat kernels on compact rank one symmetric spaces

Conclusion: Provides comprehensive quantitative control for heat kernel bounds across related mathematical contexts with explicit constant dependence

Abstract: We give a unified and optimized proof of the sharp bounds for the Jacobi heat kernel, which were obtained gradually in several papers in recent years. We lay particular emphasis on tracing and estimating all constants appearing throughout the entire reasoning. This allows us to quantitatively control the multiplicative constants in the Jacobi heat kernel bounds in terms of the parameters involved. Consequently, analogous control extends to a number of interrelated heat kernels. In particular, we obtain quantitative control in terms of the associated dimension for the spherical heat kernel and for all other heat kernels on compact rank one symmetric spaces.

</details>


### [23] [Bifurcating domains for an overdetermined eigenvalue problem in cylinders](https://arxiv.org/abs/2512.16319)
*Yuanyuan Lian,Filomena Pacella,Pieralberto Sicbaldi*

Main category: math.AP

TL;DR: The paper studies an overdetermined eigenvalue problem in domains within a half-cylinder, showing that nontrivial solutions bifurcate from trivial bounded cylinder domains at specific parameter values related to Neumann eigenvalues.


<details>
  <summary>Details</summary>
Motivation: To construct domains within a half-cylinder that admit positive eigenfunctions satisfying overdetermined boundary conditions, going beyond the obvious bounded cylinder solutions.

Method: Using bifurcation theory to show that branches of such domains emerge from the "trivial" bounded cylinder domains Ω_t at critical values t_j = π/(2√σ_j), where σ_j are simple Neumann eigenvalues of the Laplace operator on the base domain ω.

Result: The paper successfully constructs nontrivial domains in the half-cylinder that admit positive eigenfunctions solving the overdetermined eigenvalue problem, which can be reflected to generate solutions in full cylinders.

Conclusion: Bifurcation from trivial cylinder domains at specific parameter values yields nontrivial solutions to the overdetermined eigenvalue problem in half-cylinders, with applications to generating solutions in full cylinders through reflection.

Abstract: We study an overdetermined eigenvalue problem for domains $Ω$ contained in the half-cylinder $Σ=ω\times (0, +\infty)$, based on a bounded regular domain $ω\subset \mathbb{R}^{N-1}$. It is easy to see that in any bounded cylinder $Ω_{t}=ω\times (0, t)$, $t > 0$, the eigenvalue problem admits a one-dimensional positive eigenfunction which satisfies the overdetermined boundary conditions. The aim of the paper is to construct other domains $Ω\subset Σ$ for which there exists a positive eigenfunction that is a solution of the overdetermined problem. This is achieved by showing that branches of such domains bifurcate from the ``trivial'' domains $Ω_{t_j}$ at the values $t_{j} = \fracπ{2\sqrt{σ_j}}$ where $σ_j$ ($j\geq 1$) is a simple Neumann eigenvalue of the Laplace operator on $ω\subset \mathbb{R}^{N-1}$. The solutions can be reflected with respect to $ω$ to generate nontrivial solutions in a cylinder.

</details>


### [24] [Nekhoroshev type stability for Ultra-differential Hamiltonian in $L^2$ space](https://arxiv.org/abs/2512.16332)
*Bingqi Yu,Li Yong*

Main category: math.AP

TL;DR: The paper develops a normal form lemma for infinite-dimensional Hamiltonian systems with ultra-differentiable regularity, proving sub-exponential stability times for various Hamiltonian PDEs including Schrödinger equations with convolution potentials, fractional-order Schrödinger equations, and beam equations.


<details>
  <summary>Details</summary>
Motivation: To establish stability results for Hamiltonian PDEs under weaker regularity conditions than previous works, aiming to reach optimal stability time bounds predicted by Bourgain while working within a more general ultra-differentiable framework.

Method: Combines decay of high modes with smallness from high orders to develop a normal form lemma for infinite-dimensional Hamiltonian systems under ultra-differentiable regularity. Proposes a general framework applicable to the ultra-differential class.

Result: Proves sub-exponential stability time for a wide class of Hamiltonian PDEs including Schrödinger equations with convolution potentials, fractional-order Schrödinger equations, and beam equations. When conditions match previous works, achieves Bourgain's predicted optimal bound, and obtains earlier results under lower conditions.

Conclusion: The paper establishes a general framework for analyzing stability of Hamiltonian PDEs with ultra-differentiable regularity, achieving optimal stability bounds and extending previous results to weaker conditions, with applications to various important PDE models.

Abstract: This paper combines the decay of high modes with the smallness introduced by high orders, leading to a normal form lemma for infinite-dimensional Hamiltonian systems under ultra-differentiable regularity. We prove the sub-exponential stability time of a wide class of Hamiltonian PDEs, including the Schrödinger equation with convolution potentials, fractional-order Schrödinger equations, and beam equations with metrics. When the conditions are equivalent to previous ones, the stability time we obtain reaches Bourgain's predicted optimal bound. Furthermore, we approach earlier results under lower conditions. These results are discussed within a general framework we propose, which applies to the ultra-differential class.

</details>


### [25] [Quantitative stratification and optimal regularity for harmonic almost complex structures](https://arxiv.org/abs/2512.16341)
*Chang-Yu Guo,Ming-Lun Liu,Chang-Lin Xiang*

Main category: math.AP

TL;DR: New proof of partial regularity and rectifiability of singular stratum for energy minimizing harmonic almost complex structures, improving previous results.


<details>
  <summary>Details</summary>
Motivation: To provide simpler proof of partial regularity theorem and establish optimal regularity theory for energy minimizing harmonic almost complex structures, improving upon He's work.

Method: 1) New observation on equation structure for simpler partial regularity proof; 2) Quantitative stratification method of Naber-Valtorto to prove rectifiability of singular stratum; 3) Combining these to establish optimal regularity theory.

Result: 1) Easier new proof of partial regularity theorem; 2) Rectifiability of singular stratum proven; 3) Optimal regularity theory established, improving He's almost optimal higher regularity result.

Conclusion: The paper provides significant improvements to the regularity theory of energy minimizing harmonic almost complex structures through novel approaches and methods, yielding optimal results.

Abstract: In a recent interesting work [15], W.Y. He established the important partial regularity theory and the almost optimal higher regularity theory for energy minimizing harmonic almost complex structures. Based on a new observation on the structure of equations, we give an easier new proof of the partial regularity theorem, and adapting the powerful quantitative stratification method of Naber-Valtorta [22], we further prove the rectifiability of singular stratum of energy minimizing harmonic almost complex structures. Based on this, we establish an optimal regularity theory, which improves the corresponding result of He.

</details>


### [26] [Homogenization of a micropolar fluid past a porous media with non-zero spin boundary condition](https://arxiv.org/abs/2512.16353)
*Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: Study of micropolar fluid flow through porous media with periodic obstacles, deriving Darcy-like law via homogenization.


<details>
  <summary>Details</summary>
Motivation: To understand micropolar fluid behavior in porous media with non-homogeneous boundary conditions for microrotation, extending classical porous media theory.

Method: Mathematical analysis of micropolar fluid equations in periodically perforated domains with size ε, using homogenization theory to pass to the limit as ε→0.

Result: Proved existence and uniqueness of solution, derived micropolar Darcy law analogous to classical Darcy law for porous media through homogenization.

Conclusion: Successfully extended porous media theory to micropolar fluids, providing rigorous mathematical foundation for flow through periodically structured porous media.

Abstract: We consider a micropolar fluid flow in a media perforated by periodically distributed obstacles of size $\varepsilon$. A non-homogeneous boundary condition for microrotation is considered: the microrotation is assumed to be proportional to the rotation rate of the velocity on the boundary of the obstacles. The existence and uniqueness of solution is analyzed. Moreover, passing to the limit when $\varepsilon$ tends to zero, an analogue of the classical micropolar Darcy law in the theory of porous media is derived.

</details>


### [27] [Uniform vanishing damping limit for the 2D inviscid Oldroyd-B model with fractional stress tensor diffusion](https://arxiv.org/abs/2512.16436)
*Chen Liang,Zhaonan Luo,Zhaoyang Yin*

Main category: math.AP

TL;DR: The paper studies uniform vanishing damping limits in 2D inviscid Oldroyd-B models with fractional stress tensor diffusion, establishing optimal time decay rates and uniform damping vanishing rates.


<details>
  <summary>Details</summary>
Motivation: To understand how fractional stress tensor diffusion affects the global regularity and time decay behavior of 2D Oldroyd-B models with damping, and to establish uniform vanishing damping limits across different damping coefficients.

Method: Uses improved Fourier splitting method to analyze time decay rates, spectral analysis methods for specific components, and combines time decay rates with time integrability to obtain uniform damping vanishing rates.

Result: Fractional stress tensor diffusion reduces global regularity requirements; optimal time decay rates established for a=0; uniform time decay rates for a∈(0,1]; uniform damping vanishing rates obtained; improved decay rates for trτ ensure sharp uniform damping vanishing rates.

Conclusion: The paper successfully establishes uniform vanishing damping limits for 2D Oldroyd-B models with fractional diffusion, providing comprehensive decay rate analysis across different damping coefficients and demonstrating the beneficial effects of fractional stress tensor diffusion.

Abstract: This paper is devoted to the uniform vanishing damping limit of the 2D inviscid Oldroyd-B model with fractional stress tensor diffusion. Firstly, we find that fractional stress tensor diffusion helps to reduce the global regularity of the 2D Oldroyd-B model with damping coefficient $a\in[0,1]$. By virtue of improved Fourier splitting method, we then prove the optimal time decay rates under the critical regularity for $a=0$. When $a\in (0,1]$, we establish time decay rates that are uniform with respect to $a$. Combining the time decay rate for $a\in [0,1]$ and the time integrability, we obtain the uniform damping vanishing rates for the 2D Oldroyd-B model. Using spectral analysis methods, we finally improve the time decay rates for $\mathrm{tr}τ$ with $a\in (0,1]$, which ensure the sharp uniform damping vanishing rates of $\mathrm{tr}τ$.

</details>


### [28] [Normalized solutions for a class of fractional Choquard equations with mixed nonlinearities](https://arxiv.org/abs/2512.16438)
*Shaoxiong Chen,Zhipeng Yang,Xi Zhang*

Main category: math.AP

TL;DR: Study of fractional Choquard equation with mixed nonlinearities and mass constraint, establishing existence and multiplicity of normalized solutions including ground states.


<details>
  <summary>Details</summary>
Motivation: To investigate normalized solutions (solutions with prescribed L²-norm) for fractional Choquard equations with combined nonlocal nonlinearities, which arise in quantum physics and have mathematical interest due to the interplay between fractional Laplacian and Riesz potentials.

Method: Variational methods applied to constrained minimization problems, using properties of fractional Sobolev spaces and Riesz potentials, with careful analysis of the combined nonlinear structure and parameter dependence.

Result: Proved existence and multiplicity of normalized solutions for the fractional Choquard equation with mixed nonlinearities, and established existence of ground state normalized solutions for sufficiently small α parameter.

Conclusion: The fractional Choquard equation with mixed nonlocal nonlinearities admits normalized solutions with prescribed mass, including ground states, demonstrating rich solution structure despite the complex interplay between fractional diffusion and competing nonlocal interactions.

Abstract: In this paper we study the following fractional Choquard equation with mixed nonlinearities:
  \[
  \left\{
  \begin{array}{l}
  (-Δ)^s u = λu + α\left( I_μ* |u|^q \right) |u|^{q-2} u + \left( I_μ* |u|^p \right) |u|^{p-2} u, \quad x \in \mathbb{R}^N, \\[4pt]
  \displaystyle \int_{\mathbb{R}^N} |u|^2 \,\mathrm{d}x = c^2 > 0.
  \end{array}
  \right.
  \]
  Here $N > 2s$, $s \in (0,1)$, $μ\in (0, N)$, and the exponents satisfy
  \[
  \frac{2N - μ}{N} < q < p < \frac{2N - μ}{N - 2s},
  \]
  while $α> 0$ is a sufficiently small parameter, $λ\in \mathbb{R}$ is the Lagrange multiplier associated with the mass constraint, and $I_μ$ denotes the Riesz potential. We establish existence and multiplicity results for normalized solutions and, in addition, prove the existence of ground state normalized solutions for $α$ in a suitable range.

</details>


### [29] [Global existence and stability of near-affine solutions of compressible elastodynamics](https://arxiv.org/abs/2512.16505)
*Xianpeng Hu,Yuanzhi Tu,Changyou Wang,Huanyao Wen*

Main category: math.AP

TL;DR: Global existence and asymptotic behavior of strong solutions for compressible nonlinear elastodynamics in 2D and 3D under small perturbations of affine solutions.


<details>
  <summary>Details</summary>
Motivation: To establish global well-posedness and long-time behavior for compressible nonlinear elastodynamics, which models elastic wave propagation in solids, particularly for small perturbations around affine (constant strain) states.

Method: Using energy methods and perturbation theory in Sobolev spaces (H^3), analyzing the Cauchy problem for compressible nonlinear elastodynamics equations in ℝ^d (d=2,3), focusing on small perturbations of affine solutions.

Result: Proves that for sufficiently small H^3-perturbations of an affine solution, the Cauchy problem admits a unique global strong solution in both 2D and 3D, and establishes the asymptotic behavior of the solution.

Conclusion: Compressible nonlinear elastodynamics exhibits global existence and well-posedness for small perturbations of affine states, with predictable asymptotic behavior, extending understanding of elastic wave propagation in solids.

Abstract: We prove that for sufficiently small $H^3$-perturbations of an affine solution, the Cauchy problem for the compressible nonlinear elastodynamics in $\mathbb{R}^d$, for $d=2,3$, admits a unique global strong solution. Moreover, we establish the asymptotic behavior of the solution.

</details>


### [30] [Liouville-type Theorems for Stable Solutions of the Hénon-Lane-Emden System](https://arxiv.org/abs/2512.16566)
*Long-Han Huang,Wenming Zou*

Main category: math.AP

TL;DR: The paper establishes Liouville-type theorems for the Hénon-Lane-Emden system, proving non-existence of solutions in various cases including subcritical, supercritical, and solutions stable outside compact sets.


<details>
  <summary>Details</summary>
Motivation: To study the Hénon-Lane-Emden system with singular coefficients and establish non-existence results (Liouville theorems) for various parameter ranges, addressing gaps in existing literature.

Method: Analytical PDE techniques including establishing general Liouville-type theorems for subcritical case, proving validity of Hénon-Lane-Emden conjecture for solutions stable outside compact sets under specific conditions, and addressing supercritical case.

Result: First Liouville-type theorems for this class of solutions in Hénon-Lane-Emden system; refined several existing results; established validity of conjecture under conditions: min{p,q}<1, or 0≤a-b≤(N-2)(p-q), or N≤2(p+q+2)/(pq-1)+10.

Conclusion: The paper provides comprehensive Liouville-type results for Hénon-Lane-Emden system, filling important gaps in the literature and establishing foundational non-existence theorems for various parameter regimes.

Abstract: We investigate the Hénon-Lane-Emden system defined by $- Δu=|x|^a |v|^{p-1}v$ and $- Δv=|x|^b |u|^{q-1}u$ in $\mathbb{R}^N \!\setminus\! \{0\}$. We begin by establishing a general Liouville-type theorem for the subcritical case. Then we prove that the Hénon-Lane-Emden conjecture is valid for solutions stable outside a compact set, provided that $0 < \min\,\{p, q\} < 1$, or $0 \leq a - b \leq (N-2)(p - q)$, or $N \leq \frac{2(p+q+2)}{pq-1} + 10$. Additional Liouville-type theorems for the subcritical case are also obtained. Furthermore, we address the supercritical case. To our knowledge, these results constitute the first Liouville-type theorems for this class of solutions in the Hénon-Lane-Emden system. As a by-product, several existing results in the literature are refined.

</details>


### [31] [Constructing steering-type solutions for higher order Cauchy-Riemann equations in $\mathbb{R}^{m+1}$](https://arxiv.org/abs/2512.16594)
*Daniel Alfonso Santiesteban,Dixan Peña Peña,Ricardo Abreu Blaya*

Main category: math.AP

TL;DR: The paper constructs explicit solutions to higher-order PDE systems using the multidimensional Cauchy-Riemann operator framework, focusing on polymonogenic and polyharmonic functions, and identifies which solutions satisfy hypercomplex derivative equations.


<details>
  <summary>Details</summary>
Motivation: To develop explicit construction methods for solutions to higher-order partial differential equations in ℝ^(m+1) using the multidimensional Cauchy-Riemann operator framework, which generalizes classical complex analysis to higher dimensions and includes important function classes like polymonogenic and polyharmonic functions.

Method: The authors construct solutions from families of complex-valued functions that are closed under conjugation and under the action of the complex Cauchy-Riemann operator. They use this algebraic structure to generate explicit solutions to the PDE systems.

Result: The paper successfully constructs explicit solutions to the higher-order PDE systems and proves that precisely some of these solutions also satisfy homogeneous linear differential equations involving the hypercomplex derivative, establishing a connection between different types of differential operators.

Conclusion: The multidimensional Cauchy-Riemann operator provides a powerful framework for constructing explicit solutions to higher-order PDEs, and the relationship between these solutions and hypercomplex derivative equations reveals deeper algebraic structures in the theory of partial differential equations.

Abstract: The multidimensional Cauchy-Riemann operator provides a framework for studying higher order partial differential equations in $\mathbb{R}^{m+1}$, whose solutions include polymonogenic and polyharmonic functions, among others. In this work, we aim to explicitly construct solutions to such systems, generated from families of complex valued functions which are closed under conjugation and under the action of the complex Cauchy-Riemann operator. Moreover, we prove that precisely some of these solutions also satisfy homogeneous linear differential equations involving the so-called hypercomplex derivative.

</details>


### [32] [Regularity for fully nonlinear elliptic equations in generalized Orlicz spaces](https://arxiv.org/abs/2512.16600)
*Sun-Sig Byun,Jeongmin Han,Mikyoung Lee*

Main category: math.AP

TL;DR: Optimal global Calderón-Zygmund estimate for viscosity solutions of fully nonlinear elliptic equations with nonconvex nonlinearities in generalized Orlicz spaces.


<details>
  <summary>Details</summary>
Motivation: To establish optimal global regularity estimates for viscosity solutions of fully nonlinear elliptic equations, particularly when dealing with nonconvex nonlinearities and Dirichlet boundary problems, extending beyond the convex case.

Method: Prove global Calderón-Zygmund type estimates showing that the Hessian of the solution has the same integrability as the nonhomogeneous term in generalized Orlicz spaces, even for asymptotically convex nonlinearities.

Result: Established optimal global Hessian integrability results for viscosity solutions in generalized Orlicz spaces, handling nonconvex and asymptotically convex nonlinearities.

Conclusion: The paper successfully extends Calderón-Zygmund theory to fully nonlinear elliptic equations with nonconvex nonlinearities, providing optimal global regularity estimates in generalized Orlicz function spaces.

Abstract: In this paper, we establish an optimal global Calderón-Zygmund type estimate for the viscosity solution to the Dirichlet boundary problem of fully nonlinear elliptic equations with possibly nonconvex nonlinearities. We prove that the Hessian of the solution is as integrable as the nonhomogeneous term in the setting of a given generalized Orlicz space even when the nonlinearity is asymptotically convex with respect to the Hessian of the solution.

</details>


### [33] [Existence and stability of discretely self-similar blowup for a wave maps type equation](https://arxiv.org/abs/2512.16623)
*Irfan Glogić,David Hilditch,David Wallauch*

Main category: math.AP

TL;DR: Construction and nonlinear stability analysis of discretely self-similar blowup solutions for a geometric wave equation with null-form structure in all dimensions.


<details>
  <summary>Details</summary>
Motivation: To understand finite-time blowup phenomena for geometric wave equations, specifically for maps from Minkowski space to the 1-sphere, and establish the first existence and stability results for discretely self-similar blowup in this context.

Method: Construct countable family of discretely self-similar blowup solutions for all dimensions d≥1. Perform detailed nonlinear stability analysis by linearizing around self-similar profiles in similarity variables, constructing resolvents via Liouville-Green transformations and Volterra-type asymptotics, and conducting spectral analysis of linearized operators.

Result: Successfully constructed discretely self-similar blowup solutions for all dimensions d≥1 (even for d=1, radial for d≥2). Established nonlinear stability of all these profiles with precise co-dimension determined by unstable spectrum, yielding sharp semigroup bounds.

Conclusion: First existence and stability result for discretely self-similar blowup in geometric wave equations, providing comprehensive analysis of blowup phenomena with null-form structure across all dimensions.

Abstract: We study finite-time blowup for a nonlinear wave equation for maps from the Minkowski space $\mathbb{R}^{1+d}$ into the 1-sphere $\mathbb{S}^1$, whose nonlinearity exhibits a null-form structure. We construct, for every dimension $d \geq 1$, a countable family of discretely self-similar blowup solutions, which are even for $d=1$ and radial for $d \geq 2$. The main contribution of the paper is a detailed nonlinear stability analysis of this family of solutions. For $d \geq 2$, we consider radial data, while in $d=1$ we allow for general perturbations. After linearizing around the self-similar profiles in similarity variables, we construct resolvents of the resulting highly non-self-adjoint operators through Liouville-Green transformations and precise Volterra-type asymptotics. The construction itself, which occupies most of the paper, is technically challenging, as it is performed in arbitrary dimensions and for a countable family of operators in each. Combined with a detailed spectral analysis of the linearized operators, this yields sharp semigroup bounds and allows us to establish nonlinear stability of all discretely self-similar profiles in all dimensions, with precise co-dimension determined by the unstable spectrum. To our knowledge, this is the first result on the existence and stability of discretely self-similar blowup for a geometric wave equation.

</details>


### [34] [The capillary Christoffel-Minkowski problem](https://arxiv.org/abs/2512.16655)
*Xinqun Mei,Guofang Wang,Liangjun Weng*

Main category: math.AP

TL;DR: Introduces k-th capillary area measure for capillary convex bodies in Euclidean half-space, proposes Christoffel-Minkowski problem for capillary convex bodies, establishes existence/uniqueness of smooth solutions.


<details>
  <summary>Details</summary>
Motivation: To develop a boundary counterpart to classical area measure theory for capillary convex bodies in half-spaces, extending convex geometry to settings with boundary interactions.

Method: Introduces k-th capillary area measure as boundary analog of classical area measure, formulates Christoffel-Minkowski problem for capillary convex bodies, reduces to solving Hessian-type equation with Robin boundary condition.

Result: Establishes existence and uniqueness of smooth solution to the Christoffel-Minkowski problem for capillary convex bodies under natural sufficient conditions.

Conclusion: Successfully extends classical area measure theory to capillary convex bodies in half-spaces, solving the corresponding Christoffel-Minkowski problem with rigorous existence/uniqueness results.

Abstract: In this article, we introduce a $k$-th capillary area measure for capillary convex bodies in the Euclidean half-space, which serves as a boundary counterpart to the classical concept of area measure (see, e.g., \cite[Chapter 8]{Sch}). We then propose a Christoffel-Minkowski problem for capillary convex bodies, to find a capillary convex body in the Euclidean half-space with a prescribed $k$-th capillary area measure. This problem is equivalent to solving a Hessian-type equation with a Robin boundary value condition. We then establish the existence and uniqueness of a smooth solution under a natural sufficient condition.

</details>


### [35] [Unconditional uniqueness of Hardy--Hénon parabolic equations on Herz spaces](https://arxiv.org/abs/2512.16711)
*Naoya Hatano,Masahiro Ikeda*

Main category: math.AP

TL;DR: The paper proves unconditional uniqueness of solutions for the Hardy-Hénon parabolic equation in Herz spaces, relaxing previous constraints on parameters.


<details>
  <summary>Details</summary>
Motivation: To handle the power-type weight |x|^γ in the Hardy-Hénon equation more effectively using Herz spaces, which are well-suited for such weighted problems, and to improve upon previous uniqueness results by relaxing parameter restrictions.

Method: Using Herz spaces $\dot{K}^s_{q,r}({\mathbb R}^n)$ to analyze the Hardy-Hénon parabolic equation, a semilinear heat equation with weighted nonlinear term $|x|^γ|u|^{α-1}u$, and establishing unconditional uniqueness results.

Result: The authors achieve unconditional uniqueness of solutions in Herz spaces, relaxing two key constraints from previous work: the endpoint case $q=α$ and the large interpolation exponent case $r\ge q$.

Conclusion: Herz spaces provide an effective framework for handling power-type weights in the Hardy-Hénon equation, allowing for improved uniqueness results with fewer parameter restrictions compared to previous approaches.

Abstract: In this paper, we introduce the unconditional uniqueness of solutions in Herz spaces for the Hardy--Hénon parabolic equation, which is a semilinear heat equation with a power-type weight in the nonlinear term $|x|^γ|u|^{α-1}u$. It is expected that the power-type weight in the nonlinear term can be effectively handled within Herz spaces. In fact, our result in Herz spaces $\dot{K}^s_{q,r}({\mathbb R}^n)$ relaxes the endpoint case $q=α$ and the large interpolation exponent case $r\ge q$ compared to previous results.

</details>


### [36] [Stability under lamination and polycrystalline effective conductivity](https://arxiv.org/abs/2512.16787)
*Nathan Albin,Vincenzo Nesi,Mariapia Palombaro*

Main category: math.AP

TL;DR: Proves stability under lamination for a set of 3×3 symmetric matrices representing polycrystal conductivities, contributing to the best known inner bound on G-closure.


<details>
  <summary>Details</summary>
Motivation: To advance understanding of effective conductivity in three-dimensional polycrystals by establishing stability properties of previously constructed matrix sets, which helps characterize the G-closure (set of all possible effective conductivities).

Method: Mathematical proof demonstrating stability under lamination operations for a specific set of real, symmetric 3×3 matrices that represent effective conductivities of polycrystals, building on constructions from a companion paper.

Result: Successfully proves the stability under lamination of the matrix set, which when combined with previous constructions provides the best known inner bound on the G-closure of three-dimensional polycrystals.

Conclusion: The stability result significantly advances the characterization of possible effective conductivities in 3D polycrystals, providing the strongest inner approximation to the G-closure known to date.

Abstract: We prove the stability under lamination of a set of real, symmetric 3$\times$3 matrices that can be viewed as a subset of the effective conductivities of a polycrystal. Constructed in a companion paper, such set in combination with several previous constructions provides the best inner bound known so far on the $G$-closure of a three dimensional polycrystal.

</details>


### [37] [On Some Transformations Associated to a Certain Cone](https://arxiv.org/abs/2512.16840)
*Vladimir Vasilyev,Denis Tokarev*

Main category: math.AP

TL;DR: Study of elliptic pseudo-differential equations in 4-faced cones with Bochner kernel evaluation and boundary value problems with integral conditions.


<details>
  <summary>Details</summary>
Motivation: To analyze elliptic pseudo-differential equations in complex geometric settings (4-faced cones) and establish solvability results for boundary value problems with additional integral conditions.

Method: Work in Sobolev-Slobodetskii spaces, evaluate Bochner kernel for 4-faced cones, derive explicit solution formulas under symbol restrictions, and analyze boundary value problems with integral conditions.

Result: Obtained explicit formula for unique solution to the elliptic pseudo-differential equation, proved unique solvability for boundary value problem with additional integral condition.

Conclusion: Successfully established solvability theory for elliptic pseudo-differential equations in 4-faced cones with boundary conditions including integral constraints.

Abstract: A model elliptic pseudo-differential equation in $4$-faced cone is studied in Sobolev--Slobodetskii space. The Bochner kernel for such a cone is evaluated and explicit formula for unique solution to the considered equation is presented under certain restrictions on the symbol. Boundary value problem with additional integral condition is considered and unique solvability to the boundary value problem is proved.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [38] [Sparse Operator-Adapted Wavelet Decomposition Using Polygonal Elements for Multiscale FEM Problems](https://arxiv.org/abs/2512.16004)
*Furkan Şık,F. L. Teixeira,B. Shanker*

Main category: physics.comp-ph

TL;DR: A sparse multiscale wavelet-based FEM on polygonal mesh hierarchies with adaptive coarsening for memory efficiency and near-linear computational complexity.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient finite element method that can handle complex domains with varying solution gradients while maintaining computational efficiency through adaptive mesh refinement and hierarchical decomposition.

Method: Uses operator-adapted wavelet decomposition on unstructured polygonal mesh hierarchies obtained via geometric coarsening. The method decouples resolution levels, allowing independent solving at each scale. Triangular elements at finest level are coarsened to convex polygons, with adaptive refinement in high-gradient regions.

Result: The algorithm achieves nearly linear computational complexity through hierarchical sparse linear-algebra operations, with memory efficiency gained by using larger polygonal elements in smooth regions and smaller elements in high-gradient regions.

Conclusion: The proposed method provides an efficient, adaptive FEM framework that combines multiscale wavelet decomposition with polygonal mesh hierarchies for improved computational performance and memory efficiency in solving PDEs with varying solution characteristics.

Abstract: We develop a sparse multiscale operator-adapted wavelet decomposition-based finite element method (FEM) on unstructured polygonal mesh hierarchies obtained via a coarsening procedure. Our approach decouples different resolution levels, allowing each scale to be solved independently and added to the entire solution without the need to recompute coarser levels. At the finest level, the meshes consist of triangular elements which are geometrically coarsened at each step to form convex polygonal elements. Smooth field regions of the domain are solved with fewer, larger, polygonal elements, whereas high-gradient regions are represented by smaller elements, thereby improving memory efficiency through adaptivity. The proposed algorithm computes solutions via sequences of hierarchical sparse linear-algebra operations with nearly linear computational complexity.

</details>


### [39] [ClusTEK: A grid clustering algorithm augmented with diffusion imputation and origin-constrained connected-component analysis: Application to polymer crystallization](https://arxiv.org/abs/2512.16110)
*Elyar Tourani,Brian J. Edwards,Bamin Khomami*

Main category: physics.comp-ph

TL;DR: Grid clustering framework with Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) for accurate cluster topology reconstruction with O(n log n) scaling.


<details>
  <summary>Details</summary>
Motivation: Grid clustering algorithms are efficient but suffer from parameter sensitivity, loss of structural detail at coarse resolutions, and misclassification of edge/bridge cells at fine resolutions. Existing solutions (adaptive grids, parameter tuning, hybrid methods) offer limited robustness.

Method: 1) Automated preprocessing for data-driven cell size and density threshold estimation; 2) Laplacian-kernel diffusion imputation to mitigate sparsity and reconstruct missing edge cells without over-smoothing; 3) Origin-constrained connected-component analysis (OC-CCA) to constrain component growth to physically consistent origins, reducing false merges; 4) Fixed-resolution grid with spatial indexing for O(n log n) scaling.

Result: Method correctly manages edges, preserves cluster topology, avoids spurious connections. On polymer systems (9k, 180k, 989k atoms), reproduces atomic-level accuracy, captures physically meaningful morphologies, and delivers accelerated computation.

Conclusion: The proposed grid clustering framework with diffusion imputation and OC-CCA provides robust, accurate cluster topology reconstruction with computational efficiency, addressing key limitations of traditional grid clustering methods.

Abstract: Grid clustering algorithms are valued for their efficiency in large-scale data analysis but face persistent limitations: parameter sensitivity, loss of structural detail at coarse resolutions, and misclassifications of edge or bridge cells at fine resolutions. Previous studies have addressed these challenges through adaptive grids, parameter tuning, or hybrid integration with other clustering methods, each of which offers limited robustness. This paper introduces a grid clustering framework that integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid to reconstruct the cluster topology with high accuracy and computational efficiency. During grid construction, an automated preprocessing stage provides data-driven estimates of cell size and density thresholds. The diffusion step then mitigates sparsity and reconstructs missing edge cells without over-smoothing physical gradients, while OC-CCA constrains component growth to physically consistent origins, reducing false merges across narrow gaps. Operating on a fixed-resolution grid with spatial indexing ensures the scaling of O(nlog n). Experiments on synthetic benchmarks and polymer simulation datasets demonstrate that the method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems across scales (9k, 180k, and 989k atoms) shows that optimal preprocessing, combined with diffusion-based clustering, reproduces atomic-level accuracy and captures physically meaningful morphologies while delivering accelerated computation.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [40] [Tensor network approaches for plasma dynamics](https://arxiv.org/abs/2512.15924)
*Ryan J. J. Connor,Preetma Soin,Callum W. Duncan,Andrew J. Daley*

Main category: physics.plasm-ph

TL;DR: Tensor networks show promise for efficiently simulating plasma dynamics in Vlasov-Maxwell and Magnetohydrodynamics systems, with Matrix Product States working well for low-dimensional problems but requiring alternative geometries for high-dimensional cases or strong magnetic fields.


<details>
  <summary>Details</summary>
Motivation: Plasma dynamics are governed by nonlinear differential equations that are challenging to solve directly for large 2D/3D problems, creating a need for more efficient simulation methods.

Method: Applied tensor networks (specifically Matrix Product States) to the Vlasov-Maxwell system, investigated different parameter regimes, and extended the approach to Magnetohydrodynamics using Matrix Product State encoding.

Result: Matrix Product States perform sufficiently well for low-dimensional plasma problems, but regimes with strong permanent magnetic fields or high-dimensional problems may require alternative tensor network geometries. Results were validated against state-of-the-art Particle-In-Cell codes for industrially relevant test cases.

Conclusion: Tensor networks offer a promising approach for efficient plasma simulations, with Matrix Product States being effective for simpler cases but requiring more sophisticated tensor network geometries for complex plasma regimes.

Abstract: The dynamics of plasmas are governed by a set of non-linear differential equations which remain challenging to solve directly for large 2D and 3D problems. Here we investigate how tensor networks could be applied to plasmas described by the Vlasov-Maxwell system of equations and investigate parameter regimes which show promise for efficient simulations. We show for low-dimensional problems that the simplest form of tensor networks known as a Matrix Product State performs sufficiently well, however in regimes with a strong permanent magnetic field or high-dimensional problems one may need to consider alternative tensor network geometries. We conclude the study of the Vlasov-Maxwell system with the application of tensor networks to an industrially relevant test case and validate our results against state of the art plasma solvers based on Particle-In-Cell codes. We also extend the application of tensor networks to the alternative plasma description of Magnetohydrodynamics and outline how this can be encoded using Matrix Product States.

</details>


### [41] [Toward the Origins of Binding Energy Shifts and Satellites Formation During Plasma-XPS Measurements](https://arxiv.org/abs/2512.16196)
*J. Trey Diulus,Ashley R. Head,Jorge Anibal Boscoboinik,Carles Corbella Roca,Alexander Tselev,Andrei Kolmakov*

Main category: physics.plasm-ph

TL;DR: Plasma XPS enables real-time chemical analysis under semiconductor processing conditions, revealing transient surface species and complex charging effects that cause binding energy shifts up to 50 eV and satellite peak formation.


<details>
  <summary>Details</summary>
Motivation: To understand the origins of binding energy shifts and satellite peaks in plasma XPS measurements, which occur during real-time chemical analysis under conditions relevant to semiconductor processing and plasma technologies.

Method: Used a standard laboratory ambient pressure XPS apparatus coupled with an AC-driven capacitively coupled plasma source to study conductive, dielectric, and gas phase systems under plasma exposure.

Result: Detected metastable surface species like transient Au oxides; observed pressure- and plasma-type dependent BE shifts up to 50 eV in dielectrics due to charging; found spectral broadening and satellite peaks in gas phase species from oscillating plasma potentials.

Conclusion: Plasma XPS is a critical metrological tool for probing transient surface chemistry, revealing complex interplay between plasma parameters, surface charging, and local electric fields that shape XPS spectra, with implications for semiconductor processing and plasma diagnostics.

Abstract: In plasma X ray photoelectron spectroscopy emerges as a powerful platform for real time, in situ chemical analysis under conditions relevant to semiconductor processing and other plasma enabled technologies. This study investigates the origins of binding energy shifts and satellite peaks formation observed during plasma XPS measurements across conductive, dielectric, and gas phase systems. Using a standard laboratory based ambient pressure XPS apparatus coupled with an alternating current driven capacitively coupled plasma source, we show that metastable surface species, such as transient Au oxides, can be detected during plasma exposure, revealing chemical states hardly accessible using conventional ultrahigh vacuum XPS. In dielectric samples, we observe pressure- and plasma type dependent BE shifts up to 50 eV, attributed to X ray induced and plasma mediated surface charging. These shifts are mitigated at higher pressures plasmas or in electronegative plasmas, the latter due to enhanced charge compensation mechanisms involving slow negative ions. For gas phase species, AC plasma excitation leads to spectral broadening and the emergence of satellite peaks with a few eV energy separations, linked to oscillating local plasma potentials in the probing volume. These findings highlight the important and complex interplay of plasma parameters, surface charging, and local electric fields in shaping XPS spectra. Overall, plasma XPS emerges as a critical metrological tool for probing transient surface chemistry, with implications for semiconductor processing, material synthesis, and plasma diagnostics.

</details>


### [42] [SCOPE: Simple Coil Optimization for Plasma and Engineering](https://arxiv.org/abs/2512.16546)
*Nathan Welch,Chris Marsden*

Main category: physics.plasm-ph

TL;DR: A multi-scenario optimization method for superconducting tokamak coil design using simulated annealing for coil geometry and constrained optimization for currents, enabling efficient evaluation of millions of designs.


<details>
  <summary>Details</summary>
Motivation: Tokamak coil design is highly complex with multiple engineering constraints (structural, power electronics, HTS limits), must handle multiple plasma scenarios (inception to ramp-down), optimize divertor separatrices, and accommodate physical space limits for support structures and maintenance.

Method: Combined simulated annealing for optimal coil sizes and positions with constrained quadratic/quartic optimization for coil currents; designed to optimize for multiple scenarios simultaneously to avoid over-optimization of single design points; efficient implementation enables millions of evaluations in hours.

Result: The method enables efficient optimization of superconducting coils for tokamak fusion devices, handling multiple plasma scenarios and engineering constraints while being computationally practical for iterative design workflows.

Conclusion: This optimization approach provides a practical solution for the complex, multi-constraint problem of tokamak coil design, integrating into larger iterative workflows that allow detailed design feedback into the optimization process.

Abstract: Designing superconducting coils for a tokamak fusion device is a highly coupled, non-linear design problem. The coils have many disparate engineering requirements from structural to power electronics, as well strict limits placed on the system by the high temperature superconducting (HTS) cables. Simultaneously, the coils must be able to contain multiple plasma scenarios from inception, through ramp up, to flat top, and ramp down, all whilst applying a large, controlled, inductive voltage to drive current. In addition, we wish to optimize divertor separatrices to increase the likelihood of designing a suitable divertor strikepoint. Lastly, the physical limits of the entire tokamak must be taken into account and space reserved for support structures, access for maintenance schemes, and installation limits. The method outlined here uses a combined simulated annealing method to find optimal coil sizes and positions with a constrained quadratic or quartic optimization for the coil currents. The method is designed to optimize coils for multiple scenarios simultaneously, including ramp-ups, to avoid over optimization of a single design point. A key enabler is the efficient implementation that allows millions of evaluations to be performed in a few hours with modest computational power. This optimization method is part of a larger, iterative workflow which enables further, detailed design work to feedback on the optimization.

</details>


### [43] [Disruption Modelling for Engineering and Physics Design of Tokamak Energy ST-E1 Fusion Power Plant](https://arxiv.org/abs/2512.16604)
*M. Scarpari,X. Zhang,K. Borowiec,P. F. Buxton,G. Calabro,S. Carusotti,A. Ciula,V. Godhani,J. D. Lore,E. N. J. Maartensson,S. A. M. McNamara,J. H. Nichols,M. Notazio,M. Robinson,M. Romanelli,J. Willis,ST-E1 Team*

Main category: physics.plasm-ph

TL;DR: Comprehensive disruption modeling approach for ST-E1 fusion power plant design, integrating physics and engineering to assess electromagnetic and thermal impacts across different plasma configurations.


<details>
  <summary>Details</summary>
Motivation: Plasma disruptions pose critical challenges for tokamak operations, compromising machine integrity and availability. While future fusion devices need strategies to minimize disruptions, complete avoidance is impossible, making assessment of unmitigated disruption consequences essential for next-generation fusion power plant design and qualification.

Method: Integrated physics and engineering approach: 1) Engineering analysis of ST-E1 layout options to investigate electromagnetic response of key components under disruption-induced loads; 2) Physics analysis exploring broad set of disruption scenarios scanning operational parameters, plasma-material interactions, and thermal loads; 3) Examination of disruption behavior variations across different reference equilibria from Double Null to Single Null configurations.

Result: Significant contrasts in plasma dynamics and electromagnetic behavior between configurations, highlighting importance of disruption modeling for design choices. The analyses proved instrumental in shaping ST-E1 development and offered critical insights for risk mitigation and optimization of future fusion reactor designs.

Conclusion: Disruption modeling is fundamental for fusion power plant design, providing essential guidance for component design, structural integrity assessment, and risk mitigation strategies. The integrated approach successfully supported ST-E1 pre-conceptual design and offers valuable methodology for future fusion reactor development.

Abstract: Plasma disruptions represent a critical challenge for high-performance tokamak operations, as they can compromise machine integrity and reduce operational availability. Although future fusion devices essentially need to incorporate strategies to minimise disruption occurrence, complete avoidance remains unattainable. Consequently, assessing and characterising unmitigated disruption consequences is fundamental for the design and qualification of next-generation fusion power plants. This work supports the pre-conceptual design of ST-E1, a low aspect-ratio Tokamak Fusion Power Plant developed by Tokamak Energy Ltd., by presenting a comprehensive disruption modelling approach applied across different design stages. The methodology integrates both physics and engineering considerations to evaluate the impact of disruptions on machine performance and structural integrity. From an engineering perspective, several ST-E1 layout options were analysed to investigate the electromagnetic response of key components under disruption-induced loads, enabling comparison between alternative design solutions. On the physics side, a broad set of disruption scenarios was explored, scanning operational space parameters, plasma-material interactions, and associated thermal loads. Furthermore, the study examined variations in disruption behaviour arising from different reference equilibria, focusing on a range starting from Double Null to Single Null configurations, reflecting the increasing up-down asymmetry consequences. The results reveal significant contrasts in plasma dynamics and structures electromagnetic behaviour between configurations, highlighting the importance of disruption modelling in guiding design choices. These analyses have proven instrumental in shaping ST-E1 development, offering critical insights for mitigating risks and optimising future fusion reactor designs.

</details>


### [44] [Photon Accelerator in Magnetized Plasma](https://arxiv.org/abs/2512.16630)
*Sergei Bulanov,Stepan Bulanov,Timur Esirkepov,Gianluca Gregori,Gabriele Grittani,Brandon Russell,Alec Thomas,Petr Valenta*

Main category: physics.plasm-ph

TL;DR: Magnetic fields enhance photon acceleration in plasmas by altering electromagnetic wave properties and interactions with relativistic plasma waves, leading to increased frequency gain and higher efficiency.


<details>
  <summary>Details</summary>
Motivation: To understand how magnetic fields affect electromagnetic wave propagation in plasmas and their interaction with relativistic plasma waves, particularly for improving photon acceleration efficiency in both laboratory and space plasma environments.

Method: The paper analyzes the theoretical relationship between magnetic fields and electromagnetic wave properties in plasmas, examining how magnetic fields alter the frequency-wave number relationship and modify interactions between electromagnetic waves and relativistic plasma waves.

Result: Magnetic fields cause both quantitative and qualitative changes in photon acceleration properties, amplifying the increase in electromagnetic wave frequency and potentially leading to higher efficiency in photon acceleration processes.

Conclusion: Magnetic fields play a crucial role in enhancing photon acceleration in plasmas by modifying wave properties and interactions, offering potential for improved efficiency in both laboratory experiments and space plasma phenomena.

Abstract: Strong magnetic fields and plasmas are intrinsically linked in both terrestrial laboratory experiments and in space phenomena. One of the most profound consequences of that is the change in relationship between the frequency and the wave number of electromagnetic waves propagating in plasma in the presence of such magnetic fields when compared to the case without these fields. Furthermore, magnetic fields alter electromagnetic wave interaction with relativistic plasma waves, resulting in different outcomes for particle and radiation generation. For a relativistic plasma wave-based photon acceleration this leads to an increased frequency gain, and, thus, potentially to higher efficiency. The influence of a magnetic field leads to quantitative and qualitative change in the properties of photon acceleration, amplifying the increase in the electromagnetic wave frequency.

</details>


### [45] [CARONTE: a Physics-Informed Extreme Learning Machine-Based Algorithm for Plasma Boundary Reconstruction in Magnetically Confined Fusion Devices](https://arxiv.org/abs/2512.16689)
*Federico Fiorenza,Sara Dubbioso,Gianmaria De Tommasi,Alfredo Pironti*

Main category: physics.plasm-ph

TL;DR: A physics-informed neural network using Extreme Learning Machine for real-time plasma boundary reconstruction in tokamaks, outperforming traditional methods in accuracy, generalization, and noise robustness.


<details>
  <summary>Details</summary>
Motivation: Need for real-time, accurate plasma boundary reconstruction in tokamak devices that can adapt to evolving plasma equilibria without extensive retuning or massive training datasets.

Method: Uses a single Extreme Learning Machine network to solve the homogeneous Grad-Shafranov equation, enabling real-time training with magnetic sensor data to dynamically adapt to plasma equilibrium changes.

Result: Accurate reconstruction for complex configurations, outperforms JET's established algorithm, better generalizes poloidal flux function without retuning across different equilibria, and shows greater robustness to magnetic measurement noise.

Conclusion: The proposed neural network approach combines neural network generalization power with physics-informed constraints, enabling straightforward implementation on existing devices without extensive training data requirements.

Abstract: In this work, we propose a novel physics informed neural network based algorithm for real time plasma boundary reconstruction in tokamak devices. The approach is based on a single Extreme Learning Machine network used to solve the homogeneous Grad Shafranov equation, which is required to identify the plasma boundary. This architecture enables the real time training of the network parameters using the available magnetic sensor data and, consequently, dynamically adapting the network output to the evolving plasma equilibrium. We demonstrate that, the network performs accurate plasma boundary reconstruction for complex configurations, outperforming well established methods, such as the algorithm used for decades at the Joint European Torus, the world's largest tokamak, until it ceased operation in 2023. Indeed, compared to the latter, the proposed solution better generalizes the poloidal flux function, without requiring algorithm retuning across different plasma equilibria. The proposed neural network reconstructor demonstrates also greater robustness with respect to noise on the magnetic measurements. Moreover, this method takes advantage of the generalization power of neural networks but without the need for extensive, time consuming training based on a huge amount of experimental data, making its implementation on existing devices straightforward.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [46] [Manifold submetries from compact homogeneous spaces](https://arxiv.org/abs/2512.16606)
*Samuel Lin,Ricardo A. E. Mendes,Marco Radeschi*

Main category: math.DG

TL;DR: Singular Riemannian foliations on compact normal homogeneous spaces are algebraic, with correspondence between Laplace-Beltrami invariant algebras and manifold submetries.


<details>
  <summary>Details</summary>
Motivation: To establish the algebraic nature of singular Riemannian foliations/manifold submetries on compact normal homogeneous spaces and reveal connections between algebraic structures and geometric foliations.

Method: Study manifold submetries on compact normal homogeneous spaces, prove the mean curvature vector field of fibers is basic (related to base vector field), establish correspondence between Laplace-Beltrami invariant algebras and manifold submetries.

Result: Singular Riemannian foliations on compact normal homogeneous spaces have algebraic nature; one-to-one correspondence exists between algebras of algebraic functions preserved by Laplace-Beltrami operator and manifold submetries.

Conclusion: Manifold submetries on compact normal homogeneous spaces are algebraic structures, with deep connections between geometric foliations and algebraic function algebras invariant under the Laplace-Beltrami operator.

Abstract: We show that singular Riemannian foliations, or, more generally, manifold submetries, defined on a compact normal homogeneous space, have algebraic nature. Moreover, in this case there exists a one-to-one correspondence between algebras of algebraic functions preserved by the Laplace--Beltrami operator, and manifold submetries.
  A key intermediate result is that, for any manifold submetry on a compact normal homogeneous space, the vector field given by the mean curvature of the fibers is basic, in the sense that it is related to a vector field in the base.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [47] [Self-confinement of relativistic pair beams in magnetized interstellar plasmas: the case of pulsar X-ray filaments](https://arxiv.org/abs/2512.15847)
*Luca Orusa,Lorenzo Sironi*

Main category: astro-ph.HE

TL;DR: A charge-neutral electron-positron beam from pulsar wind nebulae can spontaneously generate net current via Weibel instability, driving magnetic turbulence that explains suppressed cosmic-ray diffusion and X-ray filaments.


<details>
  <summary>Details</summary>
Motivation: Observations of filamentary X-ray structures near pulsar wind nebulae and slow-diffusion regions around pulsars challenge standard cosmic-ray transport models, requiring explanation for suppressed diffusion coefficients.

Method: Used fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratios to study charge-neutral pair beams propagating through electron-proton plasma.

Result: Beam electrons become focused into self-generated magnetic filaments via Weibel instability, while beam positrons remain unconfined, creating net positron current that drives non-resonant streaming instability and amplifies magnetic fields.

Conclusion: This mechanism explains charge asymmetry generation in initially neutral pair beams and magnetic fluctuation growth, providing pathway for X-ray filament formation and particle self-confinement in TeV halos around pulsar wind nebulae.

Abstract: The observation of filamentary X-ray structures near bow-shock pulsar wind nebulae (PWNe) -- such as the Guitar, Lighthouse, and PSR J2030$+$4415 nebulae -- and of slow-diffusion regions around pulsars like Geminga, Monogem, and PSR J0622$+$3749, challenges the standard picture of cosmic-ray transport in the interstellar medium, implying a diffusion coefficient two orders of magnitude smaller than the Galactic average. The suppressed diffusion can be attributed to self-generated magnetic turbulence, driven -- via the non-resonant streaming instability -- by electron--positron pairs escaping the PWNe. This instability requires a net current, yet the beam of escaping pairs is expected to be charge-neutral. We show that a charge-neutral pair beam propagating through an electron--proton plasma can spontaneously generate a net current. Using fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratio, we find that beam electrons get focused into self-generated magnetic filaments produced by the nonlinear evolution of the Weibel instability, while beam positrons remain unconfined. The resulting net (positron) current drives the non-resonant streaming instability, further amplifying the magnetic field. This mechanism provides a pathway for the onset of charge asymmetries in initially charge-neutral pair beams and for the growth of magnetic fluctuations that efficiently scatter the beam particles, with implications for the formation of X-ray filaments and, more broadly, for particle self-confinement in TeV halos around PWNe.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [48] [Information theory and discriminative sampling for model discovery](https://arxiv.org/abs/2512.16000)
*Yuxuan Bao,J. Nathan Kutz*

Main category: cs.IT

TL;DR: The paper proposes using Fisher Information Matrix within SINDy framework to analyze chaotic/non-chaotic systems, visualize information patterns, and improve data efficiency through principled sampling strategies guided by information metrics.


<details>
  <summary>Details</summary>
Motivation: Fisher information and Shannon entropy provide complementary perspectives for analyzing dynamical systems, but there's a need to integrate these information-theoretic tools with data-driven model discovery frameworks like SINDy to improve sampling efficiency and reduce data requirements.

Method: Leverage Fisher Information Matrix (FIM) within the SINDy framework to visualize information patterns in chaotic and non-chaotic systems, analyze both single trajectories and multiple initial conditions, and use spectral analysis of FIM to elucidate benefits of statistical bagging.

Result: Demonstrated how information-based analysis improves sampling efficiency and enhances model performance by prioritizing more informative data, and showed how Fisher information and entropy metrics promote data efficiency in three scenarios: single trajectory, tunable control parameter, and freely initializable multiple trajectories.

Conclusion: Principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements in data-driven model discovery, making information-based analysis valuable for dynamical system characterization.

Abstract: Fisher information and Shannon entropy are fundamental tools for understanding and analyzing dynamical systems from complementary perspectives. They can characterize unknown parameters by quantifying the information contained in variables, or measure how different initial trajectories or temporal segments of a trajectory contribute to learning or inferring system dynamics. In this work, we leverage the Fisher Information Matrix (FIM) within the data-driven framework of {\em sparse identification of nonlinear dynamics} (SINDy). We visualize information patterns in chaotic and non-chaotic systems for both single trajectories and multiple initial conditions, demonstrating how information-based analysis can improve sampling efficiency and enhance model performance by prioritizing more informative data. The benefits of statistical bagging are further elucidated through spectral analysis of the FIM. We also illustrate how Fisher information and entropy metrics can promote data efficiency in three scenarios: when only a single trajectory is available, when a tunable control parameter exists, and when multiple trajectories can be freely initialized. As data-driven model discovery continues to gain prominence, principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [49] [Riemannian Stochastic Interpolants for Amorphous Particle Systems](https://arxiv.org/abs/2512.16607)
*Louis Grenioux,Leonardo Galliano,Ludovic Berthier,Giulio Biroli,Marylou Gabrié*

Main category: stat.ML

TL;DR: Equivariant Riemannian stochastic interpolation framework for generating equilibrium configurations of amorphous materials (glasses) with proper geometric and symmetry constraints.


<details>
  <summary>Details</summary>
Motivation: Sampling equilibrium configurations of glass-forming materials is notoriously slow and difficult. While generative models have shown promise for biomolecules and crystalline materials, amorphous materials (disordered particle systems lacking atomic periodicity) present unique challenges that require specialized generative approaches.

Method: Leverages an equivariant Riemannian stochastic interpolation framework combining Riemannian stochastic interpolant and equivariant flow matching. The method incorporates periodic boundary conditions and symmetries of multi-component particle systems, using an equivariant graph neural network adapted to operate directly on the torus.

Result: Numerical experiments on model amorphous systems demonstrate that enforcing geometric and symmetry constraints significantly improves generative performance compared to approaches without these constraints.

Conclusion: The proposed framework successfully addresses the challenge of generating equilibrium configurations for amorphous materials by properly incorporating domain-specific geometric and symmetry constraints, overcoming the slow sampling problem inherent to glass-forming systems.

Abstract: Modern generative models hold great promise for accelerating diverse tasks involving the simulation of physical systems, but they must be adapted to the specific constraints of each domain. Significant progress has been made for biomolecules and crystalline materials. Here, we address amorphous materials (glasses), which are disordered particle systems lacking atomic periodicity. Sampling equilibrium configurations of glass-forming materials is a notoriously slow and difficult task. This obstacle could be overcome by developing a generative framework capable of producing equilibrium configurations with well-defined likelihoods. In this work, we address this challenge by leveraging an equivariant Riemannian stochastic interpolation framework which combines Riemannian stochastic interpolant and equivariant flow matching. Our method rigorously incorporates periodic boundary conditions and the symmetries of multi-component particle systems, adapting an equivariant graph neural network to operate directly on the torus. Our numerical experiments on model amorphous systems demonstrate that enforcing geometric and symmetry constraints significantly improves generative performance.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [50] [An evacuation simulator for pedestrian dynamics based on the Social Force Model](https://arxiv.org/abs/2512.16887)
*Julián López,Virginia Mazzone,M. Leticia Rubio Puzzo,Juan Cruz Moreno*

Main category: physics.soc-ph

TL;DR: SiCoBioNa is an open-source evacuation simulator based on the Social Force Model, featuring an intuitive GUI for configuring pedestrian scenarios without requiring numerical modeling expertise, generating both quantitative data and visual outputs for evacuation analysis.


<details>
  <summary>Details</summary>
Motivation: Evacuation from enclosed spaces is a critical safety engineering problem that requires realistic simulation tools to analyze collective pedestrian dynamics, individual interactions, and spatial constraints during evacuation processes.

Method: Developed SiCoBioNa, an open-source evacuation simulator based on the Social Force Model framework, which represents goal-oriented motion, interpersonal interactions, and obstacle interactions. The software provides an intuitive graphical interface for configuring pedestrian properties, spatial geometries, and initial conditions without requiring numerical modeling expertise.

Result: The simulator generates both quantitative data and visual outputs, facilitating analysis of evacuation dynamics and evaluation of different spatial configurations. Its modular and extensible design makes it a reproducible research tool for pedestrian dynamics studies and practical evacuation planning support.

Conclusion: SiCoBioNa serves as an accessible, open-source tool for evacuation simulation that bridges the gap between complex numerical modeling and practical safety engineering applications, supporting both research and real-world evacuation planning through its user-friendly interface and comprehensive output capabilities.

Abstract: The evacuation of pedestrians from enclosed spaces represents a key problem in safety engineering and infrastructure design. Analyzing the collective dynamics that emerge during evacuation processes requires simulation tools capable of capturing individual interactions and spatial constraints realistically.
  In this work, we present \textit{SiCoBioNa}, an open-source evacuation simulator based on the Social Force Model (SFM). The software provides an intuitive graphical interface that allows users to configure pedestrian properties, spatial geometries, and initial conditions without requiring prior expertise in numerical modeling techniques. The SFM framework enables the representation of goal-oriented motion, interpersonal interactions, and interactions with fixed obstacles.
  The simulator generates both quantitative data and visual outputs, facilitating the analysis of evacuation dynamics and the evaluation of different spatial configurations. Due to its modular and extensible design, \textit{SiCoBioNa} serves as a reproducible research tool for studies on pedestrian dynamics providing practical support for evacuation planning.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [51] [Unveiling the amorphous ice layer during premelting using AFM integrating machine learning](https://arxiv.org/abs/2512.15772)
*Binze Tang,Chon-Hei Lo,Tiancheng Liang,Jiani Hong,Mian Qin,Yizhi Song,Duanyun Cao,Ying Jiang,Limei Xu*

Main category: cond-mat.mtrl-sci

TL;DR: Researchers discovered a novel amorphous ice layer preceding the quasi-liquid layer during ice premelting using a machine learning framework that integrates AFM with molecular dynamics simulations.


<details>
  <summary>Details</summary>
Motivation: Premelting is crucial across multiple scientific disciplines but remains poorly understood at the atomic level due to limitations in surface characterization techniques, particularly AFM's depth and signal constraints.

Method: Developed a machine learning framework that integrates atomic force microscopy (AFM) with molecular dynamics simulations to overcome AFM limitations, enabling 3D surface structure reconstruction from AFM images and exploration of premelting interfaces across wide temperature ranges.

Result: Identified a novel amorphous ice layer (AIL) present between 121-180K that displays disordered two-dimensional hydrogen-bond network with solid-like dynamics, refining the ice premelting phase diagram.

Conclusion: The discovery provides new insights into surface growth dynamics, dissolution, and interfacial chemical reactivity, while establishing a novel framework for AFM-based 3D structural discovery that enables unprecedented probing of complex disordered interfaces.

Abstract: Premelting plays a key role across physics, chemistry, materials and biology sciences but remains poorly understood at the atomic level due to surface characterization limitations. We report the discovery of a novel amorphous ice layer (AIL) preceding the quasi-liquid layer (QLL) during ice premelting, enabled by a machine learning framework integrating atomic force microscopy (AFM) with molecular dynamics simulations. This approach overcomes AFM's depth and signal limitations, allowing for three-dimensional surface structure reconstruction from AFM images. It further enables structural exploration of premelting interfaces across a wide temperature range that are experimentally inaccessible. We identify the AIL, present between 121-180K, displaying disordered two-dimensional hydrogen-bond network with solid-like dynamics. Our findings refine the ice premelting phase diagram and offering new insights into the surface growth dynamic, dissolution and interfacial chemical reactivity. Methodologically, this work establishes a novel framework for AFM-based 3D structural discovery, marking a significant leap in our ability to probe complex disordered interfaces with unprecedented precision and paving the way for future disciplinary research, including surface reconstruction, crystallization, ion solvation, and biomolecular recognition.

</details>


### [52] [Atomic forces from correlation energy functionals based on the adiabatic-connection fluctuation-dissipation theorem](https://arxiv.org/abs/2512.16460)
*Damian Contant,Maria Hellgren*

Main category: cond-mat.mtrl-sci

TL;DR: Implementation of analytical atomic forces in RPA for plane waves/pseudopotentials, with self-consistent and non-self-consistent approaches showing excellent numerical quality and systematic improvement over PBE.


<details>
  <summary>Details</summary>
Motivation: To extend correlation energy functionals based on adiabatic-connection fluctuation-dissipation theorem by implementing analytical atomic forces within RPA for more accurate geometry and vibrational frequency calculations.

Method: Implemented analytical RPA forces using plane waves and pseudopotentials, calculated self-consistent forces via optimized effective potential method and Hellmann-Feynman theorem, and non-self-consistent forces from PBE starting point using density functional perturbation theory.

Result: Forces show excellent numerical quality; self-consistency has negligible impact on geometries/vibrational frequencies for most systems; RPA systematically improves over PBE; RPAx achieves accuracy comparable to advanced wavefunction methods; provided accurate theoretical references for phonons of diamond, silicon, and germanium.

Conclusion: RPA and RPAx forces are reliable and accurate for geometry optimization and vibrational analysis, offering systematic improvements over standard DFT approximations with computational efficiency.

Abstract: We extend the capabilities of correlation energy functionals based on the adiabatic-connection fluctuation-dissipation theorem by implementing the analytical atomic forces within the random phase approximation (RPA), in the context of plane waves and pseudopotentials. Forces are calculated at self-consistency through the optimized effective potential method and the Hellmann-Feynman theorem. In addition, non-self-consistent RPA forces, starting from the PBE generalized gradient approximation, are evaluated using density functional perturbation theory. In both cases, we find forces of excellent numerical quality. Furthermore, for most molecules and solids studied, self-consistency is found to have a negligible impact on the computed geometries and vibrational frequencies. The RPA is shown to systematically improve over PBE and, by including the exact-exchange kernel within RPA + exchange (RPAx), through finite-difference total energy calculations, we obtain an accuracy comparable to advanced wavefunction methods. Finally, we estimate the anharmonic shift and provide accurate theoretical references based on RPA and RPAx for the zone-center optical phonon of diamond, silicon, and germanium.

</details>


### [53] [Thermodynamical study of N$_2$ clathrate hydrate from DFT calculations](https://arxiv.org/abs/2512.16819)
*L. Martin-Gondre,V. Meko Fotso,C. Métais,A. Patt,J. Ollivier,A. Desmedt*

Main category: cond-mat.mtrl-sci

TL;DR: DFT study shows N₂ clathrate hydrate stability depends on cage occupancy and pressure, with sI stable at lower pressures and sII with double occupancy stable at higher pressures.


<details>
  <summary>Details</summary>
Motivation: To understand the thermodynamic stability of N₂ clathrate hydrates in different crystal structures (sI and sII) under varying pressure conditions, providing a first-principles framework for predicting their behavior.

Method: Used density functional theory (DFT) with various exchange-correlation functionals to investigate N₂ clathrate hydrates at T = 0 K, explicitly accounting for composition (cage occupancies) and pressure effects. The revPBE-D3(0) functional was identified as best reproducing experimental lattice parameters and bulk moduli.

Result: revPBE-D3(0) best matches experimental data. Large cage double occupancy strongly affects sI stability. sI with single occupancy remains thermodynamically stable up to ~0.8 GPa alongside sII with single occupancy. At higher pressures, sII with double occupancy becomes stable due to its larger large-cage volume and lower framework strain.

Conclusion: The study provides a coherent first-principles thermodynamic framework for N₂ hydrate stability, establishing baseline understanding for finite-temperature extensions and showing how pressure and cage occupancy determine structural stability transitions.

Abstract: Thermodynamic stability of N$_2$ clathrate hydrates in the sI and sII structures is investigated using density functional theory with several exchange-correlation functionals, explicitly accounting for composition (cage occupancies) and pressure at T = 0 K. Among the tested functionals, revPBE-D3(0) best reproduces experimental lattice parameters and bulk moduli B$_0$ . Energetic analyses confirm the strong impact of large cage double occupancy on sI, whereas the convex-hull results show that sI with single occupancy remains thermodynamically stable up to $\sim$ 0.8 GPa alongside sII with single occupancy. Increasing pressure then stabilizes sII with double occupancy, consistent with its larger large-cage volume and lower framework strain. These results provide a coherent, first-principles thermodynamic framework for N$_2$ hydrate stability and a baseline for finite-temperature extension.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [54] [Efficient Monte-Carlo sampling of metastable systems using non-local collective variable updates](https://arxiv.org/abs/2512.16812)
*Christoph Schönle,Davide Carbone,Marylou Gabrié,Tony Lelièvre,Gabriel Stoltz*

Main category: cond-mat.stat-mech

TL;DR: Generalizes non-local proposal updates in collective-variable space for molecular simulations, extending to non-linear CVs and underdamped Langevin dynamics with proven reversibility and improved performance.


<details>
  <summary>Details</summary>
Motivation: Standard Monte-Carlo simulations suffer from metastability issues in complex molecular systems. While recent approaches use non-local proposal updates in collective-variable space, they need extension to more realistic scenarios including non-linear CVs and underdamped dynamics.

Method: Generalizes non-local proposal approaches in CV space, explicitly developing an algorithm for non-linear collective variables and underdamped Langevin dynamics. Proves reversibility of the resulting scheme and demonstrates performance through numerical examples.

Result: Substantial performance increase compared to previous methods based on overdamped Langevin dynamics. The approach enables efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables).

Conclusion: Extends applicability of generative machine-learning-based proposal samplers toward more realistic molecular systems by handling non-linear CVs and underdamped dynamics while maintaining theoretical guarantees like reversibility.

Abstract: Monte-Carlo simulations are widely used to simulate complex molecular systems, but standard approaches suffer from metastability. Lately, the use of non-local proposal updates in a collective-variable (CV) space has been proposed in several works. Here, we generalize these approaches and explicitly spell out an algorithm for non-linear CVs and underdamped Langevin dynamics. We prove reversibility of the resulting scheme and demonstrate its performance on several numerical examples, observing a substantial performance increase compared to methods based on overdamped Langevin dynamics as considered previously. Advances in generative machine-learning-based proposal samplers now enable efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables), and our results extend their applicability toward more realistic molecular systems.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [55] [On the distribution kernels of Toeplitz operators on CR manifolds](https://arxiv.org/abs/2512.16506)
*Chin-Yu Hsiao,Ood Shabtai*

Main category: math.CV

TL;DR: Analysis of Toeplitz operators on CR manifolds: diagonal values of kernel symbols and asymptotic expansions on CR orbifolds.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Toeplitz operators on complex geometric structures, specifically on compact, strictly pseudoconvex CR manifolds and more general CR orbifolds, which has applications in complex analysis, operator theory, and geometric analysis.

Method: Study distribution kernels of Toeplitz operators associated with classical pseudodifferential operators. Develop formulas for diagonal values of second coefficient in kernel symbol expansion. Establish asymptotic expansions under natural assumptions on CR orbifolds.

Result: Main result: Formula for values at diagonal of second coefficient in expansion of kernel symbol for Toeplitz operators on strictly pseudoconvex CR manifolds. Additional result: Asymptotic expansions for Toeplitz operators on positive part of compact CR orbifolds (not necessarily strictly pseudoconvex).

Conclusion: The paper provides precise analytical formulas for Toeplitz operator kernels on CR manifolds and extends asymptotic expansion techniques to more general CR orbifold settings, contributing to the spectral theory of operators on complex geometric structures.

Abstract: We study the distribution kernel of a Toeplitz operator associated with a classical pseudodifferential operator on a compact, embeddable, strictly pseudoconvex CR manifold. The main result consists of a formula for the values at the diagonal of the second coefficient in the expansion of the symbol of the kernel. We also establish asymptotic expansions for Toeplitz operators on the positive part of a compact not necessary strictly pseudoconvex CR orbifold under certain natural assumptions.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [56] [QMCkl: A Kernel Library for Quantum Monte Carlo Applications](https://arxiv.org/abs/2512.16677)
*Emiel Slootman,Vijay Gopal Chilkuri,Aurelien Delval,Max Hoffer,Tommaso Gorni,François Coppens,Joris van de Nes,Ramón L. Panadés-Barrueta,Evgeny Posenitskiy,Abdallah Ammar,Edgar Josué Landinez Borda,Kevin Camus,Oto Kohulàk,Emmanuel Giner,Pablo de Oliveira Castro,Cedric Valensi,William Jalby,Claudia Filippi,Anthony Scemama*

Main category: physics.chem-ph

TL;DR: QMCkl is a modular, portable library of high-performance kernels for Quantum Monte Carlo calculations that separates algorithmic development from hardware optimization while ensuring numerical reproducibility.


<details>
  <summary>Details</summary>
Motivation: Quantum Monte Carlo methods are highly accurate but computationally intensive, requiring efficient implementations that can work across different codes and architectures while maintaining reproducibility.

Method: Developed a modular library with C-compatible API, TREXIO standard support, and essential QMC kernels including atomic/molecular orbitals, cusp corrections, Jastrow factor, and derivatives. Combines human-readable reference implementations with performance-optimized kernels that produce identical numerical results.

Result: Enables consistent, efficient, and reproducible simulations across different QMC codes and architectures, achieving substantial speedups in energy and derivative evaluations. Also accelerates deterministic quantum chemistry workflows and visualization tools.

Conclusion: QMCkl promotes cross-code interoperability, simplifies high-performance scientific software development, and separates algorithmic concerns from hardware-specific optimization while ensuring numerical consistency.

Abstract: Quantum Monte Carlo (QMC) methods deliver highly accurate electronic structure calculations but are computationally intensive. The quantum Monte Carlo kernel library (QMCkl) provides a modular, portable collection of high-performance kernels implementing the core building blocks of QMC calculations. It offers a C-compatible API, supports the TREXIO standard for input, and covers essential QMC kernels including atomic and molecular orbitals, cusp corrections, Jastrow factor, and the necessary derivatives also to perform variational and structural optimization. QMCkl separates algorithmic development from hardware-specific tuning by combining human-readable reference implementations with performance-optimized kernels that produce identical numerical results. The library enables consistent, efficient, and reproducible simulations across different QMC codes and architectures, and achieves substantial speedups in the evaluation of the energy and its derivatives. Beyond QMC, QMCkl can accelerate deterministic quantum chemistry workflows and visualization tools, promoting cross-code interoperability and simplifying high-performance scientific software development.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [57] [Direct calculation of steady-state hydrodynamic solar wind solutions with newtonian viscosity](https://arxiv.org/abs/2512.16028)
*Roger B. Scott,Stephen J. Bradshaw,Mark G. Linton,Chris Lowder,Leonard Strachan*

Main category: astro-ph.SR

TL;DR: Viscous Navier-Stokes equations eliminate sonic point singularities in solar wind modeling, enabling efficient single-solution extrapolation from solar surface to heliosphere.


<details>
  <summary>Details</summary>
Motivation: Traditional inviscid solar wind models have singularities at sonic points that require special treatment, creating significant computational inefficiencies and limitations in modeling the full solar wind system.

Method: Include classical Newtonian viscous stress in hydrodynamic equations, cast steady-state Navier-Stokes as five coupled ODEs, add external heating and radiative losses, solve using conventional methods without special sonic point treatment.

Result: Viscous treatment eliminates sonic point singularities, enables computation of solar wind profiles from solar surface initial conditions to outer heliosphere in single solution, more realistic than analytical/empirical models with much lower computational cost.

Conclusion: Viscous Navier-Stokes approach provides efficient, accurate method for generating solar wind profiles from observational initial conditions, overcoming traditional sonic point limitations and enabling comprehensive solar wind modeling.

Abstract: Steady-state solutions to the Navier-Stokes equations are known to admit solutions that are singular at the sonic point. Consequently, inviscid solar wind models require special treatment of the solution near the sonic points, and this has proven to be a significant impediment to efficient modeling of the solar wind. In this paper we revisit the governing hydrodynamic equations for the expanding solar wind, with the inclusion of the classical (Newtonian) viscous stress , and we show how this inclusion eliminates the singularities that emerge from the inviscid equations. This result has been previously reported and used to generate solar wind profiles from initial conditions in the asymptotic limit; however, those studies did not include realistic treatments of the inner corona, and generally rejected the prospect of extrapolating solutions outward from the Sun into the heliosphere. Here, we expand this method to include external heating and optically thin radiative losses and show that solutions can be computed from initial conditions near the solar surface, thereby capturing the entire range of scales from below the transition region to the outer heliosphere in a single solution. Our approach is to cast the steady-state Navier-Stokes equations as a system of five coupled, ordinary differential equations (ODEs), which we solve using conventional methods, without any special treatment of the governing equations in the vicinity of the sonic point. The representative solutions that we present here demonstrate the utility and efficiency of this extrapolation method, which is considerably more realistic than commonly used analytical or empirical models. This method provides a direct approach to generating accurate solar wind profiles subject to observationally motivated initial conditions near the solar surface, at a fraction of the computational cost of comparable relaxation-based models.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [58] [A unified MRT-LB framework for Navier-Stokes and nonlinear convection-diffusion equations and beyond: moment equations, auxiliary moments, multispeed lattices, and Hermite matrices](https://arxiv.org/abs/2512.16230)
*Baochang Shi,Xiaolei Yuan,Zhenhua Chai*

Main category: physics.flu-dyn

TL;DR: A unified MRT-LB framework using Hermite polynomials for Navier-Stokes and nonlinear convection-diffusion equations with multispeed rectangular lattice models.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive lattice Boltzmann framework that can handle both Navier-Stokes equations and nonlinear convection-diffusion equations using a unified approach based on discrete Hermite polynomials and multispeed rectangular lattices.

Method: Developed MRT-LB framework using discrete Hermite polynomials (Hermite matrices) with multispeed rectangular lattice models. Derived macroscopic moment equations via Taylor expansion, used auxiliary moments to eliminate spurious terms, established relations for weight coefficients using weighted orthogonality, and constructed various lattice models including rD2Q25 and rD3Q53.

Result: Created a unified framework capable of simulating incompressible/compressible isothermal flows in single/multiphase systems for NSEs and handling NCDEs. Developed specific rectangular lattice models and derived generalized third-order equilibrium distribution function with corrections for Hermite matrix elements.

Conclusion: The proposed MRT-LB framework based on Hermite polynomials provides a unified approach for both NSEs and NCDEs using multispeed rectangular lattices, with specific auxiliary moments and corrections enabling accurate recovery of target equations.

Abstract: We develop a unified multi-relaxation-time lattice Boltzmann (MRT-LB) framework based on discrete Hermite polynomials (Hermite matrices) for the Navier-Stokes equations (NSEs) and nonlinear convection-diffusion equations (NCDEs), using multispeed rectangular lattice (rD$d$Q$b$) models. For NSEs, the proposed MRT-LB model simulates incompressible and compressible isothermal flows in both single-phase and multiphase systems. Macroscopic moment equations are derived from the MRT-LB model via the direct Taylor expansion method. By selecting appropriate fundamental moments, the target NSEs and NCDE are recovered from these moment equations. Critically, the elimination of spurious terms and/or the recovery of the desired terms relies on specific auxiliary moments: the second-order auxiliary moment ($\mathbf{M}_{2G}$) of the source term distribution function (SDF) and the third-order auxiliary moment ($\mathbf{M}_{30}$) of the equilibrium distribution function (EDF) for NSEs, as well as the first-order auxiliary moment ($\mathbf{M}_{1G}$) of the SDF and the second-order auxiliary moment ($\mathbf{M}_{20}$) of the EDF for NCDE. Furthermore, using the weighted orthogonality of Hermite matrices, we establish essential relations for weight coefficients and construct several multispeed rectangular lattice models, including rD2Q25 and rD3Q53, with subgroup models rD2Q21, rD2Q17, rD2Q13, rD3Q45, and rD3Q33. A generalized third-order equilibrium distribution function is derived. We emphasize that for rectangular lattices, specific elements of the Hermite matrix corresponding to third-order discrete Hermite polynomials require correction to satisfy weighted orthogonality.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [59] [Electric field diagnostics in a continuous rf plasma using Rydberg-EIT](https://arxiv.org/abs/2512.16867)
*Bineet Dash,Xinyan Xiang,Dingkun Feng,Eric Paradis,Georg Raithel*

Main category: physics.atom-ph

TL;DR: Non-invasive plasma electric field measurement using Rydberg atoms via Electromagnetically Induced Transparency spectroscopy


<details>
  <summary>Details</summary>
Motivation: Develop non-invasive techniques for measuring electric fields in various plasma environments (low-pressure plasma, plasma sheaths, process plasma, dusty plasma) without disturbing the plasma

Method: Uses Rydberg atoms with large polarizabilities and Stark shifts measured via narrow-linewidth lasers and Electromagnetically Induced Transparency (EIT) of rubidium vapor seeded into continuous, inductively coupled radio-frequency plasma in argon gas

Result: Rydberg-EIT spectra show rf modulation sidebands without plasma that vanish with plasma due to rf field screening; lineshapes reflect plasma's Holtsmark microfield distribution, enabling determination of plasma density and collisional line broadening across pressure and rf power ranges

Conclusion: Technique enables non-invasive spatio-temporal electric-field diagnostics for various plasma applications, providing a new tool for plasma characterization without disturbing the plasma environment

Abstract: We present a non-invasive spectroscopic technique to measure electric fields in plasma, leveraging large polarizabilities and Stark shifts of Rydberg atoms. Rydberg Stark shifts are measured with high precision using narrow-linewidth lasers via Electromagnetically Induced Transparency (EIT) of rubidium vapor seeded into a continuous, inductively coupled radio-frequency (rf) plasma in a few mTorr of argon gas. Without plasma, the Rydberg-EIT spectra exhibit rf modulation sidebands caused by electric- and magnetic-dipole transitions in the rf drive coil. With the plasma present, the rf modulation sidebands vanish due to screening of the rf drive field from the plasma interior. The lineshapes of the EIT spectra in the plasma reflect the plasma's Holtsmark microfield distribution, allowing us to determine plasma density and collisional line broadening over a range of pressures and rf drive powers. The work is expected to have applications in non-invasive spatio-temporal electric-field diagnostics of low-pressure plasma, plasma sheaths, process plasma and dusty plasma.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [60] [Introduction to Symbolic Regression in the Physical Sciences](https://arxiv.org/abs/2512.15920)
*Deaglan J. Bartlett,Harry Desmond,Pedro G. Ferreira,Gabriel Kronberger*

Main category: cs.LG

TL;DR: This is a special issue introduction on symbolic regression for physical sciences, covering applications from equation discovery to surrogate modeling, with methodological considerations and future directions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to showcase symbolic regression as a powerful method for discovering interpretable mathematical relationships from data in physical sciences, following a Royal Society discussion meeting in April 2025.

Method: The paper introduces a special issue collection spanning applications including automated equation discovery, emergent-phenomena modeling, and construction of compact emulators for expensive simulations. It outlines conceptual foundations, contrasts with conventional regression, and surveys main use cases.

Result: The special issue collects contributions illustrating accelerating progress of symbolic regression across physical sciences, covering effective theories, empirical functional forms, and surrogate models.

Conclusion: Symbolic regression shows growing relevance across physical sciences with emerging directions including incorporation of symmetry constraints, asymptotic behavior, and integration with modern AI approaches, though challenges like scalability and robustness remain.

Abstract: Symbolic regression (SR) has emerged as a powerful method for uncovering interpretable mathematical relationships from data, offering a novel route to both scientific discovery and efficient empirical modelling. This article introduces the Special Issue on Symbolic Regression for the Physical Sciences, motivated by the Royal Society discussion meeting held in April 2025. The contributions collected here span applications from automated equation discovery and emergent-phenomena modelling to the construction of compact emulators for computationally expensive simulations.
  The introductory review outlines the conceptual foundations of SR, contrasts it with conventional regression approaches, and surveys its main use cases in the physical sciences, including the derivation of effective theories, empirical functional forms and surrogate models. We summarise methodological considerations such as search-space design, operator selection, complexity control, feature selection, and integration with modern AI approaches. We also highlight ongoing challenges, including scalability, robustness to noise, overfitting and computational complexity. Finally we emphasise emerging directions, particularly the incorporation of symmetry constraints, asymptotic behaviour and other theoretical information. Taken together, the papers in this Special Issue illustrate the accelerating progress of SR and its growing relevance across the physical sciences.

</details>


### [61] [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](https://arxiv.org/abs/2512.15771)
*Xinjie He,Chenggong Zhang*

Main category: cs.LG

TL;DR: Extends Time-Evolving Natural Gradient (TENG) framework to handle Dirichlet boundary conditions in PDEs using natural gradient optimization with time-stepping schemes (Euler/Heun), showing Heun's superior accuracy and Euler's efficiency.


<details>
  <summary>Details</summary>
Motivation: Traditional numerical methods struggle with high-dimensional/complex PDEs, while PINNs face accuracy and boundary condition challenges. Need improved neural network-based PDE solvers that can handle complex boundary conditions effectively.

Method: Extends TENG framework to incorporate Dirichlet boundary conditions by adding penalty terms to loss function. Uses natural gradient optimization combined with numerical time-stepping schemes (Euler and Heun methods) for stability and accuracy.

Result: Heun method shows superior accuracy due to second-order corrections, while Euler method offers computational efficiency for simpler scenarios. Successfully enforces Dirichlet constraints on heat equation.

Conclusion: Establishes foundation for extending framework to Neumann/mixed boundary conditions and broader PDE classes, advancing neural network-based solvers for real-world applications.

Abstract: Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient alternative by embedding physics-based constraints into deep learning frameworks, but they face challenges in achieving high accuracy and handling complex boundary conditions. In this work, we extend the Time-Evolving Natural Gradient (TENG) framework to address Dirichlet boundary conditions, integrating natural gradient optimization with numerical time-stepping schemes, including Euler and Heun methods, to ensure both stability and accuracy. By incorporating boundary condition penalty terms into the loss function, the proposed approach enables precise enforcement of Dirichlet constraints. Experiments on the heat equation demonstrate the superior accuracy of the Heun method due to its second-order corrections and the computational efficiency of the Euler method for simpler scenarios. This work establishes a foundation for extending the framework to Neumann and mixed boundary conditions, as well as broader classes of PDEs, advancing the applicability of neural network-based solvers for real-world problems.

</details>


### [62] [Multi-Fidelity Delayed Acceptance: hierarchical MCMC sampling for Bayesian inverse problems combining multiple solvers through deep neural networks](https://arxiv.org/abs/2512.16430)
*Filippo Zacchei,Paolo Conti,Attilio Alberto Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems using neural networks to combine predictions from solvers of varying fidelity, avoiding expensive high-fidelity simulations during inference.


<details>
  <summary>Details</summary>
Motivation: Traditional inverse uncertainty quantification with physics-based models is computationally expensive, especially with PDEs requiring Finite Element Method. While surrogate models help, generating high-fidelity training data is costly, and using only low-fidelity data reduces accuracy.

Method: Extends Multi-Level Delayed Acceptance with multi-fidelity neural networks that combine predictions from solvers of different fidelity levels. High-fidelity evaluations are done only during offline training. During online inference, coarse solvers' outputs are passed through trained neural networks to approximate high-fidelity likelihoods.

Result: The method improves approximation accuracy of low-fidelity solvers, enables longer sub-chain lengths, better mixing, and accelerated posterior inference. Demonstrated effectiveness on two benchmark problems: steady isotropic groundwater flow and unsteady reaction-diffusion system, achieving substantial computational savings.

Conclusion: The proposed Multi-Fidelity Delayed Acceptance scheme provides a flexible, efficient approach for Bayesian inverse problems by leveraging multi-fidelity neural networks to avoid expensive high-fidelity simulations during inference while maintaining accuracy.

Abstract: Inverse uncertainty quantification (UQ) tasks such as parameter estimation are computationally demanding whenever dealing with physics-based models, and typically require repeated evaluations of complex numerical solvers. When partial differential equations are involved, full-order models such as those based on the Finite Element Method can make traditional sampling approaches like Markov Chain Monte Carlo (MCMC) computationally infeasible. Although data-driven surrogate models may help reduce evaluation costs, their utility is often limited by the expense of generating high-fidelity data. In contrast, low-fidelity data can be produced more efficiently, although relying on them alone may degrade the accuracy of the inverse UQ solution.
  To address these challenges, we propose a Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems. Extending the Multi-Level Delayed Acceptance framework, the method introduces multi-fidelity neural networks that combine the predictions of solvers of varying fidelity, with high fidelity evaluations restricted to an offline training stage. During the online phase, likelihood evaluations are obtained by evaluating the coarse solvers and passing their outputs to the trained neural networks, thereby avoiding additional high-fidelity simulations.
  This construction allows heterogeneous coarse solvers to be incorporated consistently within the hierarchy, providing greater flexibility than standard Multi-Level Delayed Acceptance. The proposed approach improves the approximation accuracy of the low fidelity solvers, leading to longer sub-chain lengths, better mixing, and accelerated posterior inference. The effectiveness of the strategy is demonstrated on two benchmark inverse problems involving (i) steady isotropic groundwater flow, (ii) an unsteady reaction-diffusion system, for which substantial computational savings are obtained.

</details>


### [63] [Polyharmonic Spline Packages: Composition, Efficient Procedures for Computation and Differentiation](https://arxiv.org/abs/2512.16718)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: Proposes a cascade architecture of polyharmonic spline packages to address computational scalability and high-dimensional limitations of previous kernel regression methods.


<details>
  <summary>Details</summary>
Motivation: Previous polyharmonic spline kernel regression has O(N^3) computational cost and breaks down in high-dimensional spaces, limiting practical application despite theoretical optimality.

Method: Cascade architecture built from packages of polyharmonic splines, with efficient matrix procedures for forward computation and end-to-end differentiation through the cascade.

Result: Simultaneously addresses scalability issues and provides theoretical justification for problems with unknown intrinsic low dimensionality.

Conclusion: The cascade architecture enables practical application of theoretically optimal polyharmonic spline regression while handling computational and high-dimensional challenges.

Abstract: In a previous paper it was shown that a machine learning regression problem can be solved within the framework of random function theory, with the optimal kernel analytically derived from symmetry and indifference principles and coinciding with a polyharmonic spline. However, a direct application of that solution is limited by O(N^3) computational cost and by a breakdown of the original theoretical assumptions when the input space has excessive dimensionality. This paper proposes a cascade architecture built from packages of polyharmonic splines that simultaneously addresses scalability and is theoretically justified for problems with unknown intrinsic low dimensionality. Efficient matrix procedures are presented for forward computation and end-to-end differentiation through the cascade.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [64] [The Diffusive Behavior of Solutions to the Linear Damped Wave Equation: an Undergraduate D.I.Y. Classnote](https://arxiv.org/abs/2512.15770)
*Gastão Almeida Braga,Antônio Marcos da Silva,Jussara de Matos Moreira*

Main category: math.HO

TL;DR: The paper explains to undergraduate students how solutions of the Damped Wave and Heat equations become related as time approaches infinity.


<details>
  <summary>Details</summary>
Motivation: To provide undergraduate students with a clear, hands-on understanding of the surprising mathematical relationship between solutions of the Damped Wave and Heat equations in the long-time limit, despite these equations describing fundamentally different physical phenomena.

Method: Uses a "do it yourself" pedagogical approach with suggested exercises that students are invited to complete, targeting students with strong calculus backgrounds to work through the mathematical derivations themselves.

Result: The paper establishes and explains the mathematical relationship between solutions of the Damped Wave equation and the Heat equation as time approaches infinity, providing students with a concrete understanding of this asymptotic connection.

Conclusion: The note successfully demonstrates the surprising asymptotic relationship between solutions of two fundamentally different equations (Damped Wave and Heat equations) through an accessible, exercise-based approach suitable for undergraduate mathematics students.

Abstract: Despite of the fact that the Damped Wave and the Heat equations describe phenomena of distinct nature, it is amazing that their solutions are related in the limit as $t \to \infty$. The aim of this note is to explain to undergraduate students, with a good calculus background, how the relation between these solutions is established. We follow a ``do it yourself'' strategy and the students are invited to do the suggested exercises in order to understand the content of this note.

</details>


<div id='cond-mat.supr-con'></div>

# cond-mat.supr-con [[Back]](#toc)

### [65] [Beyond dpa: an atomistic framework for a quantitative description of radiation damage in YBa2Cu3O7](https://arxiv.org/abs/2512.16249)
*Federico Ledda,Daniele Torsello,Davide Gambino,Flyura Djurabekova,Fabio Calzavara,Niccolò Di Eugenio,Ville Jantunen,Antonio Trotta,Erik Gallo,Kai Nordlund,Francesco Laviano*

Main category: cond-mat.supr-con

TL;DR: Developed multiscale modeling framework combining MD and BCA simulations to predict radiation damage in high-temperature cuprate superconductors like YBa2Cu3O7 for harsh environment applications.


<details>
  <summary>Details</summary>
Motivation: Radiation damage in cuprate superconductors is a major challenge for deployment in harsh environments like fusion reactors and accelerators, but existing damage models are inadequate for their complex crystal structures.

Method: Developed atomistic-based approach coupling Molecular Dynamics (MD) and Binary Collision Approximation (BCA) simulations, integrated with Primary Knock-on Atom spectra from Monte Carlo codes for multiscale modeling.

Result: Established framework enabling quantitative estimates of damage descriptors including defect production, defect clustering, and effective damaged volume for irradiation conditions where collision cascades dominate.

Conclusion: The computational approach is suitable for predicting irradiation effects in any complex functional oxide, with applications ranging from aerospace to nuclear fusion and high-energy physics.

Abstract: Radiation damage in high-temperature cuprate superconductors represents one of the main technological challenges for their deployment in harsh environments, such as fusion reactors and accelerator facilities. Their complex crystal structure makes modeling irradiation effects in this class of materials a particularly demanding task, for which existing damage models remain inadequate. In this work, we develop an atomistic-based approach for describing primary radiation damage in YBa2Cu3O7, by coupling Molecular Dynamics and Binary Collision Approximation simulations in a way that makes them complementary. When integrated with Primary Knock-on Atom spectra obtained from Monte Carlo codes, our results establish a framework for multiscale modeling of radiation damage, enabling quantitative estimates of several damage descriptors, such as defect production, defect clustering, and the effective damaged volume for any specific irradiation conditions where collision cascades dominate. This computational approach is suitable for the prediction of irradiation effects in any complex functional oxide, with applications ranging from aerospace to nuclear fusion and high-energy physics.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [66] [Ground states for the Hartree energy functional in the critical case](https://arxiv.org/abs/2512.16513)
*Tommaso Pistillo*

Main category: math-ph

TL;DR: Existence of ground states for Hartree energy functional with convolution potentials, including Coulomb-like potentials, with proofs of positivity, regularity, and orbital stability for associated evolution.


<details>
  <summary>Details</summary>
Motivation: Study ground state solutions for Hartree energy functionals with broad class of convolution potentials that include physically relevant cases like Coulomb potentials (-1/|x|^α) and L^{3/2} potentials, which are important in quantum mechanics and nonlinear PDEs.

Method: Variational approach in H^1(R^3) space, working with Hartree energy functional with convolution potential w in L^∞(R^3)+L^{3/2,∞}(R^3). Use functional analysis techniques to prove existence of minimizers for range of L^2 masses, then establish properties via elliptic regularity and energy estimates.

Result: Proves existence of ground states for wide range of L^2 masses, establishes positivity and regularity of these ground states, and shows global well-posedness of associated evolution problem with orbital stability of ground state set.

Conclusion: The paper provides comprehensive existence and stability results for Hartree ground states with broad class of potentials, establishing solid mathematical foundation for studying these important nonlinear models in quantum mechanics.

Abstract: We consider the problem of finding a minimizer $u$ in $ H^1(\mathbb{R}^3)$ for the Hartree energy functional with convolution potential $w$ in $L^\infty(\mathbb{R}^3)+L^{3/2,\infty}(\mathbb{R}^3)$ with $L^\infty$ part vanishing at infinity. This class includes sums of potentials of the kind $-\frac{1}{|x|^α}$, $0<α\le2$, together with the case $w$ in $L^{3/2}(\mathbb{R}^3)$. We prove the existence of such groundstates for a wide range of $L^2$ masses. We also establish basic properties of the groundstates, i.e.~positivity and regularity. Lastly, we exploit the estimates we derived for the stationary problem to prove global well-posedness of the associated evolution problem and orbital stability of the set of ground states.

</details>
