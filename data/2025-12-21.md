<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 26]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 3]
- [math.HO](#math.HO) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [math.CV](#math.CV) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.IT](#cs.IT) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [physics.atom-ph](#physics.atom-ph) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [cond-mat.supr-con](#cond-mat.supr-con) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Make the most of what you have: Resource-efficient randomized algorithms for matrix computations](https://arxiv.org/abs/2512.15929)
*Ethan N. Epperly*

Main category: math.NA

TL;DR: This thesis develops efficient randomized algorithms for computational linear algebra problems, focusing on low-rank approximation, matrix attribute estimation, and stable randomized least-squares solvers.


<details>
  <summary>Details</summary>
Motivation: Randomized algorithms are fundamental in computational linear algebra but often use information inefficiently. The thesis aims to design algorithms that maximize speed and accuracy for limited data budgets across three key problem areas.

Method: Three-part approach: 1) Randomly pivoted Cholesky for low-rank PSD matrix approximation, 2) Leave-one-out approach for matrix attribute estimation (trace, diagonal, row-norms), 3) Development of backward-stable randomized algorithms for linear least-squares problems.

Result: RPCholesky outperforms other methods for low-rank approximation; optimized trace/diagonal/row-norm estimators developed; backward-stable randomized least-squares algorithms achieved, resolving previous floating-point accuracy concerns.

Conclusion: The thesis demonstrates that randomized algorithms can be designed to use information efficiently while maintaining reliability, with applications across scientific computing, machine learning, and quantum information science.

Abstract: In recent years, randomized algorithms have established themselves as fundamental tools in computational linear algebra, with applications in scientific computing, machine learning, and quantum information science. Many randomized matrix algorithms proceed by first collecting information about a matrix and then processing that data to perform some computational task. This thesis addresses the following question: How can one design algorithms that use this information as efficiently as possible, reliably achieving the greatest possible speed and accuracy for a limited data budget?
  The first part of this thesis focuses on low-rank approximation for positive-semidefinite matrices. Here, the goal is to compute an accurate approximation to a matrix after accessing as few entries of the matrix as possible. This part of the thesis explores the randomly pivoted Cholesky (RPCholesky) algorithm for this task, which achieves a level of speed and reliability greater than other methods for the same problem.
  The second part of this thesis considers the task of estimating attributes of an implicit matrix accessible only by matrix-vector products. This thesis describes the leave-one-out approach to developing matrix attribute estimation algorithms and develops optimized trace, diagonal, and row-norm estimation algorithms.
  The third part of this thesis considers randomized algorithms for overdetermined linear least squares problems. Randomized algorithms for linear-least squares problems are asymptotically faster than any known deterministic algorithm, but recent work has raised questions about the accuracy of these methods in floating point arithmetic. This thesis shows these issues are resolvable by developing fast randomized least-squares problem achieving backward stability, the gold-standard stability guarantee for a numerical algorithm.

</details>


### [2] [Time-Frequency Analysis for Neural Networks](https://arxiv.org/abs/2512.15992)
*Ahmed Abdeljawad,Elena Cordero*

Main category: math.NA

TL;DR: The paper develops a quantitative approximation theory for shallow neural networks using time-frequency analysis, achieving dimension-independent Sobolev approximation rates with explicit constants.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous approximation rates for neural networks in Sobolev norms using time-frequency analysis tools, addressing the need for quantitative error bounds with explicit constants in neural network approximation theory.

Method: Uses weighted modulation spaces M^{p,q}_m(R^d) and time-frequency analysis tools. Networks combine standard activations with localized time-frequency windows. The approach involves constructing approximation schemes based on modulation dictionaries and proving dimension-independent error bounds.

Result: Achieves approximation rate ∥f - f_N∥_{W^{n,r}(Ω)} ≲ N^{-1/2}∥f∥_{M^{p,q}_m(R^d)} on bounded domains with explicit constants. Extends to global approximation on R^d using weighted modulation dictionaries, with applications to Feichtinger's algebra, Fourier-Lebesgue spaces, and Barron spaces.

Conclusion: Modulation-based neural networks provide superior Sobolev approximation compared to standard ReLU networks, with rigorous dimension-independent error bounds and explicit constants, validated by numerical experiments in 1D and 2D.

Abstract: We develop a quantitative approximation theory for shallow neural networks using tools from time-frequency analysis. Working in weighted modulation spaces $M^{p,q}_m(\mathbf{R}^{d})$, we prove dimension-independent approximation rates in Sobolev norms $W^{n,r}(Ω)$ for networks whose units combine standard activations with localized time-frequency windows. Our main result shows that for $f \in M^{p,q}_m(\mathbf{R}^{d})$ one can achieve \[ \|f - f_N\|_{W^{n,r}(Ω)} \lesssim N^{-1/2}\,\|f\|_{M^{p,q}_m(\mathbf{R}^{d})}, \] on bounded domains, with explicit control of all constants. We further obtain global approximation theorems on $\mathbf{R}^{d}$ using weighted modulation dictionaries, and derive consequences for Feichtinger's algebra, Fourier-Lebesgue spaces, and Barron spaces. Numerical experiments in one and two dimensions confirm that modulation-based networks achieve substantially better Sobolev approximation than standard ReLU networks, consistent with the theoretical estimates.

</details>


### [3] [A divergence-free parametric finite element method for 3D Stokes equations on curved domains](https://arxiv.org/abs/2512.16216)
*Lingxiao Li,Haiyan Su,He Zhang,Weiying Zheng*

Main category: math.NA

TL;DR: A divergence-free parametric mixed finite element method for 3D Stokes equations on curved domains using high-order elements and IPDG technique.


<details>
  <summary>Details</summary>
Motivation: The Stokes equations are crucial for incompressible flow simulation, but solving them on domains with piecewise smooth boundaries requires specialized methods that maintain divergence-free properties.

Method: Proposes a novel divergence-free parametric mixed FEM using high-order parametric Brezzi-Douglas-Marini elements for velocity and volume elements for pressure on curved tetrahedral meshes, employing interior-penalty discontinuous Galerkin (IPDG) technique.

Result: Proves inf-sup condition for the mixed finite element pair, achieves high-order optimal error estimates in energy norm, and ensures discrete velocity is exactly divergence-free (div uh = 0) in curved computational domain. Numerical experiments support theoretical analyses.

Conclusion: The method successfully solves 3D Stokes equations on curved domains while maintaining exact divergence-free properties and achieving optimal convergence rates.

Abstract: The Stokes equations play an important role in the incompressible flow simulation. In this paper, a novel divergence-free parametric mixed finite element method is proposed for solving three-dimensional Stokes equations on domains with piecewise smooth boundaries. The flow velocity and pressure are discretized with high-order parametric Brezzi-Douglas-Marini elements and volume elements, respectively, on curved tetrahedral meshes. Utilizing the interior-penalty discontinuous Galerkin (IPDG) technique, we prove the inf-sup condition for the mixed finite element pair, and high-order optimal error estimates in the energy norm, with the help of the extension and transformation of the true solution to computational domain. Moreover, the discrete velocity is exactly divergence-free, meaning that div uh = 0 holds in the curved computational domain. Numerical experiments are conducted to support the theoretical analyses.

</details>


### [4] [Numerical reconstruction of Schrödinger equations with quadratic nonlinearities](https://arxiv.org/abs/2512.16269)
*Khaoula El Maddah,Matti Lassas,Teemu Tyni*

Main category: math.NA

TL;DR: A numerical framework for reconstructing potentials in 2D semilinear elliptic PDEs with power-type nonlinearities using the nonlinear Dirichlet-to-Neumann map.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the inverse problem of recovering unknown potentials in semilinear elliptic PDEs, which has applications in various fields like medical imaging, geophysics, and material science where internal properties need to be determined from boundary measurements.

Method: Uses higher order linearization method to compute Fourier data of the unknown potential from the nonlinear Dirichlet-to-Neumann map, then inverts this data to reconstruct the potential q. The approach handles both smooth and discontinuous test cases.

Result: Numerical experiments demonstrate accurate reconstructions of potentials for both smooth and discontinuous test cases, validating the effectiveness of the proposed framework.

Conclusion: The proposed numerical framework successfully reconstructs potentials in 2D semilinear elliptic PDEs with power-type nonlinearities using boundary measurements, providing an effective solution to this inverse problem.

Abstract: We introduce a numerical framework for reconstructing the potential in two dimensional semilinear elliptic PDEs with power type nonlinearities from the nonlinear Dirichlet to Neumann map. By applying higher order linearization method, we compute the Fourier data of the unknown potential and then invert it to recover $q$. Numerical experiments show accurate reconstructions for both smooth and discontinuous test cases.

</details>


### [5] [A Locally Divergence-Free Local Characteristic Decomposition Based Path-Conservative Central-Upwind Scheme for Ideal Magnetohydrodynamics](https://arxiv.org/abs/2512.16346)
*Shaoshuai Chu,Alexander Kurganov,Maria Lukacova-Medvidova,Mingye Na*

Main category: math.NA

TL;DR: A new locally divergence-free local characteristic decomposition path-conservative central-upwind (LCD-PCCU) scheme for MHD equations that reduces numerical dissipation and improves solution resolution.


<details>
  <summary>Details</summary>
Motivation: To develop a low-dissipation extension of the existing locally divergence-free PCCU scheme for ideal magnetohydrodynamics equations, aiming to enhance numerical solution resolution.

Method: Incorporates local characteristic decomposition (LCD) into the path-conservative central-upwind (PCCU) framework to reduce numerical dissipation while maintaining locally divergence-free properties.

Result: The LCD-PCCU method successfully enhances the resolution of numerical solutions as demonstrated through a series of benchmark tests.

Conclusion: The proposed LCD-PCCU scheme provides an effective low-dissipation extension to existing PCCU methods, improving numerical accuracy for MHD simulations while preserving divergence-free properties.

Abstract: We introduce a locally divergence-free local characteristic decomposition based path-conservative central-upwind (LCD-PCCU) scheme for ideal magnetohydrodynamics (MHD) equations. The proposed method is a low-dissipation extension of the recently proposed locally divergence-free PCCU scheme. To reduce the numerical dissipation, we incorporate the LCD into the PCCU framework. The resulting LCD-PCCU method enhances the resolution of numerical solutions as demonstrated through a series of benchmark tests.

</details>


### [6] [Conserving mass, momentum, and energy for the Benjamin-Bona-Mahony, Korteweg-de Vries, and nonlinear Schrödinger equations](https://arxiv.org/abs/2512.16352)
*Hendrik Ranocha,David I. Ketcheson*

Main category: math.NA

TL;DR: High-order numerical methods that preserve multiple invariants (mass, momentum, energy) for PDEs using Fourier Galerkin in space and orthogonal projection with relaxation in time, requiring no large algebraic solves.


<details>
  <summary>Details</summary>
Motivation: To develop numerical discretizations that preserve multiple physical invariants (conservation laws) while being computationally efficient (essentially explicit, avoiding large algebraic solves) for long-term simulations of PDEs.

Method: Combines Fourier Galerkin methods in space with orthogonal projection and relaxation techniques in time. The approach is "essentially explicit" - doesn't require solving large systems of algebraic equations.

Result: The methods conserve mass, momentum, and energy up to numerical precision for Benjamin-Bona-Mahoney, Korteweg-de Vries, nonlinear Schrödinger, and hyperbolic NLS equations. This conservation leads to reduced error growth in long-term simulations.

Conclusion: The proposed high-order discretizations successfully preserve multiple invariants while maintaining computational efficiency, providing improved accuracy for long-term simulations of conservation-law PDEs.

Abstract: We propose and study a class of arbitrarily high order numerical discretizations that preserve multiple invariants and are essentially explicit (they do not require the solution of any large systems of algebraic equations). In space, we use Fourier Galerkin methods, while in time we use a combination of orthogonal projection and relaxation. We prove and numerically demonstrate the conservation properties of the method by applying it to the Benjamin-Bona-Mahoney, Korteweg-de Vries, and nonlinear Schrödinger (NLS) PDEs as well as a hyperbolic approximation of NLS. For each of these equations, the proposed schemes conserve mass, momentum, and energy up to numerical precision. We show that this conservation leads to reduced growth of numerical errors for long-term simulations.

</details>


### [7] [New Fully Discrete Active Flux Methods with Truly Multi-Dimensional Evolution Operators and WENO Reconstruction](https://arxiv.org/abs/2512.16359)
*Amelie Porfetye,Zhuyan Tang,Shaoshuai Chu,Christiane Helzel,Maria Lukacova-Medvidova*

Main category: math.NA

TL;DR: Third-order accurate Active Flux and WENO methods for 2D acoustic equations using multidimensional evolution operators with improved stability via bicharacteristics method.


<details>
  <summary>Details</summary>
Motivation: To develop high-order accurate numerical methods for two-dimensional acoustic equations that maintain robustness and accuracy even on coarse grids, addressing stability challenges in multidimensional evolution operators.

Method: Proposed fully discrete third-order accurate Active Flux and WENO methods based on truly multidimensional evolution operators using the method of bicharacteristics to derive approximate evolution operators that improve stability, with linear stability analysis to determine maximal CFL numbers.

Result: The schemes demonstrate improved stability and maintain third-order accuracy, showing robustness and accurate approximation on both continuous and discontinuous problems even when using coarse grids.

Conclusion: The proposed multidimensional evolution operators based on bicharacteristics successfully yield stable third-order accurate methods for 2D acoustic equations that perform well on challenging problems including discontinuities.

Abstract: We propose new fully discrete third-order accurate Active Flux and WENO methods based on truly multidimensional evolution operators for the two-dimensional acoustic equations. Building on the method of bicharacteristics, several approximate evolution operators are derived that yield an improved stability of the resulting schemes. A linear stability analysis is applied to determine the maximal CFL number. The schemes are tested extensively on both continuous and discontinuous problems, confirming their robustness and accurate approximation even on coarse grids.

</details>


### [8] [An Euler scheme for BSDEs via the Wiener chaos decomposition](https://arxiv.org/abs/2512.16418)
*Pere Díaz Lozano,Giulia Di Nunno*

Main category: math.NA

TL;DR: Wiener chaos decomposition implementation for Euler scheme in BSDEs, handling arbitrary terminal conditions without Markovian structure.


<details>
  <summary>Details</summary>
Motivation: The Euler scheme for BSDEs requires approximating conditional expectations and martingale terms, typically relying on forward-backward Markovian structure. This limits applicability to arbitrary terminal conditions.

Method: Proposes implementation using Wiener chaos decomposition to approximate conditional expectations and martingale terms in the Euler scheme for BSDEs. This approach doesn't require Markovian structure.

Result: Provides comprehensive convergence analysis and demonstrates the method on several numerical examples, showing it accommodates arbitrary square-integrable terminal conditions.

Conclusion: Wiener chaos decomposition offers a flexible alternative to traditional BSDE numerical methods, extending applicability beyond Markovian settings while maintaining theoretical convergence guarantees.

Abstract: The Euler scheme is a standard time discretization for BSDEs, but its implementation hinges on approximating conditional expectations and the associated martingale terms at each time step. We propose an implementation based on the Wiener chaos decomposition to approximate these quantities. In contrast to many numerical schemes that rely on a forward-backward (Markovian) structure, our approach accommodates arbitrary $\mathcal{F}_T$-measurable square-integrable terminal conditions. We provide a comprehensive convergence analysis and illustrate the method on several numerical examples.

</details>


### [9] [A non-negativity-preserving cut-cell discontinuous Galerkin method for the diffusive wave equation](https://arxiv.org/abs/2512.16525)
*Panasun Manorost,Peter Bastian*

Main category: math.NA

TL;DR: A non-negativity-preserving cut-cell DG method for degenerate parabolic diffusive wave approximation of shallow water equations, with comparison to FV method.


<details>
  <summary>Details</summary>
Motivation: To develop robust numerical methods for shallow water equations that preserve non-negativity (water depth ≥ 0), handle complex bathymetry and friction laws, and work on general triangular meshes.

Method: Two methods: 1) Cut-cell discontinuous Galerkin (DG) method with upwind flux, 2) Finite volume (FV) method on Delaunay triangulations. Both preserve non-negativity and handle Manning's and Chezy's friction laws.

Result: DG method achieves full second-order accuracy for Barenblatt analytical solution on inclined plane, while FV method is only first-order accurate. FV method requires 3-4 mesh refinements to match DG solution quality.

Conclusion: The cut-cell DG method is superior in accuracy and efficiency for solving degenerate parabolic diffusive wave approximation of shallow water equations, though both methods successfully preserve non-negativity and handle complex geometries.

Abstract: A non-negativity-preserving cut-cell discontinuous Galerkin method for the degenerate parabolic diffusive wave approximation of the shallow water equation is presented. The method can handle continuous and discontinuous bathymmetry as well as general triangular meshes. It is complemented by a finite volume method on Delauney triangulations which is also shown to be non-negativity preserving. Both methods feature an upwind flux and can handle Manning's and Chezy's friction law. By numerical experiment we demonstrate the discontinuous Galerkin method to be fully second-order accurate for the Barenblatt analytical solution on an inclined plane. In constrast, the finite volume method is only first-order accurate. Further numerical experiments show that three to four mesh refinements are needed for the finite volume method to match the solution of the discontinuous Galerkin method.

</details>


### [10] [Landscape Analysis of Excited States Calculation over Quantum Computers](https://arxiv.org/abs/2512.16539)
*Hengzhun Chen,Yingzhou Li,Bichen Lu,Jianfeng Lu*

Main category: math.NA

TL;DR: The paper analyzes three VQE models for excited state calculations that embed orthogonality constraints through specially designed cost functions, avoiding external orthogonality enforcement and ensuring local minima are global minima.


<details>
  <summary>Details</summary>
Motivation: While VQE has been successful for ground state calculations, excited state calculations are more challenging due to variational collapse to the ground state and the need to maintain orthogonality between low-lying eigenstates. Current methods require external orthogonality enforcement, which is problematic on NISQ devices.

Method: The authors analyze three VQE models that embed orthogonality constraints through specially designed cost functions. These formulations have the property that any local minimum is also a global minimum. They conduct rigorous landscape analyses of the models' stationary points and local minimizers, providing theoretical guarantees and analytical tools.

Result: The paper provides theoretical guarantees for the favorable properties of the three models and analytical tools applicable to broader VQE methods. A comprehensive comparison between the models is provided, considering their quantum resource requirements and classical optimization complexity.

Conclusion: The proposed VQE models with embedded orthogonality constraints offer promising solutions for excited state calculations on NISQ devices by avoiding external orthogonality enforcement and ensuring optimization-friendly landscapes where local minima are global minima.

Abstract: The variational quantum eigensolver (VQE) is one of the most promising algorithms for low-lying eigenstates calculation on Noisy Intermediate-Scale Quantum (NISQ) computers. Specifically, VQE has achieved great success for ground state calculations of a Hamiltonian. However, excited state calculations arising in quantum chemistry and condensed matter often requires solving more challenging problems than the ground state as these states are generally further away from a mean-field description, and involve less straightforward optimization to avoid the variational collapse to the ground state. Maintaining orthogonality between low-lying eigenstates is a key algorithmic hurdle. In this work, we analyze three VQE models that embed orthogonality constraints through specially designed cost functions, avoiding the need for external enforcement of orthogonality between states. Notably, these formulations possess the desirable property that any local minimum is also a global minimum, helping address optimization difficulties. We conduct rigorous landscape analyses of the models' stationary points and local minimizers, theoretically guaranteeing their favorable properties and providing analytical tools applicable to broader VQE methods. A comprehensive comparison between the three models is also provided, considering their quantum resource requirements and classical optimization complexity.

</details>


### [11] [Obstacle Mean Curvature Flow: Efficient Approximation and Convergence Analysis](https://arxiv.org/abs/2512.16668)
*Fabius Krämer,Tim Laux*

Main category: math.NA

TL;DR: A simple numerical method for mean curvature flow with obstacles that extends the Merriman-Bence-Osher scheme with pointwise constraint enforcement, maintaining computational efficiency while preserving key structural properties.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for computing mean curvature flow with obstacles that retains the computational simplicity of existing schemes while properly handling constraints.

Method: Augments the Merriman-Bence-Osher scheme with a pointwise update that enforces obstacle constraints, maintaining the original scheme's computational complexity while inheriting crucial structural properties.

Result: The method preserves both geometric comparison principle and minimizing movements interpretation, ensuring unconditional stability. Convergence to viscosity solution is proven, and spatially discrete model convergence is shown using minimizing movements interpretation.

Conclusion: The proposed simple scheme successfully computes obstacle mean curvature flow while inheriting key theoretical properties, with numerical experiments demonstrating its effectiveness for physical models.

Abstract: We introduce a simple and efficient numerical method to compute mean curvature flow with obstacles. The method augments the Merrimam-Bence-Osher scheme with a pointwise update that enforces the constraint and therefore retains the computational complexity of the original scheme. Remarkably, this naive scheme inherits both crucial structural properties of obstacle mean curvature flow: a geometric comparison principle and a minimizing movements interpretation. The latter immediately implies the unconditional stability of the scheme. Based on the comparison principle we prove the convergence of the scheme to the viscosity solution of obstacle mean curvature flow. Moreover, using the minimizing movements interpretation, we show convergence of a spatially discrete model. Finally, we present numerical experiments for a physical model that inspired this work.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Fokas-type closed-form solution formulae for Sobolev-type equations with time-dependent coefficients](https://arxiv.org/abs/2512.15937)
*Andreas Chatziafratis*

Main category: math.AP

TL;DR: Novel explicit integral representations derived for solving nonhomogeneous initial-boundary-value problems of Sobolev-Galpern type evolution PDEs with time-dependent coefficients and mixed spatiotemporal derivatives using extended Fokas unified transform methodology.


<details>
  <summary>Details</summary>
Motivation: To develop analytical solutions for a broad category of evolution PDEs with time-dependent coefficients and mixed derivatives that induce rational dispersion relations, extending beyond previous work limited to polynomial dispersion relations.

Method: Extension of the Fokas unified transform methodology to handle evolution equations with time-dependent coefficients and mixed spatiotemporal derivatives, carefully implementing complex-analytic techniques to overcome challenges from rational dispersion relations.

Result: Derived novel explicit integral representations for solutions of nonhomogeneous initial-boundary-value problems for Sobolev-Galpern type equations with arbitrary data in classical function spaces, demonstrated through closed-form solutions for various equations on the half-line.

Conclusion: Successfully extended Fokas methodology to handle evolution equations with rational dispersion relations, providing analytical tools for studying qualitative properties and nonlinear counterparts, with further extensions planned for future publications.

Abstract: We analytically derive novel explicit integral representations for the solution of nonhomogeneous initial-boundary-value problems for a large category of evolution partial differential equations of Sobolev-Galpern type with generic temporally variable coefficients, satisfying suitable mild conditions, and with arbitrary data in classical function spaces. This work is based on the careful implementation of the pioneering Fokas unified transform methodology alongside its recently-proposed extension for solving a class of linear evolution equations with dispersion relation of specific polynomial type and time-dependent coefficients. We herein effectively extend those techniques to a special collection of evolution equations with time-dependent coefficients and mixed spatiotemporal derivatives, which induce rational dispersion relations. The new approach is exhibited in detail through illustrative generation of closed-form solutions for a multitude of such equations (such as Milne-Taylor-Barenblatt-Coleman-Ting-Chen-type, Benjamin-Bona-Mahony-type, as well as numerous higher-order variants) posed on the half-line. Challenging technical difficulties of complex-analytic and of algebraic flavour naturally emerge due the presence of mixed-derivative terms, and these are appropriately resolved in each case. The new formulas are of utility in subsequent investigation of qualitative properties and analysis of nonlinear counterparts too. Further extensions, generalizations, rigorous aspects and implementations to other types of problems as well will soon be reported in forthcoming publications.

</details>


### [13] [Fundamental Properties and Embedding Results in a Novel $(Φ_x, ψ)$-Fractional Musielak Space with an Application to Nonlocal BVP](https://arxiv.org/abs/2512.15972)
*Ayoub Kasmi,El Houssine Azroul,Mohammed Shimi*

Main category: math.AP

TL;DR: The paper introduces a new class of generalized fractional Musielak spaces for modeling heterogeneous nonlinear phenomena with memory and nonlocal effects, establishes their properties and embeddings, and applies them to prove existence of solutions to nonlinear fractional differential problems.


<details>
  <summary>Details</summary>
Motivation: To develop a flexible mathematical framework that extends classical fractional spaces to handle heterogeneous and nonlinear phenomena with memory and nonlocal effects, particularly relevant for nonlocal boundary value problems in variable-exponent and Musielak-Orlicz settings.

Method: Introduces generalized $(Φ_x,ψ)$-fractional Musielak spaces $\mathcal{K}_{Φ_x}^{α, β, ψ}$, conducts rigorous functional analysis of their structure, establishes new properties and embedding results, and applies the framework to prove existence of nontrivial solutions using mountain pass theorem under Ambrosetti-Rabinowitz conditions.

Result: Establishes detailed properties and embedding results for the new fractional Musielak spaces, and proves existence of nontrivial solutions to nonlinear fractional differential problems, providing new analytical tools for nonlocal and nonhomogeneous equations.

Conclusion: The proposed generalized fractional Musielak spaces offer a powerful framework for analyzing heterogeneous nonlinear phenomena with memory and nonlocal effects, with applications to nonlocal BVPs and providing new perspectives for variable-exponent and Musielak-Orlicz settings.

Abstract: In this paper, we introduce and study a novel class of generalized $(Φ_x,ψ)$-fractional Musielak spaces $\mathcal{K}_{Φ_x}^{α, β, ψ}$, which extends classical fractional spaces and offers the flexibility to model heterogeneous and nonlinear phenomena with memory and nonlocal effects. A detailed and rigorous analysis of their functional structure is carried out. Several new properties and embedding results are established, highlighting the originality of the proposed framework and its relevance to nonlocal BVPs. To illustrate the significance of this functional setting, we prove the existence of nontrivial solutions to a nonlinear fractional differential problem under an Ambrosetti--Rabinowitz type condition, using the mountain pass theorem. Our results provide new perspectives for the analysis of nonlocal and nonhomogeneous equations in variable-exponent and Musielak-Orlicz settings.

</details>


### [14] [A Fourier analysis for $(θ,T)$-periodic functions and applications](https://arxiv.org/abs/2512.15974)
*André Pedroso Kowacs,Marielle Aparecida Silva*

Main category: math.AP

TL;DR: Fourier analysis for (θ,T)-periodic functions with applications to global hypoellipticity/solvability of differential operators.


<details>
  <summary>Details</summary>
Motivation: Extend Fourier analysis from classical periodic functions to a more general class of (θ,T)-periodic functions, enabling analysis of differential operators on these function spaces.

Method: Develop Fourier transform theory for (θ,T)-periodic functions, prove properties including Poincaré-type inequalities, then apply to study global hypoellipticity/solvability of continuous linear operators and first-order differential operators.

Result: Established Fourier analysis framework for (θ,T)-periodic functions with key inequalities; proved equivalence: operator is globally hypoelliptic/solvable on (θ,T)-periodic functions iff it is on classical periodic functions; characterized hypoellipticity/solvability for first-order differential operators.

Conclusion: The developed Fourier analysis successfully extends periodic function theory to (θ,T)-periodic case, providing tools to analyze differential operators and establishing equivalence results for global hypoellipticity/solvability properties.

Abstract: We develop a Fourier analysis for a generalization of the class of periodic functions, often referred to as $(θ, T)$-periodic functions, and prove several properties and inequalities related to the Fourier transform, including a type of Poincaré inequality, which extend the periodic case. As an application, we employ this analysis to show that a continuous linear operator acting on smooth $(θ, T)$-periodic functions is globally hypoelliptic/solvable if and only if the corresponding operator which acts on periodic functions is globally hypoelliptic/solvable, and characterize the global hypoellipticity/solvability of a class of first order differential operators acting on the set of smooth $(θ, T)$-periodic functions.

</details>


### [15] [A Poisson Formula for the Wave Propagator on Schwarzschild-de Sitter Backgrounds](https://arxiv.org/abs/2512.16054)
*Izak Oltman,Ben Pineau*

Main category: math.AP

TL;DR: Proves a Poisson formula for wave propagators in Schwarzschild-de Sitter spacetime, extending previous results to non-compactly supported potentials including Regge-Wheeler potentials.


<details>
  <summary>Details</summary>
Motivation: Previous Poisson formulae for wave propagators required compactly supported perturbations, limiting applicability to physically important cases like Schwarzschild-de Sitter spacetime where potentials have non-compact support.

Method: Proves a Poisson formula relating wave propagators and scattering resonances for a class of non-compactly supported potentials on the real line, specifically including Regge-Wheeler potentials obtained from separation of variables for SdS.

Result: Establishes a Poisson formula for the wave propagator of Schwarzschild-de Sitter metric, extending the classical results of Lax-Phillips and Melrose to non-compact support cases.

Conclusion: The work provides a mathematical foundation for studying wave propagation in Schwarzschild-de Sitter spacetime by overcoming the compact support limitation of previous Poisson formulae.

Abstract: This paper proposes a Poisson formula for the wave propagator of the Schwarzschild--de Sitter (SdS) metric. That is done by proving a Poisson formula relating wave propagators and scattering resonances for a class of non-compactly supported potentials on the real line. That class includes the Regge--Wheeler potentials obtained from separation of variables for SdS. The novelty lies in allowing non-compact supports -- all exact Poisson formulae of Lax--Phillips, Melrose, and other authors required compactness of the support of the perturbation.

</details>


### [16] [Low Regularity Well-Posedness of Cauchy Problem for Two-Dimensional Relativistic Euler Equation](https://arxiv.org/abs/2512.16090)
*Huali Zhang*

Main category: math.AP

TL;DR: Study of Cauchy problem for 2D relativistic Euler equations in low-regularity settings using reformulation into wave-transport system with new variables.


<details>
  <summary>Details</summary>
Motivation: To establish well-posedness results for the relativistic Euler equations with minimal regularity requirements, extending classical results to relativistic fluid dynamics.

Method: Introduce rescaled velocity, logarithmic enthalpy, and vorticity variables to reformulate equations as coupled wave-transport system. Use Strichartz estimates and semiclassical analysis for proofs.

Result: Proved existence/uniqueness for general state function p(ρ)=ρ^A (A≥1) with specific Sobolev space regularity. For p(ρ)=ρ case, established improved well-posedness results matching classical fluid dynamics regularity exponents.

Conclusion: Successfully developed low-regularity theory for 2D relativistic Euler equations, achieving optimal or near-optimal regularity exponents that align with classical fluid dynamics results in special cases.

Abstract: In this article, we initiate the study of the Cauchy problem for the two-dimensional relativistic Euler equations in a low-regularity setting. By introducing good variables--a rescaled velocity, logarithmic enthalpy, and an appropriately defined vorticity, we reformulate the equations into a coupled wave-transport system.
  First, we prove the existence and uniqueness of solutions when the initial logarithmic enthalpy $h_0$, rescaled velocity $\bv_0$, and vorticity $\bw_0$ satisfy $(h_0, \bv_0, \bw_0, \nabla \bw_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac32+}(\mathbb{R}^2) \times L^8(\mathbb{R}^2)$. By using Strichartz estimates and semiclassical analysis, a relaxed well-posedness result holds when $(h_0, \bv_0, \bw_0, \nabla \bw_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac32}(\mathbb{R}^2) \times L^8(\mathbb{R}^2)$. Both results are valid for the general state function $p(\varrho)=\varrho^A$ ($A \geq 1$).
  Secondly, in the special case where $p(\varrho)=\varrho$, the acoustic metric reduces to the standard flat Minkowski metric. We can establish the well-posedness of solutions when $(h_0, \mathbf{v}_0, \mathbf{w}_0) \in H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{\frac{7}{4}+}(\mathbb{R}^2) \times H^{1+}(\mathbb{R}^2)$. The regularity exponents for the log-enthalpy and rescaled velocity correspond to those in Smith and Tataru \cite{ST}, while the vorticity regularity corresponds to Bourgain and Li \cite{BL}. Moreover, if the stiff flow is irrotational, we can prove the local well-posedness for $(h_0, \mathbf{v}_0) \in H^{1+}(\mathbb{R}^2)$, and global well-posedness for small initial data $(h_0, \bv_0) \in \dot{B}^{1}_{2,1}(\mathbb{R}^2)$.

</details>


### [17] [Global weak solutions of 3D compressible magnetohydrodynamic equations subject to large external potential forces with discontinuous initial data and vacuum](https://arxiv.org/abs/2512.16121)
*Geyuan Chen,Xin Zhong*

Main category: math.AP

TL;DR: Global existence of weak solutions for compressible MHD equations with large external forces and discontinuous initial data in 3D bounded domains under Navier-slip boundary conditions.


<details>
  <summary>Details</summary>
Motivation: Study compressible magnetohydrodynamic equations with challenging conditions: large external potential forces, discontinuous initial data (including vacuum states and large oscillations), in bounded 3D domains with Navier-slip boundary conditions.

Method: Develop new estimates based on effective viscous flux to handle difficulties from boundary effects and large external forces. Use small initial energy condition to prove global existence.

Result: Prove global existence of weak solutions for the initial-boundary value problem when initial energy is suitably small, allowing for vacuum states and large oscillations in initial data.

Conclusion: The paper establishes global existence results for compressible MHD equations under challenging conditions by developing new analytical techniques to overcome boundary and large force difficulties.

Abstract: We investigate the compressible magnetohydrodynamic equations subject to large external potential forces with discontinuous initial data in a three-dimensional bounded domain under Navier-slip boundary conditions. We show the global existence of weak solutions for such an initial-boundary value problem provided the initial energy is suitably small. In particular, the initial data may contain vacuum states and possibly exhibit large oscillations. To overcome difficulties brought by boundary and large external forces, some new estimates based on the effective viscous flux play crucial roles.

</details>


### [18] [Well-Posedness for Low Regularity Solutions to the g-SQG Equation with Regular Level Sets](https://arxiv.org/abs/2512.16128)
*Junekey Jeon,Andrej Zlatos*

Main category: math.AP

TL;DR: The paper proves local well-posedness for generalized SQG equations in low regularity spaces with H² level sets, and shows that for α≤1/6, solutions only cease to exist when level sets lose H² regularity, not from collisions or pile-ups.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous existence and uniqueness results for generalized SQG equations in physically relevant low regularity settings, and understand the precise mechanisms of solution breakdown beyond simple geometric collisions.

Method: Analyzes the generalized SQG equation on the plane using functional analysis techniques, focusing on spaces of Hölder continuous solutions with H² level sets (L² curvatures). Employs parameter-dependent Hölder exponents and additional hypotheses for the α≤1/6 case.

Result: 1) Local well-posedness in low regularity spaces with H² level sets for α∈(0,1/2). 2) For α≤1/6, solutions only break down when level sets lose H² regularity, not from collisions or pile-ups, under additional initial data conditions.

Conclusion: The generalized SQG equation exhibits robust well-posedness properties in low regularity settings, and for sufficiently small α, solution breakdown is tied specifically to loss of geometric regularity rather than topological collisions.

Abstract: We show that the generalized SQG equation on the plane is locally well-posed in spaces of low regularity solutions (essentially Hölder continuous with Hölder exponents depending on the equation parameter $α\in(0,\frac 12)$) that have $H^2$ level sets (i.e., with $L^2$ curvatures). Moreover, for $α\le\frac 16$ and initial data satisfying some additional hypotheses we show that the corresponding solutions can stop existing only when their level sets lose $H^2$-regularity, and hence not just due to level set collisions or "pile ups".

</details>


### [19] [On the existence of full dimensional KAM tori for 1D periodic nonlinear Schrödinger equation](https://arxiv.org/abs/2512.16283)
*Yuan Wu*

Main category: math.AP

TL;DR: Proves existence of full dimensional tori for 1D nonlinear Schrödinger equation with space-dependent nonlinearity and Gevrey smooth coefficients, extending previous results to more general perturbations.


<details>
  <summary>Details</summary>
Motivation: Extend existing KAM theory results for nonlinear Schrödinger equations to cases where the nonlinear perturbation explicitly depends on the space variable x, which was not covered by previous work of Bourgain and Cong.

Method: Uses KAM (Kolmogorov-Arnold-Moser) theory and infinite-dimensional Hamiltonian systems approach. Handles Gevrey smooth coefficients and Fourier multiplier V* with boundary conditions on the torus.

Result: Proves existence of full dimensional invariant tori with radius decaying as I_n ∼ e^{-2ln^σ|n|} for any σ > 2, which is slower decay than previous results.

Conclusion: Successfully extends KAM theory to 1D nonlinear Schrödinger equations with explicit space-dependent nonlinear perturbations, establishing existence of invariant tori with specific decay properties for the action variables.

Abstract: In this paper, we will prove the existence of full dimensional tori for 1-dimensional nonlinear Schrödinger equation \begin{eqnarray}\label{maineq0} \mathbf{i}u_{t}-u_{xx}+V*u+εf(x)|u|^{4}u=0,\ x\in\mathbb{T}=\mathbb{R}/2π\mathbb{Z}, \end{eqnarray} with boundary conditions, where $V*$ is the Fourier multiplier, and $f(x)$ is Gevrey smooth. Here the radius of the invariant tori satisfies a slower decay, i.e. \[ I_n\sim e^{-2\ln^σ|n|}, \mbox{as}\ n\rightarrow\infty, \] for any $ σ> 2, $ which extends results of Bourgain \cite{BJFA2005} and Cong \cite{cong2024} to the case that the nonlinear perturbation depends explicitly on the space variable $x$.

</details>


### [20] [Low-Mach-number limit for multiphase flows](https://arxiv.org/abs/2512.16286)
*Cassandre Lebot*

Main category: math.AP

TL;DR: Review paper on low-Mach-number limit analysis for compressible Navier-Stokes/Euler equations, covering single-phase flows and various two-phase flow systems with different closure models and velocity formulations.


<details>
  <summary>Details</summary>
Motivation: To systematically study and review the mathematical analysis of low-Mach-number limits for compressible fluid equations, particularly focusing on extending single-phase results to more complex two-phase flow scenarios with different modeling approaches.

Method: Review and analysis approach: First reviews existing results for single-phase flows, then focuses on two-phase flows with different system types including algebraic vs. PDE pressure closure, single vs. two velocities, and presence/absence of entropy considerations.

Result: The paper provides a comprehensive review of low-Mach-number limit results for both single-phase and two-phase compressible flows, analyzing different mathematical formulations and closure models for two-phase systems.

Conclusion: The low-Mach-number limit analysis reveals important mathematical properties and behaviors for compressible fluid equations, with two-phase flows requiring more complex treatment due to additional modeling choices in closure relations, velocity formulations, and thermodynamic considerations.

Abstract: This paper is devoted to the study of the low-Mach-number limit for solutions of the compressible Navier-Stokes or Euler equations for different types of fluids. We first review the different results obtained in the case of flows consisting of one phase. Then, we focus on the low-Mach-number limit for two-phase flows, considering different types of systems: with an algebraic closure or a PDE closure for the pressure, with one single or two different velocities, without or with entropy.

</details>


### [21] [Nekhoroshev type stability for non-local semilinear Schrödinger equations](https://arxiv.org/abs/2512.16299)
*Bingqi Yu,Li Yong*

Main category: math.AP

TL;DR: First rigorous stability results for ultra-differentiable Schrödinger equations with non-local nonlinearities using rational normal forms, achieving optimal stability times matching Bourgain's conjecture.


<details>
  <summary>Details</summary>
Motivation: To establish Nekhoroshev-type stability for solutions of ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters, particularly for Schrödinger equations with non-local nonlinear terms where previous rigorous results were lacking.

Method: Employ the method of rational normal forms with a novel global vector field norm adapted to this framework. This norm eliminates the need for degree tracking during iteration, enabling unified treatment of nonlinear terms.

Result: First rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters. Under Gevrey class regularity assumptions, achieved stability times matching Bourgain's conjectured optimal stability time.

Conclusion: The rational normal form method with the novel global vector field norm successfully establishes Nekhoroshev-type stability for ultra-differentiable Schrödinger equations with non-local nonlinearities, achieving optimal stability bounds.

Abstract: This paper investigates Nekhoroshev-type stability for solutions of ultra-differentiable regularity in Schrödinger equations with non-local nonlinear terms, employing the method of rational normal forms. We establish the first rigorous results for logarithmic ultra-differentiable regularity in infinite-dimensional Hamiltonian systems without external parameters. Under Gevrey class regularity assumptions, we achieve the stability times matching Bourgain's conjectured optimal stability time in \cite{B04}. Furthermore, we introduce a novel global vector field norm adapted to the rational normal form framework. This norm eliminate the need for degree tracking during the iteration process, thereby enabling a unified treatment of nonlinear terms.

</details>


### [22] [A unified proof of sharp bounds for the Jacobi heat kernel with trace and estimates of multiplicative constants](https://arxiv.org/abs/2512.16306)
*Adam Nowak,Paweł Plewa,Tomasz Z. Szarek*

Main category: math.AP

TL;DR: A unified, optimized proof of sharp bounds for Jacobi heat kernel with quantitative control of all constants


<details>
  <summary>Details</summary>
Motivation: Previous sharp bounds for Jacobi heat kernel were obtained gradually in several papers; this work aims to provide a unified proof with explicit quantitative control of all multiplicative constants

Method: Develops a unified and optimized proof approach that traces and estimates all constants appearing throughout the reasoning, allowing quantitative control of multiplicative constants in terms of parameters

Result: Obtains quantitative control of multiplicative constants in Jacobi heat kernel bounds, which extends to spherical heat kernel and all other heat kernels on compact rank one symmetric spaces

Conclusion: Provides a comprehensive, quantitatively controlled proof framework for Jacobi heat kernel bounds with applications to related heat kernels on symmetric spaces

Abstract: We give a unified and optimized proof of the sharp bounds for the Jacobi heat kernel, which were obtained gradually in several papers in recent years. We lay particular emphasis on tracing and estimating all constants appearing throughout the entire reasoning. This allows us to quantitatively control the multiplicative constants in the Jacobi heat kernel bounds in terms of the parameters involved. Consequently, analogous control extends to a number of interrelated heat kernels. In particular, we obtain quantitative control in terms of the associated dimension for the spherical heat kernel and for all other heat kernels on compact rank one symmetric spaces.

</details>


### [23] [Bifurcating domains for an overdetermined eigenvalue problem in cylinders](https://arxiv.org/abs/2512.16319)
*Yuanyuan Lian,Filomena Pacella,Pieralberto Sicbaldi*

Main category: math.AP

TL;DR: The paper studies an overdetermined eigenvalue problem in domains within a half-cylinder, showing that nontrivial solutions bifurcate from trivial cylindrical domains at specific parameter values.


<details>
  <summary>Details</summary>
Motivation: To construct domains beyond simple bounded cylinders where the overdetermined eigenvalue problem admits positive eigenfunctions, moving beyond the trivial case where solutions exist in any bounded cylinder.

Method: Using bifurcation theory to show that branches of nontrivial domains bifurcate from the trivial cylindrical domains Ω_t at specific values t_j = π/(2√σ_j), where σ_j are simple Neumann eigenvalues of the Laplace operator on the base domain ω.

Result: The paper successfully constructs other domains Ω ⊂ Σ for which positive eigenfunctions exist as solutions to the overdetermined problem, generated through bifurcation from trivial cylindrical domains at critical parameter values.

Conclusion: Nontrivial solutions to the overdetermined eigenvalue problem in cylindrical-like domains can be obtained through bifurcation from trivial cylindrical domains at specific parameter values, and these solutions can be reflected to generate solutions in full cylinders.

Abstract: We study an overdetermined eigenvalue problem for domains $Ω$ contained in the half-cylinder $Σ=ω\times (0, +\infty)$, based on a bounded regular domain $ω\subset \mathbb{R}^{N-1}$. It is easy to see that in any bounded cylinder $Ω_{t}=ω\times (0, t)$, $t > 0$, the eigenvalue problem admits a one-dimensional positive eigenfunction which satisfies the overdetermined boundary conditions. The aim of the paper is to construct other domains $Ω\subset Σ$ for which there exists a positive eigenfunction that is a solution of the overdetermined problem. This is achieved by showing that branches of such domains bifurcate from the ``trivial'' domains $Ω_{t_j}$ at the values $t_{j} = \fracπ{2\sqrt{σ_j}}$ where $σ_j$ ($j\geq 1$) is a simple Neumann eigenvalue of the Laplace operator on $ω\subset \mathbb{R}^{N-1}$. The solutions can be reflected with respect to $ω$ to generate nontrivial solutions in a cylinder.

</details>


### [24] [Nekhoroshev type stability for Ultra-differential Hamiltonian in $L^2$ space](https://arxiv.org/abs/2512.16332)
*Bingqi Yu,Li Yong*

Main category: math.AP

TL;DR: The paper develops a normal form lemma for infinite-dimensional Hamiltonian systems with ultra-differentiable regularity, proving sub-exponential stability times for various Hamiltonian PDEs including Schrödinger equations and beam equations.


<details>
  <summary>Details</summary>
Motivation: To establish stability results for Hamiltonian PDEs by combining decay of high modes with smallness from high orders, extending previous results to ultra-differentiable regularity classes and achieving optimal stability bounds.

Method: Develops a normal form lemma for infinite-dimensional Hamiltonian systems under ultra-differentiable regularity, combining decay of high modes with smallness introduced by high orders. Applies this framework to analyze stability of various Hamiltonian PDEs.

Result: Proves sub-exponential stability time for a wide class of Hamiltonian PDEs including Schrödinger equations with convolution potentials, fractional-order Schrödinger equations, and beam equations. Achieves Bourgain's predicted optimal bound when conditions match previous ones, and obtains earlier results under lower conditions.

Conclusion: The paper establishes a general framework for analyzing Hamiltonian PDEs with ultra-differentiable regularity, providing optimal stability bounds and extending previous results to broader conditions and equation classes.

Abstract: This paper combines the decay of high modes with the smallness introduced by high orders, leading to a normal form lemma for infinite-dimensional Hamiltonian systems under ultra-differentiable regularity. We prove the sub-exponential stability time of a wide class of Hamiltonian PDEs, including the Schrödinger equation with convolution potentials, fractional-order Schrödinger equations, and beam equations with metrics. When the conditions are equivalent to previous ones, the stability time we obtain reaches Bourgain's predicted optimal bound. Furthermore, we approach earlier results under lower conditions. These results are discussed within a general framework we propose, which applies to the ultra-differential class.

</details>


### [25] [Quantitative stratification and optimal regularity for harmonic almost complex structures](https://arxiv.org/abs/2512.16341)
*Chang-Yu Guo,Ming-Lun Liu,Chang-Lin Xiang*

Main category: math.AP

TL;DR: New proof of partial regularity and rectifiability of singularities for energy minimizing harmonic almost complex structures, improving previous results.


<details>
  <summary>Details</summary>
Motivation: To provide simpler proofs and stronger results than He's work on regularity theory for energy minimizing harmonic almost complex structures.

Method: 1) New observation on equation structure for simpler partial regularity proof. 2) Quantitative stratification method from Naber-Valtorta to prove rectifiability of singular stratum. 3) Combined approach to establish optimal regularity theory.

Result: 1) Easier new proof of partial regularity theorem. 2) Rectifiability of singular stratum. 3) Optimal regularity theory that improves He's corresponding result.

Conclusion: The paper provides significant improvements over previous work: simpler proofs, stronger results on singularities, and optimal regularity theory for energy minimizing harmonic almost complex structures.

Abstract: In a recent interesting work [15], W.Y. He established the important partial regularity theory and the almost optimal higher regularity theory for energy minimizing harmonic almost complex structures. Based on a new observation on the structure of equations, we give an easier new proof of the partial regularity theorem, and adapting the powerful quantitative stratification method of Naber-Valtorta [22], we further prove the rectifiability of singular stratum of energy minimizing harmonic almost complex structures. Based on this, we establish an optimal regularity theory, which improves the corresponding result of He.

</details>


### [26] [Homogenization of a micropolar fluid past a porous media with non-zero spin boundary condition](https://arxiv.org/abs/2512.16353)
*Francisco J. Suárez-Grau*

Main category: math.AP

TL;DR: Analysis of micropolar fluid flow in porous media with periodic obstacles, deriving Darcy law analogue through homogenization.


<details>
  <summary>Details</summary>
Motivation: To understand micropolar fluid behavior in porous media with non-homogeneous boundary conditions for microrotation, and to derive macroscopic laws through homogenization.

Method: Mathematical analysis of micropolar fluid equations in periodically perforated domains with size ε obstacles, using non-homogeneous boundary conditions where microrotation is proportional to velocity rotation rate on boundaries.

Result: Proved existence and uniqueness of solution for the micropolar fluid system, and derived a micropolar Darcy law analogue through homogenization as ε→0.

Conclusion: The study successfully extends classical porous media theory to micropolar fluids, providing rigorous mathematical foundation for macroscopic flow laws in such complex media.

Abstract: We consider a micropolar fluid flow in a media perforated by periodically distributed obstacles of size $\varepsilon$. A non-homogeneous boundary condition for microrotation is considered: the microrotation is assumed to be proportional to the rotation rate of the velocity on the boundary of the obstacles. The existence and uniqueness of solution is analyzed. Moreover, passing to the limit when $\varepsilon$ tends to zero, an analogue of the classical micropolar Darcy law in the theory of porous media is derived.

</details>


### [27] [Uniform vanishing damping limit for the 2D inviscid Oldroyd-B model with fractional stress tensor diffusion](https://arxiv.org/abs/2512.16436)
*Chen Liang,Zhaonan Luo,Zhaoyang Yin*

Main category: math.AP

TL;DR: The paper studies uniform vanishing damping limit in 2D inviscid Oldroyd-B model with fractional stress tensor diffusion, establishing optimal time decay rates and uniform damping vanishing rates.


<details>
  <summary>Details</summary>
Motivation: To understand how fractional stress tensor diffusion affects the global regularity and time decay behavior of the 2D Oldroyd-B model with damping, and to establish uniform vanishing damping limits.

Method: Uses improved Fourier splitting method for time decay analysis, spectral analysis methods for improving decay rates of stress tensor trace, and combines time decay rates with time integrability to obtain uniform damping vanishing rates.

Result: Fractional stress tensor diffusion reduces global regularity requirements; optimal time decay rates established for a=0; uniform time decay rates for a∈(0,1]; uniform damping vanishing rates obtained; sharp uniform damping vanishing rates for stress tensor trace trτ.

Conclusion: The paper successfully establishes uniform vanishing damping limits for the 2D Oldroyd-B model with fractional diffusion, providing optimal decay rates and demonstrating how fractional diffusion improves regularity and decay properties.

Abstract: This paper is devoted to the uniform vanishing damping limit of the 2D inviscid Oldroyd-B model with fractional stress tensor diffusion. Firstly, we find that fractional stress tensor diffusion helps to reduce the global regularity of the 2D Oldroyd-B model with damping coefficient $a\in[0,1]$. By virtue of improved Fourier splitting method, we then prove the optimal time decay rates under the critical regularity for $a=0$. When $a\in (0,1]$, we establish time decay rates that are uniform with respect to $a$. Combining the time decay rate for $a\in [0,1]$ and the time integrability, we obtain the uniform damping vanishing rates for the 2D Oldroyd-B model. Using spectral analysis methods, we finally improve the time decay rates for $\mathrm{tr}τ$ with $a\in (0,1]$, which ensure the sharp uniform damping vanishing rates of $\mathrm{tr}τ$.

</details>


### [28] [Normalized solutions for a class of fractional Choquard equations with mixed nonlinearities](https://arxiv.org/abs/2512.16438)
*Shaoxiong Chen,Zhipeng Yang,Xi Zhang*

Main category: math.AP

TL;DR: Study of fractional Choquard equation with mixed nonlinearities and mass constraint, establishing existence and multiplicity of normalized solutions, including ground states for small α.


<details>
  <summary>Details</summary>
Motivation: To investigate normalized solutions (solutions with prescribed L²-norm) for fractional Choquard equations with competing nonlocal nonlinearities, which arise in quantum physics models like Bose-Einstein condensates.

Method: Variational methods for constrained minimization problems, using fractional Laplacian operator, Riesz potentials, and analysis of competing nonlinear terms with parameters satisfying specific exponent ranges.

Result: Proved existence and multiplicity of normalized solutions, and established existence of ground state normalized solutions for sufficiently small α parameter.

Conclusion: The fractional Choquard equation with mixed nonlinearities admits normalized solutions with prescribed mass, including ground states, under appropriate parameter conditions and small α.

Abstract: In this paper we study the following fractional Choquard equation with mixed nonlinearities:
  \[
  \left\{
  \begin{array}{l}
  (-Δ)^s u = λu + α\left( I_μ* |u|^q \right) |u|^{q-2} u + \left( I_μ* |u|^p \right) |u|^{p-2} u, \quad x \in \mathbb{R}^N, \\[4pt]
  \displaystyle \int_{\mathbb{R}^N} |u|^2 \,\mathrm{d}x = c^2 > 0.
  \end{array}
  \right.
  \]
  Here $N > 2s$, $s \in (0,1)$, $μ\in (0, N)$, and the exponents satisfy
  \[
  \frac{2N - μ}{N} < q < p < \frac{2N - μ}{N - 2s},
  \]
  while $α> 0$ is a sufficiently small parameter, $λ\in \mathbb{R}$ is the Lagrange multiplier associated with the mass constraint, and $I_μ$ denotes the Riesz potential. We establish existence and multiplicity results for normalized solutions and, in addition, prove the existence of ground state normalized solutions for $α$ in a suitable range.

</details>


### [29] [Global existence and stability of near-affine solutions of compressible elastodynamics](https://arxiv.org/abs/2512.16505)
*Xianpeng Hu,Yuanzhi Tu,Changyou Wang,Huanyao Wen*

Main category: math.AP

TL;DR: Global existence and asymptotic behavior of strong solutions for compressible nonlinear elastodynamics in 2D and 3D under small H³ perturbations of affine solutions.


<details>
  <summary>Details</summary>
Motivation: To establish global well-posedness and long-time behavior for compressible nonlinear elastodynamics, which describes wave propagation in elastic materials, going beyond local existence results to prove global solutions exist for small perturbations.

Method: Analysis of the Cauchy problem for compressible nonlinear elastodynamics equations in ℝᵈ (d=2,3), using perturbation theory around affine solutions, working in H³ Sobolev spaces for small initial data perturbations.

Result: Proves that for sufficiently small H³-perturbations of affine solutions, the compressible nonlinear elastodynamics system admits a unique global strong solution in 2D and 3D, and establishes the asymptotic decay behavior of solutions.

Conclusion: The compressible nonlinear elastodynamics system exhibits global well-posedness for small perturbations of affine states, with solutions decaying asymptotically, demonstrating stability of affine solutions in this nonlinear wave system.

Abstract: We prove that for sufficiently small $H^3$-perturbations of an affine solution, the Cauchy problem for the compressible nonlinear elastodynamics in $\mathbb{R}^d$, for $d=2,3$, admits a unique global strong solution. Moreover, we establish the asymptotic behavior of the solution.

</details>


### [30] [Liouville-type Theorems for Stable Solutions of the Hénon-Lane-Emden System](https://arxiv.org/abs/2512.16566)
*Long-Han Huang,Wenming Zou*

Main category: math.AP

TL;DR: The paper establishes Liouville-type theorems for the Hénon-Lane-Emden system with singular weights, covering both subcritical and supercritical cases, with applications to solutions stable outside compact sets.


<details>
  <summary>Details</summary>
Motivation: To study nonexistence (Liouville-type) results for the Hénon-Lane-Emden system with singular coefficients |x|^a and |x|^b, particularly for solutions that are stable outside a compact set, which extends previous work on related systems.

Method: The authors first prove a general Liouville theorem for the subcritical case, then establish conditions under which the Hénon-Lane-Emden conjecture holds for solutions stable outside compact sets. They consider various parameter regimes including when 0 < min{p,q} < 1, or when certain inequalities involving a, b, N, p, q hold. Additional subcritical results and supercritical case analysis are also developed.

Result: The paper proves several Liouville-type theorems: 1) A general theorem for the subcritical case, 2) Validity of the Hénon-Lane-Emden conjecture for solutions stable outside compact sets under specified conditions, 3) Additional subcritical results, and 4) Results for the supercritical case. These constitute the first Liouville-type theorems for this class of solutions in the Hénon-Lane-Emden system.

Conclusion: The paper successfully establishes comprehensive Liouville-type theorems for the Hénon-Lane-Emden system with singular weights, covering both subcritical and supercritical regimes. The results refine existing literature and provide new nonexistence criteria for solutions stable outside compact sets.

Abstract: We investigate the Hénon-Lane-Emden system defined by $- Δu=|x|^a |v|^{p-1}v$ and $- Δv=|x|^b |u|^{q-1}u$ in $\mathbb{R}^N \!\setminus\! \{0\}$. We begin by establishing a general Liouville-type theorem for the subcritical case. Then we prove that the Hénon-Lane-Emden conjecture is valid for solutions stable outside a compact set, provided that $0 < \min\,\{p, q\} < 1$, or $0 \leq a - b \leq (N-2)(p - q)$, or $N \leq \frac{2(p+q+2)}{pq-1} + 10$. Additional Liouville-type theorems for the subcritical case are also obtained. Furthermore, we address the supercritical case. To our knowledge, these results constitute the first Liouville-type theorems for this class of solutions in the Hénon-Lane-Emden system. As a by-product, several existing results in the literature are refined.

</details>


### [31] [Constructing steering-type solutions for higher order Cauchy-Riemann equations in $\mathbb{R}^{m+1}$](https://arxiv.org/abs/2512.16594)
*Daniel Alfonso Santiesteban,Dixan Peña Peña,Ricardo Abreu Blaya*

Main category: math.AP

TL;DR: The paper constructs explicit solutions to PDE systems using the multidimensional Cauchy-Riemann operator framework, showing some solutions also satisfy hypercomplex derivative equations.


<details>
  <summary>Details</summary>
Motivation: To develop explicit solution methods for higher-order PDE systems in ℝ^{m+1} using the multidimensional Cauchy-Riemann operator framework, which generalizes polymonogenic and polyharmonic functions.

Method: Construct solutions from families of complex-valued functions closed under conjugation and the action of the complex Cauchy-Riemann operator. Prove connections between these solutions and homogeneous linear differential equations involving the hypercomplex derivative.

Result: Explicit construction of solutions to PDE systems generated from special function families. Proof that some of these solutions also satisfy homogeneous linear differential equations with hypercomplex derivative.

Conclusion: The multidimensional Cauchy-Riemann framework enables systematic construction of solutions to higher-order PDEs, with connections to hypercomplex derivative equations providing deeper structural insights.

Abstract: The multidimensional Cauchy-Riemann operator provides a framework for studying higher order partial differential equations in $\mathbb{R}^{m+1}$, whose solutions include polymonogenic and polyharmonic functions, among others. In this work, we aim to explicitly construct solutions to such systems, generated from families of complex valued functions which are closed under conjugation and under the action of the complex Cauchy-Riemann operator. Moreover, we prove that precisely some of these solutions also satisfy homogeneous linear differential equations involving the so-called hypercomplex derivative.

</details>


### [32] [Regularity for fully nonlinear elliptic equations in generalized Orlicz spaces](https://arxiv.org/abs/2512.16600)
*Sun-Sig Byun,Jeongmin Han,Mikyoung Lee*

Main category: math.AP

TL;DR: Optimal global Calderón-Zygmund estimate for viscosity solutions of fully nonlinear elliptic equations with nonconvex nonlinearities in generalized Orlicz spaces.


<details>
  <summary>Details</summary>
Motivation: To establish global regularity estimates for viscosity solutions of fully nonlinear elliptic equations, particularly when dealing with nonconvex nonlinearities and asymptotically convex cases, which are challenging scenarios in elliptic PDE theory.

Method: Proves an optimal global Calderón-Zygmund type estimate for the Hessian of viscosity solutions to Dirichlet boundary problems of fully nonlinear elliptic equations, working within the framework of generalized Orlicz spaces.

Result: Shows that the Hessian of the solution has the same integrability as the nonhomogeneous term, even when the nonlinearity is asymptotically convex with respect to the Hessian of the solution.

Conclusion: Establishes a comprehensive regularity theory for viscosity solutions of fully nonlinear elliptic equations with nonconvex nonlinearities, extending Calderón-Zygmund estimates to more general settings including asymptotically convex cases.

Abstract: In this paper, we establish an optimal global Calderón-Zygmund type estimate for the viscosity solution to the Dirichlet boundary problem of fully nonlinear elliptic equations with possibly nonconvex nonlinearities. We prove that the Hessian of the solution is as integrable as the nonhomogeneous term in the setting of a given generalized Orlicz space even when the nonlinearity is asymptotically convex with respect to the Hessian of the solution.

</details>


### [33] [Existence and stability of discretely self-similar blowup for a wave maps type equation](https://arxiv.org/abs/2512.16623)
*Irfan Glogić,David Hilditch,David Wallauch*

Main category: math.AP

TL;DR: The paper constructs and analyzes nonlinear stability of discretely self-similar blowup solutions for a geometric wave equation mapping from Minkowski space to the 1-sphere, with detailed spectral analysis in all dimensions.


<details>
  <summary>Details</summary>
Motivation: To study finite-time blowup phenomena for geometric wave equations with null-form structure, particularly establishing existence and stability of discretely self-similar blowup solutions - a first result for geometric wave equations.

Method: Construct countable family of discretely self-similar blowup solutions for all dimensions d≥1. Perform detailed nonlinear stability analysis by linearizing around self-similar profiles in similarity variables, constructing resolvents via Liouville-Green transformations and Volterra-type asymptotics, and conducting spectral analysis of linearized operators.

Result: Successfully constructs discretely self-similar blowup solutions for all dimensions d≥1 (even for d=1, radial for d≥2). Establishes nonlinear stability of all these profiles with precise co-dimension determined by unstable spectrum, providing sharp semigroup bounds.

Conclusion: This represents the first existence and stability result for discretely self-similar blowup in geometric wave equations, with comprehensive analysis covering arbitrary dimensions and a countable family of operators, overcoming significant technical challenges in non-self-adjoint operator theory.

Abstract: We study finite-time blowup for a nonlinear wave equation for maps from the Minkowski space $\mathbb{R}^{1+d}$ into the 1-sphere $\mathbb{S}^1$, whose nonlinearity exhibits a null-form structure. We construct, for every dimension $d \geq 1$, a countable family of discretely self-similar blowup solutions, which are even for $d=1$ and radial for $d \geq 2$. The main contribution of the paper is a detailed nonlinear stability analysis of this family of solutions. For $d \geq 2$, we consider radial data, while in $d=1$ we allow for general perturbations. After linearizing around the self-similar profiles in similarity variables, we construct resolvents of the resulting highly non-self-adjoint operators through Liouville-Green transformations and precise Volterra-type asymptotics. The construction itself, which occupies most of the paper, is technically challenging, as it is performed in arbitrary dimensions and for a countable family of operators in each. Combined with a detailed spectral analysis of the linearized operators, this yields sharp semigroup bounds and allows us to establish nonlinear stability of all discretely self-similar profiles in all dimensions, with precise co-dimension determined by the unstable spectrum. To our knowledge, this is the first result on the existence and stability of discretely self-similar blowup for a geometric wave equation.

</details>


### [34] [The capillary Christoffel-Minkowski problem](https://arxiv.org/abs/2512.16655)
*Xinqun Mei,Guofang Wang,Liangjun Weng*

Main category: math.AP

TL;DR: Introduces k-th capillary area measure for capillary convex bodies in Euclidean half-space and solves the corresponding Christoffel-Minkowski problem with existence/uniqueness results.


<details>
  <summary>Details</summary>
Motivation: To extend classical area measure theory to capillary convex bodies (convex bodies in half-space with contact angle boundary conditions) and formulate a boundary counterpart to the Christoffel-Minkowski problem.

Method: Define k-th capillary area measure for capillary convex bodies, formulate Christoffel-Minkowski problem for these bodies, reduce to solving Hessian-type equation with Robin boundary condition, apply PDE techniques.

Result: Establish existence and uniqueness of smooth solution to the Christoffel-Minkowski problem for capillary convex bodies under natural sufficient conditions.

Conclusion: Successfully extends classical convex geometry concepts to capillary setting, solving the capillary Christoffel-Minkowski problem with rigorous existence/uniqueness results.

Abstract: In this article, we introduce a $k$-th capillary area measure for capillary convex bodies in the Euclidean half-space, which serves as a boundary counterpart to the classical concept of area measure (see, e.g., \cite[Chapter 8]{Sch}). We then propose a Christoffel-Minkowski problem for capillary convex bodies, to find a capillary convex body in the Euclidean half-space with a prescribed $k$-th capillary area measure. This problem is equivalent to solving a Hessian-type equation with a Robin boundary value condition. We then establish the existence and uniqueness of a smooth solution under a natural sufficient condition.

</details>


### [35] [Unconditional uniqueness of Hardy--Hénon parabolic equations on Herz spaces](https://arxiv.org/abs/2512.16711)
*Naoya Hatano,Masahiro Ikeda*

Main category: math.AP

TL;DR: The paper proves unconditional uniqueness for Hardy-Hénon parabolic equation solutions in Herz spaces, handling power-type weights better than previous results.


<details>
  <summary>Details</summary>
Motivation: To establish uniqueness results for the Hardy-Hénon parabolic equation (semilinear heat equation with power-type weight |x|^γ|u|^{α-1}u) in Herz spaces, which are better suited for handling power-type weights than traditional function spaces.

Method: Using Herz spaces $\dot{K}^s_{q,r}({\mathbb R}^n)$ to analyze solutions, relaxing constraints from previous results by addressing the endpoint case q=α and large interpolation exponent case r≥q.

Result: Achieved unconditional uniqueness of solutions in Herz spaces, effectively handling the power-type weight in the nonlinear term and improving upon previous limitations.

Conclusion: Herz spaces provide an effective framework for analyzing the Hardy-Hénon parabolic equation with power-type weights, yielding improved uniqueness results compared to previous approaches.

Abstract: In this paper, we introduce the unconditional uniqueness of solutions in Herz spaces for the Hardy--Hénon parabolic equation, which is a semilinear heat equation with a power-type weight in the nonlinear term $|x|^γ|u|^{α-1}u$. It is expected that the power-type weight in the nonlinear term can be effectively handled within Herz spaces. In fact, our result in Herz spaces $\dot{K}^s_{q,r}({\mathbb R}^n)$ relaxes the endpoint case $q=α$ and the large interpolation exponent case $r\ge q$ compared to previous results.

</details>


### [36] [Stability under lamination and polycrystalline effective conductivity](https://arxiv.org/abs/2512.16787)
*Nathan Albin,Vincenzo Nesi,Mariapia Palombaro*

Main category: math.AP

TL;DR: The paper proves stability under lamination for a set of 3×3 symmetric matrices representing effective conductivities of polycrystals, contributing to improved inner bounds on G-closure.


<details>
  <summary>Details</summary>
Motivation: To advance the understanding of effective material properties in polycrystals by establishing stability properties that help characterize the complete set of achievable effective conductivities (G-closure).

Method: The authors prove mathematical stability under lamination for a specific set of real, symmetric 3×3 matrices constructed in a companion paper, using analytical techniques to establish that this set remains stable under the lamination process.

Result: Successfully proves the stability under lamination of the constructed matrix set, which when combined with previous constructions provides the best known inner bound on the G-closure of three-dimensional polycrystals.

Conclusion: The stability result represents significant progress in characterizing the G-closure of 3D polycrystals, providing the tightest known inner bound and advancing the mathematical theory of effective material properties.

Abstract: We prove the stability under lamination of a set of real, symmetric 3$\times$3 matrices that can be viewed as a subset of the effective conductivities of a polycrystal. Constructed in a companion paper, such set in combination with several previous constructions provides the best inner bound known so far on the $G$-closure of a three dimensional polycrystal.

</details>


### [37] [On Some Transformations Associated to a Certain Cone](https://arxiv.org/abs/2512.16840)
*Vladimir Vasilyev,Denis Tokarev*

Main category: math.AP

TL;DR: Analysis of elliptic pseudo-differential equations in 4-faced cones using Sobolev-Slobodetskii spaces, with explicit solution formulas and boundary value problem solvability proofs.


<details>
  <summary>Details</summary>
Motivation: To study elliptic pseudo-differential equations in complex geometric domains (4-faced cones) and develop solution methods for boundary value problems with integral conditions, which have applications in mathematical physics and engineering.

Method: Uses Sobolev-Slobodetskii function spaces, evaluates Bochner kernel for 4-faced cones, derives explicit solution formulas under symbol restrictions, and analyzes boundary value problems with additional integral conditions.

Result: Obtained explicit formula for unique solution to the elliptic pseudo-differential equation, proved unique solvability of boundary value problem with integral condition, and evaluated the Bochner kernel for 4-faced cones.

Conclusion: Successfully developed analytical framework for solving elliptic pseudo-differential equations in 4-faced cones, providing explicit solution formulas and proving solvability of boundary value problems with integral conditions.

Abstract: A model elliptic pseudo-differential equation in $4$-faced cone is studied in Sobolev--Slobodetskii space. The Bochner kernel for such a cone is evaluated and explicit formula for unique solution to the considered equation is presented under certain restrictions on the symbol. Boundary value problem with additional integral condition is considered and unique solvability to the boundary value problem is proved.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [38] [Sparse Operator-Adapted Wavelet Decomposition Using Polygonal Elements for Multiscale FEM Problems](https://arxiv.org/abs/2512.16004)
*Furkan Şık,F. L. Teixeira,B. Shanker*

Main category: physics.comp-ph

TL;DR: A sparse multiscale wavelet-based FEM using adaptive polygonal mesh hierarchies with nearly linear computational complexity.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient finite element method that can handle complex domains with varying resolution needs while maintaining computational efficiency through adaptive mesh hierarchies.

Method: Uses operator-adapted wavelet decomposition on unstructured polygonal mesh hierarchies obtained via geometric coarsening. Starts with triangular elements at finest level, coarsens to convex polygons. Decouples resolution levels for independent solving.

Result: Achieves memory efficiency through adaptivity (smaller elements in high-gradient regions, larger in smooth regions). Enables hierarchical sparse linear-algebra operations with nearly linear computational complexity.

Conclusion: The method provides an efficient, adaptive FEM approach that combines multiscale decomposition with polygonal meshes for improved computational performance and memory usage.

Abstract: We develop a sparse multiscale operator-adapted wavelet decomposition-based finite element method (FEM) on unstructured polygonal mesh hierarchies obtained via a coarsening procedure. Our approach decouples different resolution levels, allowing each scale to be solved independently and added to the entire solution without the need to recompute coarser levels. At the finest level, the meshes consist of triangular elements which are geometrically coarsened at each step to form convex polygonal elements. Smooth field regions of the domain are solved with fewer, larger, polygonal elements, whereas high-gradient regions are represented by smaller elements, thereby improving memory efficiency through adaptivity. The proposed algorithm computes solutions via sequences of hierarchical sparse linear-algebra operations with nearly linear computational complexity.

</details>


### [39] [ClusTEK: A grid clustering algorithm augmented with diffusion imputation and origin-constrained connected-component analysis: Application to polymer crystallization](https://arxiv.org/abs/2512.16110)
*Elyar Tourani,Brian J. Edwards,Bamin Khomami*

Main category: physics.comp-ph

TL;DR: A grid clustering framework using Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis to overcome parameter sensitivity and edge misclassification issues in traditional grid clustering.


<details>
  <summary>Details</summary>
Motivation: Grid clustering algorithms are efficient for large-scale data but suffer from parameter sensitivity, loss of structural detail at coarse resolutions, and misclassification of edge/bridge cells at fine resolutions. Existing solutions (adaptive grids, parameter tuning, hybrid methods) offer limited robustness.

Method: Integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid. Automated preprocessing provides data-driven cell size and density thresholds. Diffusion mitigates sparsity and reconstructs missing edge cells without over-smoothing. OC-CCA constrains component growth to physically consistent origins to reduce false merges. Uses fixed-resolution grid with spatial indexing for O(n log n) scaling.

Result: Method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems (9k, 180k, and 989k atoms) shows atomic-level accuracy, captures physically meaningful morphologies, and delivers accelerated computation.

Conclusion: The proposed framework overcomes key limitations of traditional grid clustering through diffusion-based reconstruction and origin-constrained analysis, achieving both high accuracy and computational efficiency for large-scale data analysis.

Abstract: Grid clustering algorithms are valued for their efficiency in large-scale data analysis but face persistent limitations: parameter sensitivity, loss of structural detail at coarse resolutions, and misclassifications of edge or bridge cells at fine resolutions. Previous studies have addressed these challenges through adaptive grids, parameter tuning, or hybrid integration with other clustering methods, each of which offers limited robustness. This paper introduces a grid clustering framework that integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid to reconstruct the cluster topology with high accuracy and computational efficiency. During grid construction, an automated preprocessing stage provides data-driven estimates of cell size and density thresholds. The diffusion step then mitigates sparsity and reconstructs missing edge cells without over-smoothing physical gradients, while OC-CCA constrains component growth to physically consistent origins, reducing false merges across narrow gaps. Operating on a fixed-resolution grid with spatial indexing ensures the scaling of O(nlog n). Experiments on synthetic benchmarks and polymer simulation datasets demonstrate that the method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems across scales (9k, 180k, and 989k atoms) shows that optimal preprocessing, combined with diffusion-based clustering, reproduces atomic-level accuracy and captures physically meaningful morphologies while delivering accelerated computation.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [40] [Tensor network approaches for plasma dynamics](https://arxiv.org/abs/2512.15924)
*Ryan J. J. Connor,Preetma Soin,Callum W. Duncan,Andrew J. Daley*

Main category: physics.plasm-ph

TL;DR: Tensor networks (specifically Matrix Product States) can efficiently simulate plasma dynamics described by Vlasov-Maxwell and Magnetohydrodynamics systems, with validation against Particle-In-Cell codes for industrial applications.


<details>
  <summary>Details</summary>
Motivation: Plasma dynamics governed by non-linear differential equations are computationally challenging for large 2D/3D problems, requiring more efficient simulation methods.

Method: Apply tensor networks (Matrix Product States) to Vlasov-Maxwell system and Magnetohydrodynamics, testing different parameter regimes and tensor network geometries.

Result: Matrix Product States work well for low-dimensional problems, but strong magnetic fields or high-dimensional cases may require alternative tensor network geometries. Results validated against state-of-the-art Particle-In-Cell codes.

Conclusion: Tensor networks show promise for efficient plasma simulations across different descriptions (Vlasov-Maxwell and Magnetohydrodynamics), with potential for industrial applications.

Abstract: The dynamics of plasmas are governed by a set of non-linear differential equations which remain challenging to solve directly for large 2D and 3D problems. Here we investigate how tensor networks could be applied to plasmas described by the Vlasov-Maxwell system of equations and investigate parameter regimes which show promise for efficient simulations. We show for low-dimensional problems that the simplest form of tensor networks known as a Matrix Product State performs sufficiently well, however in regimes with a strong permanent magnetic field or high-dimensional problems one may need to consider alternative tensor network geometries. We conclude the study of the Vlasov-Maxwell system with the application of tensor networks to an industrially relevant test case and validate our results against state of the art plasma solvers based on Particle-In-Cell codes. We also extend the application of tensor networks to the alternative plasma description of Magnetohydrodynamics and outline how this can be encoded using Matrix Product States.

</details>


### [41] [Toward the Origins of Binding Energy Shifts and Satellites Formation During Plasma-XPS Measurements](https://arxiv.org/abs/2512.16196)
*J. Trey Diulus,Ashley R. Head,Jorge Anibal Boscoboinik,Carles Corbella Roca,Alexander Tselev,Andrei Kolmakov*

Main category: physics.plasm-ph

TL;DR: Plasma XPS enables real-time chemical analysis of plasma-exposed surfaces, revealing transient species and showing how plasma parameters affect binding energy shifts and satellite peaks in conductive, dielectric, and gas phase systems.


<details>
  <summary>Details</summary>
Motivation: To understand the origins of binding energy shifts and satellite peaks observed during plasma XPS measurements, which is crucial for accurate chemical analysis under plasma processing conditions relevant to semiconductor manufacturing and other plasma technologies.

Method: Used a standard laboratory ambient pressure XPS apparatus coupled with an alternating current driven capacitively coupled plasma source to study conductive (Au), dielectric, and gas phase systems under plasma exposure.

Result: Detected metastable surface species like transient Au oxides; observed pressure- and plasma-type dependent BE shifts up to 50 eV in dielectrics due to charging effects; found spectral broadening and satellite peaks in gas phase species from oscillating plasma potentials; showed mitigation of charging at higher pressures or in electronegative plasmas.

Conclusion: Plasma XPS is a critical metrological tool for probing transient surface chemistry, with complex interplay between plasma parameters, surface charging, and local electric fields shaping XPS spectra, having important implications for semiconductor processing and plasma diagnostics.

Abstract: In plasma X ray photoelectron spectroscopy emerges as a powerful platform for real time, in situ chemical analysis under conditions relevant to semiconductor processing and other plasma enabled technologies. This study investigates the origins of binding energy shifts and satellite peaks formation observed during plasma XPS measurements across conductive, dielectric, and gas phase systems. Using a standard laboratory based ambient pressure XPS apparatus coupled with an alternating current driven capacitively coupled plasma source, we show that metastable surface species, such as transient Au oxides, can be detected during plasma exposure, revealing chemical states hardly accessible using conventional ultrahigh vacuum XPS. In dielectric samples, we observe pressure- and plasma type dependent BE shifts up to 50 eV, attributed to X ray induced and plasma mediated surface charging. These shifts are mitigated at higher pressures plasmas or in electronegative plasmas, the latter due to enhanced charge compensation mechanisms involving slow negative ions. For gas phase species, AC plasma excitation leads to spectral broadening and the emergence of satellite peaks with a few eV energy separations, linked to oscillating local plasma potentials in the probing volume. These findings highlight the important and complex interplay of plasma parameters, surface charging, and local electric fields in shaping XPS spectra. Overall, plasma XPS emerges as a critical metrological tool for probing transient surface chemistry, with implications for semiconductor processing, material synthesis, and plasma diagnostics.

</details>


### [42] [SCOPE: Simple Coil Optimization for Plasma and Engineering](https://arxiv.org/abs/2512.16546)
*Nathan Welch,Chris Marsden*

Main category: physics.plasm-ph

TL;DR: A simulated annealing optimization method for designing superconducting tokamak coils that handles multiple plasma scenarios, engineering constraints, and HTS cable limits while enabling efficient computation.


<details>
  <summary>Details</summary>
Motivation: Superconducting coil design for tokamaks is complex due to coupled engineering requirements, HTS cable limits, multiple plasma operational scenarios, divertor optimization needs, and physical space constraints - requiring a comprehensive optimization approach.

Method: Combined simulated annealing for coil sizes/positions with constrained quadratic/quartic optimization for coil currents, designed to optimize for multiple scenarios simultaneously (including ramp-ups) to avoid single-point over-optimization.

Result: Efficient implementation enabling millions of evaluations in hours with modest computational power, integrated into larger iterative workflow allowing detailed design feedback into optimization process.

Conclusion: The method provides a practical optimization framework for tokamak coil design that addresses multiple engineering and operational constraints simultaneously while maintaining computational efficiency for iterative design workflows.

Abstract: Designing superconducting coils for a tokamak fusion device is a highly coupled, non-linear design problem. The coils have many disparate engineering requirements from structural to power electronics, as well strict limits placed on the system by the high temperature superconducting (HTS) cables. Simultaneously, the coils must be able to contain multiple plasma scenarios from inception, through ramp up, to flat top, and ramp down, all whilst applying a large, controlled, inductive voltage to drive current. In addition, we wish to optimize divertor separatrices to increase the likelihood of designing a suitable divertor strikepoint. Lastly, the physical limits of the entire tokamak must be taken into account and space reserved for support structures, access for maintenance schemes, and installation limits. The method outlined here uses a combined simulated annealing method to find optimal coil sizes and positions with a constrained quadratic or quartic optimization for the coil currents. The method is designed to optimize coils for multiple scenarios simultaneously, including ramp-ups, to avoid over optimization of a single design point. A key enabler is the efficient implementation that allows millions of evaluations to be performed in a few hours with modest computational power. This optimization method is part of a larger, iterative workflow which enables further, detailed design work to feedback on the optimization.

</details>


### [43] [Disruption Modelling for Engineering and Physics Design of Tokamak Energy ST-E1 Fusion Power Plant](https://arxiv.org/abs/2512.16604)
*M. Scarpari,X. Zhang,K. Borowiec,P. F. Buxton,G. Calabro,S. Carusotti,A. Ciula,V. Godhani,J. D. Lore,E. N. J. Maartensson,S. A. M. McNamara,J. H. Nichols,M. Notazio,M. Robinson,M. Romanelli,J. Willis,ST-E1 Team*

Main category: physics.plasm-ph

TL;DR: Comprehensive disruption modeling approach for ST-E1 fusion power plant design, integrating physics and engineering analyses to assess electromagnetic and thermal impacts across different plasma configurations.


<details>
  <summary>Details</summary>
Motivation: Plasma disruptions threaten tokamak integrity and availability; complete avoidance is impossible, so understanding unmitigated disruption consequences is essential for designing next-generation fusion power plants like ST-E1.

Method: Integrated physics-engineering approach: 1) Engineering analysis of electromagnetic response of components under disruption loads across layout options, 2) Physics analysis of disruption scenarios scanning operational parameters, plasma-material interactions, and thermal loads, 3) Examination of disruption behavior variations from Double Null to Single Null equilibria configurations.

Result: Significant contrasts in plasma dynamics and electromagnetic behavior between configurations; analyses revealed important insights for design choices and have shaped ST-E1 development by identifying risks and optimization opportunities.

Conclusion: Disruption modeling is crucial for guiding fusion reactor design decisions; the integrated approach provides critical insights for risk mitigation and optimization of future fusion power plants like ST-E1.

Abstract: Plasma disruptions represent a critical challenge for high-performance tokamak operations, as they can compromise machine integrity and reduce operational availability. Although future fusion devices essentially need to incorporate strategies to minimise disruption occurrence, complete avoidance remains unattainable. Consequently, assessing and characterising unmitigated disruption consequences is fundamental for the design and qualification of next-generation fusion power plants. This work supports the pre-conceptual design of ST-E1, a low aspect-ratio Tokamak Fusion Power Plant developed by Tokamak Energy Ltd., by presenting a comprehensive disruption modelling approach applied across different design stages. The methodology integrates both physics and engineering considerations to evaluate the impact of disruptions on machine performance and structural integrity. From an engineering perspective, several ST-E1 layout options were analysed to investigate the electromagnetic response of key components under disruption-induced loads, enabling comparison between alternative design solutions. On the physics side, a broad set of disruption scenarios was explored, scanning operational space parameters, plasma-material interactions, and associated thermal loads. Furthermore, the study examined variations in disruption behaviour arising from different reference equilibria, focusing on a range starting from Double Null to Single Null configurations, reflecting the increasing up-down asymmetry consequences. The results reveal significant contrasts in plasma dynamics and structures electromagnetic behaviour between configurations, highlighting the importance of disruption modelling in guiding design choices. These analyses have proven instrumental in shaping ST-E1 development, offering critical insights for mitigating risks and optimising future fusion reactor designs.

</details>


### [44] [Photon Accelerator in Magnetized Plasma](https://arxiv.org/abs/2512.16630)
*Sergei Bulanov,Stepan Bulanov,Timur Esirkepov,Gianluca Gregori,Gabriele Grittani,Brandon Russell,Alec Thomas,Petr Valenta*

Main category: physics.plasm-ph

TL;DR: Magnetic fields enhance photon acceleration in plasmas by altering electromagnetic wave properties and interactions with relativistic plasma waves, leading to increased frequency gain and potentially higher efficiency.


<details>
  <summary>Details</summary>
Motivation: To understand how magnetic fields affect electromagnetic wave propagation in plasmas and their interaction with relativistic plasma waves, particularly for improving photon acceleration efficiency in both laboratory and space environments.

Method: The paper analyzes the theoretical relationship between magnetic fields, electromagnetic waves, and relativistic plasma waves, examining how magnetic fields alter wave dispersion relations and wave-wave interactions.

Result: Magnetic fields cause both quantitative and qualitative changes in photon acceleration properties, amplifying electromagnetic wave frequency increase and potentially leading to higher efficiency of the acceleration process.

Conclusion: The presence of magnetic fields significantly enhances photon acceleration in plasmas by modifying wave properties and interactions, offering potential for improved efficiency in both laboratory experiments and space phenomena applications.

Abstract: Strong magnetic fields and plasmas are intrinsically linked in both terrestrial laboratory experiments and in space phenomena. One of the most profound consequences of that is the change in relationship between the frequency and the wave number of electromagnetic waves propagating in plasma in the presence of such magnetic fields when compared to the case without these fields. Furthermore, magnetic fields alter electromagnetic wave interaction with relativistic plasma waves, resulting in different outcomes for particle and radiation generation. For a relativistic plasma wave-based photon acceleration this leads to an increased frequency gain, and, thus, potentially to higher efficiency. The influence of a magnetic field leads to quantitative and qualitative change in the properties of photon acceleration, amplifying the increase in the electromagnetic wave frequency.

</details>


### [45] [CARONTE: a Physics-Informed Extreme Learning Machine-Based Algorithm for Plasma Boundary Reconstruction in Magnetically Confined Fusion Devices](https://arxiv.org/abs/2512.16689)
*Federico Fiorenza,Sara Dubbioso,Gianmaria De Tommasi,Alfredo Pironti*

Main category: physics.plasm-ph

TL;DR: A physics-informed neural network using Extreme Learning Machine for real-time plasma boundary reconstruction in tokamaks, outperforming traditional methods like JET's algorithm with better generalization and noise robustness.


<details>
  <summary>Details</summary>
Motivation: Need for real-time plasma boundary reconstruction in tokamak devices that can adapt to evolving plasma equilibria, overcome limitations of traditional methods requiring retuning for different plasma conditions, and handle noisy magnetic measurements.

Method: Uses a single Extreme Learning Machine network to solve the homogeneous Grad-Shafranov equation. The network parameters are trained in real-time using available magnetic sensor data, enabling dynamic adaptation to evolving plasma equilibrium without extensive pre-training on experimental data.

Result: Accurate plasma boundary reconstruction for complex configurations, outperforming established methods like JET's algorithm. Better generalization of poloidal flux function without requiring algorithm retuning across different plasma equilibria. Greater robustness to noise on magnetic measurements.

Conclusion: The proposed physics-informed neural network approach provides an effective solution for real-time plasma boundary reconstruction that combines neural network generalization power with real-time adaptability, making it suitable for implementation on existing tokamak devices.

Abstract: In this work, we propose a novel physics informed neural network based algorithm for real time plasma boundary reconstruction in tokamak devices. The approach is based on a single Extreme Learning Machine network used to solve the homogeneous Grad Shafranov equation, which is required to identify the plasma boundary. This architecture enables the real time training of the network parameters using the available magnetic sensor data and, consequently, dynamically adapting the network output to the evolving plasma equilibrium. We demonstrate that, the network performs accurate plasma boundary reconstruction for complex configurations, outperforming well established methods, such as the algorithm used for decades at the Joint European Torus, the world's largest tokamak, until it ceased operation in 2023. Indeed, compared to the latter, the proposed solution better generalizes the poloidal flux function, without requiring algorithm retuning across different plasma equilibria. The proposed neural network reconstructor demonstrates also greater robustness with respect to noise on the magnetic measurements. Moreover, this method takes advantage of the generalization power of neural networks but without the need for extensive, time consuming training based on a huge amount of experimental data, making its implementation on existing devices straightforward.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [46] [Efficient Monte-Carlo sampling of metastable systems using non-local collective variable updates](https://arxiv.org/abs/2512.16812)
*Christoph Schönle,Davide Carbone,Marylou Gabrié,Tony Lelièvre,Gabriel Stoltz*

Main category: cond-mat.stat-mech

TL;DR: Generalized algorithm for non-linear collective variables and underdamped Langevin dynamics improves sampling efficiency in molecular simulations compared to previous overdamped methods.


<details>
  <summary>Details</summary>
Motivation: Standard Monte-Carlo simulations suffer from metastability issues, and existing non-local proposal methods in collective-variable space need extension to handle non-linear CVs and underdamped dynamics for more realistic molecular systems.

Method: Generalized approach with explicit algorithm for non-linear collective variables and underdamped Langevin dynamics, proving reversibility of the resulting scheme.

Result: Substantial performance increase compared to methods based on overdamped Langevin dynamics, demonstrated through several numerical examples.

Conclusion: The algorithm extends applicability of generative machine-learning-based proposal samplers to more realistic molecular systems by enabling efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables).

Abstract: Monte-Carlo simulations are widely used to simulate complex molecular systems, but standard approaches suffer from metastability. Lately, the use of non-local proposal updates in a collective-variable (CV) space has been proposed in several works. Here, we generalize these approaches and explicitly spell out an algorithm for non-linear CVs and underdamped Langevin dynamics. We prove reversibility of the resulting scheme and demonstrate its performance on several numerical examples, observing a substantial performance increase compared to methods based on overdamped Langevin dynamics as considered previously. Advances in generative machine-learning-based proposal samplers now enable efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables), and our results extend their applicability toward more realistic molecular systems.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [47] [Unveiling the amorphous ice layer during premelting using AFM integrating machine learning](https://arxiv.org/abs/2512.15772)
*Binze Tang,Chon-Hei Lo,Tiancheng Liang,Jiani Hong,Mian Qin,Yizhi Song,Duanyun Cao,Ying Jiang,Limei Xu*

Main category: cond-mat.mtrl-sci

TL;DR: Researchers discovered a novel amorphous ice layer preceding the quasi-liquid layer during ice premelting using a machine learning framework that integrates AFM with molecular dynamics simulations.


<details>
  <summary>Details</summary>
Motivation: Premelting is crucial across multiple scientific disciplines but remains poorly understood at the atomic level due to limitations in surface characterization techniques, particularly AFM's depth and signal constraints.

Method: Developed a machine learning framework that integrates atomic force microscopy (AFM) with molecular dynamics simulations to overcome AFM's limitations, enabling 3D surface structure reconstruction from AFM images and exploration of premelting interfaces across wide temperature ranges.

Result: Identified a novel amorphous ice layer (AIL) present between 121-180K that displays a disordered two-dimensional hydrogen-bond network with solid-like dynamics, refining the ice premelting phase diagram.

Conclusion: This work establishes a novel framework for AFM-based 3D structural discovery, significantly advancing our ability to probe complex disordered interfaces and opening new research avenues in surface reconstruction, crystallization, ion solvation, and biomolecular recognition.

Abstract: Premelting plays a key role across physics, chemistry, materials and biology sciences but remains poorly understood at the atomic level due to surface characterization limitations. We report the discovery of a novel amorphous ice layer (AIL) preceding the quasi-liquid layer (QLL) during ice premelting, enabled by a machine learning framework integrating atomic force microscopy (AFM) with molecular dynamics simulations. This approach overcomes AFM's depth and signal limitations, allowing for three-dimensional surface structure reconstruction from AFM images. It further enables structural exploration of premelting interfaces across a wide temperature range that are experimentally inaccessible. We identify the AIL, present between 121-180K, displaying disordered two-dimensional hydrogen-bond network with solid-like dynamics. Our findings refine the ice premelting phase diagram and offering new insights into the surface growth dynamic, dissolution and interfacial chemical reactivity. Methodologically, this work establishes a novel framework for AFM-based 3D structural discovery, marking a significant leap in our ability to probe complex disordered interfaces with unprecedented precision and paving the way for future disciplinary research, including surface reconstruction, crystallization, ion solvation, and biomolecular recognition.

</details>


### [48] [Atomic forces from correlation energy functionals based on the adiabatic-connection fluctuation-dissipation theorem](https://arxiv.org/abs/2512.16460)
*Damian Contant,Maria Hellgren*

Main category: cond-mat.mtrl-sci

TL;DR: Implementation of analytical atomic forces within RPA for plane waves/pseudopotentials, showing excellent force quality and systematic improvement over PBE, with RPAx achieving accuracy comparable to advanced wavefunction methods.


<details>
  <summary>Details</summary>
Motivation: To extend correlation energy functionals based on adiabatic-connection fluctuation-dissipation theorem by implementing analytical atomic forces within RPA, enabling accurate geometry and vibrational frequency calculations for molecules and solids.

Method: Implemented analytical RPA forces using plane waves and pseudopotentials, calculated forces at self-consistency via optimized effective potential method and Hellmann-Feynman theorem, and evaluated non-self-consistent RPA forces from PBE using density functional perturbation theory.

Result: Forces show excellent numerical quality; self-consistency has negligible impact on geometries and vibrational frequencies for most systems; RPA systematically improves over PBE; RPAx achieves accuracy comparable to advanced wavefunction methods; provided accurate theoretical references for phonons of diamond, silicon, and germanium.

Conclusion: RPA and RPAx forces are successfully implemented and validated, offering accurate computational tools for geometry optimization and vibrational analysis that systematically improve upon standard DFT approximations.

Abstract: We extend the capabilities of correlation energy functionals based on the adiabatic-connection fluctuation-dissipation theorem by implementing the analytical atomic forces within the random phase approximation (RPA), in the context of plane waves and pseudopotentials. Forces are calculated at self-consistency through the optimized effective potential method and the Hellmann-Feynman theorem. In addition, non-self-consistent RPA forces, starting from the PBE generalized gradient approximation, are evaluated using density functional perturbation theory. In both cases, we find forces of excellent numerical quality. Furthermore, for most molecules and solids studied, self-consistency is found to have a negligible impact on the computed geometries and vibrational frequencies. The RPA is shown to systematically improve over PBE and, by including the exact-exchange kernel within RPA + exchange (RPAx), through finite-difference total energy calculations, we obtain an accuracy comparable to advanced wavefunction methods. Finally, we estimate the anharmonic shift and provide accurate theoretical references based on RPA and RPAx for the zone-center optical phonon of diamond, silicon, and germanium.

</details>


### [49] [Thermodynamical study of N$_2$ clathrate hydrate from DFT calculations](https://arxiv.org/abs/2512.16819)
*L. Martin-Gondre,V. Meko Fotso,C. Métais,A. Patt,J. Ollivier,A. Desmedt*

Main category: cond-mat.mtrl-sci

TL;DR: DFT study shows N₂ clathrate hydrate stability depends on cage occupancy and pressure, with sI stable at lower pressures and sII with double occupancy favored at higher pressures.


<details>
  <summary>Details</summary>
Motivation: To establish a first-principles thermodynamic framework for understanding N₂ clathrate hydrate stability under different pressure conditions and cage occupancies, providing baseline for finite-temperature studies.

Method: Density functional theory calculations with various exchange-correlation functionals (revPBE-D3(0) performed best), analyzing lattice parameters, bulk moduli, and convex-hull thermodynamic stability at T = 0 K for sI and sII structures with different cage occupancies.

Result: Large cage double occupancy strongly impacts sI stability; sI with single occupancy remains thermodynamically stable up to ~0.8 GPa alongside sII with single occupancy; above this pressure, sII with double occupancy becomes stabilized due to larger cage volume and lower framework strain.

Conclusion: The study provides a coherent first-principles thermodynamic framework for N₂ hydrate stability, establishing pressure-dependent stability regimes and highlighting the importance of cage occupancy effects, serving as baseline for finite-temperature extensions.

Abstract: Thermodynamic stability of N$_2$ clathrate hydrates in the sI and sII structures is investigated using density functional theory with several exchange-correlation functionals, explicitly accounting for composition (cage occupancies) and pressure at T = 0 K. Among the tested functionals, revPBE-D3(0) best reproduces experimental lattice parameters and bulk moduli B$_0$ . Energetic analyses confirm the strong impact of large cage double occupancy on sI, whereas the convex-hull results show that sI with single occupancy remains thermodynamically stable up to $\sim$ 0.8 GPa alongside sII with single occupancy. Increasing pressure then stabilizes sII with double occupancy, consistent with its larger large-cage volume and lower framework strain. These results provide a coherent, first-principles thermodynamic framework for N$_2$ hydrate stability and a baseline for finite-temperature extension.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [50] [The Diffusive Behavior of Solutions to the Linear Damped Wave Equation: an Undergraduate D.I.Y. Classnote](https://arxiv.org/abs/2512.15770)
*Gastão Almeida Braga,Antônio Marcos da Silva,Jussara de Matos Moreira*

Main category: math.HO

TL;DR: The paper explains to undergraduate students how solutions of Damped Wave and Heat equations become related as time approaches infinity, using a hands-on exercise-based approach.


<details>
  <summary>Details</summary>
Motivation: To help undergraduate students with good calculus background understand the surprising mathematical relationship between solutions of Damped Wave and Heat equations in the long-time limit, despite these equations describing fundamentally different physical phenomena.

Method: A "do it yourself" pedagogical strategy where students work through suggested exercises to actively discover and understand the mathematical relationship between the two equations' solutions as t→∞.

Result: The paper provides an accessible explanation showing how solutions to the Damped Wave equation approach those of the Heat equation in the infinite time limit, demonstrating this mathematical connection through student exercises.

Conclusion: The note successfully demonstrates the surprising asymptotic relationship between Damped Wave and Heat equation solutions to undergraduate students through an interactive, exercise-based learning approach.

Abstract: Despite of the fact that the Damped Wave and the Heat equations describe phenomena of distinct nature, it is amazing that their solutions are related in the limit as $t \to \infty$. The aim of this note is to explain to undergraduate students, with a good calculus background, how the relation between these solutions is established. We follow a ``do it yourself'' strategy and the students are invited to do the suggested exercises in order to understand the content of this note.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [51] [Ground states for the Hartree energy functional in the critical case](https://arxiv.org/abs/2512.16513)
*Tommaso Pistillo*

Main category: math-ph

TL;DR: Existence, properties, and stability of ground states for Hartree energy functional with convolution potentials in R³, including Coulomb-type potentials.


<details>
  <summary>Details</summary>
Motivation: Study ground states for Hartree energy with broad class of convolution potentials (including Coulomb-type -1/|x|^α and L³/² potentials) to understand existence, properties, and stability.

Method: Variational approach in H¹(R³) for Hartree energy functional with potentials in L∞+L³/²,∞ vanishing at infinity; prove existence via minimization, establish positivity/regularity properties, then extend to evolution problem.

Result: Existence of ground states for wide range of L² masses; positivity and regularity properties; global well-posedness of evolution problem; orbital stability of ground state set.

Conclusion: Comprehensive theory for Hartree ground states with broad potential class: existence, properties, and stability results provide foundation for studying related nonlinear evolution problems.

Abstract: We consider the problem of finding a minimizer $u$ in $ H^1(\mathbb{R}^3)$ for the Hartree energy functional with convolution potential $w$ in $L^\infty(\mathbb{R}^3)+L^{3/2,\infty}(\mathbb{R}^3)$ with $L^\infty$ part vanishing at infinity. This class includes sums of potentials of the kind $-\frac{1}{|x|^α}$, $0<α\le2$, together with the case $w$ in $L^{3/2}(\mathbb{R}^3)$. We prove the existence of such groundstates for a wide range of $L^2$ masses. We also establish basic properties of the groundstates, i.e.~positivity and regularity. Lastly, we exploit the estimates we derived for the stationary problem to prove global well-posedness of the associated evolution problem and orbital stability of the set of ground states.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [52] [An evacuation simulator for pedestrian dynamics based on the Social Force Model](https://arxiv.org/abs/2512.16887)
*Julián López,Virginia Mazzone,M. Leticia Rubio Puzzo,Juan Cruz Moreno*

Main category: physics.soc-ph

TL;DR: SiCoBioNa is an open-source evacuation simulator based on Social Force Model with GUI for pedestrian dynamics analysis without requiring numerical modeling expertise.


<details>
  <summary>Details</summary>
Motivation: Pedestrian evacuation from enclosed spaces is critical for safety engineering and infrastructure design, requiring simulation tools that can realistically capture individual interactions and spatial constraints.

Method: Developed SiCoBioNa, an open-source evacuation simulator using Social Force Model framework with intuitive graphical interface for configuring pedestrian properties, spatial geometries, and initial conditions.

Result: The simulator generates both quantitative data and visual outputs for analyzing evacuation dynamics and evaluating spatial configurations, with modular/extensible design for reproducible research.

Conclusion: SiCoBioNa serves as a practical research tool for pedestrian dynamics studies and evacuation planning support due to its accessibility and reproducibility features.

Abstract: The evacuation of pedestrians from enclosed spaces represents a key problem in safety engineering and infrastructure design. Analyzing the collective dynamics that emerge during evacuation processes requires simulation tools capable of capturing individual interactions and spatial constraints realistically.
  In this work, we present \textit{SiCoBioNa}, an open-source evacuation simulator based on the Social Force Model (SFM). The software provides an intuitive graphical interface that allows users to configure pedestrian properties, spatial geometries, and initial conditions without requiring prior expertise in numerical modeling techniques. The SFM framework enables the representation of goal-oriented motion, interpersonal interactions, and interactions with fixed obstacles.
  The simulator generates both quantitative data and visual outputs, facilitating the analysis of evacuation dynamics and the evaluation of different spatial configurations. Due to its modular and extensible design, \textit{SiCoBioNa} serves as a reproducible research tool for studies on pedestrian dynamics providing practical support for evacuation planning.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [53] [On the distribution kernels of Toeplitz operators on CR manifolds](https://arxiv.org/abs/2512.16506)
*Chin-Yu Hsiao,Ood Shabtai*

Main category: math.CV

TL;DR: Analysis of Toeplitz operators on CR manifolds: diagonal values of kernel symbols and asymptotic expansions on CR orbifolds.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of Toeplitz operators on complex CR manifolds, particularly the kernel structure and asymptotic properties, which are fundamental in pseudodifferential operator theory and CR geometry.

Method: Study distribution kernels of Toeplitz operators associated with classical pseudodifferential operators on compact, embeddable, strictly pseudoconvex CR manifolds. Analyze the second coefficient in the kernel symbol expansion at the diagonal. Also examine asymptotic expansions for Toeplitz operators on positive parts of compact CR orbifolds (not necessarily strictly pseudoconvex) under natural assumptions.

Result: Main result: Formula for diagonal values of the second coefficient in the kernel symbol expansion. Additional result: Established asymptotic expansions for Toeplitz operators on positive parts of compact CR orbifolds under certain conditions.

Conclusion: The paper provides explicit formulas for kernel coefficients and establishes asymptotic expansions, advancing the understanding of Toeplitz operators in CR geometry and pseudodifferential operator theory on complex manifolds.

Abstract: We study the distribution kernel of a Toeplitz operator associated with a classical pseudodifferential operator on a compact, embeddable, strictly pseudoconvex CR manifold. The main result consists of a formula for the values at the diagonal of the second coefficient in the expansion of the symbol of the kernel. We also establish asymptotic expansions for Toeplitz operators on the positive part of a compact not necessary strictly pseudoconvex CR orbifold under certain natural assumptions.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [54] [Self-confinement of relativistic pair beams in magnetized interstellar plasmas: the case of pulsar X-ray filaments](https://arxiv.org/abs/2512.15847)
*Luca Orusa,Lorenzo Sironi*

Main category: astro-ph.HE

TL;DR: A new mechanism explains how charge-neutral electron-positron beams from pulsar wind nebulae can spontaneously generate net currents that drive magnetic turbulence, explaining suppressed cosmic-ray diffusion and X-ray filament formation.


<details>
  <summary>Details</summary>
Motivation: Observations of filamentary X-ray structures near pulsar wind nebulae and slow-diffusion regions around pulsars challenge standard cosmic-ray transport models, requiring explanation of suppressed diffusion coefficients two orders of magnitude smaller than Galactic average.

Method: Used fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratio to study charge-neutral pair beam propagation through electron-proton plasma, focusing on beam electron focusing into magnetic filaments via Weibel instability.

Result: Beam electrons become focused into self-generated magnetic filaments while beam positrons remain unconfined, creating a net positron current that drives non-resonant streaming instability and further amplifies magnetic fields.

Conclusion: This mechanism explains onset of charge asymmetries in initially charge-neutral pair beams and growth of magnetic fluctuations that scatter beam particles, providing pathway for X-ray filament formation and particle self-confinement in TeV halos around pulsar wind nebulae.

Abstract: The observation of filamentary X-ray structures near bow-shock pulsar wind nebulae (PWNe) -- such as the Guitar, Lighthouse, and PSR J2030$+$4415 nebulae -- and of slow-diffusion regions around pulsars like Geminga, Monogem, and PSR J0622$+$3749, challenges the standard picture of cosmic-ray transport in the interstellar medium, implying a diffusion coefficient two orders of magnitude smaller than the Galactic average. The suppressed diffusion can be attributed to self-generated magnetic turbulence, driven -- via the non-resonant streaming instability -- by electron--positron pairs escaping the PWNe. This instability requires a net current, yet the beam of escaping pairs is expected to be charge-neutral. We show that a charge-neutral pair beam propagating through an electron--proton plasma can spontaneously generate a net current. Using fully kinetic two- and three-dimensional particle-in-cell simulations with realistic mass ratio, we find that beam electrons get focused into self-generated magnetic filaments produced by the nonlinear evolution of the Weibel instability, while beam positrons remain unconfined. The resulting net (positron) current drives the non-resonant streaming instability, further amplifying the magnetic field. This mechanism provides a pathway for the onset of charge asymmetries in initially charge-neutral pair beams and for the growth of magnetic fluctuations that efficiently scatter the beam particles, with implications for the formation of X-ray filaments and, more broadly, for particle self-confinement in TeV halos around PWNe.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [55] [Introduction to Symbolic Regression in the Physical Sciences](https://arxiv.org/abs/2512.15920)
*Deaglan J. Bartlett,Harry Desmond,Pedro G. Ferreira,Gabriel Kronberger*

Main category: cs.LG

TL;DR: This is a special issue introduction on symbolic regression for physical sciences, covering applications from equation discovery to surrogate modeling, with discussion of methods, challenges, and future directions.


<details>
  <summary>Details</summary>
Motivation: To introduce a Special Issue on Symbolic Regression for the Physical Sciences, motivated by a Royal Society discussion meeting, highlighting SR's potential for scientific discovery and empirical modeling in physics.

Method: The paper serves as an introductory review outlining SR's conceptual foundations, contrasting it with conventional regression, surveying use cases, and discussing methodological considerations like search-space design, operator selection, complexity control, and integration with modern AI.

Result: The special issue collects contributions spanning applications from automated equation discovery and emergent-phenomena modeling to compact emulators for computationally expensive simulations, illustrating accelerating progress in SR.

Conclusion: Symbolic regression shows growing relevance across physical sciences, with emerging directions including incorporation of symmetry constraints, asymptotic behavior, and theoretical information, though challenges remain in scalability, robustness, and computational complexity.

Abstract: Symbolic regression (SR) has emerged as a powerful method for uncovering interpretable mathematical relationships from data, offering a novel route to both scientific discovery and efficient empirical modelling. This article introduces the Special Issue on Symbolic Regression for the Physical Sciences, motivated by the Royal Society discussion meeting held in April 2025. The contributions collected here span applications from automated equation discovery and emergent-phenomena modelling to the construction of compact emulators for computationally expensive simulations.
  The introductory review outlines the conceptual foundations of SR, contrasts it with conventional regression approaches, and surveys its main use cases in the physical sciences, including the derivation of effective theories, empirical functional forms and surrogate models. We summarise methodological considerations such as search-space design, operator selection, complexity control, feature selection, and integration with modern AI approaches. We also highlight ongoing challenges, including scalability, robustness to noise, overfitting and computational complexity. Finally we emphasise emerging directions, particularly the incorporation of symmetry constraints, asymptotic behaviour and other theoretical information. Taken together, the papers in this Special Issue illustrate the accelerating progress of SR and its growing relevance across the physical sciences.

</details>


### [56] [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](https://arxiv.org/abs/2512.15771)
*Xinjie He,Chenggong Zhang*

Main category: cs.LG

TL;DR: Extends Time-Evolving Natural Gradient (TENG) framework to handle Dirichlet boundary conditions in PDEs using natural gradient optimization with time-stepping schemes (Euler/Heun), achieving improved accuracy and stability.


<details>
  <summary>Details</summary>
Motivation: Traditional numerical methods struggle with high-dimensional/complex PDEs, and while PINNs offer an alternative, they face challenges with accuracy and complex boundary conditions. There's a need for more effective neural network-based PDE solvers that can properly handle boundary constraints.

Method: Extends TENG framework to incorporate Dirichlet boundary conditions by adding penalty terms to the loss function. Combines natural gradient optimization with numerical time-stepping schemes (Euler and Heun methods) to ensure stability and accuracy while enforcing boundary constraints.

Result: Experiments on heat equation show Heun method provides superior accuracy due to second-order corrections, while Euler method offers computational efficiency for simpler scenarios. The approach successfully enforces Dirichlet constraints with improved performance.

Conclusion: Establishes foundation for extending framework to Neumann/mixed boundary conditions and broader PDE classes, advancing neural network-based solvers for real-world applications with complex boundary conditions.

Abstract: Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient alternative by embedding physics-based constraints into deep learning frameworks, but they face challenges in achieving high accuracy and handling complex boundary conditions. In this work, we extend the Time-Evolving Natural Gradient (TENG) framework to address Dirichlet boundary conditions, integrating natural gradient optimization with numerical time-stepping schemes, including Euler and Heun methods, to ensure both stability and accuracy. By incorporating boundary condition penalty terms into the loss function, the proposed approach enables precise enforcement of Dirichlet constraints. Experiments on the heat equation demonstrate the superior accuracy of the Heun method due to its second-order corrections and the computational efficiency of the Euler method for simpler scenarios. This work establishes a foundation for extending the framework to Neumann and mixed boundary conditions, as well as broader classes of PDEs, advancing the applicability of neural network-based solvers for real-world problems.

</details>


### [57] [Multi-Fidelity Delayed Acceptance: hierarchical MCMC sampling for Bayesian inverse problems combining multiple solvers through deep neural networks](https://arxiv.org/abs/2512.16430)
*Filippo Zacchei,Paolo Conti,Attilio Alberto Frangi,Andrea Manzoni*

Main category: cs.LG

TL;DR: Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems using neural networks to combine solvers of varying fidelity, avoiding expensive high-fidelity simulations during online inference.


<details>
  <summary>Details</summary>
Motivation: Traditional inverse uncertainty quantification (UQ) methods like MCMC are computationally expensive for physics-based models requiring repeated PDE solver evaluations. While surrogate models can help, generating high-fidelity training data is costly, and relying solely on low-fidelity data reduces accuracy.

Method: Extends Multi-Level Delayed Acceptance framework with multi-fidelity neural networks that combine predictions from solvers of varying fidelity. High-fidelity evaluations are used only in offline training, while online phase uses coarse solvers with trained neural networks to avoid additional high-fidelity simulations.

Result: The approach improves approximation accuracy of low-fidelity solvers, enables longer sub-chain lengths, better mixing, and accelerated posterior inference. Demonstrated on two benchmark problems (steady groundwater flow and unsteady reaction-diffusion system) with substantial computational savings.

Conclusion: Proposed Multi-Fidelity Delayed Acceptance scheme provides flexible integration of heterogeneous coarse solvers, reduces computational costs while maintaining accuracy, and enables efficient Bayesian inverse UQ for complex physics-based models.

Abstract: Inverse uncertainty quantification (UQ) tasks such as parameter estimation are computationally demanding whenever dealing with physics-based models, and typically require repeated evaluations of complex numerical solvers. When partial differential equations are involved, full-order models such as those based on the Finite Element Method can make traditional sampling approaches like Markov Chain Monte Carlo (MCMC) computationally infeasible. Although data-driven surrogate models may help reduce evaluation costs, their utility is often limited by the expense of generating high-fidelity data. In contrast, low-fidelity data can be produced more efficiently, although relying on them alone may degrade the accuracy of the inverse UQ solution.
  To address these challenges, we propose a Multi-Fidelity Delayed Acceptance scheme for Bayesian inverse problems. Extending the Multi-Level Delayed Acceptance framework, the method introduces multi-fidelity neural networks that combine the predictions of solvers of varying fidelity, with high fidelity evaluations restricted to an offline training stage. During the online phase, likelihood evaluations are obtained by evaluating the coarse solvers and passing their outputs to the trained neural networks, thereby avoiding additional high-fidelity simulations.
  This construction allows heterogeneous coarse solvers to be incorporated consistently within the hierarchy, providing greater flexibility than standard Multi-Level Delayed Acceptance. The proposed approach improves the approximation accuracy of the low fidelity solvers, leading to longer sub-chain lengths, better mixing, and accelerated posterior inference. The effectiveness of the strategy is demonstrated on two benchmark inverse problems involving (i) steady isotropic groundwater flow, (ii) an unsteady reaction-diffusion system, for which substantial computational savings are obtained.

</details>


### [58] [Polyharmonic Spline Packages: Composition, Efficient Procedures for Computation and Differentiation](https://arxiv.org/abs/2512.16718)
*Yuriy N. Bakhvalov*

Main category: cs.LG

TL;DR: Proposes a cascade architecture of polyharmonic spline packages to address computational scalability and high-dimensional limitations of previous kernel regression methods.


<details>
  <summary>Details</summary>
Motivation: Previous polyharmonic spline kernel regression has O(N^3) computational cost and breaks down in high-dimensional spaces, limiting practical application despite theoretical optimality.

Method: Cascade architecture built from packages of polyharmonic splines, with efficient matrix procedures for forward computation and end-to-end differentiation through the cascade.

Result: Simultaneously addresses scalability issues (O(N^3) cost) and provides theoretical justification for problems with unknown intrinsic low dimensionality.

Conclusion: The cascade architecture enables practical application of theoretically optimal polyharmonic spline regression while handling high-dimensional data through intrinsic dimensionality assumptions.

Abstract: In a previous paper it was shown that a machine learning regression problem can be solved within the framework of random function theory, with the optimal kernel analytically derived from symmetry and indifference principles and coinciding with a polyharmonic spline. However, a direct application of that solution is limited by O(N^3) computational cost and by a breakdown of the original theoretical assumptions when the input space has excessive dimensionality. This paper proposes a cascade architecture built from packages of polyharmonic splines that simultaneously addresses scalability and is theoretically justified for problems with unknown intrinsic low dimensionality. Efficient matrix procedures are presented for forward computation and end-to-end differentiation through the cascade.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [59] [Information theory and discriminative sampling for model discovery](https://arxiv.org/abs/2512.16000)
*Yuxuan Bao,J. Nathan Kutz*

Main category: cs.IT

TL;DR: The paper proposes using Fisher Information Matrix (FIM) within SINDy framework to analyze chaotic/non-chaotic systems, visualize information patterns, and improve data efficiency through principled sampling strategies.


<details>
  <summary>Details</summary>
Motivation: Fisher information and Shannon entropy are fundamental tools for analyzing dynamical systems, but there's a need to leverage them within data-driven frameworks like SINDy to improve sampling efficiency and model performance by prioritizing informative data.

Method: Integrates Fisher Information Matrix (FIM) into the sparse identification of nonlinear dynamics (SINDy) framework. Visualizes information patterns in chaotic and non-chaotic systems for single and multiple trajectories, uses spectral analysis of FIM to elucidate benefits of statistical bagging.

Result: Demonstrates how information-based analysis improves sampling efficiency and enhances model performance by prioritizing more informative data. Shows how Fisher information and entropy metrics promote data efficiency in three scenarios: single trajectory, tunable control parameter, and multiple freely initialized trajectories.

Conclusion: Principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements in data-driven model discovery.

Abstract: Fisher information and Shannon entropy are fundamental tools for understanding and analyzing dynamical systems from complementary perspectives. They can characterize unknown parameters by quantifying the information contained in variables, or measure how different initial trajectories or temporal segments of a trajectory contribute to learning or inferring system dynamics. In this work, we leverage the Fisher Information Matrix (FIM) within the data-driven framework of {\em sparse identification of nonlinear dynamics} (SINDy). We visualize information patterns in chaotic and non-chaotic systems for both single trajectories and multiple initial conditions, demonstrating how information-based analysis can improve sampling efficiency and enhance model performance by prioritizing more informative data. The benefits of statistical bagging are further elucidated through spectral analysis of the FIM. We also illustrate how Fisher information and entropy metrics can promote data efficiency in three scenarios: when only a single trajectory is available, when a tunable control parameter exists, and when multiple trajectories can be freely initialized. As data-driven model discovery continues to gain prominence, principled sampling strategies guided by quantifiable information metrics offer a powerful approach for improving learning efficiency and reducing data requirements.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [60] [Manifold submetries from compact homogeneous spaces](https://arxiv.org/abs/2512.16606)
*Samuel Lin,Ricardo A. E. Mendes,Marco Radeschi*

Main category: math.DG

TL;DR: Singular Riemannian foliations on compact normal homogeneous spaces are algebraic, with correspondence between algebra-preserving Laplace-Beltrami operator and manifold submetries.


<details>
  <summary>Details</summary>
Motivation: To establish the algebraic nature of singular Riemannian foliations/manifold submetries on compact normal homogeneous spaces and reveal connections between algebraic structures and geometric objects.

Method: Analyze manifold submetries on compact normal homogeneous spaces, prove that mean curvature vector fields of fibers are basic (related to base vector fields), establish algebraic correspondence.

Result: Singular Riemannian foliations on compact normal homogeneous spaces are algebraic; one-to-one correspondence exists between algebras of algebraic functions preserved by Laplace-Beltrami operator and manifold submetries.

Conclusion: Manifold submetries on compact normal homogeneous spaces have algebraic structure, with fundamental connection between algebraic function algebras and geometric submetries through Laplace-Beltrami operator preservation.

Abstract: We show that singular Riemannian foliations, or, more generally, manifold submetries, defined on a compact normal homogeneous space, have algebraic nature. Moreover, in this case there exists a one-to-one correspondence between algebras of algebraic functions preserved by the Laplace--Beltrami operator, and manifold submetries.
  A key intermediate result is that, for any manifold submetry on a compact normal homogeneous space, the vector field given by the mean curvature of the fibers is basic, in the sense that it is related to a vector field in the base.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [61] [A unified MRT-LB framework for Navier-Stokes and nonlinear convection-diffusion equations and beyond: moment equations, auxiliary moments, multispeed lattices, and Hermite matrices](https://arxiv.org/abs/2512.16230)
*Baochang Shi,Xiaolei Yuan,Zhenhua Chai*

Main category: physics.flu-dyn

TL;DR: A unified MRT-LB framework using discrete Hermite polynomials for Navier-Stokes and nonlinear convection-diffusion equations with multispeed rectangular lattice models.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive lattice Boltzmann framework that can handle both Navier-Stokes equations and nonlinear convection-diffusion equations using a unified approach with rectangular lattice structures.

Method: Developed MRT-LB framework based on discrete Hermite polynomials using multispeed rectangular lattice models (rDdQb). Derived macroscopic moment equations via direct Taylor expansion, used auxiliary moments to eliminate spurious terms, and established relations for weight coefficients using weighted orthogonality of Hermite matrices.

Result: Created several multispeed rectangular lattice models (rD2Q25, rD3Q53, and subgroup models rD2Q21, rD2Q17, rD2Q13, rD3Q45, rD3Q33) with generalized third-order equilibrium distribution function. Demonstrated correction requirements for third-order discrete Hermite polynomials in rectangular lattices.

Conclusion: The proposed unified MRT-LB framework successfully handles both NSEs and NCDEs using rectangular lattice models, with specific auxiliary moments and corrections enabling accurate recovery of target equations.

Abstract: We develop a unified multi-relaxation-time lattice Boltzmann (MRT-LB) framework based on discrete Hermite polynomials (Hermite matrices) for the Navier-Stokes equations (NSEs) and nonlinear convection-diffusion equations (NCDEs), using multispeed rectangular lattice (rD$d$Q$b$) models. For NSEs, the proposed MRT-LB model simulates incompressible and compressible isothermal flows in both single-phase and multiphase systems. Macroscopic moment equations are derived from the MRT-LB model via the direct Taylor expansion method. By selecting appropriate fundamental moments, the target NSEs and NCDE are recovered from these moment equations. Critically, the elimination of spurious terms and/or the recovery of the desired terms relies on specific auxiliary moments: the second-order auxiliary moment ($\mathbf{M}_{2G}$) of the source term distribution function (SDF) and the third-order auxiliary moment ($\mathbf{M}_{30}$) of the equilibrium distribution function (EDF) for NSEs, as well as the first-order auxiliary moment ($\mathbf{M}_{1G}$) of the SDF and the second-order auxiliary moment ($\mathbf{M}_{20}$) of the EDF for NCDE. Furthermore, using the weighted orthogonality of Hermite matrices, we establish essential relations for weight coefficients and construct several multispeed rectangular lattice models, including rD2Q25 and rD3Q53, with subgroup models rD2Q21, rD2Q17, rD2Q13, rD3Q45, and rD3Q33. A generalized third-order equilibrium distribution function is derived. We emphasize that for rectangular lattices, specific elements of the Hermite matrix corresponding to third-order discrete Hermite polynomials require correction to satisfy weighted orthogonality.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [62] [QMCkl: A Kernel Library for Quantum Monte Carlo Applications](https://arxiv.org/abs/2512.16677)
*Emiel Slootman,Vijay Gopal Chilkuri,Aurelien Delval,Max Hoffer,Tommaso Gorni,François Coppens,Joris van de Nes,Ramón L. Panadés-Barrueta,Evgeny Posenitskiy,Abdallah Ammar,Edgar Josué Landinez Borda,Kevin Camus,Oto Kohulàk,Emmanuel Giner,Pablo de Oliveira Castro,Cedric Valensi,William Jalby,Claudia Filippi,Anthony Scemama*

Main category: physics.chem-ph

TL;DR: QMCkl is a modular, portable library of high-performance kernels for Quantum Monte Carlo calculations that separates algorithmic development from hardware optimization, enabling efficient and reproducible simulations across different codes and architectures.


<details>
  <summary>Details</summary>
Motivation: Quantum Monte Carlo methods are highly accurate but computationally intensive. There's a need for modular, portable, and high-performance implementations of core QMC building blocks to enable consistent, efficient, and reproducible simulations across different codes and hardware architectures.

Method: Developed QMCkl as a library providing C-compatible API with TREXIO standard for input. It includes essential QMC kernels (atomic/molecular orbitals, cusp corrections, Jastrow factor, derivatives) and combines human-readable reference implementations with performance-optimized kernels that produce identical numerical results.

Result: Achieves substantial speedups in energy and derivative evaluations. Enables consistent, efficient, and reproducible simulations across different QMC codes and architectures. Also accelerates deterministic quantum chemistry workflows and visualization tools.

Conclusion: QMCkl successfully separates algorithmic development from hardware-specific tuning, promotes cross-code interoperability, simplifies high-performance scientific software development, and extends utility beyond QMC to other quantum chemistry applications.

Abstract: Quantum Monte Carlo (QMC) methods deliver highly accurate electronic structure calculations but are computationally intensive. The quantum Monte Carlo kernel library (QMCkl) provides a modular, portable collection of high-performance kernels implementing the core building blocks of QMC calculations. It offers a C-compatible API, supports the TREXIO standard for input, and covers essential QMC kernels including atomic and molecular orbitals, cusp corrections, Jastrow factor, and the necessary derivatives also to perform variational and structural optimization. QMCkl separates algorithmic development from hardware-specific tuning by combining human-readable reference implementations with performance-optimized kernels that produce identical numerical results. The library enables consistent, efficient, and reproducible simulations across different QMC codes and architectures, and achieves substantial speedups in the evaluation of the energy and its derivatives. Beyond QMC, QMCkl can accelerate deterministic quantum chemistry workflows and visualization tools, promoting cross-code interoperability and simplifying high-performance scientific software development.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [63] [Electric field diagnostics in a continuous rf plasma using Rydberg-EIT](https://arxiv.org/abs/2512.16867)
*Bineet Dash,Xinyan Xiang,Dingkun Feng,Eric Paradis,Georg Raithel*

Main category: physics.atom-ph

TL;DR: Non-invasive plasma electric field measurement using Rydberg atom Stark shifts via Electromagnetically Induced Transparency spectroscopy.


<details>
  <summary>Details</summary>
Motivation: Develop non-invasive spatio-temporal electric-field diagnostics for low-pressure plasmas, plasma sheaths, process plasmas, and dusty plasmas without disturbing the plasma environment.

Method: Uses Rydberg atoms with large polarizabilities and Stark shifts measured via narrow-linewidth lasers and Electromagnetically Induced Transparency (EIT) of rubidium vapor seeded into continuous inductively-coupled rf plasma in argon gas at few mTorr pressure.

Result: Rf modulation sidebands vanish with plasma present due to screening of rf drive field; EIT spectra lineshapes reflect plasma's Holtsmark microfield distribution, enabling determination of plasma density and collisional line broadening across pressure and rf power ranges.

Conclusion: Technique enables non-invasive electric field measurement in plasmas using Rydberg Stark spectroscopy, with applications for plasma diagnostics in various low-pressure plasma environments.

Abstract: We present a non-invasive spectroscopic technique to measure electric fields in plasma, leveraging large polarizabilities and Stark shifts of Rydberg atoms. Rydberg Stark shifts are measured with high precision using narrow-linewidth lasers via Electromagnetically Induced Transparency (EIT) of rubidium vapor seeded into a continuous, inductively coupled radio-frequency (rf) plasma in a few mTorr of argon gas. Without plasma, the Rydberg-EIT spectra exhibit rf modulation sidebands caused by electric- and magnetic-dipole transitions in the rf drive coil. With the plasma present, the rf modulation sidebands vanish due to screening of the rf drive field from the plasma interior. The lineshapes of the EIT spectra in the plasma reflect the plasma's Holtsmark microfield distribution, allowing us to determine plasma density and collisional line broadening over a range of pressures and rf drive powers. The work is expected to have applications in non-invasive spatio-temporal electric-field diagnostics of low-pressure plasma, plasma sheaths, process plasma and dusty plasma.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [64] [Riemannian Stochastic Interpolants for Amorphous Particle Systems](https://arxiv.org/abs/2512.16607)
*Louis Grenioux,Leonardo Galliano,Ludovic Berthier,Giulio Biroli,Marylou Gabrié*

Main category: stat.ML

TL;DR: A generative framework using equivariant Riemannian stochastic interpolation to efficiently sample equilibrium configurations of amorphous materials (glasses), overcoming slow traditional sampling methods.


<details>
  <summary>Details</summary>
Motivation: Sampling equilibrium configurations of glass-forming materials is notoriously slow and difficult, creating a bottleneck that could be overcome by developing a generative framework capable of producing equilibrium configurations with well-defined likelihoods.

Method: Leverages an equivariant Riemannian stochastic interpolation framework combining Riemannian stochastic interpolant and equivariant flow matching. The method rigorously incorporates periodic boundary conditions and symmetries of multi-component particle systems, adapting an equivariant graph neural network to operate directly on the torus.

Result: Numerical experiments on model amorphous systems demonstrate that enforcing geometric and symmetry constraints significantly improves generative performance.

Conclusion: The proposed framework successfully addresses the challenge of sampling equilibrium glass configurations by incorporating domain-specific geometric and symmetry constraints, offering a promising approach to accelerate simulations of amorphous materials.

Abstract: Modern generative models hold great promise for accelerating diverse tasks involving the simulation of physical systems, but they must be adapted to the specific constraints of each domain. Significant progress has been made for biomolecules and crystalline materials. Here, we address amorphous materials (glasses), which are disordered particle systems lacking atomic periodicity. Sampling equilibrium configurations of glass-forming materials is a notoriously slow and difficult task. This obstacle could be overcome by developing a generative framework capable of producing equilibrium configurations with well-defined likelihoods. In this work, we address this challenge by leveraging an equivariant Riemannian stochastic interpolation framework which combines Riemannian stochastic interpolant and equivariant flow matching. Our method rigorously incorporates periodic boundary conditions and the symmetries of multi-component particle systems, adapting an equivariant graph neural network to operate directly on the torus. Our numerical experiments on model amorphous systems demonstrate that enforcing geometric and symmetry constraints significantly improves generative performance.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [65] [Direct calculation of steady-state hydrodynamic solar wind solutions with newtonian viscosity](https://arxiv.org/abs/2512.16028)
*Roger B. Scott,Stephen J. Bradshaw,Mark G. Linton,Chris Lowder,Leonard Strachan*

Main category: astro-ph.SR

TL;DR: Viscous Navier-Stokes equations eliminate sonic point singularities in solar wind models, enabling efficient extrapolation from solar surface to heliosphere.


<details>
  <summary>Details</summary>
Motivation: Traditional inviscid solar wind models have singularities at sonic points that complicate modeling and require special treatment, hindering efficient solar wind simulation from solar surface to heliosphere.

Method: Include classical Newtonian viscous stress in hydrodynamic equations, cast steady-state Navier-Stokes as 5 coupled ODEs, solve with conventional methods without special sonic point treatment, and incorporate external heating and radiative losses.

Result: Viscosity eliminates sonic point singularities, enabling solutions from solar surface initial conditions to outer heliosphere in single computation, more realistic than analytical/empirical models at lower computational cost.

Conclusion: Viscous approach provides efficient, accurate solar wind modeling from observational surface conditions to heliosphere without sonic point complications, superior to traditional inviscid methods.

Abstract: Steady-state solutions to the Navier-Stokes equations are known to admit solutions that are singular at the sonic point. Consequently, inviscid solar wind models require special treatment of the solution near the sonic points, and this has proven to be a significant impediment to efficient modeling of the solar wind. In this paper we revisit the governing hydrodynamic equations for the expanding solar wind, with the inclusion of the classical (Newtonian) viscous stress , and we show how this inclusion eliminates the singularities that emerge from the inviscid equations. This result has been previously reported and used to generate solar wind profiles from initial conditions in the asymptotic limit; however, those studies did not include realistic treatments of the inner corona, and generally rejected the prospect of extrapolating solutions outward from the Sun into the heliosphere. Here, we expand this method to include external heating and optically thin radiative losses and show that solutions can be computed from initial conditions near the solar surface, thereby capturing the entire range of scales from below the transition region to the outer heliosphere in a single solution. Our approach is to cast the steady-state Navier-Stokes equations as a system of five coupled, ordinary differential equations (ODEs), which we solve using conventional methods, without any special treatment of the governing equations in the vicinity of the sonic point. The representative solutions that we present here demonstrate the utility and efficiency of this extrapolation method, which is considerably more realistic than commonly used analytical or empirical models. This method provides a direct approach to generating accurate solar wind profiles subject to observationally motivated initial conditions near the solar surface, at a fraction of the computational cost of comparable relaxation-based models.

</details>


<div id='cond-mat.supr-con'></div>

# cond-mat.supr-con [[Back]](#toc)

### [66] [Beyond dpa: an atomistic framework for a quantitative description of radiation damage in YBa2Cu3O7](https://arxiv.org/abs/2512.16249)
*Federico Ledda,Daniele Torsello,Davide Gambino,Flyura Djurabekova,Fabio Calzavara,Niccolò Di Eugenio,Ville Jantunen,Antonio Trotta,Erik Gallo,Kai Nordlund,Francesco Laviano*

Main category: cond-mat.supr-con

TL;DR: Developed multiscale atomistic approach combining Molecular Dynamics and Binary Collision Approximation to model radiation damage in YBa2Cu3O7 superconductors for harsh environment applications.


<details>
  <summary>Details</summary>
Motivation: Radiation damage in high-temperature cuprate superconductors is a major technological challenge for deployment in harsh environments like fusion reactors and accelerator facilities, but existing damage models are inadequate for their complex crystal structures.

Method: Developed atomistic-based approach coupling Molecular Dynamics and Binary Collision Approximation simulations in complementary way, integrated with Primary Knock-on Atom spectra from Monte Carlo codes for multiscale modeling.

Result: Established framework for quantitative estimates of damage descriptors including defect production, defect clustering, and effective damaged volume for irradiation conditions where collision cascades dominate.

Conclusion: The computational approach is suitable for predicting irradiation effects in any complex functional oxide, with applications ranging from aerospace to nuclear fusion and high-energy physics.

Abstract: Radiation damage in high-temperature cuprate superconductors represents one of the main technological challenges for their deployment in harsh environments, such as fusion reactors and accelerator facilities. Their complex crystal structure makes modeling irradiation effects in this class of materials a particularly demanding task, for which existing damage models remain inadequate. In this work, we develop an atomistic-based approach for describing primary radiation damage in YBa2Cu3O7, by coupling Molecular Dynamics and Binary Collision Approximation simulations in a way that makes them complementary. When integrated with Primary Knock-on Atom spectra obtained from Monte Carlo codes, our results establish a framework for multiscale modeling of radiation damage, enabling quantitative estimates of several damage descriptors, such as defect production, defect clustering, and the effective damaged volume for any specific irradiation conditions where collision cascades dominate. This computational approach is suitable for the prediction of irradiation effects in any complex functional oxide, with applications ranging from aerospace to nuclear fusion and high-energy physics.

</details>
