<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [math.AP](#math.AP) [Total: 8]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [physics.class-ph](#physics.class-ph) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [math-ph](#math-ph) [Total: 2]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 3]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [math.OC](#math.OC) [Total: 4]
- [quant-ph](#quant-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Asymptotic preserving methods for the low mach limit in discrete velocity models approximating kinetic equations](https://arxiv.org/abs/2512.19847)
*Giacomo Dimarco,Axel Klar,Theresa Köfler,Lorenzo Pareschi*

Main category: math.NA

TL;DR: A uniformly valid Lattice Boltzmann scheme for all flow regimes (kinetic to hydrodynamic) using IMEX Runge-Kutta for temporal accuracy and WENO/central differences for spatial resolution, reducing to incompressible Navier-Stokes in the hydrodynamic limit.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical scheme that works across all regimes of mean free path (from kinetic to hydrodynamic scales) without losing accuracy or stability, addressing the challenge of simulating flows with varying degrees of rarefaction.

Method: Combines Implicit-Explicit (IMEX) Runge-Kutta methods for high-order temporal accuracy and stability in stiff regimes, with finite difference WENO reconstructions and high-order central difference approximations for spatial resolution in a Lattice Boltzmann framework.

Result: The scheme reduces to a high-order finite difference formulation of incompressible Navier-Stokes equations in the hydrodynamic limit, ensuring physical consistency. Numerical experiments on 2D benchmark problems confirm accuracy, stability, and versatility across different flow regimes.

Conclusion: The proposed Lattice Boltzmann scheme provides a uniformly valid numerical framework that maintains high-order accuracy and stability across all flow regimes, from kinetic to hydrodynamic scales, with proven physical consistency in the hydrodynamic limit.

Abstract: We consider a Lattice Boltzmann type discrete velocity model in the low Mach number scaling and develop a corresponding numerical scheme that remains uniformly valid across all regimes of the mean free path, from the kinetic to the hydrodynamic scale. The proposed framework ensures high order temporal accuracy through the use of Implicit Explicit Runge Kutta methods, which provide stability and efficiency in stiff regimes, while spatial resolution is enhanced by combining finite difference WENO reconstructions with high order central difference approximations. In the appropriate asymptotic limit, the scheme reduces to a high order finite difference formulation of the incompressible Navier Stokes equations, thereby guaranteeing physical consistency of the numerical approximation with the limit model. To corroborate the theoretical findings, a set of numerical experiments is performed on two dimensional benchmark problems, which confirm the accuracy, stability, and versatility of the method across different flow regimes.

</details>


### [2] [Hybrid Weight Window Method for Global Time-Dependent Monte Carlo Particle Transport Calculations](https://arxiv.org/abs/2512.19925)
*Caleb A. Shaw,Dmitriy Y. Anistratov*

Main category: math.NA

TL;DR: A hybrid Monte Carlo/deterministic method for time-dependent particle transport using automatic weight windows based on low-order second-moment equations for global variance reduction.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient variance reduction technique for time-dependent Monte Carlo particle transport simulations that maintains uniform particle distribution across space and time steps.

Method: Uses automatic weight windows defined by solving auxiliary hybrid MC/deterministic low-order second-moment equations, with closures calculated by MC, second-order discretization in time/space, and filtering to reduce noise effects.

Result: The algorithm achieves sufficiently uniform MC particle distribution in space on each time step, with performance analyzed using analytic transport benchmark, figure of merit, and relative error metrics demonstrating computational efficiency.

Conclusion: The hybrid MC method with automatic weight windows based on low-order second-moment equations provides effective global variance reduction for time-dependent particle transport problems with quantified computational efficiency.

Abstract: This paper presents a new Monte Carlo (MC) algorithm for time-dependent particle transport problems with global variance reduction based on automatic weight windows (WWs). The centers of WWs at a time step are defined by the solution of an auxiliary hybrid MC / deterministic problem formed by the low-order second-moment (LOSM) equations. The closures for the hybrid LOSM equations are calculated by the MC method. The LOSM equations are discretized by a scheme of the second-order accuracy in time and space. Filtering techniques are applied to reduce noise effects in the LOSM closures. The WWs defined with the auxiliary solution give rise to sufficiently uniform MC particle distribution in space on each time step. The algorithm is analyzed by means of an analytic transport benchmark. We study performance of the MC algorithm depending on a set parameters of WWs. Figure of merit and relative error results are presented, demonstrating the performance of the hybrid MC method and quantifying its computational efficiency.

</details>


### [3] [Quasi-interpolation with random sampling centers](https://arxiv.org/abs/2512.19988)
*Wenwu Gao,Le Hu,Xingping Sun,Xuan Zhou*

Main category: math.NA

TL;DR: A quasi-interpolation framework for stochastic function approximation with Monte Carlo discretization, featuring dimension-independent L¹ concentration inequalities that partially mitigate the curse of dimensionality.


<details>
  <summary>Details</summary>
Motivation: To develop a general stochastic function approximation framework motivated by convolution-type solutions for weighted variational problems, addressing the curse of dimensionality through stochastic methods.

Method: Propose quasi-interpolants using Monte Carlo discretization of integrals, establish L^p-McDiarmid-type concentration inequalities (1≤p≤∞), and provide verifiable expected error estimates for stochastic quasi-interpolants.

Result: L¹ concentration inequalities are dimension-independent, offering partial stochastic mitigation of the curse of dimensionality. L^∞ version strengthens existing expected L^∞-error estimates. Numerical simulations validate theoretical analysis.

Conclusion: The framework provides effective stochastic quasi-interpolation with dimension-independent error bounds, partially overcoming the curse of dimensionality while improving existing error estimates.

Abstract: We propose and study a general quasi-interpolation framework for stochastic function approximation, which stems and draws motivation from convolution-type solutions for certain practical weighted variational problems.
  We obtain our quasi-interpolants using Monte Carlo discretization of the pertinent integrals and establish a family of $L^p$-McDiarmid-type concentration inequalities for $1\leq p\leq \infty$, which resulted in verifiable expected error estimates for the stochastic quasi-interpolants. The $L^1$-version of these concentration inequalities
  is dynamically-independent of dimensions, which offers a partial stochastic mitigation of the so called ``curse of dimensionality". The $L^\infty$-version of these concentration inequalities strengthens the existing expected $L^\infty$-error estimates in the literature. Numerical simulation results are provided at the end of the paper to validate the underlying theoretical analysis.

</details>


### [4] [Deep Eigenspace Network and Its Application to Parametric Non-selfadjoint Eigenvalue Problems](https://arxiv.org/abs/2512.20058)
*H. Li,J. Sun,Z. Zhang*

Main category: math.NA

TL;DR: A hybrid operator learning framework called Deep Eigenspace Network (DEN) learns stable invariant eigensubspace mappings for parametric non-selfadjoint eigenvalue problems, overcoming spectral instability through Fourier Neural Operators, geometry-adaptive POD bases, and cross-mode mixing.


<details>
  <summary>Details</summary>
Motivation: To efficiently solve parametric non-selfadjoint eigenvalue problems while overcoming spectral instability and mode switching inherent in non-selfadjoint operators, which makes learning individual eigenfunctions challenging.

Method: Proposed Deep Eigenspace Network (DEN) architecture that integrates Fourier Neural Operators, geometry-adaptive Proper Orthogonal Decomposition (POD) bases, and explicit banded cross-mode mixing mechanisms to capture complex spectral dependencies on unstructured meshes.

Result: Applied DEN to parametric non-selfadjoint Steklov eigenvalue problem, provided theoretical proofs for Lipschitz continuity of eigensubspace with respect to parameters, derived error bounds for eigenspace reconstruction, and validated high accuracy and zero-shot generalization across different discretizations.

Conclusion: The DEN framework successfully addresses spectral instability in non-selfadjoint eigenvalue problems by learning stable invariant eigensubspace mappings rather than individual eigenfunctions, with theoretical guarantees and strong empirical performance.

Abstract: We consider operator learning for efficiently solving parametric non-selfadjoint eigenvalue problems. To overcome the spectral instability and mode switching inherent in non-selfadjoint operators, we introduce a hybrid framework that learns the stable invariant eigensubspace mapping rather than individual eigenfunctions. We proposed a Deep Eigenspace Network (DEN) architecture integrating Fourier Neural Operators, geometry-adaptive POD bases, and explicit banded cross-mode mixing mechanisms to capture complex spectral dependencies on unstructured meshes. We apply DEN to the parametric non-selfadjoint Steklov eigenvalue problem and provide theoretical proofs for the Lipschitz continuity of the eigensubspace with respect to the parameters. In addition, we derive error bounds for the reconstruction of the eigenspace. Numerical experiments validate DEN's high accuracy and zero-shot generalization capabilities across different discretizations.

</details>


### [5] [An energy- and helicity-conserving enriched galerkin method for the incompressible Navier-Stokes equations](https://arxiv.org/abs/2512.20109)
*Siyuan Tong,Qilong Zhai,Qian Zhang,Ran Zhang*

Main category: math.NA

TL;DR: An enriched Galerkin method for incompressible Navier-Stokes equations that conserves both kinetic energy and helicity in inviscid limit without extra projection variables.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method for incompressible Navier-Stokes equations that can simultaneously conserve both kinetic energy and helicity in the inviscid limit, which is important for accurate simulation of turbulent flows and maintaining physical invariants.

Method: Uses enriched Galerkin velocity space (first-order continuous Galerkin space enriched with piecewise constants on mesh faces) with piecewise-constant pressure. Two schemes based on rotational form of convective term: nonlinear scheme and linear variant. Both preserve discrete helicity and kinetic energy exactly.

Result: Both proposed schemes exactly preserve discrete helicity and kinetic energy. Picard iteration maintains conservation properties of nonlinear scheme. Stability and rigorous error estimates established for nonlinear scheme. Numerical examples demonstrate accuracy and conservation of linear scheme.

Conclusion: The developed enriched Galerkin method successfully achieves simultaneous conservation of kinetic energy and helicity for incompressible Navier-Stokes equations without introducing additional projection variables, providing a robust numerical framework for accurate flow simulations.

Abstract: We develop an enriched Galerkin (EG) method for the incompressible Navier-Stokes equations that conserves both kinetic energy and helicity in the inviscid limit without introducing any additional projection variables. The method employs an EG velocity space, which is the first-order continuous Galerkin space enriched with piecewise constants defined on mesh faces, together with piecewise-constant pressure. Two numerical schemes based on the rotational form of the convective term are proposed: a nonlinear scheme and a linear variant. Both schemes exactly preserve the discrete helicity and kinetic energy, and the Picard iteration maintains the conservation properties of the nonlinear scheme. We prove the conservation properties of both the methods, and establish stability and rigorous error estimates for the nonlinear scheme. Numerical examples demonstrate the accuracy and conservation of the proposed linear scheme.

</details>


### [6] [A Certified Goal-Oriented A Posteriori Defeaturing Error Estimator for Elliptic PDEs](https://arxiv.org/abs/2512.20124)
*Philipp Weder,Annalisa Buffa*

Main category: math.NA

TL;DR: This paper develops mathematically certified, goal-oriented a posteriori defeaturing error estimators for Poisson's equation, linear elasticity, and Stokes flow to estimate errors in specific quantities of interest rather than just global energy-norm errors.


<details>
  <summary>Details</summary>
Motivation: While rigorous a posteriori estimators exist for global energy-norm errors from geometry simplifications, practitioners care more about accuracy of specific quantities of interest (QoIs) in simulations. There's a gap between existing global error estimators and practical needs for QoI accuracy assessment.

Method: 1) Derive new reliable energy-norm estimators for features with Dirichlet BCs in linear elasticity and Stokes flow (extending existing Poisson results). 2) Formulate general energy-norm estimators for multiple negative features with either Dirichlet or Neumann BCs (first time). 3) Combine these estimators with dual-weighted residual (DWR) method to obtain reliable estimates for linear QoIs.

Result: The paper develops mathematically certified, goal-oriented a posteriori defeaturing error estimators that provide reliable error estimates for specific quantities of interest, demonstrated through a range of numerical experiments.

Conclusion: The proposed framework bridges the gap between existing global energy-norm defeaturing error estimators and practical needs for assessing accuracy of specific quantities of interest, providing mathematically certified goal-oriented estimators for industrial simulation pipelines.

Abstract: Defeaturing, the process of simplifying computational geometries, is a critical step in industrial simulation pipelines for reducing computational cost. Rigorous a posteriori estimators exist for the global energy-norm error introduced by geometry simplifications. However, practitioners are usually more concerned with the accuracy of specific quantities of interest (QoIs) in the solution. This paper bridges that gap by developing mathematically certified, goal-oriented a posteriori defeaturing error estimators for Poisson's equation, linear elasticity, and Stokes flow. First, we derive new reliable energy-norm estimators for features subject to Dirichlet boundary conditions in linear elasticity and Stokes flow, based on existing results for Poisson's equation. Second, we formulate general energy-norm estimators for multiple negative features, subject to either Dirichlet or Neumann boundary conditions for the first time. Finally, we combine these estimators with the dual-weighted residual (DWR) method to obtain reliable estimates for linear QoIs and demonstrate their effectiveness across a range of numerical experiments.

</details>


### [7] [Manifold Function Encoder: Identifying Different Functions Defined on Different Manifolds](https://arxiv.org/abs/2512.20227)
*Jun Hu,Pengzhan Jin,Weijun Zhang*

Main category: math.NA

TL;DR: MFE is a novel method for encoding functions defined on different manifolds by treating them as elements in dual spaces and using spectral bases for super-algebraic convergence.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of identifying and encoding functions defined on different manifolds, which is important for applications like PDEs on varying domains and operator learning.

Method: Treats manifolds and functions as bounded linear functionals in dual spaces, expands them using approximating sequence of spectral bases (Legendre polynomials, Fourier basis), and proves super-algebraic convergence.

Result: MFE achieves super-algebraic convergence, handles complex cases (joint manifold functions of different dimensions, different measures), and shows approximation theory for operator learning including PDEs on varying domains.

Conclusion: MFE provides an effective framework for encoding manifold functions with theoretical guarantees and practical applications in PDE learning and real-world problems like 3D elasticity.

Abstract: We propose the Manifold Function Encoder (MFE) for identifying different functions defined on different manifolds. Both a manifold in Euclidean space and a function defined on this manifold can be viewed as bounded linear functionals on a suitable space of continuous functions. From this perspective, we treat manifold functions as elements of the dual space. By expanding them in the dual space based on appropriate approximating sequence of bases, we obtain a corresponding method for encoding manifold functions, that is MFE. Especially, we prove that MFE achieves super-algebraic convergence based on smooth bases commonly used in spectral methods, such as Legendre polynomials and Fourier basis. We further extend MFE to handle more complex cases, including joint manifold functions of different dimensions and manifold functions with different measures. In addition, we show the approximation theory for MFE-based operator learning, in particular learning the solution mappings of PDEs defined on varying domains, together with several numerical experiments including the 2-d Poisson equation and the 3-d elasticity problem on the real-world bearing.

</details>


### [8] [A Pick function approach for designing energy-decay preserving schemes of the Maxwell equations in Havriliak-Negami dispersive media](https://arxiv.org/abs/2512.20231)
*Baoli Yin,Guoyu Zhang,Yang Liu,Hong Li*

Main category: math.NA

TL;DR: A novel approach for designing high-order energy-decaying schemes for Maxwell's equations in Havriliak-Negami dispersive media, overcoming limitations of conventional convolution quadrature methods.


<details>
  <summary>Details</summary>
Motivation: Conventional convolution quadrature (CQ) methods based on linear multistep methods cannot generate completely monotonic sequences beyond first-order accuracy for Maxwell's equations in dispersive media, limiting the development of high-order energy-decaying schemes.

Method: The authors prove that for any second-or higher-order linear multistep method, the generating function cannot satisfy both Pick function properties and analyticity requirements. They overcome this by reconstructing the generating function's structure using Pick function theory to construct a second-order completely monotonic sequence.

Result: Successfully constructed a second-order completely monotonic sequence leading to a discrete scheme that inherits the continuous model's energy decay property with unconditional stability. Numerical experiments confirm convergence rates and energy dissipation behavior.

Conclusion: The proposed approach overcomes fundamental limitations of conventional CQ methods, enabling high-order energy-decaying schemes for Maxwell's equations in Havriliak-Negami dispersive media with guaranteed unconditional stability.

Abstract: This work proposes a novel approach for designing high-order energy-decaying schemes for Maxwell's equations in Havriliak-Negami dispersive media. It is shown that conventional convolution quadrature (CQ) methods, which rely directly on the generating function of linear multistep methods, cannot generate completely monotonic sequences beyond first-order accuracy. We rigorously prove that for any linear multistep method of second-or higher-order, the associated generating function $δ(ζ)$ cannot satisfy both that \(-δ(ζ)\) is a Pick function and that it is analytic on \((-\infty,1)\) - a key requirement for constructing completely monotonic sequences. To overcome this fundamental limitation, we introduce a reconstruction of the generating function's structure. By strategically incorporating the theory of Pick functions, we successfully construct a second-order completely monotonic sequence. This theoretical advance leads to a discrete scheme that inherits the continuous model's energy decay property, guaranteeing unconditional stability. Numerical experiments confirm the convergence rates and energy dissipation behavior of the proposed method.

</details>


### [9] [A variational multiscale approach to PDE-constrained optimization problems arising in Data-Driven Computational Mechanics](https://arxiv.org/abs/2512.20254)
*Ramon Codina,Roberto Federico Ausas,Pedro Balbão Bazon,Cristian Guillermo Gebhardt*

Main category: math.NA

TL;DR: The paper analyzes primal and dual optimality conditions for PDE-constrained optimization in Data-Driven Computational Mechanics, focusing on reaction-diffusion problems. It establishes well-posedness, proposes stable finite element approximations using Variational MultiScale framework, and provides numerical validation.


<details>
  <summary>Details</summary>
Motivation: To develop stable and consistent numerical approximations for primal and dual formulations of PDE-constrained optimization problems in Data-Driven Computational Mechanics, specifically for reaction-diffusion contexts, enabling reliable computational solutions.

Method: The authors start with continuous primal and dual optimality conditions, establish well-posedness, then propose finite element approximations using the Variational MultiScale framework. They investigate two sub-grid scale choices (Algebraic Sub-Grid Scale and Orthogonal Sub-Grid Scale) and analyze properties for quasi-uniform partitions. They show how to switch between discrete primal and dual formulations by adjusting stabilization parameters.

Result: The paper establishes well-posedness for both continuous and discrete formulations, develops stable finite element approximations, and demonstrates through numerical tests that the proposed methods perform well across progressively sophisticated cases, providing comparative assessment of different sub-grid scale approaches.

Conclusion: The proposed Variational MultiScale-based finite element approximations provide stable and consistent numerical methods for primal and dual formulations of PDE-constrained optimization in Data-Driven Computational Mechanics, with flexibility to switch between formulations via stabilization parameter adjustments, validated through comprehensive numerical testing.

Abstract: We consider the primal and dual forms of the optimality conditions for PDE-contrained optimization problems arising in Data-Driven Computational Mechanics when specialized to the reaction-diffusion context. Starting with the continuous setting, we establish well-posedness of such concomitant formulations. Then, we propose stable and consistent finite element approximations for these underlying primal and dual problems relying on the Variational MultiScale framework. For quasi-uniform finite element partitions, we investigate approximations' general properties and establish well-posedness for two canonical choices of the sub-grid scales, i.e., the Algebraic Sub-Grid Scale and Orthogonal Sub-Grid Scale. Moreover, for continuous finite element functions, we are able to move back and forth between the discrete primal and dual formulations only by changing the design of the stabilization parameters. To conclude, we stress-test the proposed approximations through a series of progressively sophisticated cases, providing both a comparative and qualitative assessment of their numerical performance.

</details>


### [10] [The Isogeometric Fast Fourier-based Diagonalization method](https://arxiv.org/abs/2512.20269)
*Monica Montardini,Stefan Takacs,Mattia Tani*

Main category: math.NA

TL;DR: A new preconditioner for Isogeometric Analysis linear systems that combines Fast Diagonalization with Fast Fourier Transform to achieve near-linear computational complexity while maintaining robustness in grid size and spline degree.


<details>
  <summary>Details</summary>
Motivation: Linear systems from Isogeometric Analysis discretization of PDEs have condition numbers that grow both with reciprocal square of grid size and exponentially with spline degree. Existing Fast Diagonalization method is robust but has superlinear computational complexity.

Method: Develop a variant of Fast Diagonalization method that exploits Fast Fourier Transform. Use stable splitting of spline space to handle boundary effects (since Fourier Transform cannot diagonalize the overall problem due to boundaries).

Result: The resulting preconditioner maintains robustness with respect to both grid size and spline degree while achieving computational complexity that grows almost linearly with the number of degrees of freedom.

Conclusion: The proposed method successfully combines Fast Diagonalization with Fast Fourier Transform through stable spline space splitting, creating an efficient preconditioner with near-linear complexity that remains robust for Isogeometric Analysis systems.

Abstract: The construction of robust solvers for linear systems obtained from the discretization of partial differential equations using Isogeometric Analysis is challenging since the condition number of the system matrix not only grows with the reciprocal square of the grid size (for second order problems), but also exponentially with the spline degree. The Fast Diagonalization method allows the construction of a preconditioner that is robust both in grid size and spline degree. Although this method is efficient in practice, its computational complexity is superlinear in the number of degrees of freedom. In this work, we construct a variant of the Fast Diagonalization method that can exploit the Fast Fourier Transformation. Note that, because of boundary effects, a Fourier Transformation cannot diagonalize the overall problem. We circumvent this issue using a stable splitting of the spline space. The resulting preconditioner is still robust with respect to the grid size and spline degree and can be realized with a computational complexity that grows almost linearly with the number of degrees of freedom.

</details>


### [11] [Implicit-explicit schemes for compressible Cahn-Hilliard-Navier-Stokes equations on staggered grids](https://arxiv.org/abs/2512.20351)
*Andreu Martorell,Pep Mulet,Dionisio F. Yáñez*

Main category: math.NA

TL;DR: A second-order IMEX scheme for compressible Cahn-Hilliard-Navier-Stokes equations on staggered grids, handling stiff terms implicitly and convective terms explicitly to overcome severe time-step restrictions.


<details>
  <summary>Details</summary>
Motivation: Standard explicit methods suffer from severe time-step restrictions due to high-order diffusion terms from Cahn-Hilliard and Navier-Stokes operators. Need efficient time-stepping for coupled velocity, density, and phase field equations.

Method: Second-order IMEX Runge-Kutta scheme with finite difference approximations on staggered (MAC) grids. Stiff terms (viscosity, diffusion) treated implicitly, convective terms handled explicitly. Only linear systems solved at each stage.

Result: Numerical experiments verify stability, accuracy, and efficiency of the proposed approach. The scheme overcomes time-step restrictions while maintaining stable coupling among velocity, density, and phase field.

Conclusion: The proposed second-order IMEX scheme provides an efficient and stable time-stepping method for compressible Cahn-Hilliard-Navier-Stokes equations, overcoming limitations of explicit methods through implicit treatment of stiff terms.

Abstract: We propose a second-order implicit-explicit (IMEX) time-stepping scheme for the isentropic, compressible Cahn-Hilliard-Navier-Stokes equations discretized on staggered (MAC) grids. The scheme is based on finite difference approximations that ensure a stable coupling among the velocity, density and phase field, with symmetric operators acting on the discretized viscosity terms.
  Standard explicit methods suffer from severe time-step restrictions due to the presence of second to fourth-order diffusion terms introduced by the Cahn-Hilliard and Navier-Stokes operators. To overcome these challenges, we develop an IMEX Runge-Kutta scheme that treats the stiff terms implicitly while the convective terms are dealt with explicitly, with the advantage that only linear systems are solved at each stage.
  Numerical experiments are performed to verify the stability, accuracy and efficiency of the proposed approach.

</details>


### [12] [Approximation bounds for norm constrained deep neural networks](https://arxiv.org/abs/2512.20422)
*Francesco Paolo Maiale,Anastasiia Trofimova,Arturo De Marinis*

Main category: math.NA

TL;DR: This paper analyzes approximation capacity of neural networks with arbitrary activation functions and weight norm constraints, providing both upper and lower bounds for smooth function classes.


<details>
  <summary>Details</summary>
Motivation: To understand the theoretical approximation capabilities of neural networks with general activation functions and constrained weights, which is important for understanding why neural networks work well in practice despite architectural constraints.

Method: 1) Proves upper bounds by approximating high-degree monomials and extending to functions via partition of unity and Taylor expansion. 2) Derives lower bounds through Rademacher complexity analysis. 3) Provides probabilistic version with randomly sampled weights. 4) Shows activation regularity assumptions can be weakened without worsening error. 5) Validates with numerical experiments.

Result: Establishes both upper and lower bounds on approximation error for smooth function classes, shows probabilistic upper bounds hold with random weights, demonstrates weaker activation regularity assumptions suffice, and provides numerical validation.

Conclusion: Neural networks with arbitrary activation functions and weight constraints have strong approximation capabilities for smooth functions, with bounds that hold even with weaker activation regularity and random weight initialization.

Abstract: This paper studies the approximation capacity of neural networks with an arbitrary activation function and with norm constraint on the weights. Upper and lower bounds on the approximation error of these networks are computed for smooth function classes. The upper bound is proven by first approximating high-degree monomials and then generalizing it to functions via a partition of unity and Taylor expansion. The lower bound is derived through the Rademacher complexity of neural networks. A probabilistic version of the upper bound is also provided by considering neural networks with randomly sampled weights and biases. Finally, it is shown that the assumption on the regularity of the activation function can be significantly weakened without worsening the approximation error, and the approximation upper bound is validated with numerical experiments.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [13] [Quantization for sequences of blow-up solutions to an elliptic equation having nonlocal exponential nonlinearity](https://arxiv.org/abs/2512.19865)
*Mathew Gluck*

Main category: math.AP

TL;DR: Analysis of asymptotic behavior of solutions to elliptic equations with nonlocal Choquard-type exponential nonlinearities, establishing concentration-compactness alternatives and energy quantization results.


<details>
  <summary>Details</summary>
Motivation: The paper studies a nonlocal analog of the classical prescribed Gaussian curvature equation, motivated by understanding the asymptotic behavior of solutions to elliptic equations with nonlocal exponential nonlinearities of Choquard type.

Method: Establishes a concentration-compactness alternative for sequences of solutions under suitable integrability assumptions on solutions and curvature functions. Under further regularity assumptions and when blow-up occurs, proves an energy quantization result.

Result: Provides description of asymptotic behavior of solution sequences, establishes concentration-compactness alternative, and proves energy quantization when blow-up occurs in the concentration-compactness scenario.

Conclusion: The work successfully characterizes the asymptotic behavior of solutions to nonlocal elliptic equations with exponential nonlinearities, establishing important analytical tools (concentration-compactness alternative and energy quantization) for studying these types of equations.

Abstract: This work provides a description of the asymptotic behavior of sequences of solutions to an elliptic equation with a nonlocal exponential nonlinearity of Choquard type. The equation under consideration is a nonlocal analog of the classical prescribed Gaussian curvature equation. A concentration-compactness alternative is established for sequences of solutions to the equation under consideration whenever suitable integrability assumptions on the solutions and the curvature functions are satisfied. Under further regularity assumptions on the curvature functions, and when blow-up occurs in the concentration-compactness alternative, an energy quantization result is established.

</details>


### [14] [On non-uniqueness for the system $\bu_t+(\bu\cdot\nabla)\bu=μΔ{\bf u}$](https://arxiv.org/abs/2512.19878)
*Helge Kristian Jenssen*

Main category: math.AP

TL;DR: The paper demonstrates non-uniqueness for the Cauchy problem in supercritical L^p, W^{1,p}, and W^{2,p} spaces using explicit irrotational solutions derived via Cole-Hopf transform from the multi-d heat equation.


<details>
  <summary>Details</summary>
Motivation: To investigate non-uniqueness phenomena in supercritical Sobolev spaces for the Cauchy problem, specifically addressing whether solutions are unique in various function spaces and understanding the limitations of uniqueness results.

Method: Uses explicit irrotational solutions obtained via Cole-Hopf transform from the multi-dimensional heat equation. Constructs classical solutions for positive times that vanish in specified norms but explode in L^∞ as t→0+.

Result: Proves non-uniqueness of the trivial solution in L^p(R^n) for n≥2 and 1≤p<n; in W^{1,p}(R^n) for 1≤p<n/2; and in W^{2,p}(R^n) for 1≤p<n/3. Solutions are classical for t>0, vanish in stated norms, but explode in L^∞ as t→0+.

Conclusion: The paper establishes explicit non-uniqueness examples in supercritical Sobolev spaces, demonstrating that uniqueness fails in certain L^p and Sobolev space regimes. This non-uniqueness is distinct from the Tikhonov phenomenon for the heat equation.

Abstract: Explicit irrotational solutions, obtained via the Cole-Hopf transform from the multi-d heat
  equation, give examples of non-uniqueness for the Cauchy problem in supercritical
  $L^p$, $W^{1,p}$, and $W^{2,p}$ regimes.
  We verify non-uniqueness of the trivial solution in the sense of $L^p(\RR^n)$, whenever $n\geq2$
  and $1\leq p<n$. The same solutions give non-uniqueness in $W^{1,p}(\RR^n)$
  and $W^{2,p}(\RR^n)$ for $1\leq p<\frac{n}{2}$ and $1\leq p<\frac{n}{3}$,
  respectively. The main example provides solutions which are classical for
  strictly positive times, and vanish in the stated norms, but explode in $L^\infty(\RR^n)$,
  as $t\to0+$. The non-uniqueness is unrelated to the
  Tikhonov non-uniqueness phenomenon for the heat equation.

</details>


### [15] [The Boltzmann Equation for 2D Taylor-Couette Flow](https://arxiv.org/abs/2512.20036)
*Renjun Duan,Weiqiang Wang,Yong Wang*

Main category: math.AP

TL;DR: Existence of 2-D Taylor-Couette flow for rarefied gas between rotating cylinders established using Boltzmann equation with geometric corrections and shear force.


<details>
  <summary>Details</summary>
Motivation: Investigate existence of steady Taylor-Couette flow for rarefied gas between coaxial rotating cylinders with different angular velocities, addressing non-equilibrium steady states in kinetic theory with geometric effects.

Method: Formulate using steady Boltzmann equation in polar coordinates with rotation-invariant ansatz. Use Caflisch's decomposition with Guo's L∞∩L² framework. Develop double-parameter (ε,σ)-approximation for solution construction, including test functions from second-order ODEs with geometric corrections.

Result: Prove existence of non-equilibrium steady solution for small shear rates. Steady profile shows polynomial tail at large velocities. Establish uniform macroscopic dissipation estimates without mass conservation. Justify non-negativity via large-time asymptotic stability with exponential convergence under radial perturbations.

Conclusion: Successfully established existence of Taylor-Couette flow for rarefied gases using Boltzmann equation with geometric corrections, providing rigorous mathematical foundation for non-equilibrium steady states in kinetic theory with rotational symmetry.

Abstract: In this paper, we investigate the existence of 2-D Taylor-Couette flow for a rarefied gas between two coaxial rotating cylinders, characterized by differing angular velocities at the outer boundary $\{r=1\}$ and the inner boundary $\{r=r_{1}>0\}$, with a small relative strength denoted by $α$. We formulate the problem using the steady Boltzmann equation in polar coordinates and seek a solution invariant under rotation. We assume that the steady state has the specific form $F(r,v_{r},v_φ-α\frac{r-r_{1}}{1-r_{1}},v_{z})$, where the translation angular velocity $α\frac{r-r_{1}}{1-r_{1}}$ is linearly sheared along the radial direction. With this ansatz, the problem is reduced to solve the nonlinear steady Boltzmann equation with geometric correction, subject to an external shear force of strength $α$ and the homogeneous non-moving diffuse reflection boundary condition. We establish the existence of a non-equilibrium steady solution for any small enough shear rate $α$ through Caflisch's decomposition, complemented by careful uniform estimates based on Guo's $L^{\infty} \cap L^2$ framework. The steady profile displays a polynomial tail behavior at large velocities. For the proof, we develop a delicate double-parameter $(ε,σ)$-approximation argument for the construction of solutions. In particular, we obtain uniform macroscopic dissipation estimates in the absence of mass conservation for $σ\in [0,1)$ getting close to 1. Additionally, due to the non-trivial geometric effects, we develop subtle constructions of test functions by solving second-order ODEs with geometric corrections to establish macroscopic dissipation. Furthermore, we justify the non-negativity of the steady profile by demonstrating its large-time asymptotic stability with an exponential convergence rate under radial perturbations.

</details>


### [16] [Weighted Robin eigenvalue problems and nonlinear elliptic equations with general growth in the gradient](https://arxiv.org/abs/2512.20192)
*Francesco Della Pietra,Giuseppina di Blasio,Giuseppe Riey*

Main category: math.AP

TL;DR: Existence result for Robin boundary value problems with gradient term and singular data in Marcinkiewicz space under smallness assumption on λ.


<details>
  <summary>Details</summary>
Motivation: Study existence of solutions to Robin boundary value problems with nonlinear gradient term and singular data, which arise in various PDE applications.

Method: Analyze weighted singular Robin eigenvalue problem to establish properties, then use these to prove existence for the main problem under smallness condition on λ.

Result: Prove existence of solutions for Robin boundary value problems with gradient term and singular data f ∈ M^{N/2} when λ is sufficiently small.

Conclusion: The paper establishes existence results for singular Robin boundary value problems by studying associated weighted eigenvalue problems and imposing smallness conditions on the parameter λ.

Abstract: We prove an existence result for Robin boundary value problems modeled on \[
  \begin{cases}
  Δu + |\nabla u|^2 + λf(x) = 0 & \text{in } Ω
  \\ \frac{\partial u}{\partial ν} + βu = 0 & \text{on } \partialΩ\end{cases} \] where $Ω$ is a bounded, sufficiently smooth open set in $\mathbb R^N$, $f(x)$ belongs to the Marcinkiewicz space $M^{\frac N2}$ and {$β>0$}, under a smallness assumption on the datum $λ$. In order to study such problem, we will show several properties of the weighted, singular Robin eigenvalue problem \[ λ_{1,f,γ}(Ω)= \inf_{ψ\in H^{1},\;\int_Ωfψ^{2}=1}\left\{\int_Ω|\nabla ψ|^{2}dx+γ\int_{\partialΩ}ψ^{2}\right\}. \]

</details>


### [17] [Fractional hypocoercivity in bounded domains in the anomalous diffusion limit](https://arxiv.org/abs/2512.20222)
*Maxime Herda,Marc Pegon,Isabelle Tristani*

Main category: math.AP

TL;DR: Exponential stability results for dissipative linear kinetic equations with heavy-tailed equilibria, with uniform estimates in anomalous diffusion limit, handling various boundary conditions and operators.


<details>
  <summary>Details</summary>
Motivation: To establish stability results for kinetic equations with heavy-tailed equilibria, which are challenging due to their non-standard equilibrium distributions, while maintaining robustness across different boundary conditions and in anomalous diffusion limits.

Method: Uses an L²-hypocoercivity inspired approach that provides uniform estimates in anomalous diffusion limit, handles periodic and Maxwell boundary conditions (specular to diffusive), and accommodates linear collisional operators acting on both velocity and spatial variables.

Result: Proves exponential stability for several dissipative linear kinetic equations with heavy-tailed equilibria, with estimates that remain uniform in the anomalous diffusion limit.

Conclusion: The developed framework successfully handles challenging kinetic equations with heavy-tailed equilibria, providing robust stability results that work across various boundary conditions and maintain uniformity in anomalous diffusion limits.

Abstract: In this paper, we provide a result of exponential stability for several dissipative linear kinetic equations with heavy-tailed equilibria. The approach, inspired by the so-called $L^2$-hypocoercivity method, is robust enough to provide estimates that are uniform in the anomalous diffusion limit. Moreover, it is able to deal with bounded domains with periodic boundary condition or general Maxwell boundary condition (from the pure specular to the pure diffusive case). In addition, our framework accommodates linear collisional operators that act simultaneously on the velocity and spatial variables.

</details>


### [18] [A supersolution approach to doubly degenerate parabolic equations with weights](https://arxiv.org/abs/2512.20373)
*Daniele Andreucci,Anatoli F. Tedeev*

Main category: math.AP

TL;DR: Study of Cauchy problem for doubly degenerate parabolic equation with exponential weight, establishing sharp temporal decay bounds via supersolution/subsolution construction.


<details>
  <summary>Details</summary>
Motivation: To analyze the behavior of solutions to doubly degenerate parabolic equations with space-dependent exponential weights, which appear in various physical applications including porous media and filtration problems with inhomogeneous densities.

Method: Construct supersolutions and subsolutions for the Cauchy problem using the doubling condition on the exponent, covering both logconvex and logconcave cases. Apply variable transformation to handle equations with inhomogeneous density.

Result: Obtain precise sharp temporal decay bounds for solutions, demonstrating control over solution behavior through the constructed supersolutions and subsolutions.

Conclusion: The method successfully establishes decay estimates for doubly degenerate parabolic equations with exponential weights, with applications extended to equations with inhomogeneous density via appropriate transformations.

Abstract: We consider the Cauchy problem in the Euclidean space for a doubly
  degenerate parabolic equation with a space-dependent exponential
  weight, where the exponent satisfies the doubling condition. In
  particular, both the so called logconvex and logconcave cases may be
  considered. Under the additional natural assumptions we construct
  supersolutions and subsolutions allowing us to control the precise
  sharp temporal decay bounds. We apply our results also to an
  equation with inhomogeneous density, via a suitable variable
  transformation.

</details>


### [19] [Supersonic sonic patch solution for the two-dimensional Euler equations with a van der Waals equation of state](https://arxiv.org/abs/2512.20484)
*Anamika Pandey,T. Raja Sekhar*

Main category: math.AP

TL;DR: The paper constructs supersonic sonic patch solutions for the 2D compressible Euler equations with van der Waals equation of state, extending transonic flow theory from ideal to non-ideal gases.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend transonic flow theory from ideal gases to more realistic non-ideal gases described by van der Waals equations of state, which introduce stronger nonlinear effects and modify degeneracy structures near sonic states, complicating analytical treatment.

Method: The authors use a self-similar framework associated with the four-state Riemann problem, employing characteristic decomposition combined with partial hodograph transformation to reformulate the problem as a degenerate hyperbolic system. They construct supersonic sonic patch solutions connecting strictly supersonic regions to sonic boundaries along pseudo streamlines.

Result: The authors establish the existence of globally defined supersonic solutions and prove their uniform regularity up to the sonic curve. They also investigate regularity properties of the resulting sonic boundary, extending supersonic sonic patch theory from polytropic gases to realistic non-ideal gas models.

Conclusion: The paper successfully extends the theory of supersonic sonic patches from polytropic ideal gases to non-ideal van der Waals gases, providing analytical tools to handle the stronger nonlinear effects and modified degeneracy structures in realistic gas models.

Abstract: We investigate supersonic transonic phenomena in the two-dimensional compressible Euler equations governed by a polytropic van der Waals equation of state. In contrast to the ideal gas setting, the non-ideal pressure law introduces stronger nonlinear effects and modifies the degeneracy structure near sonic states, which significantly complicates the analytical treatment of transonic flows. Within the self-similar framework associated with the four-state Riemann problem, we construct a supersonic sonic patch solution that connects a strictly supersonic region to a sonic boundary along a pseudo streamline. The analysis is based on a characteristic decomposition combined with a partial hodograph transformation, through which the problem is reformulated as a degenerate hyperbolic system. We establish the existence of a globally defined supersonic solution and prove its uniform regularity up to the sonic curve. In addition, we investigate the regularity properties of the resulting sonic boundary. Our results extend the theory of supersonic sonic patches from polytropic gases to a realistic non-ideal gas model.

</details>


### [20] [Global attractors for the Signorini problem with pointwise damping](https://arxiv.org/abs/2512.20549)
*Jaime E. Muñoz Rivera,Maria Grazia Naso*

Main category: math.AP

TL;DR: The paper proves global attractors exist for Signorini problems with pointwise dissipation, showing exponential decay to zero and compact global attractors for both semilinear Signorini and elastic obstacle problems.


<details>
  <summary>Details</summary>
Motivation: To investigate the existence of global attractors for Signorini problems with pointwise dissipation, which are important in contact mechanics and obstacle problems, to understand their long-time behavior.

Method: Approximates the original problem by a hybrid PDE-ODE system, then performs rigorous analysis of well-posedness and long-time behavior of solutions.

Result: Both semilinear Signorini problem and elastic obstacle problem with normal compliance exhibit exponential decay to zero and admit compact global attractors.

Conclusion: The hybrid PDE-ODE approximation method successfully establishes the existence of global attractors and exponential decay properties for Signorini problems with pointwise dissipation.

Abstract: The existence of global attractors is investigated for the Signorini problem with pointwise dissipation. It is shown that both the semilinear Signorini problem and the elastic obstacle problem with normal compliance exhibit exponential decay to zero and admit compact global attractors. To establish these results, the original problem is approximated by a hybrid PDE-ODE system, which allows for a rigorous analysis of well-posedness and the long-time behavior of its solutions.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [21] [URANOS -- a novel voxel engine Neutron Transport Monte-Carlo Simulation](https://arxiv.org/abs/2512.19704)
*Markus Köhli,Martin Schrön,Steffen Zacharias,Ulrich Schmidt*

Main category: physics.comp-ph

TL;DR: URANOS is a new 3D Monte Carlo neutron transport code with intuitive GUI for simulating neutron detectors and cosmic-ray induced environmental neutrons.


<details>
  <summary>Details</summary>
Motivation: To provide a fast computational workflow with intuitive GUI for small to medium-sized neutron transport projects, avoiding the need for extensive modeling and training on dedicated packages.

Method: Uses Monte Carlo neutron transport with ray-casting algorithm based on voxel engine. Geometry is defined layerwise from pixel matrices. Features scattering kernel for elastic/inelastic collisions, absorption, and evaporation processes. Models charged particle transport for boron-lined detectors with electron track projection via diffusion.

Result: Developed URANOS code that is freely available, capable of simulating response functions of neutron detectors, laboratory setups, and cosmic-ray induced environmental neutron transport with easy accessibility and complex geometry handling.

Conclusion: URANOS offers an accessible simulation tool for neutron environments at instruments, providing capabilities that would otherwise require extensive modeling expertise and dedicated software packages.

Abstract: URANOS is a newly developed 3D neutron transport Monte-Carlo code from thermal to fast energy domains. It was originally developed for the CASCADE detector. The purpose of this simulation program is to provide a fast computational workflow and an intuitive graphical user interface (GUI) for small to medium-sized projects. It features a ray-casting algorithm based on a voxel engine. The simulation domain is defined layerwise, whereas the geometry is extruded from a pixel matrix of materials, identified by specific numbers. Input files are a stack of pictures, all other settings, including the configuration of predefined sources, can be adjusted via the GUI. The scattering kernel features the treatment of elastic and inelastic collisions, absorption and absorption-like processes like evaporation. Cross sections, energy distributions and angular distributions are taken from evaluated data bases. In order to simulate boron-lined detectors it also models the charged particle transport following the conversion by computing the energy loss in the boron and its consecutive layer. The electron track is then projected onto a readout unit by longitudinal and transversal diffusion. URANOS is freely available and can be used to simulate the response function of boron-lined or epithermal neutron detectors, small-scale laboratory setups and especially transport studies of cosmic-ray induced environmental neutrons. It offers an easy accessibility and comparably simple interface capable of handling complex geometries. URANOS therefore offers possibilities to understand and simulate the neutron environment at instruments, which would otherwise require extensive modeling and training on dedicated packages.

</details>


### [22] [Molecular Dynamics Investigation of Mass Transport During Evaporation for the Binary System of n-Dodecane and Nitrogen](https://arxiv.org/abs/2512.19996)
*Suman Chakraborty,Bongseok Kim,Li Qiao*

Main category: physics.comp-ph

TL;DR: Study of mass transport across liquid-vapor interface in n-dodecane/nitrogen binary mixture using molecular dynamics, showing evaporation coefficient decreases with temperature despite increased molecular activity.


<details>
  <summary>Details</summary>
Motivation: Continuum models fail to capture thermodynamic property variations at interfaces under high-temperature/high-pressure conditions, especially for complex binary mixtures. Need improved models using diffused interfaces and Kinetic Boundary Conditions (KBCs) for better mass transport prediction.

Method: Non-equilibrium molecular dynamics simulation of Type-III binary mixture (n-dodecane and nitrogen) at near-critical temperatures. Analyzed interfacial properties (thickness, density gradient, surface tension) and temporal evolution of evaporation/reflected mass fluxes.

Result: Both evaporation and reflection fluxes increase with temperature, indicating enhanced molecular activity. However, evaporation coefficient (α_evap) decreases from ~0.978 at Tr=0.70 to ~0.905 at Tr=0.95 due to increased reflected flux reducing net evaporation efficiency.

Conclusion: First study estimating mass transport coefficients for Type-III binary systems, providing foundation for developing Kinetic Boundary Conditions for hydrocarbon-nitrogen mixtures in high-temperature applications.

Abstract: The study of interfacial fluxes under evaporative or condensation processes are ubiquitous in thermal systems, propulsion devices, and many other engineering applications. Most continuum scale models fail to capture the true nature of thermodynamic property variation across the interface, particularly under high-temperature and high-pressure conditions. An improvement over the sharp interface assumption of such continuum scale models is the consideration of a diffused interface and using Kinetic Boundary Conditions (KBCs) to model the mass-transport across the liquid vapor interface. Prior studies on KBCs mainly address monoatomic fluids. Two of the main ingredients required to form KBCs are: density and mass flux. Here, we study a Type-III binary mixture of n-dodecane and nitrogen using non-equilibrium molecular dynamics at near-critical temperatures. Interfacial properties such as thickness, density gradient, and surface tension were analyzed. A key result is the temporal evolution of the evaporation and reflected mass fluxes across the vapor-liquid interface. We observe that both the evaporation and reflection fluxes increase with increasing temperature, indicating enhanced molecular activity and mass transport across the interface at higher Tr. In contrast, the evaporation coefficient alpha_evap decreases from about alpha approximately 0.978 at Tr equals 0.70 to alpha approximately 0.905 at Tr equals 0.95 because the reflected-out flux increases along with the evaporation flux, which reduces the net efficiency of molecular evaporation across the interface. To the authors' knowledge, this is one of the very few studies estimating mass transport coefficients for Type-III binary systems, laying the foundation for KBCs in hydrocarbon and nitrogen mixtures.

</details>


### [23] [An immersed boundary method for the discrete velocity model of the Boltzmann equation](https://arxiv.org/abs/2512.20252)
*Longqing Ge,Qingdong Cai,Yonghao Zhang,Tianbai Xiao*

Main category: physics.comp-ph

TL;DR: An immersed boundary method for Boltzmann equation's discrete velocity model with Maxwell gas-surface interaction, featuring upwind-weighted compact interpolation and cut-cell correction for accurate slip/jump effects on Cartesian grids.


<details>
  <summary>Details</summary>
Motivation: To develop a unified immersed boundary framework for simulating fluid-structure interactions in aerospace engineering, particularly for non-equilibrium flows with velocity slip and temperature jump effects, while maintaining the simplicity of Cartesian grids.

Method: Combines Maxwell gas-surface interaction model with ghost-cell particle distribution functions, uses upwind-weighted compact interpolation in physical space for stability, and implements cut-cell correction in velocity space to handle surface discontinuities.

Result: The method achieves second-order accuracy in both physical and velocity space, provides numerical stability for arbitrary geometries, and delivers predictions comparable to body-conformal solvers while retaining Cartesian grid advantages.

Conclusion: The proposed approach offers a unified, physically consistent immersed boundary framework for simulating dynamic interactions between non-equilibrium flows and structural components across various flow regimes.

Abstract: Computational modeling and simulation of fluid-structure interactions constitute a fundamental cornerstone for advancing aerospace engineering endeavors. This paper addresses the notion and implementation of the immersed boundary method for the discrete velocity model of the Boltzmann equation. The method incorporates the Maxwell gas-surface interaction model into the construction of ghost-cell particle distribution functions, facilitating meticulous characterization of velocity slip and temperature jump effects within a Cartesian grid framework, which ultimately achieves accurate prediction of aerodynamic parameters. This study presents two principal advancements. First, an upwind-weighted compact interpolation strategy is developed in physical space, which ensures numerical stability and robustness for arbitrary geometries without relying on large stencils or normal-direction projections. Second, a cut-cell correction methodology is proposed in velocity space to address the degradation of quadrature accuracy caused by surface discontinuities. The resulting framework is equally applicable to both two- and three-dimensional problems without requiring any dimension-specific modifications. Rigorous analysis is provided to prove that the approach maintains second-order accuracy across both physical and velocity space, while ensuring robust numerical stability. Comprehensive numerical experiments demonstrate that the solution algorithm achieves the designed accuracy and delivers precise predictions comparable to body-conformal solvers, while retaining the simplicity, flexibility, and scalability of the Cartesian grid method. The proposed approach provides a unified and physically consistent immersed boundary framework for simulating dynamic interactions between non-equilibrium flows and structural components across a wide range of flow regimes.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [24] [Thermal wakefield structure in plasma acceleration processes: insights from fluid models and PIC simulations](https://arxiv.org/abs/2512.20150)
*Daniele Simeoni,Andrea Renato Rossi,Gianmarco Parise,Fabio Guglietta,Mauro Sbragaglia*

Main category: physics.plasm-ph

TL;DR: This paper analyzes plasma acceleration with thermal effects, comparing fluid models with different thermal closures against PIC simulations to determine appropriate modeling approaches.


<details>
  <summary>Details</summary>
Motivation: To understand plasma acceleration processes when thermal effects are significant, and to determine which thermal closure assumptions in fluid models are most appropriate for accurate numerical simulations.

Method: Numerical simulations using fluid models with different thermal closure assumptions, systematically compared against ground-truth particle-in-cell (PIC) simulations. Focus on analyzing the first electron depletion bubble after the driver.

Result: Detailed characterization of the size of the first electron depletion bubble and the electromagnetic fields developed inside. Results help determine correct thermal closure assumptions for fluid models in plasma acceleration simulations.

Conclusion: The study provides guidance on appropriate thermal closure assumptions for fluid models in plasma acceleration simulations and clarifies the limits of applicability for different modeling approaches when thermal effects are non-negligible.

Abstract: We focus on the process of plasma acceleration in the presence of non-negligible thermal effects, wherein a driver of relativistic electrons perturbs a warm neutral plasma and generates a wakefield structure. We study the acceleration process via numerical simulations based on fluid models with different thermal closure assumptions, and also provide systematic comparisons against ground-truth data coming from particle-in-cell (PIC) simulations. The focus of the analysis is on the first electron depletion bubble after the driver, where we provide a detailed characterization of its size and the electromagnetic fields developed inside. Our results are instrumental in determining the correct thermal closure assumption to be used in fluid models for the numerical simulations of plasma acceleration processes, as well as elucidating the corresponding limits of applicability.

</details>


<div id='physics.class-ph'></div>

# physics.class-ph [[Back]](#toc)

### [25] [A Dynamical-Time Framework for the Dynamics of Charged Particles](https://arxiv.org/abs/2512.19768)
*Zui Oporto,Gonzalo Marcelo Ramírez-Ávila*

Main category: physics.class-ph

TL;DR: A dynamical framework for modeling charged particle motion in electromagnetic fields that treats time as a dynamical variable, works for both relativistic and nonrelativistic regimes, and offers computational advantages over conventional approaches.


<details>
  <summary>Details</summary>
Motivation: To develop a more flexible and efficient framework for modeling charged particle dynamics in electromagnetic fields that can handle both massive and massless particles, work across relativistic regimes, and provide computational advantages over traditional uniform-time approaches.

Method: Treats time coordinate as a dynamical variable, develops velocity space representation of particle trajectories, and applies the framework to analyze particle motion in constant electromagnetic fields and other configurations.

Result: The framework successfully models both massive and massless particles, reveals that asymptotic behavior in constant electromagnetic fields is independent of mass and initial conditions, and demonstrates computational improvements in accuracy and efficiency for uniform fields and elliptically polarized waves.

Conclusion: The dynamical-time formulation provides a versatile and computationally efficient approach for studying charged particle motion in electromagnetic fields, offering insights into asymptotic behavior and practical advantages over conventional methods.

Abstract: We present a dynamical framework for modeling the motion of point-like charged particles, with or without mass, in general external electromagnetic fields. A key feature of this formulation is the treatment of the time coordinate as a dynamical variable. The framework applies to the relativistic regime while consistently admitting a nonrelativistic limit. We also present a representation of particle trajectories in velocity space, which provides a clear insight into the nature and asymptotic behavior of the dynamics. As an application, we compare the motion of massive and massless particles in a constant electromagnetic field and find that, for identical field configurations, their asymptotic behavior is independent of both mass and initial conditions. Finally, we explore the computational advantages of the dynamical-time formulation over the conventional uniform-time approach in two study cases: an uniform electromagnetic field and an elliptically polarized wave propagating along a uniform magnetic field. In both scenarios, the proposed scheme exhibits improvements in accuracy and computational efficiency.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [26] [Climate change impacts on supra-permafrost soil and aquifer hydrology: broader, deeper, and longer activity](https://arxiv.org/abs/2512.19860)
*Neelarun Mukherjee,Bo Gao,Ethan T. Coon,Pin Shuai,Devon Hill,Bethany T. Neilson,George W. Kling,Jingyi Chen,M. Bayani Cardenas*

Main category: physics.geo-ph

TL;DR: Permafrost warming increases active layer thaw depth and extends winter liquid water presence, amplifying carbon release feedbacks.


<details>
  <summary>Details</summary>
Motivation: To understand how climate warming (air temperature +3.5°C, snowfall +40mm from 1981-2020) affects hydrological dynamics in carbon-rich permafrost aquifers, which is critical for predicting permafrost-carbon-climate feedbacks.

Method: Observation-informed thermal hydrology modeling of a hillslope drained by Imnavait Creek headwater stream in Arctic Alaska's continuous permafrost region, analyzing changes from 1981 to 2020.

Result: Warmer summers deepened annual thaw depths; warmer winters with heavier snowfall increased aquifer outflow to streams, warmed soils, and expanded zero-curtain zones. In 2017-2018, zero-curtain areas with liquid water persisted through winter.

Conclusion: Both summer and winter warming drive year-round aquifer dynamics, creating conditions that amplify the permafrost-carbon-climate feedback through extended liquid water presence and increased hydrological activity.

Abstract: The thermal dynamics and hydrology of active layer soils and supra-permafrost aquifers determine the fate of the vast pool of carbon that they hold. In permafrost watersheds of Arctic Alaska, air temperature has warmed by up to 3.5 °C and snowfall has increased by up to ~40 mm from 1981 to 2020. How these changes impact the seasonal to decadal hydrological activity of the carbon-rich aquifers is mostly unknown. Observation-informed thermal hydrology modeling of a hillslope drained by a headwater stream (Imnavait Creek) within continuous permafrost showed profound changes from 1981 to 2020. Warmer summer temperatures deepened annual thaw depths. Steadily warming winter air temperatures, heavier snowfall, and stored energy from summer increased annual water outflow from the hillslope aquifer to the stream, warmed soil temperatures, and expanded and prolonged zero-curtain (stable at 0 °C) zones. In 2017-2018, zero-curtain areas with liquid water persisted through winter. Our findings reveal that both summer and winter warming drive year-round aquifer dynamics, creating conditions that amplify the permafrost-carbon-climate feedback.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [27] [Koopman for stochastic dynamics: error bounds for kernel extended dynamic mode decomposition](https://arxiv.org/abs/2512.20247)
*Maximiliano Hertel,Friedrich M. Philipp,Manuel Schaller,Karl Worthmann*

Main category: math.DS

TL;DR: Kernel extended dynamic mode decomposition (kEDMD) error bounds for stochastic systems, analyzing pointwise error in terms of data points, split into deterministic kernel regression error and probabilistic Monte Carlo sampling error.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous error bounds for kEDMD approximations of the Koopman operator in stochastic dynamical systems, which is important for understanding the accuracy and reliability of these approximations in practical applications.

Method: Prove L∞-error bounds by establishing Koopman invariance of reproducing kernel Hilbert spaces, analyze pointwise error in terms of data points, split error into deterministic kernel regression component (fill distance) and probabilistic Monte Carlo component (number of samples).

Result: Derived error bounds for kEDMD approximants of Koopman operator for stochastic systems, with error decomposition showing deterministic component related to fill distance and probabilistic component related to sample size.

Conclusion: The paper provides theoretical error bounds for kEDMD in stochastic systems, validated through Langevin-type SDEs with nonlinear double-well potential, offering insights into the approximation quality and convergence properties of the method.

Abstract: We prove $L^\infty$-error bounds for kernel extended dynamic mode decomposition (kEDMD) approximants of the Koopman operator for stochastic dynamical systems. To this end, we establish Koopman invariance of suitably chosen reproducing kernel Hilbert spaces and provide an in-depth analysis of the pointwise error in terms of the data points. The latter is split into two parts by showing that kEDMD for stochastic systems involves a kernel regression step leading to a deterministic error in the fill distance as well as Monte Carlo sampling to approximate unknown expected values yielding a probabilistic error in terms of the number of samples. We illustrate the derived bounds by means of Langevin-type stochastic differential equations involving a nonlinear double-well potential.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [28] [Localization of the eigenfunctions of a Bloch-Torrey operator on the half-plane](https://arxiv.org/abs/2512.20202)
*Martin Averseng,Nicolas Frantz,Frédéric Hérau,Nicolas Raymond*

Main category: math-ph

TL;DR: The paper studies eigenfunction localization for a non-self adjoint operator on the upper half-plane, showing that eigenfunctions concentrate in an O(h^{1/2}) neighborhood of x=0, which is sharper than the O(h^{1/3}) scale suggested by variational estimates.


<details>
  <summary>Details</summary>
Motivation: To understand the precise localization properties of eigenfunctions for non-self adjoint operators in semiclassical limits, particularly when variational estimates may not be optimal.

Method: Uses symbolic calculus of operator-valued pseudodifferential operators to analyze the eigenfunction behavior and establish sharp localization scales.

Result: Proves that eigenfunctions are concentrated in an O(h^{1/2}) neighborhood of the axis {x=0}, which is sharper than the O(h^{1/3}) scale from variational estimates, and shows this scale is optimal.

Conclusion: The O(h^{1/2}) localization scale for eigenfunctions in the x-direction is sharp and represents the true optimal concentration behavior, demonstrating that variational methods can overestimate localization scales.

Abstract: We consider a non-self adjoint operator of the form $-h^2 Δ+ i(V(x) + α(x)y)$ on the upper half plane $y > 0$ with Dirichlet boundary conditions on $\{y = 0\}$ with $V \geq 0$, $V$ admitting a non-degenerate minimum at $x = 0$ and $α'(0) = 0$. We study its eigenfunctions associated to the smallest eigenvalues in magnitude in the semiclassical limit $h \to 0$. Elementary variational estimates show that these eigenfunctions are localized near the point $(0,0)$ at the scales $O(h^{1/3})$ in $x$ and $O(h^{2/3})$ in $y$. In this paper, we show that the $O(h^{1/3})$ localization in $x$ is not optimal; more precisely, we establish that the eigenfunctions are concentrated in a neighborhood of size $O(h^{1/2})$ of the axis $\{x = 0\}$, and this scale is shown to be sharp. The proof relies on the symbolic calculus of operator-valued pseudodifferential operators.

</details>


### [29] [Exponential Decay outside of the Light Cone for the Pseudo-Relativistic Non-Autonomous Schrödinger Equation](https://arxiv.org/abs/2512.20488)
*Sébastien Breteaux,Jérémy Faupin,Viviana Grasselli*

Main category: math-ph

TL;DR: Maximal velocity bound for pseudo-relativistic quantum particles in time-dependent potentials, showing probability decays exponentially with distance outside light cone.


<details>
  <summary>Details</summary>
Motivation: To establish fundamental limits on quantum particle propagation speed in relativistic quantum mechanics with time-dependent external potentials, extending finite propagation speed results to more general settings.

Method: Mathematical analysis using convex geometry and probability theory to derive exponential decay bounds for particle propagation probabilities outside light cones generated by initial regions.

Result: Proves that probability for particle starting in convex set X to reach convex set Y at time t is bounded by e^{-2δ}, where δ is distance from Y to time-t section of light cone generated by X.

Conclusion: Pseudo-relativistic quantum particles obey maximal velocity bounds similar to relativistic causality, with exponentially suppressed probabilities for propagation outside light cones even in time-dependent potentials.

Abstract: We establish a maximal velocity bound for a pseudo-relativistic quantum particle in an external time-dependent potential. Our estimate shows that the probability for the particle, starting in a convex set $X\subset\mathbb{R}^d$ at $t=0$, to reach a convex set $Y\subset\mathbb{R}^d$ at a time $t>0$, is bounded by $e^{-2δ}$ where $δ$ is the distance from $Y$ to the section at time $t$ of the light cone generated by $X$.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [30] [The AI Scaling Wall of Diminishing Returns: Of LLMs, Electric Dogs, and General Relativity](https://arxiv.org/abs/2512.20264)
*Hemant Shukla*

Main category: astro-ph.IM

TL;DR: LLM scaling is hitting diminishing returns - compute grows 10-100x while accuracy barely improves, suggesting the next AI breakthrough will come from smarter, more efficient models rather than bigger ones.


<details>
  <summary>Details</summary>
Motivation: The motivation is to quantify and address the diminishing returns in large language model scaling, where massive increases in computational resources yield minimal accuracy improvements, indicating a fundamental limitation in current scaling approaches.

Method: The paper appears to use quantitative analysis to measure the slowdown in LLM scaling efficiency, likely analyzing compute-accuracy tradeoffs across different model sizes and architectures to demonstrate the diminishing returns.

Result: The results show that LLMs are hitting a "scaling wall" where compute requirements grow 10-100x while accuracy improvements are minimal, indicating severe diminishing returns in current scaling approaches.

Conclusion: The conclusion argues that the next major advancement in AI will not come from simply making models larger, but from developing smarter, more efficient architectures and training methods that can achieve better performance with less computational resources.

Abstract: LLMs are hitting the scaling wall - compute grows 10-100x while accuracy barely moves. This note quantifies the slowdown and argues that the next leap in AI will come not from bigger models, but from smarter, more efficient ones.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [31] [Iterative learning scheme for crystal structure prediction with anharmonic lattice dynamics](https://arxiv.org/abs/2512.20424)
*Hao Gao,Yue-Wen Fang,Ion Errea*

Main category: cond-mat.mtrl-sci

TL;DR: Combines evolutionary algorithms, atomic foundation models, and SSCHA for crystal structure prediction with anharmonic lattice dynamics, achieving accurate phase stability predictions for H3S from 50-200 GPa.


<details>
  <summary>Details</summary>
Motivation: Current CSP methods struggle with displacive phase transitions in solids (common in ferroelectrics, thermoelectrics, etc.) where ionic contributions to free energy and lattice anharmonicity become essential. Variational methods like SSCHA are accurate but computationally expensive, while ML potentials need extensive training data and have limited generalization.

Method: Iterative learning framework combining evolutionary algorithms, atomic foundation models, and stochastic self-consistent harmonic approximation (SSCHA). Foundation models enable robust relaxations of random structures, reducing required training data. SSCHA's statistical averaging reduces free energy evaluation errors.

Result: Applied to highly anharmonic H3S system, achieves good agreement with DFT benchmarks, accurately predicting phase stability and vibrational properties from 50 to 200 GPa. Statistical averaging in SSCHA reduces free energy evaluation errors without needing extremely high ML potential accuracy.

Conclusion: Bridges gap between data efficiency and predictive power, establishing practical pathway for crystal structure prediction with anharmonic lattice dynamics by combining evolutionary algorithms, foundation models, and SSCHA.

Abstract: First-principles based crystal structure prediction (CSP) methods have revealed an essential tool for the discovery of new materials. However, in solids close to displacive phase transitions, which are common in ferroelectrics, thermoelectrics, charge-density wave systems, or superconducting hydrides, the ionic contribution to the free energy and lattice anharmonicity become essential, limiting the capacity of CSP techniques to determine the thermodynamical stability of competing phases. While variational methods like the stochastic self-consistent harmonic approximation (SSCHA) accurately account for anharmonic lattice dynamics \emph{ab initio}, their high computational cost makes them impractical for CSP. Machine-learning interatomic potentials offer accelerated sampling of the energy landscape compared to purely first-principles approaches, but their reliance on extensive training data and limited generalization restricts practical applications. Here, we propose an iterative learning framework combining evolutionary algorithms, atomic foundation models, and SSCHA to enable CSP with anharmonic lattice dynamics. Foundation models enable robust relaxations of random structures, drastically reducing required training data. Applied to the highly anharmonic H$_3$S system, our framework achieves good agreement with the benchmarks based on density functional theory, accurately predicting phase stability and vibrational properties from 50 to 200 GPa. Importantly, we find that the statistical averaging in the SSCHA reduces the error in the free energy evaluation, avoiding the need for extremely high accuracy of machine-learning potentials. This approach bridges the gap between data efficiency and predictive power, establishing a practical pathway for CSP with anharmonic lattice dynamics.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [32] [Ab initio Simulations of EMI-BF4 Neutral-Surface Interactions in Electrospray Thrusters](https://arxiv.org/abs/2512.19752)
*Nicholas Laws,Elaine Petro*

Main category: physics.chem-ph

TL;DR: QM/MM molecular dynamics simulations of EMI-BF4 collisions with gold surfaces reveal energy-dependent fragmentation patterns and charge states, providing insights for electrospray thruster design and ground test de-biasing.


<details>
  <summary>Details</summary>
Motivation: Electrospray thruster characterization is complicated by secondary species emission and incomplete neutral product diagnostics, requiring better understanding of ionic liquid-surface interactions.

Method: Energy-resolved mixed quantum/classical (QM/MM) ab initio molecular dynamics simulations of neutral EMI-BF4 colliding with Au surfaces at impact energies from 10 to 100 eV.

Result: Three-stage energy-dependent fragmentation: low energy (10-20 eV) favors ionic dissociation, intermediate (30-40 eV) opens neutralization window, high energy (>50 eV) drives covalent fragmentation. Heavy fragments scatter at small angles, light fragments at large angles. Neutral bombardment still produces charged secondaries.

Conclusion: Findings enable de-biasing of facility measurements using tandem TOF-SIMS and RGA with suppression-bias corrections, informing electrospray thruster designs to reduce extractor surface interception and contamination.

Abstract: Electrospray thrusters promise compact, high specific impulse propulsion for small spacecraft, yet ground characterization remains confounded by secondary species emission and incomplete diagnostics of neutral products. To address these limitations, we perform energy-resolved mixed quantum/classical (QM/MM) ab initio molecular dynamics (MD) of neutral 1-ethyl-3-methylimidazolium tetrafluoroborate, EMI-BF4, colliding with Au extractor surfaces with impact energies from 10 to 100 eV to resolve fragment species spectra, charge states, kinetic energy partitioning, and scattering geometry. The simulations reveal a three-stage sequence with impact energy: the low energy regime, 10 to 20 eV, which favors ionic dissociation, intermediate energy regime, between 30 to 40 eV, opens a neutralization window, and high energy regime, greater than 50 eV, drives covalent fragmentation into many light products with mixed charge states. Fractional energy distributions show a transition from few-body, energy-concentrated outcomes in the low energy regime to many-body, energy-dispersed outcomes in the high energy regime. Deflection angle distributions exhibit a strong mass-to-angle anti-correlation such that heavier fragments favor small deflection, whereas lighter fragments populate larger deflection angles. The fraction of transient metastables peaks near 50 eV, coinciding with abundant neutral fragment production. Importantly, neutral bombardment still produces charged secondaries at the target even when the upstream ion plume is fully suppressed by a decelerating electrode. These findings provide a basis for de-biasing facility measurements by pairing tandem time-of-flight secondary ion mass spectrometry and residual gas analyzer with suppression-bias corrections to inform the design of electrospray thrusters that reduce interception and contamination on extractor surfaces.

</details>


### [33] [Finite-Temperature Thermally-Assisted-Occupation Density Functional Theory, Ab Initio Molecular Dynamics, and Quantum Mechanics/Molecular Mechanics Methods](https://arxiv.org/abs/2512.20313)
*Shaozhi Li,Jeng-Da Chai*

Main category: physics.chem-ph

TL;DR: FT-TAO-DFT extends thermally-assisted-occupation DFT to finite temperatures for studying multi-reference systems, enabling AIMD and QM/MM applications to explore thermal equilibrium properties of n-acenes.


<details>
  <summary>Details</summary>
Motivation: To study thermal equilibrium properties of large multi-reference systems at finite electronic temperatures, extending the capabilities of TAO-DFT which was previously limited to absolute zero temperature.

Method: Developed finite-temperature extension of TAO-DFT (FT-TAO-DFT), combined it with ab initio molecular dynamics (FT-TAO-AIMD), and created QM/MM version (FT-TAO-QM/MM). Applied these methods to study n-acenes (n=2-6) in vacuum and argon matrix.

Result: For n-acenes at ≤1000K, electronic temperature effects on radical nature and IR spectra are minor, while nuclear temperature effects are noticeable. Ar matrix has minimal impact on radical nature but co-deposition procedure may affect IR spectra.

Conclusion: FT-TAO-DFT and its extensions provide efficient computational tools for studying thermal properties of multi-reference systems, revealing important insights about temperature effects on n-acenes' electronic and vibrational properties.

Abstract: Recently, thermally-assisted-occupation density functional theory (TAO-DFT) [J.-D. Chai, J. Chem. Phys. 136, 154104 (2012)] has been demonstrated to be an efficient and accurate electronic structure method for studying the ground-state properties of large multi-reference (MR) systems at absolute zero. To explore the thermal equilibrium properties of large MR systems at finite electronic temperatures, in the present work, we propose the finite-temperature (FT) extension of TAO-DFT, denoted as FT-TAO-DFT. Besides, to unlock the dynamical information of large MR systems at finite temperatures, FT-TAO-DFT is combined with ab initio molecular dynamics, leading to FT-TAO-AIMD. In addition, we also develop FT-TAO-DFT-based quantum mechanics/molecular mechanics (QM/MM), denoted as FT-TAO-QM/MM, to provide a cost-effective description of the thermal equilibrium properties of a QM subsystem with MR character embedded in an MM environment at finite temperatures. Moreover, the FT-TAO-DFT, FT-TAO-AIMD, and FT-TAO-QM/MM methods are employed to explore the radical nature and infrared (IR) spectra of n-acenes (n = 2--6), consisting of n linearly fused benzene rings, in vacuum and in an argon (Ar) matrix at finite temperatures. According to our calculations, for n-acenes at 1000 K or below, the electronic temperature effects on the radical nature and IR spectra are very minor, while the nuclear temperature effects on these properties are noticeable. For n-acene in an Ar matrx at absolute zero, the Ar matrix has minimal impact on the radical nature of n-acene, while the co-deposition procedure of n-acene and Ar atoms may affect the IR spectrum of n-acene.

</details>


### [34] [Topological resolution of conical intersection seams and the coupled cluster bifurcation via mixed Hodge modules](https://arxiv.org/abs/2512.20414)
*Prasoon Saurabh*

Main category: physics.chem-ph

TL;DR: QuMorpheus is an open-source computational package that resolves numerical instabilities in characterizing conical intersections using topological methods based on Dissipative Mixed Hodge Modules, enabling robust mapping of intersection seams in complex molecular systems.


<details>
  <summary>Details</summary>
Motivation: The accurate characterization of conical intersections (CIs) using high-level electronic structure methods like Coupled Cluster theory suffers from numerical instabilities and root bifurcations near ground state CIs, making the "Gold Standard" of chemistry inapplicable where it's most needed.

Method: QuMorpheus implements a topological framework based on Dissipative Mixed Hodge Modules that maps Coupled Cluster polynomial equations to a spectral sheaf, computing exact Monodromy (μ) invariants of the intersection to resolve singularities algorithmically.

Result: The approach correctly identifies physical ground state topology in the Köhn-Tajti model, resolves intersection seams in realistic chemical systems (Ethylene and Chloronium ion), and explains Woodward-Hoffmann selection rules in Previtamin D photoisomerization as topological "Monodromy Wall" effects rather than purely energetic barriers.

Conclusion: QuMorpheus establishes a general software solution to the "Yarkony Problem," enabling robust, automated mapping of global intersection seams in complex molecular systems, with topological stability that enables control protocols for quantum dynamics.

Abstract: The rigorous description of Conical Intersections (CIs) remains the central challenge of non-adiabatic quantum chemistry. While the ``Yarkony Seam'' -- the $(3N-8)$-dimensional manifold of degeneracy -- is well-understood geometrically, its accurate characterization by high-level electronic structure methods is plagued by numerical instabilities. Specifically, standard Coupled Cluster (CC) theory suffers from root bifurcations near Ground State CIs, rendering the ``Gold Standard'' of chemistry inapplicable where it is needed most. Here, we present \textbf{QuMorpheus}, an open-source computational package that resolves these singularities by implementing a topological framework based on Dissipative Mixed Hodge Modules (DMHM) [P. Saurabh, arXiv:2512.19487 (2025)]. By algorithmically mapping the CC polynomial equations to a spectral sheaf, we compute the exact Monodromy ($μ$) invariants of the intersection. We demonstrate that this automated algebraic geometry approach correctly identifies the physical ground state topology in the Köhn-Tajti model and resolves the intersection seams of realistic chemical systems, including Ethylene and the Chloronium ion ($\mathrm{H_2Cl^+}$). Furthermore, we apply QuMorpheus to the photoisomerization of Previtamin D, proving that the experimentally observed Woodward-Hoffmann selection rules are a direct consequence of a topological ``Monodromy Wall'' ($μ=1, γ=π$) rather than purely energetic barriers. This establishes a general software solution to the ``Yarkony Problem,'' enabling the robust, automated mapping of global intersection seams in complex molecular systems. The topological stability of these intersections allows for the control protocols discussed in Ref.[P. Saurabh, Submitted to Phys. Rev. X (2025)].

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [35] [Superluminal Wave Activation at Relativistic Magnetized Shocks](https://arxiv.org/abs/2512.19892)
*Jens F. Mahlmann,Logan Eskildsen,Arno Vanthieghem,Dawei Dai,Lorenzo Sironi*

Main category: astro-ph.HE

TL;DR: The paper validates a mechanism where Alfvénic perturbations convert into superluminal O-modes at magnetized shocks, potentially explaining fast radio burst generation in magnetar environments.


<details>
  <summary>Details</summary>
Motivation: Fast radio bursts (FRBs) are energetic radio transients whose emission mechanisms remain poorly understood despite growing observations. The paper aims to validate a proposed mechanism involving wave conversion at shocks in magnetar magnetospheres and winds.

Method: The study uses pair-plasma theory and 1D particle-in-cell (PIC) simulations to validate the superluminal wave activation mechanism. Simulations model both monochromatic upstream waves and broadband spectra across magnetized shocks.

Result: Theory predicts two downstream modes: non-propagating Alfvénic perturbations and propagating superluminal O-modes. Superluminal wave activation occurs when upstream perturbation frequency exceeds downstream plasma frequency. PIC simulations confirm wavenumber and frequency jumps across shocks for perturbations above plasma frequency, with downstream plasma frequency acting as a high-pass filter.

Conclusion: The validated superluminal wave activation mechanism provides a plausible explanation for FRB generation in relativistic magnetized winds from magnetars, offering insights into how Alfvénic perturbations can convert into observable radio signals at shocks.

Abstract: Fast radio bursts (FRBs) are extremely energetic radio transients, some are generated in magnetar magnetospheres and winds. Despite a growing number of observations, their emission mechanisms remain elusive. It has recently been proposed that Alfvénic perturbations can convert into superluminal O-modes at magnetized shocks and propagate in the downstream as a radio signal. We validate this superluminal wave activation mechanism using pair-plasma theory and particle-in-cell simulations. Theory predicts two different downstream modes: non-propagating Alfvénic perturbations and propagating superluminal O-modes. Superluminal wave activation occurs if the frequency of upstream perturbations in the shock frame exceeds the downstream plasma frequency. 1D particle-in-cell simulations confirm wavenumber and frequency jumps across the shock for upstream perturbations with frequencies well above the plasma frequency. Our simulations model both monochromatic upstream waves and broadband spectra with the downstream plasma frequency acting like a high-pass filter for superluminal O-modes. We discuss implications for FRB generation in relativistic magnetized winds.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [36] [Quantitative approximation of a Keller--Segel PDE by a branching moderately interacting particle system and suppression of blow-up](https://arxiv.org/abs/2512.20504)
*Thomas Cavallazzi,Alexandre Richard,Milica Tomasevic*

Main category: math.PR

TL;DR: The paper studies the Keller-Segel PDE with logistic damping, proves local well-posedness and global existence under certain conditions, and establishes convergence of a stochastic particle system to this PDE with explicit convergence rate.


<details>
  <summary>Details</summary>
Motivation: To understand the Keller-Segel PDE with logistic damping (which prevents blow-up) and provide a microscopic justification through a stochastic particle system that captures both attractive chemotactic interactions and demographic competition effects.

Method: Two-part approach: 1) PDE analysis proving local well-posedness of mild solutions and global existence in dimensions 2 or with strong damping; 2) Introduction of stochastic moderately interacting particle system with singular attractive kernel and branching structure due to birth/death events, then proving convergence to the PDE.

Result: Local well-posedness established for the Keller-Segel PDE with logistic damping; global solutions exist in dimension 2 or with sufficient damping; empirical measure of particle system converges to PDE solution with rate N^{-1/(2(d+1))}.

Conclusion: The paper successfully connects microscopic stochastic particle dynamics with macroscopic Keller-Segel PDE behavior, providing both analytical results for the PDE and probabilistic justification through particle approximation with explicit convergence rate.

Abstract: The Keller--Segel PDE is a model for chemotaxis known to exhibit possible finite-time blow-up. Following a seminal work by Tello and Winkler, a logistic damping term is added in this PDE and local well-posedness of mild solutions is proven. When the space dimension is $2$ or when the damping is strong enough, the solution is global in time. In the second part of this work, a microscopic description of this model is introduced in terms of a system of stochastic moderately interacting particles. This system features two main characteristics: the interaction between particles happens through a singular (Coulomb-type) kernel which is attractive; and the particles are subject to demographic events, birth and death due to local competition with other particles. The latter induces a branching structure of the particle system. Then the main result of this work is the convergence of the empirical measure of the particle system towards the Keller--Segel PDE with logistic damping, with a rate of order $N^{-\frac{1}{2(d+1)}}$.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Reduced Order Modeling for Tsunami Forecasting with Bayesian Hierarchical Pooling](https://arxiv.org/abs/2512.19804)
*Shane X. Coffing,John Tipton,Arvind T. Mohan,Darren Engwirda*

Main category: cs.LG

TL;DR: A novel reduced order model called randPROM combines neural Galerkin projections with statistical hierarchical pooling to create physics surrogates that generate statistically calibrated simulations for similar problems, demonstrated on tsunami modeling.


<details>
  <summary>Details</summary>
Motivation: Traditional ROMs like proper orthogonal decomposition are constrained to specific processes they model and lack statistical interpretability. There's a need for ROMs that can generalize to similar problems while providing statistically interpretable and physically justified predictions.

Method: Uses neural Galerkin projections to create an initial value problem encoding PDE physics via neural networks for temporal weight trajectories. Applies statistical hierarchical pooling to learn distributions on initial temporal weights, enabling generation of new statistically interpretable weights. Combines these with spatial features to form randPROM physics surrogates.

Result: Successfully applied to tsunami modeling (synthetic Fiji case and real-world Tohoku 2011 disaster). Demonstrates significant reduction in simulations needed for statistically calibrated predictions of tsunami wave arrival time and height while maintaining physical defensibility.

Conclusion: randPROMs enable creation of physics surrogates that generate simulations consistent in distribution to neighborhoods of initial conditions, providing statistically interpretable and physically justified predictions for complex nonlinear problems like tsunamis with reduced computational cost.

Abstract: Reduced order models (ROM) can represent spatiotemporal processes in significantly fewer dimensions and can be solved many orders faster than their governing partial differential equations (PDEs). For example, using a proper orthogonal decomposition produces a ROM that is a small linear combination of fixed features and weights, but that is constrained to the given process it models. In this work, we explore a new type of ROM that is not constrained to fixed weights, based on neural Galerkin-Projections, which is an initial value problem that encodes the physics of the governing PDEs, calibrated via neural networks to accurately model the trajectory of these weights. Then using a statistical hierarchical pooling technique to learn a distribution on the initial values of the temporal weights, we can create new, statistically interpretable and physically justified weights that are generalized to many similar problems. When recombined with the spatial features, we form a complete physics surrogate, called a randPROM, for generating simulations that are consistent in distribution to a neighborhood of initial conditions close to those used to construct the ROM. We apply the randPROM technique to the study of tsunamis, which are unpredictable, catastrophic, and highly-detailed non-linear problems, modeling both a synthetic case of tsunamis near Fiji and the real-world Tohoku 2011 disaster. We demonstrate that randPROMs may enable us to significantly reduce the number of simulations needed to generate a statistically calibrated and physically defensible prediction model for arrival time and height of tsunami waves.

</details>


### [38] [GeoTransolver: Learning Physics on Irregumar Domains Using Multi-scale Geometry Aware Physics Attention Transformer](https://arxiv.org/abs/2512.20399)
*Corey Adams,Rishikesh Ranade,Ram Cherukuri,Sanjay Choudhry*

Main category: cs.LG

TL;DR: GeoTransolver is a multiscale geometry-aware physics attention transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention with cross-attention to shared geometry/global/boundary-condition context from multi-scale ball queries.


<details>
  <summary>Details</summary>
Motivation: To advance operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes by unifying multiscale geometry-aware context with physics-based attention in a scalable transformer architecture.

Method: Replaces standard attention with GALE (Geometry-Aware Physics Attention), coupling physics-aware self-attention on learned state slices with cross-attention to shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO). Persistently projects geometry, global and boundary condition parameters into physical state spaces to anchor latent computations to domain structure and operating regimes.

Result: Benchmarked on DrivAerML, Luminary SHIFT-SUV, and Luminary SHIFT-Wing, showing better accuracy, improved robustness to geometry/regime shifts, and favorable data efficiency compared to Domino, Transolver, and AB-UPT. Achieved superior drag/lift R2 and Relative L1 errors for field variables.

Conclusion: GeoTransolver advances operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes by unifying multiscale geometry-aware context with physics-based attention in a scalable transformer architecture.

Abstract: We present GeoTransolver, a Multiscale Geometry-Aware Physics Attention Transformer for CAE that replaces standard attention with GALE, coupling physics-aware self-attention on learned state slices with cross-attention to a shared geometry/global/boundary-condition context computed from multi-scale ball queries (inspired by DoMINO) and reused in every block. Implemented and released in NVIDIA PhysicsNeMo, GeoTransolver persistently projects geometry, global and boundary condition parameters into physical state spaces to anchor latent computations to domain structure and operating regimes. We benchmark GeoTransolver on DrivAerML, Luminary SHIFT-SUV, and Luminary SHIFT-Wing, comparing against Domino, Transolver (as released in PhysicsNeMo), and literature-reported AB-UPT, and evaluate drag/lift R2 and Relative L1 errors for field variables. GeoTransolver delivers better accuracy, improved robustness to geometry/regime shifts, and favorable data efficiency; we include ablations on DrivAerML and qualitative results such as contour plots and design trends for the best GeoTransolver models. By unifying multiscale geometry-aware context with physics-based attention in a scalable transformer, GeoTransolver advances operator learning for high-fidelity surrogate modeling across complex, irregular domains and non-linear physical regimes.

</details>


### [39] [DeepONet-accelerated Bayesian inversion for moving boundary problems](https://arxiv.org/abs/2512.20268)
*Marco A. Iglesias,Michael. E. Causon,Mikhail Y. Matveev,Andreas Endruweit,Michael . V. Tretyakov*

Main category: cs.LG

TL;DR: DeepONet neural operator enables fast surrogate modeling for moving boundary Darcy flow, coupled with Ensemble Kalman Inversion for real-time parameter estimation in Resin Transfer Moulding processes.


<details>
  <summary>Details</summary>
Motivation: Need for fast, accurate emulators of moving boundary systems for digital twin platforms, particularly for real-time monitoring and control of industrial processes like Resin Transfer Moulding.

Method: Deep Operator Network (DeepONet) architecture for surrogate modeling of moving boundary Darcy flow, coupled with Ensemble Kalman Inversion (EKI) for Bayesian inverse problems.

Result: DeepONet surrogate accelerates inversion by several orders of magnitude compared to full-model EKI, enabling real-time, high-resolution estimation of permeability, porosity, and other parameters.

Conclusion: Neural operator learning provides powerful framework for digital twins, with generalization across spatial/temporal domains and arbitrary sensor configurations, representing significant step toward practical industrial deployment.

Abstract: This work demonstrates that neural operator learning provides a powerful and flexible framework for building fast, accurate emulators of moving boundary systems, enabling their integration into digital twin platforms. To this end, a Deep Operator Network (DeepONet) architecture is employed to construct an efficient surrogate model for moving boundary problems in single-phase Darcy flow through porous media. The surrogate enables rapid and accurate approximation of complex flow dynamics and is coupled with an Ensemble Kalman Inversion (EKI) algorithm to solve Bayesian inverse problems.
  The proposed inversion framework is demonstrated by estimating the permeability and porosity of fibre reinforcements for composite materials manufactured via the Resin Transfer Moulding (RTM) process. Using both synthetic and experimental in-process data, the DeepONet surrogate accelerates inversion by several orders of magnitude compared with full-model EKI. This computational efficiency enables real-time, accurate, high-resolution estimation of local variations in permeability, porosity, and other parameters, thereby supporting effective monitoring and control of RTM processes, as well as other applications involving moving boundary flows. Unlike prior approaches for RTM inversion that learn mesh-dependent mappings, the proposed neural operator generalises across spatial and temporal domains, enabling evaluation at arbitrary sensor configurations without retraining, and represents a significant step toward practical industrial deployment of digital twins.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [40] [Spatiotemporal Chaos and Defect Proliferation in Polar-Apolar Active Mixture](https://arxiv.org/abs/2512.20289)
*Partha Sarathi Mondal,Tamas Vicsek,Shradha Mishra*

Main category: cond-mat.soft

TL;DR: Active mixture of polar and apolar self-driven components exhibits complex dynamical states including spatiotemporal chaos with band-like structures and topological defects, showing non-monotonic response to polar component variations.


<details>
  <summary>Details</summary>
Motivation: To investigate active mixtures with both polar and apolar self-driven components, which should display richer behaviors than living liquid crystal systems where apolar constituents are passive. This addresses how energy injection at microscopic scales in active systems leads to unconventional flow patterns compared to inertial fluids.

Method: Numerical solutions of hydrodynamic equations for the active mixture system, analyzing dynamical states through spectral properties of density fluctuations and maximal Lyapunov exponent to quantify spatiotemporal chaos.

Result: Discovery of complex dynamical states including a dynamically disordered phase with high-density band-like structures and half-integer topological defects. The system shows non-monotonic response of apolar species to changes in polar component density and activity. Intermediate regime exhibits spatiotemporal chaos quantified by spectral analysis and Lyapunov exponents.

Conclusion: Active mixtures with both polar and apolar self-driven components exhibit richer behaviors than passive apolar systems, broadening understanding of complex transitions in active matter. Findings suggest experimental realizations in bacterial suspensions or synthetic microswimmer assemblies.

Abstract: Chaotic transitions in inertial fluids typically proceed through a direct energy cascade from large to small scales. In contrast, active systems, composed of self propelled units, inject energy at microscopic scales and therefore exhibit an inverse cascade, giving rise to distinctly unconventional flow patterns. Here, we investigate an active mixture consisting of both apolar and polar self driven components, a setting expected to display richer behaviours than those found in living liquid crystal (LLC) systems, where the apolar constituent is passive. Using numerical solutions of the corresponding hydrodynamic equations, we uncover a variety of complex dynamical states. Our results reveal a non-monotonic response of the apolar species to changes in the density and activity of the polar component. In an intermediate regime, reminiscent of LLC-induced disorder, the system develops a dynamically disordered phase characterised by high-density, chaotically evolving band-like structures and by the continual creation and annihilation of half integer topological defects. We show that this regime exhibits spatiotemporal chaos, which we quantify through two complementary measures: the spectral properties of density fluctuations and the maximal Lyapunov exponent. Together, these findings broaden the understanding of complex transitions in active matter and suggest potential experimental realisations in bacterial suspensions or synthetic microswimmer assemblies.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [41] [A Variational Characterization and A Line Search Newton-Noda Method for the unifying spectral problem of nonnegative tensors](https://arxiv.org/abs/2512.20031)
*Jiefeng Xu,Xueli Bai,Dong-Hui Li*

Main category: math.OC

TL;DR: The paper proposes a new min-max Collatz-Wielandt formula for (σ,p)-spectral radius of nonnegative tensors and develops a line search Newton-Noda method for computing positive eigenpairs.


<details>
  <summary>Details</summary>
Motivation: The (σ,p)-eigenvalue problem unifies several tensor eigenvalue and singular value problems, but existing approaches use auxiliary multihomogeneous mappings. The authors aim to provide a more direct variational characterization and develop efficient numerical methods for computing positive eigenpairs.

Method: 1) Proposes an alternative min-max Collatz-Wielandt formula that bypasses auxiliary mappings and connects directly to convex programs. 2) Develops LS-NNM (line search Newton-Noda method) that integrates Newton method with Noda iteration, uses positivity-preserving line search based on constrained optimization.

Result: The new variational characterization recovers classical results and admits natural convex reformulation. LS-NNM achieves global and quadratic convergence for problems with unique positive eigenpairs (guaranteed by Perron-Frobenius theorem). Numerical experiments demonstrate the method's performance.

Conclusion: The paper provides a more direct approach to (σ,p)-spectral problems and an efficient numerical method with proven convergence properties, advancing the computational framework for tensor eigenvalue problems.

Abstract: We study the general $(\boldsymbolσ,\mathbf{p})$-eigenvalue problem of nonnegative tensors introduced by A. Gautier, F. Tudisco, and M. Hein [SIAM J. Matrix Anal. Appl., 40 (2019), pp. 1206--1231], which unifies several well-studied tensor eigenvalue and singular value problems. First, we propose an alternative min-max Collatz--Wielandt formula for the $(\boldsymbolσ,\mathbf{p})$-spectral radius, which bypasses the auxiliary multihomogeneous mapping employed in that work. This variational characterization both recovers several classical results and admits a natural convex reformulation. It arises from an alternative approach that directly connects the $(\boldsymbolσ,\mathbf{p})$-spectral problem to a class of convex programs.
  We then develop and analyze a line search Newton-Noda method (LS-NNM) for computing the positive $(\boldsymbolσ,\mathbf{p})$-eigenpair of nonnegative tensors. The proposed method integrates Newton method with Noda iteration. The Newton equation is derived from an equivalent nonlinear system, while the eigenvalue sequence is updated by the strategy of the Noda iteration and its variants. To ensure global convergence, we introduce a positivity-preserving line search procedure based on an equivalent constrained optimization problem. The global and quadratic convergence of LS-NNM are established for the class of $(\boldsymbolσ,\mathbf{p})$-spectral problem that admits a unique positive $(\boldsymbolσ,\mathbf{p})$-eigenpair, as guaranteed by the Perron-Frobenius theorem. Finally, numerical experiments are conducted to illustrate the performance of LS-NNM.

</details>


### [42] [Exact boundary controllability and stabilizability of a degenerated Timoshenko beam](https://arxiv.org/abs/2512.20446)
*Günter Leugering,Yue Wang,Qiong Zhang*

Main category: math.OC

TL;DR: This paper studies boundary controllability and stabilization of a Timoshenko beam with stiffness degeneracy at one end, controlled at the opposite boundary, distinguishing between weak and strong degeneracy types.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address control challenges in structural systems where stiffness degeneracy occurs, which is relevant for real-world structural damping and control applications. The work extends previous results from the 1D wave equation to the more complex Timoshenko beam system.

Method: The authors use energy multiplier techniques and the Hilbert Uniqueness Method (HUM) to establish observability inequalities for both weakly and strongly degenerate equations under various boundary conditions (Dirichlet, Robin, Neumann).

Result: The study establishes conditions for exact boundary controllability and shows that appropriate boundary state and velocity feedback controls at the non-degenerate end can achieve exponential stabilization of the system.

Conclusion: The research highlights new control strategies and stabilization effects specific to degenerate Timoshenko beam systems, successfully extending previous wave equation results to address stiffness degeneracy in structural control applications.

Abstract: This paper investigates the boundary controllability and stabilizability of a Timoshenko beam subject to degeneracy at one end, while control is applied at the opposite boundary. Degeneracy in this context is measured by the real parameters for $μ_a\in [0,2)$ for $a\in\{K,EI\}$, where $K(x)$ denotes shear stiffness and $EI(x)$ bending stiffness. We differentiate between weak degeneracy $μ_a\in [0,1)$ and strong degeneracy $μ_a\in [1,2)$, which may occur independently in shear and bending. Our study establishes observability inequalities for both weakly and strongly degenerate equations under Dirichlet, Robin, and Neumann boundary conditions. Using energy multiplier techniques and the Hilbert Uniqueness Method (HUM), we derive conditions for exact boundary controllability and show that appropriate boundary state and velocity feedback controls at the non-degenerate end can stabilize the system exponentially. Extending results previously obtained for the 1-dimensional wave equation in \cite{AlabauCannarsaLeugering2017}, this study highlights new control strategies and stabilization effects specific to the degenerate Timoshenko beam system, addressing challenges pertinent to real-world structural damping and control applications.

</details>


### [43] [Asymmetric exact controllability for networks of spatial elastic strings, springs and masses](https://arxiv.org/abs/2512.20462)
*Günter Leugering,Charlotte Rodriguez,Yue Wang*

Main category: math.OC

TL;DR: Analysis of elastic string networks with spring-coupled masses showing convergence to classical models, well-posedness, and controllability with complex smoothing patterns at junctions.


<details>
  <summary>Details</summary>
Motivation: To study networks of elastic strings coupled via springs with end masses, which model mechanical vibration systems with potential damage (missing springs), and understand how these systems converge to classical string network models while exhibiting unique dynamic boundary conditions and controllability properties.

Method: Model strings as quasilinear balance laws with nonlocal boundary conditions due to point masses at nodes. Analyze convergence to classical Kirchhoff/continuity conditions as spring stiffness → ∞ and masses vanish. Prove semi-global classical solutions existence and study exact boundary controllability for star-like networks with control at endpoints (except one clamped end).

Result: System converges to classical string network model. Well-posedness established for semi-global classical solutions with extra regularity at masses. Local and global-local exact boundary controllability proven for star-like networks, revealing complex smoothing patterns at junctions and asymmetric control spaces. Laplacian matrix rank at junctions crucial for controllability.

Conclusion: Spring-mass coupled string networks exhibit rich mathematical structure with convergence properties to classical models, well-posedness guarantees, and nontrivial controllability characteristics dependent on junction topology and spring/mass parameters, with applications to damaged mechanical vibration systems.

Abstract: We consider networks of elastic strings with end masses, where the coupling is modeled via elastic springs. The model is representative of a network of nonlinear strings, where the strings are coupled to elastic bodies. The coupled system converges to the classical string network model with Kirchhoff and continuity transmission conditions as the spring stiffness terms approach infinity and the masses at the nodes vanish. Due to the presence of point masses at the nodes, the boundary conditions become dynamic, and consequently, the corresponding first-order system of quasilinear balance laws exhibits nonlocal boundary conditions. We demonstrate well-posedness in the sense of semi-global classical solutions \cite{li} (i.e., for arbitrarily large time intervals provided that the initial and boundary data are small enough) and observe extra regularity at the masses as in \cite{WangLeugeringLi2017,WangLeugeringLi2019}. We prove local and global-local exact boundary controllability of a star-like network when control is active at the endpoints of the string-spring-mass system, except for one clamped end. In this case, at multiple nodes, a complex smoothing pattern appears, leading to asymmetric control spaces when the springs and masses are present. Furthermore, the rank of the Laplacian matrix at the junction is crucial for the controllability property, particularly in models containing wave equations with degeneration at dynamic boundaries, which can be interpreted as damage in mechanical vibration systems where parts of the springs are missing.

</details>


### [44] [Optimality Conditions for Control Systems Governed by Monotone Stochastic Evolution Equations](https://arxiv.org/abs/2512.20505)
*Ioana Ciotir,Nicolas Forcadel,Piero Visconti,Hasnaa Zidani*

Main category: math.OC

TL;DR: This paper develops first-order necessary optimality conditions for optimal control problems governed by nonlinear stochastic monotone equations with coercivity and linear growth conditions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to establish rigorous optimality conditions for control problems involving nonlinear stochastic equations of monotone type, which have important applications in various fields including porous media equations.

Method: The authors study optimal control problems governed by nonlinear stochastic monotone equations under coercivity and linear growth conditions. They derive first-order necessary conditions of optimality and show that a stochastic Pontryagin principle can be recovered when the diffusion doesn't depend on the control.

Result: The main results include: 1) First-order necessary optimality conditions for the general class of problems, 2) Recovery of stochastic Pontryagin principle for control-independent diffusion, and 3) Several applications, most notably for stochastic porous media equations in the Lipschitz case.

Conclusion: The paper successfully establishes optimality conditions for a broad class of nonlinear stochastic control problems with monotone structure, providing theoretical foundations with practical applications to stochastic porous media equations.

Abstract: We study a class of optimal control problems governed by nonlinear stochastic equations of monotone type under certain coercivity and linear growth conditions. We give first order necessary conditions of optimality. A stochastic Pontryagin principle can be recovered in the case that the diffusion doesn't depend on the control. We give several applications, most notably for stochastic porous media equations in the Lipschitz case.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [45] [Variational (matrix) product states for combinatorial optimization](https://arxiv.org/abs/2512.20613)
*Guillermo Preisser,Conor Mc Keever,Michael Lubasch*

Main category: quant-ph

TL;DR: Quantum-inspired variational methods using product state and matrix product state ansatzes combined with iterated local search outperform traditional approaches on large-scale maximum cut problems.


<details>
  <summary>Details</summary>
Motivation: To develop efficient quantum-inspired algorithms for combinatorial optimization problems that can scale to large problem sizes (up to 50000 variables) and outperform existing quantum and classical methods.

Method: Variational energy minimization using product state (PS) and matrix product state (MPS) ansatzes with respect to a quantum annealing Hamiltonian, embedded within the metaheuristic iterated local search (ILS) framework to incorporate randomness.

Result: The quantum-inspired ILS algorithms outperform traditional (M)PS methods, classical ILS, the quantum approximate optimization algorithm (QAOA), and other variational quantum-inspired solvers on maximum cut problems of up to 50000 variables.

Conclusion: Combining variational quantum-inspired ansatzes with classical metaheuristics like iterated local search creates powerful hybrid algorithms that can solve large-scale combinatorial optimization problems more effectively than pure quantum or classical approaches alone.

Abstract: To compute approximate solutions for combinatorial optimization problems, we describe variational methods based on the product state (PS) and matrix product state (MPS) ansatzes. We perform variational energy minimization with respect to a quantum annealing Hamiltonian and utilize randomness by embedding the approaches in the metaheuristic iterated local search (ILS). The resulting quantum-inspired ILS algorithms are benchmarked on maximum cut problems of up to 50000 variables. We show that they can outperform traditional (M)PS methods, classical ILS, the quantum approximate optimization algorithm and other variational quantum-inspired solvers.

</details>
