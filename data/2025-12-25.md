<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 9]
- [math.AP](#math.AP) [Total: 17]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [gr-qc](#gr-qc) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math-ph](#math-ph) [Total: 1]
- [math.OC](#math.OC) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A dichotomy of finite element spaces and its application to an energy-conservative scheme for the regularized long wave equation](https://arxiv.org/abs/2512.20737)
*Dimitrios Antonopoulos,Dimitrios Mitsotakis*

Main category: math.NA

TL;DR: Odd-degree finite elements give optimal convergence for nonlinear dispersive wave equations, while even-degree elements show reduced accuracy due to super-approximation properties of L²-projections.


<details>
  <summary>Details</summary>
Motivation: To explain the unusual convergence behavior observed in energy-conservative Galerkin discretizations for nonlinear dispersive wave equations, where odd polynomial degrees yield optimal convergence but even degrees don't.

Method: Analyzes the structure of finite element spaces and connects the convergence behavior to super-approximation properties of standard L²-projections of derivatives, which only occur for odd polynomial degrees. Examines implications for energy-conservative Galerkin approximation of the regularized long-wave equation.

Result: Shows that the convergence behavior is intrinsic to finite element space structure, demonstrates that the scheme conserves mass and energy, approximates impulse with high accuracy, and establishes a priori error bounds for the semi-discrete formulation.

Conclusion: The observed convergence pattern (odd-degree optimal, even-degree reduced) is fundamentally linked to mathematical properties of finite element spaces and their projection operators, providing theoretical understanding for practical numerical observations.

Abstract: Certain energy-conservative Galerkin discretizations for nonlinear dispersive wave equations have revealed an unusual convergence behavior: optimal convergence is attained when continuous Lagrange finite element spaces of odd polynomial degree are employed, whereas the use of even-degree polynomials leads to reduced accuracy. The present work demonstrates that this behavior is intrinsic to the structure of the finite element spaces themselves. In particular, it is shown to be closely connected to the standard $L^2$-projection of derivatives, which possesses a super-approximation property exclusively for odd polynomial degrees. We also examine the implications of this feature for an energy-conservative Galerkin approximation of the regularized long-wave equation where the energy is a cubic functional. Although the resulting scheme conserves both mass and energy, we further show that the impulse is approximated with high accuracy, and we establish {\em a priori} error bounds for the associated semi-discrete formulation.

</details>


### [2] [On stability of Weak Greedy Algorithm in the presence of noise](https://arxiv.org/abs/2512.20750)
*V. N. Temlyakov*

Main category: math.NA

TL;DR: Theoretical study of greedy algorithm stability, focusing on how small perturbations (noisy data) affect algorithm outcomes without causing large changes.


<details>
  <summary>Details</summary>
Motivation: While greedy algorithm research typically focuses on convergence and rate of convergence, there's a need to study another important property: stability. Stability ensures that small perturbations don't cause large changes in algorithm outcomes, which is crucial for practical applications with noisy data.

Method: Theoretical analysis of greedy algorithms, specifically examining their stability properties when dealing with perturbations, particularly noisy data. The paper presents formal mathematical results on algorithm stability.

Result: The paper presents theoretical results demonstrating the stability properties of certain greedy algorithms, showing how they maintain consistent outcomes despite small perturbations in input data.

Conclusion: Stability is an important third property of greedy algorithms alongside convergence and rate of convergence. Understanding algorithm stability is crucial for practical applications where data may contain noise or small perturbations.

Abstract: This paper is devoted to the theoretical study of the efficiency, namely, stability of some greedy algorithms. In the greedy approximation theory researchers are mostly interested in the following two important properties of an algorithm -- convergence and rate of convergence. In this paper we present some results on one more important property of an algorithm -- stability. Stability means that small perturbations do not result in a large change in the outcome of the algorithm. In this paper we discuss one kind of perturbations -- noisy data.

</details>


### [3] [Streamfunction-vorticity formulation for incompressible viscid and inviscid flows on general surfaces](https://arxiv.org/abs/2512.20763)
*Tim Brüers,Christoph Lehrenfeld,Max Wardetzky*

Main category: math.NA

TL;DR: Streamfunction-vorticity formulation for Navier-Stokes/Euler equations on general surfaces (including non-simply connected ones) that ensures exactly tangential, incompressible velocity fields with pressure robustness.


<details>
  <summary>Details</summary>
Motivation: Traditional velocity-pressure formulations on surfaces require increased computational costs to guarantee tangential and incompressible velocity fields. The harmonic components of velocity on non-simply connected surfaces play a fundamental role in dynamics but are challenging to handle.

Method: Develops a streamfunction-vorticity formulation that relies only on scalar and finite-dimensional quantities. The approach works on general surfaces including non-simply connected ones, properly handling harmonic velocity components.

Result: The formulation ensures exactly tangential and incompressible velocity fields while being pressure robust. It's proven equivalent to velocity-pressure formulation under reasonable regularity assumptions. Numerical examples demonstrate applicability.

Conclusion: The streamfunction-vorticity formulation provides a key advantage over traditional methods by guaranteeing structural properties (tangential, incompressible velocity) without increasing computational costs, especially important for non-simply connected surfaces.

Abstract: This paper presents a streamfunction-vorticity formulation for the Navier--Stokes and Euler equations on general surfaces. Notably, this includes non-simply connected surfaces, on which the harmonic components of the velocity field play a fundamental role in the dynamics. By relying only on scalar and finite-dimensional quantities, our formulation ensures that the resulting methods give exactly tangential and incompressible velocity fields, while also being pressure robust. Compared to traditional methods based on velocity-pressure formulations, where one can only guarantee these structural properties by increasing the computational costs, this is a key advantage. We rigorously validate our formulation by proving its equivalence to the well understood velocity-pressure formulation under reasonable regularity assumptions. Furthermore, we demonstrate the applicability of the approach with numerical examples.

</details>


### [4] [Computing nonlinear Schrödinger equations with Hermite functions beyond harmonic traps](https://arxiv.org/abs/2512.20840)
*Valeria Banica,Georg Maierhofer,Katharina Schratz*

Main category: math.NA

TL;DR: Hermite basis functions extend from Schrödinger equations with harmonic potential to those without potential, making them suitable for nonlinear dispersive equations on unbounded domains.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that Hermite basis functions, known for their effectiveness in discretizing Schrödinger equations with harmonic potential, maintain stability properties for Schrödinger equations without potential, enabling their use as a natural basis for nonlinear dispersive equations on unbounded domains.

Method: Extending the application of Hermite basis functions from Schrödinger equations with harmonic potential to those without potential, analyzing their stability properties in this new context.

Result: Hermite basis functions maintain their stability properties when applied to Schrödinger equations without potential, making them a suitable basis for spatial discretization of nonlinear dispersive equations on unbounded domains.

Conclusion: Hermite basis functions are a natural and stable choice for computing nonlinear dispersive equations on unbounded domains, extending their proven effectiveness from harmonic potential Schrödinger equations to more general cases.

Abstract: Hermite basis functions are a powerful tool for spatial discretisation of Schrödinger equations with harmonic potential. In this work we show that their stability properties extend to the simulation of Schrödinger equations without potential, thus leading them as a natural basis for computation of nonlinear dispersive equations on unbounded domains.

</details>


### [5] [Parameter-free inexact block Schur complement preconditioning for linear poroelasticity under a hybrid Bernardi-Raugel and weak Galerkin finite element discretization](https://arxiv.org/abs/2512.20844)
*Weizhang Huang,Zhuoran Wang*

Main category: math.NA

TL;DR: Inexact block Schur complement preconditioning for hybrid-discretized linear poroelasticity with locking regularization and mesh/locking-parameter robust convergence.


<details>
  <summary>Details</summary>
Motivation: Pure Dirichlet boundary conditions for displacement cause near-singularity in the leading block of the algebraic system in nearly incompressible (locking) regimes, hindering efficient iterative solution of poroelasticity problems.

Method: Reformulate as three-field problem with inherent regularization to maintain original solution while ensuring nonsingularity. Apply MINRES and GMRES with inexact block diagonal and triangular Schur complement preconditioners. Analyze both pure Dirichlet and mixed boundary conditions.

Result: Both MINRES and GMRES achieve mesh-size and locking-parameter independent convergence for the regularized system. Similar theoretical results hold for mixed boundary conditions even without regularization. Numerical experiments in 2D/3D confirm robustness, and spinal cord simulation demonstrates effectiveness.

Conclusion: Regularization effectively addresses locking issues in pure Dirichlet conditions, and the proposed inexact block Schur complement preconditioners provide robust, efficient iterative solvers for hybrid-discretized linear poroelasticity problems across various boundary conditions.

Abstract: This work investigates inexact block Schur complement preconditioning for linear poroelasticity problems discretized using a hybrid approach: Bernardi-Raugel elements for solid displacement and lowest-order weak Galerkin elements for fluid pressure. When pure Dirichlet boundary conditions are applied to the displacement, the leading block of the resulting algebraic system becomes almost singular in the nearly incompressible (locking) regime, hindering efficient iterative solution. To overcome this, the system is reformulated as a three-field problem with an inherent regularization that maintains the original solution while ensuring nonsingularity. Analysis shows that both the minimal residual (MINRES) and generalized minimal residual (GMRES) methods, when preconditioned with inexact block diagonal and triangular Schur complement preconditioners, achieve convergence independent of mesh size and the locking parameter for the regularized system. Similar theoretical results are established for the situation with displacement subject to mixed boundary conditions, even without regularization. Numerical experiments in 2D and 3D confirm the benefits of regularization under pure Dirichlet conditions and the robustness of the preconditioners with respect to mesh size and the locking parameter in both boundary condition scenarios. Finally, a spinal cord simulation with discontinuous material parameters further illustrates the effectiveness and robustness of the proposed iterative solvers.

</details>


### [6] [Mixed Precision General Alternating-Direction Implicit Method for Solving Large Sparse Linear Systems](https://arxiv.org/abs/2512.21164)
*Jifeng Ge,Bastien Vieublé,Juan Zhang*

Main category: math.NA

TL;DR: Mixed precision GADI method accelerates large sparse linear systems by solving subsystems in low precision while maintaining high precision residuals, achieving 1.7-3.1× speedups on GPU.


<details>
  <summary>Details</summary>
Motivation: To accelerate solution of large-scale sparse linear systems by reducing computational cost while maintaining high accuracy, leveraging mixed precision computing on modern hardware.

Method: Three-precision GADI formulation that solves subsystems in low precision (Bfloat16/FP32), computes residuals and solution updates in high precision, with rounding error analysis, convergence guarantees, and GPR-based parameter selection.

Result: Speedups of 2.6× (2D), 1.7× (3D convection-diffusion), and 3.1× (complex reaction-diffusion) over double precision GADI on NVIDIA A100 GPU for problems up to 1.3×10⁸ unknowns.

Conclusion: Mixed precision GADI effectively accelerates large-scale sparse linear solvers while maintaining accuracy, with systematic parameter selection and proven convergence properties.

Abstract: In this article, we introduce a three-precision formulation of the General Alternating-Direction Implicit method (GADI) designed to accelerate the solution of large-scale sparse linear systems $Ax=b$. GADI is a framework that can represent many existing Alternating-Direction Implicit (ADI) methods. These methods are a class of linear solvers based on a splitting of $A$ such that the solution of the original linear system can be decomposed into the successive computation of easy-to-solve structured subsystems. Our proposed mixed precision scheme for GADI solves these subsystems in low precision to reduce the overall execution time while computing the residual and solution update in high precision to enable the solution to converge to high accuracy. We develop a rounding error analysis of mixed precision GADI that establishes the rates of convergence of the forward and backward errors to certain limiting accuracies. Our analysis also highlights the conditions on the splitting matrices under which mixed precision GADI is guaranteed to converge for a given set of precisions. We then discuss a systematic and robust strategy for selecting the GADI regularization parameter $α$, whose adjustment is critical for performance. Specifically, our proposed strategy makes use of a Gaussian Process Regression (GPR) model trained on a dataset of low-dimensional problems to initialize $α$. Finally, we proceed to a performance analysis of mixed precision GADI on an NVIDIA A100 GPU to validate our approach. Using low precision (Bfloat16 or FP32) to solve the subsystems, we obtain speedups of $2.6\times$, $1.7\times$, and $3.1\times$ over a full double precision GADI implementation on large-scale 2D, 3D convection-diffusion and complex reaction-diffusion problems (up to $1.3\times 10^{8}$ unknowns), respectively.

</details>


### [7] [A mixed finite element method for the stochastic Boussinesq equations with multiplicative noise](https://arxiv.org/abs/2512.21297)
*Liet Vo*

Main category: math.NA

TL;DR: A fully discrete mixed finite element method for stochastic Boussinesq systems with multiplicative noise, using spatial mixed FEM and temporal semi-implicit Euler-Maruyama scheme, with error analysis and convergence proofs.


<details>
  <summary>Details</summary>
Motivation: To develop and analyze a fully discrete numerical method for stochastic Boussinesq systems driven by multiplicative noise, which are important in fluid dynamics and heat transfer modeling with random perturbations.

Method: Combines standard mixed finite element method for spatial discretization with semi-implicit Euler-Maruyama scheme for temporal discretization. Uses localization technique and high-moment stability estimates for error analysis.

Result: Established error bounds for velocity, pressure, and temperature approximations. Proved convergence in probability for the fully discrete method in both L² and H¹-type norms. Numerical experiments validate theoretical estimates.

Conclusion: The proposed fully discrete mixed finite element method is effective for stochastic Boussinesq systems with multiplicative noise, with rigorous convergence guarantees and validated by numerical experiments.

Abstract: This work investigates a fully discrete mixed finite element method for the stochastic Boussinesq system driven by multiplicative noise. The spatial discretization is performed using a standard mixed finite element method, while the temporal discretization is based on a semi-implicit Euler-Maruyama scheme. By combining a localization technique with high-moment stability estimates, we establish error bounds for the velocity, pressure, and temperature approximations. As a direct consequence, we prove convergence in probability for the fully discrete method in both $L^2$ and $H^1$-type norms. Several numerical experiments are presented to validate the theoretical error estimates and demonstrate the effectiveness of the proposed scheme.

</details>


### [8] [FORCE-$α$ Numerical Fluxes within the Arbitrary High Order Semidiscrete WENO-DeC Framework: A Competitive Alternative to Upwind Fluxes](https://arxiv.org/abs/2512.21306)
*Lorenzo Micalizzi,Eleuterio Toro*

Main category: math.NA

TL;DR: Systematic investigation of FORCE-α centered numerical fluxes in high-order finite volume schemes for hyperbolic PDEs, showing they are competitive alternatives to upwind fluxes.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that FORCE-α centered numerical fluxes are competitive alternatives to classical upwind fluxes (Rusanov, HLL, exact Riemann solvers) in high-order finite volume frameworks, especially for complicated hyperbolic systems where Riemann solvers may be impossible to construct or computationally expensive.

Method: Uses a semidiscrete finite volume framework with WENO spatial reconstruction and Deferred Correction (DeC) time discretization up to order 7. Investigates FORCE-α numerical fluxes (a family of centered fluxes derived from First-Order Centered fluxes) for the ideal Euler equations in 1D and 2D.

Result: FORCE-α numerical fluxes perform competitively with classical upwind fluxes within high-order finite volume schemes. As order of accuracy increases, differences between results from different numerical fluxes decrease, making centered fluxes a viable alternative.

Conclusion: FORCE-α centered numerical fluxes are a flexible and competitive alternative to upwind fluxes in high-order finite volume frameworks, particularly beneficial for complex hyperbolic systems where Riemann solvers are difficult to construct or computationally expensive.

Abstract: This work systematically investigates the performance of FORCE--$α$ numerical fluxes within an arbitrary high order semidiscrete finite volume (FV) framework for hyperbolic partial differential equations (PDEs). Such numerical fluxes have been recently introduced by Toro, Saggiorato, Tokareva, and Hidalgo (Journal of Computational Physics, 416, 2020), and constitute a family of centred fluxes obtained from a suitable modification of First--Order Centred (FORCE) numerical fluxes. In contrast with upwind fluxes, such as Rusanov, Harten--Lax--van Leer (HLL) or the exact Riemann solver (RS) numerical flux, centred ones do not consider in any way the structure of the Riemann problem at cell interfaces. Adopting centred numerical fluxes leads to a high level of flexibility of the resulting numerical schemes, for example in the context of complicated hyperbolic systems, for which RSs may be impossible to construct or computationally expensive.
  The baseline framework adopted in this investigation is a FV semidiscrete approach with Weighted Essentially Non--Oscillatory (WENO) spatial reconstruction and Deferred Correction (DeC) time discretization, and results are reported up to order 7. Previous investigations involving the same framework have established that increasing the order of accuracy tends to decrease the differences in the results obtained through different numerical fluxes. The goal of this paper is to show that the employment of FORCE--$α$ numerical fluxes within such a framework is a competitive alternative to the adoption of more classical upwind fluxes. The hyperbolic system considered for this investigation is the ideal Euler equations in one and two space dimensions.

</details>


### [9] [Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation](https://arxiv.org/abs/2512.21319)
*Yuan Qiu,Wolfgang Dahmen,Peng Chen*

Main category: math.NA

TL;DR: A variationally correct operator learning framework using FOSLS objectives with provable error equivalence, implemented via Reduced Basis Neural Operators for stability and efficiency.


<details>
  <summary>Details</summary>
Motivation: Standard PDE-residual losses in neural operators lack variational correctness - small residuals don't guarantee small solution errors due to non-compliant norms or inconsistent boundary condition penalties.

Method: Develops FOSLS objectives with provable equivalence to solution error in PDE-induced norms. Uses Reduced Basis Neural Operator (RBNO) to ensure function space conformity by predicting coefficients for pre-computed conforming reduced basis. Incorporates mixed Dirichlet-Neumann boundary conditions via variational lifts.

Result: Rigorous convergence analysis bounds total error by sum of finite element discretization bias, reduced basis truncation error, neural network approximation error, and statistical estimation errors. Numerical benchmarks show superior accuracy in PDE-compliant norms compared to baselines, with residual loss serving as reliable a posteriori error estimator.

Conclusion: The proposed variationally correct operator learning framework with FOSLS objectives and RBNO architecture provides mathematically sound, stable, and efficient neural operator training with provable error bounds and reliable error estimation.

Abstract: Minimizing PDE-residual losses is a common strategy to promote physical consistency in neural operators. However, standard formulations often lack variational correctness, meaning that small residuals do not guarantee small solution errors due to the use of non-compliant norms or ad hoc penalty terms for boundary conditions. This work develops a variationally correct operator learning framework by constructing first-order system least-squares (FOSLS) objectives whose values are provably equivalent to the solution error in PDE-induced norms. We demonstrate this framework on stationary diffusion and linear elasticity, incorporating mixed Dirichlet-Neumann boundary conditions via variational lifts to preserve norm equivalence without inconsistent penalties. To ensure the function space conformity required by the FOSLS loss, we propose a Reduced Basis Neural Operator (RBNO). The RBNO predicts coefficients for a pre-computed, conforming reduced basis, thereby ensuring variational stability by design while enabling efficient training. We provide a rigorous convergence analysis that bounds the total error by the sum of finite element discretization bias, reduced basis truncation error, neural network approximation error, and statistical estimation errors arising from finite sampling and optimization. Numerical benchmarks validate these theoretical bounds and demonstrate that the proposed approach achieves superior accuracy in PDE-compliant norms compared to standard baselines, while the residual loss serves as a reliable, computable a posteriori error estimator.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [10] [Dispersive decay for the Inter-critical nonlinear Schrödinger equation in $\mathbb{R}^3$](https://arxiv.org/abs/2512.20683)
*Boyu Jiang,Jiawei Shen,Kexue Li*

Main category: math.AP

TL;DR: The paper establishes uniform decay estimates for long-time dynamics of mass-supercritical, energy-subcritical NLS in 3D with initial data in critical homogeneous Sobolev space.


<details>
  <summary>Details</summary>
Motivation: To extend previous results on the Cauchy problem for nonlinear Schrödinger equations by obtaining uniform decay estimates for long-time dynamics in the mass-supercritical and energy-subcritical regime in three dimensions.

Method: Analyzes the Cauchy problem for NLS in 3D with initial data in critical homogeneous Sobolev space $\dot{H}^{s_c}(\mathbb{R}^3)$ where $s_c = \frac{5}{6}$, focusing on establishing uniform decay estimates for long-time dynamics.

Result: Obtains uniform decay estimates for the long-time dynamics of solutions, extending previous results in this regime.

Conclusion: The paper successfully establishes uniform decay estimates for NLS solutions in the mass-supercritical, energy-subcritical regime in 3D, providing important insights into long-time behavior of such nonlinear dispersive equations.

Abstract: This paper investigates the Cauchy problem for the nonlinear Schrödinger equation (NLS) in the mass-supercritical and energy-subcritical regime within three spatial dimensions. For initial data in the critical homogeneous Sobolev space $\dot{H}^{s_c}(\mathbb{R}^3)$ (where $s_c = \frac{5}{6}$), we get a uniform decay estimate for the long-time dynamics of solutions, which extends the previous results.

</details>


### [11] [On a Hamilton-Jacobi PDE theory for hydrodynamic limit of action minimizing collective dynamics](https://arxiv.org/abs/2512.20809)
*Jin Feng*

Main category: math.AP

TL;DR: Multi-scale convergence theory for Hamilton-Jacobi PDEs in probability measure spaces, derived from hydrodynamic limits of N-particle Lagrangian dynamics, using variational approaches and weak K.A.M. theory.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous convergence theory for Hamilton-Jacobi PDEs in probability measure spaces that arise from hydrodynamic limits of deterministic N-particle Lagrangian dynamics, addressing infinite dimensional singular averaging structures.

Method: Develops indirect variational approach to apply finite-dimensional weak K.A.M. theory to infinite-dimensional setting; uses viscosity solution techniques for equations with submetry structure, multi-scale convergence in metric spaces, and comparison principles in probability measure spaces; treats weakly interacting particles via individual particle averaging.

Result: Establishes rigorous convergence result for solutions of nonlinear PDEs in probability measure spaces by identifying limiting Hamiltonian; develops new techniques for Hamilton-Jacobi equations in metric spaces and probability measure spaces (special Alexandrov spaces with curvature bounded below).

Conclusion: Successfully extends finite-dimensional weak K.A.M. theory to infinite-dimensional Hamilton-Jacobi equations in probability measure spaces, providing rigorous multi-scale convergence framework with new technical developments in viscosity solution theory for metric spaces.

Abstract: We establish multi-scale convergence theory for a class of Hamilton-Jacobi PDEs in space of probability measures. They arise from context of hydrodynamic limit of N-particle deterministic action minimizing (global) Lagrangian dynamics.
  From a Lagrangian point of view, this can also be viewed as a limit result on two scale convergence of action minimizing probability-measure-valued paths. However, we focus on the Hamiltonian formulation here mostly. We derive and study convergence of the associated abstract but scalar Hamilton-Jacobi equations, defined in space of probability measures. There is an infinite dimensional singular averaging structure within these equations. We develop an indirect variational approach to apply finite dimensional weak K.A.M. theory to such infinite dimensional setting here. With a weakly interacting particle assumption, the averaging step only involves that of individual particles, which is implicitly but rigorously treated using the weak K.A.M. theory. Consequently, we can close the above mentioned averaging step by identifying limiting Hamiltonian, and arrive at a rigorous convergence result on solutions of the nonlinear PDEs in space of probability measures.
  In technical development parts of the paper, we devise new viscosity solution techniques regarding projection of equations with a submetry structure in state space, multi-scale convergence for certain abstract Hamilton-Jacobi equations in metric spaces, as well as comparison principles for equations in space of probability measures. The space of probability measure we consider is a special case of Alexandrov metric space with curvature bounded from below. Since some results are better explained in such metric space setting, we also develop some techniques in the general settings which are of independent interests.

</details>


### [12] [Infinitely many solutions and asymptotics for resonant oscillatory problems](https://arxiv.org/abs/2512.20816)
*Philip Korman,Dieter S. Schmidt*

Main category: math.AP

TL;DR: The paper proves existence of infinitely many solutions for oscillatory resonant PDEs on balls/rectangles, develops asymptotic formulas, and validates with numerical computations.


<details>
  <summary>Details</summary>
Motivation: To study oscillatory resonant problems for semilinear PDEs where the first harmonic of the right-hand side is not required to be zero or small, addressing existence and structure of solutions.

Method: Analytical approach for Dirichlet problems on balls and rectangles in R^n, proving existence of infinitely many solutions, deriving asymptotic formulas in terms of first harmonic, and implementing numerical method for validation.

Result: Existence of infinitely many solutions is established, asymptotic formulas are derived, and numerical computations demonstrate accuracy of the theoretical results.

Conclusion: The paper successfully addresses oscillatory resonant problems without restrictive assumptions on the first harmonic, provides comprehensive analytical results, and validates them with detailed numerical methods.

Abstract: For a class of oscillatory resonant problems, involving Dirichlet problems for semilinear PDE's on balls and rectangles in $R^n$, we show the existence of infinitely many solutions, and study the global solution set. The first harmonic of the right hand side is not required to be zero, or small. We also derive asymptotic formulas in terms of the first harmonic of solutions, and illustrate their accuracy by numerical computations. The numerical method is explained in detail.

</details>


### [13] [Uniqueness for the Homogeneous Landau-Coulomb Equation in $L^{3/2}$](https://arxiv.org/abs/2512.20899)
*Maria Pia Gualdani,Weiran Sun*

Main category: math.AP

TL;DR: Proves uniqueness of H-solutions to homogeneous Landau-Coulomb equation in critical space L^{3/2}, completing global well-posedness theory.


<details>
  <summary>Details</summary>
Motivation: To establish uniqueness of rough solutions to nonlinear kinetic equations, particularly completing the global well-posedness theory for the Landau-Coulomb equation in the critical space L^{3/2}(ℝ³).

Method: Uses the ℳ-operator technique (Bessel potential operator in space-homogeneous case) to prove uniqueness of H-solutions satisfying specific regularity conditions.

Result: Proves uniqueness of H-solutions with ⟨v⟩^{k₀}f ∈ C([0,T]; L^{3/2}) and ⟨v⟩^{-3/2}∇_v((⟨v⟩^{k₀}f)^{3/4}) ∈ L² for any k₀ ≥ 5, showing solutions from cited work are unique.

Conclusion: Completes global well-posedness theory in critical space L^{3/2}(ℝ³) for homogeneous Landau-Coulomb equation using ℳ-operator technique.

Abstract: We prove the uniqueness of $H$-solutions to the homogeneous Landau-Coulomb equation satisfying $\langle v \rangle^{k_0} f \in C([0, T]; L^{3/2}(\mathbb{R}^3))$ and $\langle v \rangle^{-3/2} \nabla_v ((\langle v \rangle^{k_0} f)^{3/4}) \in L^2((0, T) \times \mathbb{R}^3)$ for any $k_0 \geq 5$. In particular, this shows that the solutions constructed in~\cite{GGL25} are unique. The present work thus completes the global well-posedness theory in the critical space $L^{3/2}(\mathbb{R}^3)$. Our proof is part of a broader effort to use the $\mathcal{M}$-operator technique developed in~\cite{AGS2025, AMSY2020} to establish the uniqueness of rough solutions to nonlinear kinetic equations. When applied to the space-homogeneous case, the $\mathbb{M}$-operator can be taken simply as a Bessel potential operator.

</details>


### [14] [Quantitative bounds for Hölder exponents in the Krylov--Safonov and Evans--Krylov theories](https://arxiv.org/abs/2512.21025)
*Jongmyeong Kim,Se-Chan Lee*

Main category: math.AP

TL;DR: The paper establishes quantitative bounds for Hölder exponents in Krylov-Safonov and Evans-Krylov theories when ellipticity ratio is close to 1.


<details>
  <summary>Details</summary>
Motivation: To provide precise quantitative estimates for Hölder regularity in two important PDE theories when the ellipticity ratio approaches unity, which is a critical limiting case in elliptic regularity theory.

Method: Uses Ishii-Lions method for Krylov-Safonov theory and Schauder-type perturbation argument for Evans-Krylov theory.

Result: Establishes explicit quantitative bounds for Hölder exponents that become sharper as the ellipticity ratio approaches 1.

Conclusion: The paper provides rigorous quantitative regularity estimates in the near-unity ellipticity regime, connecting classical PDE theories with precise numerical bounds.

Abstract: We establish quantitative bounds for Hölder exponents in the Krylov--Safonov and Evans--Krylov theories when the ellipticity ratio is close to one. Our analysis relies on the Ishii--Lions method for the Krylov--Safonov theory and a Schauder-type perturbation argument for the Evans--Krylov theory.

</details>


### [15] [Calderón-Zygmund gradient estimates for $p$-Laplace systems with BMO complex coefficients](https://arxiv.org/abs/2512.21036)
*Van-Chuong Quach,Thanh-Nhan Nguyen,Minh-Phuong Tran*

Main category: math.AP

TL;DR: The paper establishes global gradient bounds and Calderón-Zygmund type estimates for weak solutions to degenerate elliptic systems with complex-valued coefficients, requiring only small BMO conditions rather than VMO.


<details>
  <summary>Details</summary>
Motivation: To extend regularity theory for elliptic systems with complex coefficients beyond the VMO condition, using only small BMO conditions which are strictly weaker, and to better understand solution behavior in the complex-valued setting.

Method: Proves global Calderón-Zygmund type estimates for weak solutions to divergence-form degenerate elliptic systems with complex coefficients, building on recent work that established existence/uniqueness under less restrictive assumptions than strong accretivity conditions.

Result: Establishes global gradient bounds and Calderón-Zygmund estimates for weak solutions, from which Morrey-space regularity follows as a consequence, under the condition that leading coefficients are sufficiently small in BMO.

Conclusion: This work contributes to extending regularity theory in the complex-valued setting by proving global gradient bounds under weaker coefficient conditions (small BMO rather than VMO), advancing understanding of solution behavior for degenerate elliptic systems.

Abstract: This work is concerned with global gradient bounds for a class of divergence-form degenerate elliptic systems with complex-valued coefficients. Notably, the leading coefficients are merely required to be sufficiently small in BMO, which is strictly weaker than the VMO condition. In the complex setting, the well-posedness of this problem was recently investigated in [W. Kim, M. Vestberg, Existence, uniqueness and regularity for elliptic $p$-Laplace systems with complex coefficients,arXiv:2503.18932], where the authors established a strong accretivity condition on the leading coefficients, and this structural condition allows them to derive Schauder-type estimates for weak solutions. In our study, it has already been observed that gaining existence and uniqueness of weak solutions is possible under a natural and less restrictive assumption on the complex-valued coefficients. Following this direction, we prove a global Caderón-Zygmund-type estimate for weak solutions, from which the Morrey-space regularity follows as a consequence. This paper is a contribution to the better understanding of solution behavior and may be viewed as part of a series of works aimed at extending regularity theory in the complex-valued setting.

</details>


### [16] [A Unified Truncation Method for Infinitely Many Solutions Without Symmetry](https://arxiv.org/abs/2512.21119)
*Anouar Bahrouni*

Main category: math.AP

TL;DR: The paper introduces a refined variational truncation method that proves existence of infinitely many solutions for nonlinear problems without symmetry, covering semilinear elliptic PDEs, nonvariational elliptic PDEs with gradient dependence, and periodic Hamiltonian systems.


<details>
  <summary>Details</summary>
Motivation: To address the challenging problem of proving existence of infinitely many solutions for nonlinear problems that lack symmetry, which has been a long-standing difficulty particularly for nonvariational elliptic PDEs with gradient dependence and for ensuring multiplicity persists in infinite dimensional dynamical systems.

Method: Develops a refined variational truncation method that systematically separates solutions, combined with an iterative scheme for nonvariational PDEs. For Hamiltonian systems, shows multiplicity constructed on finite intervals survives in the limit without collapse.

Result: Three major advances: 1) Infinite sequences of positive and negative solutions for semilinear elliptic PDEs, 2) First proof of infinitely many solutions for nonvariational elliptic PDEs with gradient dependence, 3) Multiple distinct solutions on whole real line for periodic Hamiltonian systems without collapse.

Conclusion: The carefully designed truncation methodology provides a unified, robust, and versatile tool for addressing multiplicity problems across variational/non-variational PDEs and infinite dimensional dynamical systems in the absence of symmetry.

Abstract: This paper establishes the existence of infinitely many solutions for nonlinear problems without any symmetry, achieving three major advances. First, in the setting of semilinear elliptic PDEs, we introduce a refined variational truncation method that yields infinite sequences of positive as well as negative solutions. Second and most notably, we resolve a long-standing and difficult problem for nonvariational elliptic PDEs with gradient dependence. By combining our truncation method with an iterative scheme, we prove, for the first time, the existence of infinitely many solutions for this class of PDEs. Third, we overcome a central difficulty for periodic Hamiltonian systems on the real line: we show that the multiplicity of solutions, constructed on a sequence of finite intervals, survives in the limit; in other words, no collapse occurs, and we obtain multiple distinct solutions on the whole real line.
  The core novelty lies in a carefully designed truncation methodology that systematically separates solutions and remains effective across variational and non-variational PDEs as well as infinite dimensional dynamical systems. This unified perspective provides a robust and versatile tool for addressing multiplicity problems in the absence of symmetry.

</details>


### [17] [Equilibrium Configurations and their Uniqueness in a Fluid-Solid Interaction Problem](https://arxiv.org/abs/2512.21130)
*D. Bonheure,G. P. Galdi,C. Patriarca*

Main category: math.AP

TL;DR: Existence of large solutions and uniqueness of small solutions for Navier-Stokes fluid interacting with a rigid body under spring forces and restoring moments, driven by uniform far-field velocity.


<details>
  <summary>Details</summary>
Motivation: To study the equilibrium configurations of coupled fluid-structure interaction systems where a rigid body with rotational degrees of freedom interacts with a Navier-Stokes fluid under external forcing from far-field velocity.

Method: Mathematical analysis of the coupled Navier-Stokes equations with rigid body dynamics, considering spring forces and restoring moments, with the main challenge being the body's rotation around a given axis which creates nonlinearity.

Result: Demonstrates existence of equilibrium configurations in the "large" (for general solutions) and uniqueness in the "small" (for sufficiently small solutions) despite the nonlinear challenges posed by rotational degrees of freedom.

Conclusion: The coupled fluid-structure interaction system with rotational rigid body dynamics admits equilibrium solutions, with existence established for general cases and uniqueness guaranteed for sufficiently small solutions.

Abstract: We demonstrate existence in the ``large" and uniqueness in the ``small" of equilibrium configurations for the coupled system consisting of a Navier-Stokes fluid interacting with a rigid body subjected to spring forces and restoring moments. The driving mechanism is a uniform, given velocity field of the fluid at large spatial distances from the body. The main difficulty in the proof of the above properties arises from the fact that the body can rotate around a given axis, which produces a highly nonlinear problem.

</details>


### [18] [Existence and non-existence phenomena for nonlinear elliptic equations with $L^1$ data and singular reactions](https://arxiv.org/abs/2512.21131)
*Francescantonio Oliva,Francesco Petitta,Matheus F. Stapenhorst*

Main category: math.AP

TL;DR: The paper studies existence and non-existence of solutions for singular elliptic boundary value problems involving p-Laplacian with singular term a(x)/u^γ, showing solvability for large μ and non-existence for small μ.


<details>
  <summary>Details</summary>
Motivation: To extend the celebrated work of Diaz, Morel and Oswald (1997) from the Laplacian case (p=2) to the p-Laplacian case (p≠2), and to provide new results even for p=2 when the singular term has critical growth near zero (γ=1).

Method: Study singular elliptic boundary value problems with p-Laplacian operator, using variational methods and analysis techniques to establish existence thresholds for the parameter μ. The approach involves analyzing the interplay between the singular term a(x)/u^γ and the forcing term μf(x).

Result: 1. For any positive f ∈ L¹(Ω), problem (1) is solvable for any μ > μ₀ > 0, where μ₀ is sufficiently large. 2. No finite energy solution exists if 0 < μ < μ₀*, where μ₀* is sufficiently small. These results extend previous work to p ≠ 2 and provide new insights even for p=2 with critical singular growth (γ=1).

Conclusion: The paper establishes sharp existence thresholds for singular p-Laplacian problems, showing that solutions exist only when the forcing parameter μ is sufficiently large, extending classical results to the nonlinear p-Laplacian framework and providing new results for critical singular growth.

Abstract: We study existence and non-existence of solutions for singular elliptic boundary value problems as \begin{equation}\label{eintro}\begin{cases}\tag{1}
  \displaystyle -Δ_p u+ \frac{a(x)}{u^γ}=μf(x) \ &\text{ in }Ω, \newline
  u>0&\text{ in }Ω, \newline
  u = 0 \ &\text{ on }
  \partialΩ,
  \end{cases} \end{equation} where $Ω$ is a smooth bounded open subset of $\mathbb{R}^N$ ($N\ge 2$), $Δ_p u$ is the $p$-Laplacian with $p>1$, $0<γ\leq 1$, and $a\geq0$ is bounded and non-trivial. For any positive $ f\in L^{1}(Ω)$ we show that problem \eqref{eintro} is solvable for any $μ>μ_0>0$, for some $μ_0$ large enough. As a reciprocal outcome we also show that no finite energy solution exists if $0<μ<μ_{0*}$, for some small $μ_{0*}$.
  This paper extends the celebrated one of J. I. Diaz, J. M. Morel and L. Oswald ([16]) to the case $p\neq2$. Our result is also new for $p=2$ provided the singular term has a critical growth near zero (i.e. $γ=1$).

</details>


### [19] [Well-posedness and the Łojasiewicz-Simon inequality in the asymptotic analysis of a nonlinear heat equation with constraints of finite codimension](https://arxiv.org/abs/2512.21158)
*Ashish Bawalia,Zdzisław Brzeźniak,Manil T. Mohan,Piotr Rybka*

Main category: math.AP

TL;DR: Global well-posedness and asymptotic convergence of norm-preserving nonlinear heat equation on Poincaré domains with L² constraint.


<details>
  <summary>Details</summary>
Motivation: To establish global existence and analyze long-term behavior of solutions to nonlinear heat equations with L²-norm preserving constraints, which arise in various physical and geometric contexts where conservation of mass or energy is required.

Method: Modify nonlinearity and use m-accretive evolution equation theory for global existence; employ resolvent ideas and Yosida approximation for regularity; apply Łojasiewicz-Simon gradient inequality on Hilbert submanifolds for asymptotic convergence analysis.

Result: Proves existence of global strong solution for nonlinear heat equation with L² constraint; shows solution converges to stationary state in W^{2,q} ∩ W^{1,q}_0 spaces under specific parameter conditions.

Conclusion: Provides alternative method for establishing global well-posedness and analyzing long-term behavior of norm-preserving nonlinear heat equations, demonstrating convergence to equilibrium using geometric analysis on constraint manifolds.

Abstract: We establish the global well-posedness of the $D(A)-$valued strong solution to a nonlinear heat equation with constraints on a \textit{Poincaré domain} $\bO\subset \R^d$ whose boundary is of class $C^2$. Consider the following nonlinear heat equation
  \begin{align*}
  \frac{\partial u}{\partial t} - Δu + |u|^{p-2}u = 0,
  \end{align*}
  projected onto the tangent space $T_u\bM$, where
  $\mathcal{M}:=\left\{u\in L^2(\bO):\|u\|_{L^2(\bO)}=1\right\}$ is a submanifold of $L^2(\bO)$. The nonlinearity exponent satisfies $2\le p < \infty$ for $1\leq d\leq 4$ and $2 \le p \le \frac{2d-4}{d-4}$ for $d \ge 5$. The solution is constrained to lie within $\mathcal{M}$ which encodes the norm-preserving constraint. By modifying the nonlinearity and exploiting the abstract theory for \textit{$m-$accretive }evolution equations, we prove the existence of a global strong solution.
  Using {resolvent-idea } and the \textit{Yosida approximation} method, we derive regularity results. In the asymptotic analysis, $\bO$ is restricted to bounded domains with even $p$
  and $1\le d \le 3$. For any initial data in $D(A) \cap \mathcal{M}$, we apply the \textit{Łojasiewicz-Simon gradient inequality} on a Hilbert submanifold [F. Rupp, \textit{J. Funct. Anal.}, 279(8), 2020], to demonstrate that the unique global strong solution converges in $W^{2,q}(\bO) \cap W^{1,q}_0(\bO)$ to a stationary state, where $2 \le q < \frac{2d}{d + 4 - 4β}$ and $1 < β< \frac{3}{2}$.
  This work proposes an alternative method for establishing the global existence and analyzing long-term behavior of the unique strong solution to an $L^2-$norm preserving nonlinear heat equation.

</details>


### [20] [Optimal Hardy-weights for the Finsler $p$-Dirichlet integral with a potential](https://arxiv.org/abs/2512.21162)
*Yongjun Hou*

Main category: math.AP

TL;DR: The paper constructs optimal Hardy-weights for Finsler p-Dirichlet integrals with and without potentials, using local Morrey spaces for the potential terms.


<details>
  <summary>Details</summary>
Motivation: To extend Hardy-type inequalities to Finsler p-Dirichlet integrals in domains with singularities (removing a point) and with potentials, finding optimal weights that ensure the inequalities are sharp.

Method: Construct optimal Hardy-weights for the Finsler p-Dirichlet integral Q₀ on Ω* (domain minus a point) and Q_V on Ω with potential V in a subspace of local Morrey space M^q_loc(p;Ω).

Result: Successfully constructs optimal Hardy-weights for both Finsler p-Dirichlet integrals, extending Hardy-type inequalities to the Finsler setting with singular domains and potentials.

Conclusion: The paper provides optimal Hardy-weights for Finsler p-Dirichlet operators, generalizing classical Hardy inequalities to anisotropic settings with singularities and potentials.

Abstract: Fix an integer $n\geq 2$, an exponent $1<p<\infty$, and a domain $Ω\subseteq\mathbb{R}^{n}$. Let $Ω^{*}\triangleqΩ\setminus\{\hat{x}\}$ where $\hat{x}\inΩ$. Under some further conditions, we construct optimal Hardy-weights for the Finsler $p$-Dirichlet integral $$Q_{0}[φ;Ω^{*}]\triangleq\int_{Ω^{*}}H(x,\nabla φ)^{p}\,\mathrm{d}x\quad \mbox{on}\quad C^{\infty}_{c}(Ω^{*}),$$ and the Finsler $p$-Dirichlet integral with a potential $$Q_{V}[φ;Ω]\triangleq\int_Ω\left(H(x,\nabla φ)^{p}+ V|φ|^{p}\right)\,\mathrm{d}x\quad \mbox{on}\quad C^{\infty}_{c}(Ω),$$where $H(x,\cdot)$ is a family of norms on $\mathbb{R}^{n}$ parameterized by $x\inΩ^{*}$ or $x\inΩ$, respectively, and the potential $V$ lies in a subspace $\widehat{M}^{q}_{\rm loc}(p;Ω)$ of a local Morrey space $M^{q}_{\rm loc}(p;Ω)$.

</details>


### [21] [Navier-Stokes-Cahn-Hilliard system in a $3$D perforated domain with free slip and source term: Existence and homogenization](https://arxiv.org/abs/2512.21171)
*Amartya Chakrabortty,Haradhan Dutta,Hari Shankar Mahato*

Main category: math.AP

TL;DR: Analysis of a diffuse-interface model for binary mixtures in perforated porous media, studying existence of weak solutions and homogenization limits with varying capillarity strength.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of binary incompressible mixtures in porous media with microscopic heterogeneities, and to derive effective macroscopic models through homogenization that account for different capillarity regimes.

Method: Two-part analysis: (1) Prove existence of weak solutions for fixed microscopic scale ε with uniform a priori estimates; (2) Perform periodic homogenization as ε→0, deriving different effective models depending on the limit of capillarity strength λ^ε.

Result: Two distinct homogenized models emerge: (i) Stokes-Cahn-Hilliard system without macroscopic convection for vanishing capillarity (λ=0); (ii) Full Navier-Stokes-Cahn-Hilliard system with nonlinear convection and advective transport for balanced capillarity (λ∈(0,∞)). Also establishes convergence of microscopic free energy to homogenized energy functional.

Conclusion: The capillarity strength scaling relative to microscopic scale crucially determines the effective macroscopic behavior, with different regimes leading to fundamentally different homogenized models for binary mixtures in porous media.

Abstract: We study a diffuse-interface model for a binary incompressible mixture in a periodically perforated porous medium, described by a time-dependent Navier-Stokes-Cahn-Hilliard (NSCH) system posed on the pore domain $Ω_p^\varepsilon\subset\mathbb{R}^3$. The microscopic model involves a variable viscosity tensor, a non-conservative source term in the Cahn--Hilliard equation, and mixed boundary conditions: no-slip on the outer boundary and Navier slip with zero tangential stress on the surfaces of the solid inclusions. The capillarity strength $λ^\varepsilon>0$ depends on the microscopic scale $\varepsilon>0$.
  The analysis consists of two main parts. First, for each fixed $\varepsilon>0$, we prove the existence of a weak solution on a finite time interval $(0,T)$ and derive a priori estimates that are uniform with respect to $\varepsilon$ (and $λ^\varepsilon$). Second, we perform the periodic homogenization for the perforated setting, a limit $\varepsilon\to0$. Depending on the limit value $λ$ of the capillarity strength $λ^\varepsilon$, we obtain two distinct effective models: (i) in the vanishing capillarity regime $λ=0$, the limit system is of Stokes-Cahn-Hilliard type, with no macroscopic convection or advection; (ii) in the balanced regime $λ\in(0,+\infty)$, we derive a Navier-Stokes-Cahn-Hilliard system with nonlinear convection and advective transport of the phase field at the macroscopic scale. Finally, we establish the convergence of the microscopic free energy to a homogenized energy functional satisfying an analogous dissipation law.

</details>


### [22] [Long-Time Existence and Behavior of Solutions to the Inhomogeneous Kinetic FPU Equation](https://arxiv.org/abs/2512.21187)
*Haoling Xiang*

Main category: math.AP

TL;DR: The paper analyzes the inhomogeneous kinetic Fermi-Pasta-Ulam equation, showing that spatial dispersion effects extend solution lifespan from quadratic to quartic time scales for small initial data near vacuum.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand the interplay between spatial transport and degeneracies in the collision operator of the kinetic FPU equation, which describes phonon density evolution with four-phonon interactions. The equation combines free transport in physical space with a nonlinear collision operator in momentum space that has structural degeneracies.

Method: Developed a functional framework capturing spatial transport and collision operator degeneracies. Key technique: dispersive estimate for transport flow quantifying decay from spatial propagation. Used this dispersive mechanism to obtain improved bounds for the nonlinear collision operator.

Result: Small solutions near vacuum can be propagated on time scales significantly longer than those dictated by conservation laws alone. Specifically, dispersion extends the classical quadratic lifespan to a quartic time scale.

Conclusion: Spatial dispersion provides a mechanism to overcome limitations from conservation laws, allowing much longer existence times for solutions to the inhomogeneous kinetic FPU equation through the interplay between transport and collision operator degeneracies.

Abstract: We study the inhomogeneous kinetic Fermi-Pasta-Ulam (FPU) equation, a nonlinear transport equation describing the evolution of phonon density distributions with four-phonon interactions. The equation combines free transport in physical space with a nonlinear collision operator acting in momentum space and exhibiting structural degeneracies. We develop a functional framework that captures the interplay between spatial transport and the degeneracies arising in the collision operator. A key ingredient of the analysis is a dispersive estimate for the transport flow, which quantifies decay effects generated by spatial propagation. Using this dispersive mechanism, we obtain improved bounds for the nonlinear collision operator and show that small solutions near the vacuum can be propagated on time scales significantly longer than those dictated by conservation laws alone. In particular, dispersion allows one to extend the classical quadratic lifespan to a quartic time scale.

</details>


### [23] [Green's Function and Solution Representation for a Boundary Value Problem Involving the Prabhakar Fractional Derivative](https://arxiv.org/abs/2512.21259)
*Erkinjon Karimov,Doniyor Usmonov,Maftuna Mirzaeva*

Main category: math.AP

TL;DR: The paper develops Green's function methods for boundary value problems involving Prabhakar fractional derivatives, providing explicit solution representations and proving existence/uniqueness.


<details>
  <summary>Details</summary>
Motivation: To extend classical Green-function techniques to Prabhakar-type fractional differential equations, which represent a broader class of fractional operators beyond traditional fractional calculus.

Method: Uses structural properties of Prabhakar kernel and generalized Mittag-Leffler functions to reduce the boundary value problem to a Volterra integral equation, enabling explicit construction of Green's function.

Result: Successfully constructs Green's function for Prabhakar fractional derivative problems, derives closed-form integral solution representation, and proves existence and uniqueness of solutions.

Conclusion: The work extends analytical tools to Prabhakar-type fractional equations, providing foundation for studying boundary and inverse problems in this broader fractional calculus framework.

Abstract: We investigate a first boundary value problem for a second-order partial differential equation involving the Prabhakar fractional derivative in time. Using structural properties of the Prabhakar kernel and generalized Mittag-Leffler functions, we reduce the problem to a Volterra type integral equation. This reduction enables the explicit construction of the corresponding Green's function. Based on the obtained Green's function, we derive a closed-form integral representation of the solution and prove its existence and uniqueness. The results extend classical Green-function techniques to a wider class of fractional operators and provide analytical tools for further study of boundary and inverse problems associated with Prabhakar-type fractional differential equations.

</details>


### [24] [Operational Calculus for the nth-Level Prabhakar Type Fractional Derivative with Applications](https://arxiv.org/abs/2512.21273)
*Imtiaz Waheed,Erkinjon Karimov,Mujeeb ur Rehman*

Main category: math.AP

TL;DR: Study investigates nth-level Prabhakar fractional derivative, establishes its properties, develops operational calculus, and applies it to solve fractional differential equations.


<details>
  <summary>Details</summary>
Motivation: To explore and formalize the nth-level Prabhakar fractional derivative as a generalization of known fractional derivatives, and to develop mathematical tools for solving equations involving this operator.

Method: Establish fundamental properties of the nth-level Prabhakar derivative, investigate its relationship with Prabhakar fractional integral, develop Mikusinski-type operational calculus framework, and apply to solve specific differential equations.

Result: Successfully established properties of the derivative, developed operational calculus framework, and obtained analytical solutions for fractional ODE and time fractional heat equation containing the nth-level Prabhakar derivative.

Conclusion: The nth-level Prabhakar fractional derivative is a viable generalization with well-defined properties, and the developed operational calculus provides effective tools for solving related differential equations, as demonstrated by successful applications.

Abstract: This study investigates the nth-level Prabhakar fractional derivative, a generalization encompassing some well-known fractional derivatives. We establish its fundamental properties, particularly its relationship with the corresponding Prabhakar fractional integral. Furthermore, we develop Mikusinski-type operational calculus for this derivative, providing a framework for solving differential equations involving this operator. To illustrate its application, we present analytical solutions of two problems: a fractional order ordinary differential equation and the time fractional heat equation, both of which include the nth-level Prabhakar derivative.

</details>


### [25] [Non-Algebraic Decay for Solutions to the Navier-Stokes Equations](https://arxiv.org/abs/2512.21312)
*Lorenzo Brandolese,Matthieu Pageard,Cilon F. Perusato*

Main category: math.AP

TL;DR: The paper addresses a gap in Wiegner's theorem about Navier-Stokes solution decay rates in 2D for non-algebraic decay cases.


<details>
  <summary>Details</summary>
Motivation: Wiegner's seminal work 40 years ago established sharp algebraic decay rates for Navier-Stokes solutions, showing they behave asymptotically like heat equation solutions. However, there's a gap in the conclusion for 2D solutions with non-algebraic decay rates that needs to be addressed.

Method: The paper likely involves mathematical analysis of Navier-Stokes equations in 2D, focusing on asymptotic behavior and decay rates, particularly comparing with heat equation solutions and addressing the specific gap in Wiegner's theorem for non-algebraic decay cases.

Result: The paper closes the identified gap in Wiegner's theorem for 2D Navier-Stokes solutions with non-algebraic decay rates, providing complete asymptotic characterization of solution behavior as t→∞.

Conclusion: The work completes Wiegner's theorem by addressing the missing case in 2D for non-algebraic decay, providing a comprehensive understanding of Navier-Stokes solution asymptotics in relation to heat equation behavior.

Abstract: Around forty years ago, Michael Wiegner provided, in a seminal paper, sharp algebraic decay rates for solutions of the Navier--Stokes equations, showing that these solutions behave asymptotically like the solutions of the heat equation with the same data as $t\to+\infty$, in the $L^2$-norm, up to some critical decay rate. In the present paper, we close a gap that appears in the conclusion of Wiegner's theorem in the 2D case, for solutions with non-algebraic decay rate.

</details>


### [26] [Large time behavior of the solution to the Cauchy problem for the discrete p-Laplacian with density on infinite graphs](https://arxiv.org/abs/2512.21321)
*Alan A. Tedeev*

Main category: math.AP

TL;DR: Study of Cauchy problem for nonstationary discrete p-Laplacian with inhomogeneous density on infinite graphs, proving precise stabilization rates and universal bounds for p>2.


<details>
  <summary>Details</summary>
Motivation: To understand the long-time behavior of solutions to the discrete p-Laplacian equation with variable density on infinite graphs, particularly how solutions stabilize over time and establishing universal bounds under certain conditions.

Method: Uses energy inequalities and develops a new embedding result to analyze the Cauchy problem for the nonstationary discrete p-Laplacian with inhomogeneous density on infinite graphs supporting Sobolev inequality.

Result: For p>2 and nonnegative solutions, proves precise stabilization rate in time when density is non-power function; establishes universal bound when p>2 and density decays sufficiently fast.

Conclusion: The paper provides rigorous analysis of temporal behavior for discrete p-Laplacian equations on graphs, establishing both precise stabilization rates and universal bounds through novel embedding techniques and energy methods.

Abstract: We consider the Cauchy problem for the nonstationary discrete p-Laplacian with inhomogeneous density \r{ho}(x) on an infinite graph which supports the Sobolev inequality. For nonnegative solutions when p > 2, we prove the precise rate of stabilization in time, provided \r{ho}(x) is a non-power function. When p > 2 and \r{ho}(x) goes to zero fast enough, we prove the universal bound. Our technique relies on suitable energy inequalities and a new embedding result.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [27] [Quantum Origin of Classical Background Fields from Coherent States: A First-Principles Formulation in QED](https://arxiv.org/abs/2512.21122)
*Keita Seto*

Main category: physics.plasm-ph

TL;DR: The paper provides a first-principles quantum foundation for classical background fields in QED by deriving them from coherent states of the electromagnetic field.


<details>
  <summary>Details</summary>
Motivation: Classical background fields are widely used in QED for various applications (laser-matter interactions, strong-field phenomena), but their quantum origin needs clarification. The paper aims to systematically derive these classical fields from coherent states to provide a rigorous foundation.

Method: Starting from the operator formulation of QED, the authors show how scattering amplitudes between coherent states lead to effective background field descriptions. They maintain separation between coherent laser modes and other quantized photons, and derive both operator-based and functional approaches.

Result: The framework consistently incorporates effects beyond fixed background approximation (depletion, backreaction) without assuming specific field strengths. The conventional generating functional with prescribed background fields emerges as a limiting case with fixed coherent state boundary conditions.

Conclusion: The work establishes a general, intensity-independent foundation for QED with coherent background fields, showing that standard strong-field QED formulations arise as well-defined special cases within this unified framework.

Abstract: Classical background electromagnetic fields are routinely employed in quantum electrodynamics to describe a wide range of physical situations, from laser-matter interactions to strong-field phenomena. In this work, we present a first-principles formulation that clarifies the quantum origin of such classical background fields in QED by systematically deriving them from coherent states of the electromagnetic field.
  Abstract Starting from the operator formulation of QED, we show how scattering amplitudes between coherent states naturally lead to an effective description in terms of background fields, while maintaining a clear separation between the coherent laser mode and other quantized photon degrees of freedom. This framework allows one to consistently incorporate effects beyond the fixed background approximation, such as depletion and backreaction, without assuming any particular field strength or intensity regime.
  Abstract We further demonstrate how the conventional generating functional with a prescribed background field emerges as a limiting case, corresponding to fixed coherent state boundary conditions. The path integral representation is then obtained as a reformulation of the same underlying Heisenberg picture amplitudes, providing a unified view of operator-based and functional approaches.
  Abstract Our results establish a general and intensity-independent foundation for QED with coherent background fields, within which the standard formulations of strong-field QED arise as well-defined special cases.

</details>


### [28] [Multivariate scaling of proton and ion energies, divergence, and charge states in Target Normal Sheath Acceleration](https://arxiv.org/abs/2512.21279)
*Vasiliki E. Alexopoulou*

Main category: physics.plasm-ph

TL;DR: Researchers develop predictive scaling laws for laser-driven ion acceleration using a unified multiphysics model, correlating ion beam properties with laser/target parameters for applications in medicine and physics.


<details>
  <summary>Details</summary>
Motivation: Current laser-driven ion acceleration lacks predictive correlations between laser/target parameters and resulting ion-beam properties due to the complex, multiphysics nature of TNSA (Target Normal Sheath Acceleration), hindering optimization for applications like proton therapy and materials science.

Method: Used a unified multiphysics model with >95% accuracy across pulse conditions, applied multivariate regression with cross-validation for continuous beam properties (cutoff energies, divergences), and classification/regression tree (CART) methods for discrete ionization states to capture nonlinear/threshold behaviors.

Result: Derived statistically validated scaling laws and probability maps correlating proton, carbon, and oxygen ion properties (cutoff energies, divergences, ionization states) with comprehensive laser/target parameters including pulse duration, power, spot size, target thickness, contrast, wavelength, and polarization.

Conclusion: The developed framework provides predictive, physically interpretable scaling relations that elucidate coupled laser-target effects on TNSA acceleration, enabling optimization of laser-driven ion sources across broad parameter spaces for various applications.

Abstract: The interaction of an intense laser pulse with a solid target produces energetic proton and ion beams through the Target Normal Sheath Acceleration (TNSA) mechanism. Such beams are under active investigation for applications in proton beam therapy, materials modification, and nuclear and high-energy-density physics. Despite extensive experimental and theoretical effort, predictive correlations between laser and target parameters and the resulting ion-beam properties remain an open research question, owing to the intrinsically multiphysics and strongly coupled nature of laser-plasma interactions. Here, we employ our unified multiphysics model that reproduces laser-solid interaction dynamics with accuracy exceeding 95% over a broad range of short- and ultrashort-pulse conditions. Using this model, we derive statistically validated scaling laws and probability maps that correlate proton, carbon, and oxygen ion cutoff energies, beam divergences, and ionization states to a wide set of laser and target parameters, including pulse duration, laser power, laser beam spot, target thickness, prepulse-main pulse interval, contrast, laser wavelength, and polarization. Continuous beam properties (cutoff energies and beam divergences) are described using multivariate regression with cross-validation, while discrete ionization states are analyzed using classification and regression tree (CART) methods, enabling nonlinear and threshold-dependent behavior to be captured. The resulting scaling relations, contour maps, and box plots elucidate the coupled roles of laser pulse, and target geometry in governing TNSA ion acceleration and charge-state formation. These results provide a predictive and physically interpretable framework for understanding and optimizing laser-driven ion sources across a wide parameter space.

</details>


### [29] [Impurity peaking of SPARC H-modes: a sensitivity study on physics and engineering assumptions](https://arxiv.org/abs/2512.21286)
*Marco Muraca,Pablo Rodriguez-Fernandez,Joe Hall,Nathaniel T. Howard,Daniel Fajardo,Giovanni Tardini,Benedikt Zimmermann,Thomas Body*

Main category: physics.plasm-ph

TL;DR: SPARC tokamak impurity transport simulations show turbulent transport dominates over neoclassical, leading to low tungsten accumulation in H-mode plasmas with minimal impact from rotation and pedestal impurity concentrations.


<details>
  <summary>Details</summary>
Motivation: To predict impurity transport behavior in the upcoming SPARC tokamak, specifically for tungsten (W) and argon (Ar) impurities in H-mode plasmas, and understand how modeling assumptions affect predictions for next-generation fusion devices.

Method: Used ASTRA+STRAHL framework with FACIT for neoclassical transport, TGLF-SAT2 for turbulent transport, and neural network trained on EPED simulations for self-consistent pedestal calculations. Benchmarking with previous simulations and sensitivity studies for three H-mode scenarios with varying plasma parameters.

Result: Turbulent impurity transport dominates neoclassical transport; predictions are insensitive to W pedestal concentrations; Ar pedestal variations show small effects on impurity peaking; rotation has minimal impact; optimal DT fuel composition is 55-45%; all results indicate low W accumulation in SPARC.

Conclusion: SPARC will experience low tungsten accumulation due to dominant turbulent impurity transport over neoclassical transport, similar to ITER predictions, with modeling showing robustness to various uncertainties in pedestal impurity concentrations and rotation effects.

Abstract: In this paper, an overview of the impurity transport for three H-mode plasmas in the upcoming SPARC tokamak has been provided. The simulations have been performed within the ASTRA+STRAHL framework, using FACIT and TGLF-SAT2 to predict, respectively, neoclassical and turbulent core transport, while a neural network trained on EPED simulations has been employed to calculate the pedestal height and width self-consistently. A benchmark with previous simulations at constant impurity fraction has been provided for three H-modes, spanning different plasma current and magnetic field values. For a scenario, additional simulations have been performed to account for uncertainties in the modeling assumptions. The predictions are nearly insensitive to changes in the top of pedestal W concentrations. Varying the Ar pedestal concentration has shown a small effect on the impurity peaking and nearly constant fusion gain values, due to multiple effects on pedestal pressure, main ion dilution and density peaking. The inclusion of rotation in ASTRA simulations has shown minimal impact on confinement and impurity transport predictions. An exploratory study has been provided with a first set of simulations treating D and T separately, experiencing a maximum fusion power at 55-45% DT fuel composition, and an asymmetric distribution with respect to the D concentration. All the results, including sensitivity scans of toroidal velocity and ion temperature and density gradients, highlighted that turbulent impurity transport prevails on the neoclassical component, aligning with previous ITER predictions, and suggesting that next generation devices like SPARC, operating at low collisionality, will experience low W accumulation.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [30] [Ab initio Approach to Collective Excitations in Excitonic Insulators](https://arxiv.org/abs/2512.20969)
*Fengyuan Xuan,Jiexi Song,Zhiyuan Sun*

Main category: cond-mat.mtrl-sci

TL;DR: Ab initio method for studying collective excitations in symmetry-broken electronic systems like excitonic insulators, density waves, and superconductors using Bethe-Salpeter equation in quasiparticle representation.


<details>
  <summary>Details</summary>
Motivation: To develop a first-principles approach for quantitatively predicting excited state phenomena in electronic systems with spontaneous symmetry breaking, which is challenging with conventional methods.

Method: Derives Bethe-Salpeter equation for particle-hole excitations in quasiparticle representation, solves for collective excited states, and computes order parameter fluctuations from first principles.

Result: Successfully applied to excitonic insulating phases in biased WSe2-MoSe2 bilayer, revealing gapless phase-mode, subgap Bardasis-Schrieffer modes, and above-gap scattering states.

Conclusion: This work establishes a pathway for quantitative first-principles predictions of excited state phenomena in symmetry-broken electronic systems, advancing beyond ground-state calculations.

Abstract: An ab initio approach is presented for studying the collective excitations in excitonic insulators, charge/spin density waves and superconductors. We derive the Bethe-Salpeter-Equation for the particle-hole excitations in the quasiparticle representation, from which the collective excited states are solved and the corresponding order parameter fluctuations are computed. This method is demonstrated numerically for the excitonic insulating phases of the biased WSe2-MoSe2 bilayer. It reveals the gapless phase-mode, the subgap Bardasis-Schrieffer modes and the above-gap scattering states. Our work paves the way for quantitative predictions of excited state phenomena from first-principles calculations in electronic systems with spontaneous symmetry breaking.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [31] [Minijets and Broken Stationarity in a Blazar : Novel Insights into the Origin of $γ$-ray Variability in CTA 102](https://arxiv.org/abs/2512.21240)
*Agniva Roychowdhury*

Main category: astro-ph.HE

TL;DR: Analysis of 18-year Fermi-LAT data shows CTA 102's GeV light curves don't follow strict log-normal distributions, with skewness decreasing post-2017 flare, indicating state transition from frequent to occasional flaring explained by magnetic relaxation and minijets-in-a-jet model.


<details>
  <summary>Details</summary>
Motivation: To understand why high-energy blazar light curves historically show log-normal flux distributions and to analyze the statistical properties of CTA 102's GeV light curves before and after its major 2017 flare.

Method: Used 18-year archival Fermi-LAT light curves (0.1-100 GeV) from 2008-2025, performed statistical analyses on pre- and post-flare data, and developed Monte Carlo simulations of a modified minijets-in-a-jet model within an external Compton framework.

Result: Found neither pre- nor post-flare GeV light curves follow strict log-normal distributions; observed significant reduction in skewness from pre- to post-flare, indicating state transition. Simulations show modified minijets model can reproduce both flares and their flux distributions.

Conclusion: CTA 102 transitioned from energetic flaring state to more plateaued state after 2017 flare, explained by magnetic relaxation where reconnection events caused the flare and subsequent magnetic field ordering. The modified minijets-in-a-jet model successfully explains observed GeV flare properties.

Abstract: High-energy blazar light curves, in X-rays and beyond, have historically preferred a log-normal flux distribution, signifying multiplicative processes either in the jet itself or due to connection(s) with accretion. Here we present 18 year archival Fermi-LAT light curves (0.1-100 GeV) of the flat spectrum radio quasar (FSRQ) CTA 102 from August 2008 to November 2025, which underwent a huge flare in 2017, with a $\sim$ factor of 100 jump in $γ$-ray flux, along with similar flaring in X-rays. Our statistical analyses confirm that neither the pre nor the post-flare total GeV light curves follow a strictly log-normal distribution. Instead, we observe a statistically significant reduction in skewness from the pre to the post-flare light curves, which implies the blazar transitioned from an energetic state with frequent flaring to a more plateaued state with occasional flaring. We further find that this state transition can be explained through magnetic relaxation, where many reconnection events caused the 2017 flare, after which the magnetic field was ordered and its energy reached a minimum. To explain this further, we use a Monte Carlo simulation of a modified minijets-in-a-jet model where GeV flares are produced only when a maximum number of minijets move toward the broad line region and towards the line of sight, in the context of an external Compton model. The flux distributions (both observed and simulated) could be fit by a modified log-normal power-law distribution, implying our minijets model can reproduce the GeV flares in CTA 102 as well as their flux distributions.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [32] [The space spinor formalism and estimates for spinor fields](https://arxiv.org/abs/2512.20768)
*Mariem Magdy,Juan A. Valiente Kroon*

Main category: gr-qc

TL;DR: The paper adapts the space spinor formalism and positive commutator method to construct estimates for first-order spinor equations, connecting it to hyperbolicity concepts.


<details>
  <summary>Details</summary>
Motivation: To develop systematic methods for constructing estimates for spinor fields satisfying first-order equations, bridging techniques from second-order hyperbolic equations to spinor analysis.

Method: Uses space spinor formalism for 2-component spinors to adapt the method of positive commutators (originally for second-order hyperbolic equations) to first-order spinor equations.

Result: Provides a framework for constructing estimates for spinor fields, establishes connections with other estimation strategies, and recasts hyperbolicity concepts in spinor context.

Conclusion: The space spinor formalism offers an effective approach for analyzing first-order spinor equations, extending techniques from second-order hyperbolic theory to spinor field analysis.

Abstract: We show how the space spinor formalism for 2-component spinors can be used to construct estimates for spinor fields satisfying first order equations. We discuss the connection of the approach presented in this article with other strategies for the construction of estimates. In addition, we recast several concepts related to the notion of hyperbolicity in the context of spinor equations. The approach described in this article can be regarded as an adaptation to first order equations of the method of positive commutators for second order hyperbolic equations.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [33] [Mathematical Analysis of Symmetry-Protected Bound States in the Continuum in Waveguide Arrays](https://arxiv.org/abs/2512.20895)
*Xin Feng,Wei Wu*

Main category: physics.optics

TL;DR: Rigorous mathematical analysis of symmetry-based Bound States in the Continuum (BICs) in optical waveguide arrays using nonorthogonal coupled-mode equations and Bessel function addition theorems.


<details>
  <summary>Details</summary>
Motivation: To provide a rigorous mathematical foundation for symmetry-based BICs in optical waveguide arrays, moving beyond approximations like tight-binding or orthogonal coupled-mode equations to enable precise computational modeling for device design.

Method: Transforms wave propagation into Nonorthogonal Coupled-Mode Equations (NCME), derives exact expressions using Bessel function addition theorems, generalizes to infinite arrays using harmonic analysis, and proves BIC existence in symmetric waveguide configurations with numerical validation of symmetry-breaking effects.

Result: Successfully derived exact expressions for overlap integrals and coupling coefficients, rigorously characterized dispersion relations, proved existence of BICs in symmetric waveguide systems, and numerically demonstrated transition from perfect BICs to leaky modes with symmetry-breaking perturbations.

Conclusion: Provides comprehensive mathematical framework for symmetry-protected BICs with precise computational model for designing BIC-based optical devices, establishing rigorous foundation beyond previous approximation-based approaches.

Abstract: This paper presents a rigorous mathematical analysis for symmetry-based Bound States in the Continuum (BICs) in optical waveguide arrays. Different from existing research, we consider a finite system of horizontally and equidistantly aligned waveguides and transform the wave propagation problem into Nonorthogonal Coupled-Mode Equations (NCME), rather than adopting the tight-binding approximation or orthogonal coupled-mode equations. We derive the exact expressions of the overlap integrals and coupling coefficients by utilizing the addition theorems of Bessel functions. We then generalize the discussion to an infinite waveguide array and rigorously characterize the dispersion relation and continuum with the help of theories in harmonic analysis. In the second part of the paper, we give a strict proof of the existence of BICs in the aforementioned waveguide system with two additional identical vertical waveguides aligned symmetrically above and below the horizontal waveguide array. We further numerically demonstrate the transition from a perfect BIC to a leaky mode by introducing a symmetry-breaking refractive index perturbation and quantitatively analyze the resulting radiation losses. This work gives a comprehensive study of symmetry-protected BICs and provides an efficient and precise computational model for designing such BICs devices.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [34] [On the Relationship Between Nanoflare Energy and Delay in the Closed Solar Corona](https://arxiv.org/abs/2512.20875)
*Shanwlee Sow Mondal,James A. Klimchuk,Craig D. Johnston,Lars K. S. Daldorff*

Main category: astro-ph.SR

TL;DR: No correlation found between nanoflare energies and their delays, suggesting nanoflare onset is not solely determined by magnetic stress thresholds but may involve complex triggering mechanisms.


<details>
  <summary>Details</summary>
Motivation: To understand the physical mechanism of nanoflares and plasma response by determining the relationship between nanoflare energies and their delays, which could reveal whether onset is determined by critical magnetic stress values.

Method: Used 3D multi-strand simulation with prescribed photospheric motions to generate nanoflares self-consistently. Quantified energies and durations using three distinct methods. Applied two non-parametric, rank-based statistical tests to investigate correlation between energies (E) and delays (τ_D). Analyzed distribution of exponent α in E ∝ τ_D^α relation and delay distributions within fixed energy bins.

Result: Consistently found little to no correlation between nanoflare energies and delays across all methods. Distribution of exponent α peaks near zero. Broad delay distributions within fixed energy bins. Results hold for both preceding and subsequent event correlations, and for high-energy nanoflares subset.

Conclusion: The absence of correlation suggests nanoflare onset is not solely determined by a critical value of magnetic stress. May involve triggering by other events, possibly related to locally complex magnetic topology.

Abstract: Determining the relationship between nanoflare energies and their delays is the key for understanding the physical mechanism of the events and the plasma response. Nanoflares analyzed in this study were generated self-consistently via prescribed photospheric motions in a 3D multi-strand simulation of a subset of active region magnetic flux. Energies and durations were quantified using three distinct methods. In this study, we investigated the correlation between nanoflare energies (E) and delays ($τ_D$) using two non-parametric, rank-based statistical tests. Across all methods, results consistently show little to no correlation. This is further supported by the distribution of the exponent $α$ in the assumed relation $E \propto τ_D^α$, which peaks near zero, and by broad delay distributions within fixed energy bins. These findings are irrespective of whether delays are correlated with the energy of the preceding or subsequent event. They also hold for a subset of high-energy nanoflares. The absence of correlation suggests that nanoflare onset is not solely determined by a critical value of magnetic stress and may involve triggering by other events, perhaps related to a locally complex topology.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [35] [Implicit Numerical Scheme for the Hamilton-Jacobi-Bellman Quasi-Variational Inequality in the Optimal Market-Making Problem with Alpha Signal](https://arxiv.org/abs/2512.20850)
*Alexey Meteykin*

Main category: q-fin.MF

TL;DR: Market maker control problem solved using HJBQVI with implicit time discretization and policy iteration for unconditional stability


<details>
  <summary>Details</summary>
Motivation: Address the combined stochastic and impulse control problem for market makers in limit order books, overcoming time-step restrictions of explicit methods

Method: Formulate as Hamilton-Jacobi-Bellman quasi-variational inequality (HJBQVI), use implicit time-discretization scheme coupled with policy iteration algorithm

Result: Removes time-step restrictions, ensures unconditional stability, and establishes convergence to unique viscosity solution via monotonicity, stability, and consistency conditions

Conclusion: Proposed method provides stable and convergent solution for market maker control problems without explicit method limitations

Abstract: We address the problem of combined stochastic and impulse control for a market maker operating in a limit order book. The problem is formulated as a Hamilton-Jacobi-Bellman quasi-variational inequality (HJBQVI). We propose an implicit time-discretization scheme coupled with a policy iteration algorithm. This approach removes time-step restrictions typical of explicit methods and ensures unconditional stability. Convergence to the unique viscosity solution is established by verifying monotonicity, stability, and consistency conditions and applying the comparison principle.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [36] [Prediction Air Temperature in Geothermal Heat Exchangers Using Pseudorandom Numbers: The New DARL Model](https://arxiv.org/abs/2512.19976)
*C. Ramírez-Dolores,J. C. Zamora-Luria,J. A. Altamirano-Acosta,L. Sarao-Cruz,P. Jiménez-Palma,J. Moreno-Falconi*

Main category: cs.CY

TL;DR: DARL model predicts air temperature distribution in Earth-Air-Water Heat Exchangers using experimental data and pseudo-random numbers, reducing sensor dependency with <6.2% error.


<details>
  <summary>Details</summary>
Motivation: EAWHE systems for sustainable air conditioning lack comprehensive study, and current characterization methods require dense sensor networks with high instrumentation, data acquisition, and computational costs.

Method: DARL model integrates experimental boundary condition data with simulations using pseudo-random numbers generated from Fermat's prime seeds, employing ordinary linear regressions and robust statistical validation (Shapiro-Wilk test, RMSE).

Result: Model achieves <6.2% relative error in estimating thermal air distribution at different lengths, demonstrating efficiency and predictive capacity while reducing sensor dependency.

Conclusion: DARL represents a significant methodological advance for EAWHE characterization, offering an efficient alternative to dense sensor networks with validated predictive performance.

Abstract: The use of Earth-Air-Water Heat Exchangers (EAWHE) for sustainable air conditioning has not been widely studied. Due to their experimental nature, methods of characterizing internal thermal air distribution impose high dependence on instrumentation by sensors and entail data acquisition and computational costs. This document presents an alternative method that estimates air temperature distribution while minimizing the need for a dense network of sensors in the experimental system. The proposed model, DARL (Data of Air and Random Length), can predict the temperature of air circulating inside EAWHEs. DARL is a significant methodological advance that integrates experimental data from boundary conditions with simulations based on pseudo-random numbers (PRNs). These PRNs are generated using Fermat's prime numbers as seeds to initialize the generator. Ordinary linear regressions and robust statistical validations, including the Shapiro-Wilk test and root mean square error, have demonstrated that the model can estimate the thermal distribution of air at different lengths with a relative error of less than 6.2%. These results demonstrate the model's efficiency, predictive capacity, and potential to reduce dependence on sensors.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [37] [Formal O(N3) scaling GW calculations by block tensor decomposition for large molecule systems](https://arxiv.org/abs/2512.21022)
*Yueyang Zhang,Wei Wu,Peifeng Su*

Main category: physics.chem-ph

TL;DR: BTD-based GW algorithm achieves O(N²) scaling for large molecular systems, enabling calculations with 3000+ basis functions.


<details>
  <summary>Details</summary>
Motivation: The GW approximation is crucial for quasiparticle energies but has high computational cost and poor scaling for large molecular systems.

Method: Extends block tensor decomposition (BTD) algorithm, integrates with imaginary-time GW formalism, uses real space screening for polarizability, and optimizes parameters on S66 dataset with JADE algorithm.

Result: Achieves O(N²) scaling in test systems, BTD-based random phase approximation also shows O(N²) scaling, enables eigenvalue-self-consistent GW calculations for 3000+ basis functions.

Conclusion: BTD establishes an efficient and scalable approach for large-scale GW calculations in molecular systems.

Abstract: Within the framework of many-body perturbation theory based on Green's functions, the $GW$ approximation has emerged as a pivotal method for computing quasiparticle energies and excitation spectra. However, its high computational cost and steep scaling present significant challenges for applications to large molecular systems. In this work, we extend the block tensor decomposition (BTD) algorithm, recently developed in our previous work [J. Chem. Phys. 163, 174109 (2025)] for low-rank tensor compression, to enable a formally $O(N^3)$-scaling $GW$ algorithm. By integrating BTD with an imaginary-time $GW$ formalism and introducing a real space screening strategy for the polarizability, we achieve an observed scaling of approximately $O(N^2)$ in test systems. Key parameters of the algorithm are optimized on the S66 dataset using the JADE algorithm, ensuring a balanced compromise between accuracy and efficiency. Our BTD-based random phase approximation also exhibits $O(N^2)$ scaling, and eigenvalue-self-consistent $GW$ calculations become feasible for systems with over 3000 basis functions. This work establishes BTD as an efficient and scalable approach for large-scale $GW$ calculations in molecular systems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [38] [Quantum Homotopy Algorithm for Solving Nonlinear PDEs and Flow Problems](https://arxiv.org/abs/2512.21033)
*Sachin S. Bharadwaj,Balasubramanya Nadiga,Stephan Eidenbenz,Katepalli R. Sreenivasan*

Main category: quant-ph

TL;DR: A near-optimal quantum algorithm for solving time-dependent, dissipative, nonlinear PDEs using quantum homotopy analysis and compact quantum finite-difference methods.


<details>
  <summary>Details</summary>
Motivation: Quantum algorithms for nonlinear PDEs governing flow problems are challenging but critical for enhancing the practical usefulness of quantum computing in simulating complex physical phenomena.

Method: Embeds PDEs in truncated high-dimensional linear space using quantum homotopy analysis, then discretizes and integrates with finite-difference methods using a compact quantum algorithm. Adapts to nonlinearity and underlying physics.

Result: Complexity estimates improve existing approaches in scaling of matrix operator norms, condition number, simulation time, and accuracy. Provides embedding strategy, stability bounds, accuracy, gate counts, and query complexity. Introduces nonlinearity measure similar to Reynolds number.

Conclusion: Demonstrates potential of hybrid quantum algorithms for simulating practical nonlinear phenomena on near-term and fault-tolerant quantum devices, with numerical validation on 1D Burgers problem.

Abstract: Quantum algorithms to integrate nonlinear PDEs governing flow problems are challenging to discover but critical to enhancing the practical usefulness of quantum computing. We present here a near-optimal, robust, and end-to-end quantum algorithm to solve time-dependent, dissipative, and nonlinear PDEs. We embed the PDEs in a truncated, high dimensional linear space on the basis of quantum homotopy analysis. The linearized system is discretized and integrated using finite-difference methods that use a compact quantum algorithm. The present approach can adapt its input to the nature of nonlinearity and underlying physics. The complexity estimates improve existing approaches in terms of scaling of matrix operator norms, condition number, simulation time, and accuracy. We provide a general embedding strategy, bounds on stability criteria, accuracy, gate counts and query complexity. A physically motivated measure of nonlinearity is connected to a parameter that is similar to the flow Reynolds number $Re_{\textrm{H}}$, whose inverse marks the allowed integration window, for given accuracy and complexity. We illustrate the embedding scheme with numerical simulations of a one-dimensional Burgers problem. This work shows the potential of the hybrid quantum algorithm for simulating practical and nonlinear phenomena on near-term and fault-tolerant quantum devices.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [39] [Regularity of Einstein 5-manifolds via 4-dimensional gap theorems](https://arxiv.org/abs/2512.21317)
*Yiqi Huang,Tristan Ozuch*

Main category: math.DG

TL;DR: The paper refines regularity results for noncollapsed limits of 5-dimensional Einstein manifolds, showing tangent cone uniqueness, structure of singular sets, geodesic properties, and orbifold regularity, with applications to gap theorems for Einstein 4-orbifolds.


<details>
  <summary>Details</summary>
Motivation: To improve understanding of the regularity and structure of noncollapsed limits of 5-dimensional manifolds with bounded Ricci curvature, particularly Einstein manifolds, and to characterize their singular sets and tangent cones.

Method: The proofs rely on a new result showing that all spherical and hyperbolic 4-orbifolds are isolated among Einstein 4-orbifolds in the Gromov-Hausdorff sense. This isolation property enables various gap theorems and structural analyses for the 5-dimensional case.

Result: Five main results: (1) Tangent cones are unique and of form ℝ×ℝ⁴/Γ on the top stratum; (2) Singular set contained in countable union of Lipschitz curves and points; (3) Away from nowhere dense subset, these curves are smooth geodesics; (4) Geodesic interiors are removable, yielding real-analytic orbifolds; (5) Asymptotically Ricci-flat 5-manifolds with Euclidean volume growth have unique tangent cones at infinity if one splits off a line.

Conclusion: The results establish refined regularity for noncollapsed limits of 5-dimensional Einstein manifolds and raise the question of whether similar orbifold regularity holds for noncollapsed limits of Einstein manifolds off a codimension 5 set in arbitrary dimension. The gap theorems for Einstein 4-orbifolds do not extend to higher dimensions.

Abstract: We refine the regularity of noncollapsed limits of 5-dimensional manifolds with bounded Ricci curvature. In particular, for noncollapsed limits of Einstein 5-manifolds, we prove that
  (1) tangent cones are unique of the form $\mathbb{R}\times\mathbb{R}^4/Γ$ on the top stratum, hence outside a countable set of points,
  (2) the singular set is entirely contained in a countable union of Lipschitz curves and points,
  (3) away from a nowhere dense subset, these Lipschitz curves consist of smooth geodesics,
  (4) the interior of any geodesic is removable: limits of Einstein manifolds are real-analytic orbifolds with singularities along geodesic and bounded curvature away from their extreme points, and
  (5) if an asymptotically Ricci-flat 5-manifold with Euclidean volume growth has one tangent cone at infinity that splits off a line, then it is the unique tangent cone at infinity.
  These results prompt the question of the orbifold regularity of noncollapsed limits of Einstein manifolds off a codimension 5 set in arbitrary dimension.
  The proofs rely on a new result of independent interest: all spherical and hyperbolic 4-orbifolds are isolated among Einstein 4-orbifolds in the Gromov-Hausdorff sense. This yields various gap theorems for Einstein 4-orbifolds, which do not extend to higher dimensions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [40] [Forecasting N-Body Dynamics: A Comparative Study of Neural Ordinary Differential Equations and Universal Differential Equations](https://arxiv.org/abs/2512.20643)
*Suriya R S,Prathamesh Dinesh Joshi,Rajat Dandekar,Raj Dandekar,Sreedath Panat*

Main category: cs.LG

TL;DR: Scientific ML approach using Neural ODEs and UDEs for n-body problem forecasting, with UDEs showing superior data efficiency (20% vs 90% data needed).


<details>
  <summary>Details</summary>
Motivation: Traditional ML models for n-body trajectory prediction are data-intensive black boxes that ignore physical laws and lack interpretability. Scientific ML addresses this by embedding known physical laws into ML frameworks.

Method: Uses Scientific ML frameworks in Julia: Neural ODEs and Universal Differential Equations (UDEs) to predict n-body system dynamics. Employs synthetically created noisy data to simulate real-world observational limitations. Determines forecasting breakdown point - minimum training data needed for accurate predictions.

Result: UDE model is much more data efficient, requiring only 20% of data for correct forecasting, while Neural ODE requires 90% of data.

Conclusion: Scientific ML with UDEs provides a more interpretable and data-efficient approach to n-body problem forecasting compared to traditional ML and even Neural ODEs, with significant practical advantages for astrophysical applications.

Abstract: The n body problem, fundamental to astrophysics, simulates the motion of n bodies acting under the effect of their own mutual gravitational interactions. Traditional machine learning models that are used for predicting and forecasting trajectories are often data intensive black box models, which ignore the physical laws, thereby lacking interpretability. Whereas Scientific Machine Learning ( Scientific ML ) directly embeds the known physical laws into the machine learning framework. Through robust modelling in the Julia programming language, our method uses the Scientific ML frameworks: Neural ordinary differential equations (NODEs) and Universal differential equations (UDEs) to predict and forecast the system dynamics. In addition, an essential component of our analysis involves determining the forecasting breakdown point, which is the smallest possible amount of training data our models need to predict future, unseen data accurately. We employ synthetically created noisy data to simulate real-world observational limitations. Our findings indicate that the UDE model is much more data efficient, needing only 20% of data for a correct forecast, whereas the Neural ODE requires 90%.

</details>


### [41] [Improving Matrix Exponential for Generative AI Flows: A Taylor-Based Approach Beyond Paterson--Stockmeyer](https://arxiv.org/abs/2512.20777)
*Jorge Sastre,Daniel Faronbi,José Miguel Alonso,Peter Traver,Javier Ibáñez,Nuria Lloret*

Main category: cs.LG

TL;DR: Optimized Taylor-based algorithm for matrix exponential with dynamic parameter selection, designed for high-throughput generative AI applications.


<details>
  <summary>Details</summary>
Motivation: Matrix exponential is fundamental in scientific computing and generative AI, but existing methods (Padé approximants with scaling/squaring) are being surpassed by newer Taylor-based approaches that offer better accuracy and computational efficiency.

Method: Develops an optimized Taylor-based algorithm with rigorous error analysis and dynamic selection strategy for Taylor order and scaling factor to minimize computational effort under prescribed error tolerance.

Result: Extensive experiments show significant acceleration and high numerical stability compared to state-of-the-art implementations, establishing the method as highly efficient for large-scale generative modeling.

Conclusion: The proposed Taylor-based matrix exponential algorithm provides an efficient, stable solution for high-throughput generative AI applications, outperforming traditional Padé-based methods.

Abstract: The matrix exponential is a fundamental operator in scientific computing and system simulation, with applications ranging from control theory and quantum mechanics to modern generative machine learning. While Padé approximants combined with scaling and squaring have long served as the standard, recent Taylor-based methods, which utilize polynomial evaluation schemes that surpass the classical Paterson--Stockmeyer technique, offer superior accuracy and reduced computational complexity. This paper presents an optimized Taylor-based algorithm for the matrix exponential, specifically designed for the high-throughput requirements of generative AI flows. We provide a rigorous error analysis and develop a dynamic selection strategy for the Taylor order and scaling factor to minimize computational effort under a prescribed error tolerance. Extensive numerical experiments demonstrate that our approach provides significant acceleration and maintains high numerical stability compared to existing state-of-the-art implementations. These results establish the proposed method as a highly efficient tool for large-scale generative modeling.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [42] [Flow Gym](https://arxiv.org/abs/2512.20642)
*Francesco Banelli,Antonio Terpin,Alan Bonomi,Raffaello D'Andrea*

Main category: physics.flu-dyn

TL;DR: Flow Gym is a toolkit for flow-field quantification research and deployment, inspired by OpenAI Gym and Stable-Baselines3, providing unified interface for testing, deployment, and training of learning-based algorithms.


<details>
  <summary>Details</summary>
Motivation: To create a standardized toolkit for flow-field quantification research that addresses the need for unified testing, deployment, and training environments for algorithms that analyze tracer particle images.

Method: Uses SynthPix as synthetic image generation engine, provides OpenAI Gym-like interface, includes integrations of existing algorithms, and offers stable JAX re-implementations for flow-field quantification from consecutive tracer particle images.

Result: A comprehensive toolkit that enables researchers to work with flow-field quantification methods in a standardized way, with growing library of algorithm integrations and JAX implementations.

Conclusion: Flow Gym successfully creates a unified framework for flow-field quantification research, facilitating algorithm development, testing, and deployment through standardized interfaces and synthetic data generation.

Abstract: Flow Gym is a toolkit for research and deployment of flow-field quantification methods inspired by OpenAI Gym and Stable-Baselines3. It uses SynthPix as synthetic image generation engine and provides a unified interface for the testing, deployment and training of (learning-based) algorithms for flow-field quantification from a number of consecutive images of tracer particles. It also contains a growing number of integrations of existing algorithms and stable (re-)implementations in JAX.

</details>


### [43] [Velocity dip in turbulent mixed convection of an open Poiseuille-Rayleigh-Bénard channel](https://arxiv.org/abs/2512.20977)
*Ben-Rui Xu,Ao Xu,Heng-Dong Xi*

Main category: physics.flu-dyn

TL;DR: Velocity-dip phenomenon emerges in turbulent mixed convection in open channels with free-slip upper boundary due to large-scale rolls transporting low-speed fluid upward and roll fragmentation creating near-surface low-speed regions.


<details>
  <summary>Details</summary>
Motivation: To understand the emergence of velocity-dip phenomenon in turbulent mixed convection in open Poiseuille-Rayleigh-Bénard channels with free-slip upper boundary, where the maximum mean streamwise velocity occurs below the upper boundary rather than at the surface.

Method: Three-dimensional direct numerical simulations (DNS) for Rayleigh numbers 10^5 ≤ Ra ≤ 10^8 at fixed Prandtl number Pr = 0.71 and bulk Reynolds number Re_b = 2850, analyzing flow regimes and proposing a model based on buoyancy-shear production balance with dissipation.

Result: Velocity dip emerges due to two mechanisms: large-scale rolls transporting low-speed fluid upward creating laterally extended low-speed regions, and roll fragmentation inducing upstream low-speed regions near upper boundary. The model accurately reproduces DNS mean velocity profiles across the Ra range.

Conclusion: The velocity-dip phenomenon in turbulent mixed convection is caused by large-scale roll structures that modify near-surface velocity profiles, with the proposed model successfully capturing this behavior through a balance of buoyancy and shear production with dissipation.

Abstract: We study the emergence of a velocity-dip phenomenon in turbulent mixed convection in open Poiseuille-Rayleigh-Bénard (PRB) channels with a free-slip upper boundary. Three-dimensional direct numerical simulations (DNS) are performed for Rayleigh numbers in the range $10^5 \leq Ra \leq 10^8$, at a fixed Prandtl number $Pr = 0.71$ and a bulk Reynolds number $Re_b = 2850$. In the shear-dominated regime, the flow is characterised by small-scale structures such as near-wall streaks. As buoyancy becomes comparable to shear, streamwise-oriented large-scale rolls emerge and span the full channel height. At higher Rayleigh numbers, buoyancy dominates and the rolls fragment, giving rise to a convection-cell-dominated regime. Short-time-averaged flow fields show that streamwise rolls transport low-speed fluid from the bottom wall towards the upper boundary, forming laterally extended low-speed regions, while roll fragmentation induces upstream low-speed regions near the upper boundary. Both mechanisms locally reduce the near-surface mean velocity, leading to a velocity dip in which the maximum mean streamwise velocity is located below the upper boundary. Consistent with the mean momentum budget, the near-surface region exhibits a large-scale Reynolds shear stress that exceeds the local total shear stress, implying a negative viscous contribution and a reversal of the mean velocity gradient. To model this behaviour, we propose a model based on a balance between buoyancy and shear production with dissipation, incorporating a linear wall-normal profile for the Reynolds shear stress, a wall-normal-independent buoyancy-production term, and a decomposition of the dissipation into shear-induced and buoyancy-induced contributions. Our model accurately reproduces the DNS mean velocity profiles across the explored $Ra$ range.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [44] [Propagation Estimates for the Boson Star Equation](https://arxiv.org/abs/2512.20718)
*Sébastien Breteaux,Jérémy Faupin,Viviana Grasselli*

Main category: math-ph

TL;DR: The paper analyzes boson star equations with general two-body potentials, proving finite speed of propagation bounds and asymptotic phase-space estimates for global solutions.


<details>
  <summary>Details</summary>
Motivation: To understand propagation properties of solutions to boson star equations with general interaction potentials, particularly establishing speed-of-light propagation bounds and asymptotic behavior for global solutions.

Method: The authors work with boson star equations in Sobolev spaces, assuming the two-body potential w decomposes as a sum of a finite signed measure and an essentially bounded function. They prove local-in-time finite speed propagation bounds with exponentially small remainders, and for short-range potentials with regular small initial data, they establish asymptotic phase-space propagation estimates and minimal velocity estimates.

Result: 1) For general potentials w, local solutions cannot propagate faster than light speed (up to exponentially small remainders). 2) For short-range potentials with sufficiently regular and small initial data, global solutions satisfy asymptotic phase-space propagation estimates and minimal velocity bounds that depend on the momentum of the scattering state associated with the initial data.

Conclusion: The paper establishes rigorous propagation bounds for boson star equations, showing that solutions respect relativistic causality (finite speed of light propagation) and exhibit controlled asymptotic behavior for global solutions with short-range interactions.

Abstract: We consider the boson star equation with a general two-body interaction potential $w$ and initial data $ψ_0$ in a Sobolev space. Under general assumptions on $w$, namely that $w$ decomposes as a sum of a finite, signed measure and an essentially bounded function, we prove that the (local in time) solution cannot propagate faster than the speed of light, up to a sharp exponentially small remainder term. If $w$ is short-range and $ψ_0$ is regular and small enough, we prove in addition asymptotic phase-space propagation estimates and minimal velocity estimates for the (global in time) solution, depending on the momentum of the scattering state associated to $ψ_0$.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [45] [The Dynamical Anatomy of Anderson Acceleration:From Adaptive Momentum to Variable-Mass ODEs](https://arxiv.org/abs/2512.21269)
*Kewang Chen,Yongqiu Jiang,Kees Vuik*

Main category: math.OC

TL;DR: This paper bridges Anderson Acceleration (AA) with continuous dynamical systems via High-Resolution ODEs, revealing AA's instability mechanism and proposing Energy-Guarded AA (EG-AA) for improved convergence.


<details>
  <summary>Details</summary>
Motivation: The dynamics of Anderson Acceleration (introduced in 1965) remain poorly understood compared to classical Nesterov acceleration. The paper aims to provide theoretical foundations for AA by connecting discrete algorithms with continuous dynamical systems and addressing fundamental questions about AA's physical nature.

Method: 1) Prove AA can be rewritten as an adaptive momentum method converging to a second-order ODE with Variable Effective Mass. 2) Use Lyapunov energy analysis to identify AA's instability mechanism (unchecked growth in effective mass acts as negative damping). 3) Identify implicit Hessian-driven damping that stabilizes stiff regimes. 4) Propose Energy-Guarded Anderson Acceleration (EG-AA) as an inertial governor enforcing thermodynamic consistency.

Result: 1) Theoretical analysis reveals AA's specific instability mechanism. 2) EG-AA is proven to be no worse than standard AA via Acceleration Gain Factor analysis. 3) Numerical experiments show EG-AA achieves strictly improved convergence stability and rates in ill-conditioned convex composite problems compared to standard Anderson mixing.

Conclusion: The paper provides rigorous theoretical foundations for Anderson Acceleration through High-Resolution ODE analysis, identifies its instability mechanism, and proposes EG-AA as a thermodynamically consistent algorithm that improves convergence while maintaining theoretical guarantees.

Abstract: This paper provides a rigorous derivation and analysis of accelerated optimization algorithms through the lens of High-Resolution Ordinary Differential Equations (ODEs). While classical Nesterov acceleration is well-understood via asymptotic vanishing damping, the dynamics of Anderson Acceleration (AA) remain less transparent. This work makes significant theoretical contributions to AA by bridging discrete acceleration algorithms with continuous dynamical systems, while also providing practical algorithmic innovations. Our work addresses fundamental questions about the physical nature of Anderson Acceleration that have remained unanswered since its introduction in 1965. Firstly, we prove that AA can be exactly rewritten as an adaptive momentum method and, in the high-resolution limit, converges to a second-order ODE with Variable Effective Mass. Through a Lyapunov energy analysis, we reveal the specific instability mechanism of standard AA: unchecked growth in effective mass acts as negative damping, physically injecting energy into the system and violating dissipation constraints. Conversely, high-resolution analysis identifies an implicit Hessian-driven damping term that provides stabilization in stiff regimes. Leveraging these dynamical insights, we then propose Energy-Guarded Anderson Acceleration (EG-AA), an algorithm that acts as an inertial governor to enforce thermodynamic consistency. Morevoer, our convergence analysis, formulated via the Acceleration Gain Factor, proves that EG-AA improves upon gradient descent by maximizing the geometric contraction of the linear subspace projection while actively suppressing nonlinear approximation errors. Theoretical bounds confirm that EG-AA is no worse than standard AA, and numerical experiments demonstrate strictly improved convergence stability and rates in ill-conditioned convex composite problems compared to standard Anderson mixing.

</details>
