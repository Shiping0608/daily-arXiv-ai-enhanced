{"id": "2601.04429", "pdf": "https://arxiv.org/pdf/2601.04429", "abs": "https://arxiv.org/abs/2601.04429", "authors": ["Ming Zhou", "Klaus Neymeyr"], "title": "Toward genuine efficiency and cluster robustness of preconditioned CG-like eigensolvers", "categories": ["math.NA"], "comment": "25 pages, 8 figures", "summary": "The performance of eigenvalue problem solvers (eigensolvers) depends on various factors such as preconditioning and eigenvalue distribution. Developing stable and rapidly converging vectorwise eigensolvers is a crucial step in improving the overall efficiency of their blockwise implementations. The present paper is concerned with the locally optimal block preconditioned conjugate gradient (LOBPCG) method for Hermitian eigenvalue problems, and motivated by two recently proposed alternatives for its single-vector version LOPCG. A common basis of these eigensolvers is the well-known CG method for linear systems. However, the optimality of CG search directions cannot perfectly be transferred to CG-like eigensolvers. In particular, while computing clustered eigenvalues, LOPCG and its alternatives suffer from frequent delays, leading to a staircase-shaped convergence behavior which cannot be explained by the existing estimates. Keeping this in mind, we construct a class of cluster robust vector iterations where LOPCG is replaced by asymptotically equivalent two-term recurrences and the search directions are timely corrected by selecting a far previous iterate as augmentation. The new approach significantly reduces the number of required steps and the total computational time.", "AI": {"tldr": "The paper proposes a new cluster-robust vector iteration method for Hermitian eigenvalue problems that improves upon LOBPCG/LOPCG by using asymptotically equivalent two-term recurrences and timely correction with far previous iterates, significantly reducing computational steps and time for clustered eigenvalues.", "motivation": "Existing vectorwise eigensolvers like LOPCG and its alternatives suffer from frequent delays and staircase-shaped convergence behavior when computing clustered eigenvalues, which cannot be explained by existing estimates. This inefficiency motivates the development of more robust methods for clustered eigenvalue problems.", "method": "The authors construct a class of cluster robust vector iterations where LOPCG is replaced by asymptotically equivalent two-term recurrences. The search directions are timely corrected by selecting a far previous iterate as augmentation, addressing the convergence delays in clustered eigenvalue computations.", "result": "The new approach significantly reduces the number of required steps and the total computational time compared to existing methods like LOPCG and its alternatives, particularly for problems with clustered eigenvalues.", "conclusion": "The proposed cluster-robust vector iteration method effectively addresses the convergence issues of existing CG-like eigensolvers for clustered eigenvalues, offering improved efficiency through modified recurrence relations and strategic augmentation with previous iterates."}}
{"id": "2601.04479", "pdf": "https://arxiv.org/pdf/2601.04479", "abs": "https://arxiv.org/abs/2601.04479", "authors": ["Ren-Cang Li"], "title": "Approximations of Extremal Eigenspace and Orthonormal Polar Factor", "categories": ["math.NA"], "comment": null, "summary": "This paper is concerned with two extremal problems from matrix analysis. One is about approximating the top eigenspaces of a Hermitian matrix and the other one about approximating the orthonormal polar factor of a general matrix. Tight error bounds on the quality of the approximations are obtained.", "AI": {"tldr": "Paper presents tight error bounds for approximating top eigenspaces of Hermitian matrices and orthonormal polar factors of general matrices.", "motivation": "The paper addresses fundamental problems in matrix analysis: approximating principal eigenspaces (important for dimensionality reduction, PCA, spectral methods) and approximating polar factors (relevant for matrix decompositions, optimization, and numerical linear algebra). Both problems have practical applications but lack tight theoretical error bounds.", "method": "The paper develops mathematical analysis techniques to derive tight error bounds for both problems. For Hermitian matrices, it analyzes approximation quality of top eigenspaces. For general matrices, it studies approximation of orthonormal polar factors (the unitary part of polar decomposition). The methods likely involve perturbation theory, matrix analysis, and optimization techniques.", "result": "The main results are tight error bounds on the approximation quality for both problems. These bounds are optimal in the sense that they cannot be improved without additional assumptions. The bounds quantify how well approximations capture the true eigenspaces/polar factors under various conditions.", "conclusion": "The paper establishes fundamental theoretical limits for two important matrix approximation problems. The tight error bounds provide theoretical foundations for algorithms that approximate eigenspaces and polar factors, with implications for numerical linear algebra, machine learning, and scientific computing."}}
{"id": "2601.04482", "pdf": "https://arxiv.org/pdf/2601.04482", "abs": "https://arxiv.org/abs/2601.04482", "authors": ["Haojun Qin", "Zhiwei Gao", "Jinye Shen", "George Karniadakis"], "title": "Nonlinear parametrization solver for fractional Burgers equations", "categories": ["math.NA"], "comment": null, "summary": "Fractional Burgers equations pose substantial challenges for classical numerical methods due to the combined effects of nonlocality and shock-forming nonlinear dynamics. In particular, linear approximation frameworks-such as spectral, finite-difference, or discontinuous Galerkin methods-often suffer from Gibbs-type oscillations or require carefully tuned stabilization mechanisms, whose effectiveness degrades in transport-dominated and long-time integration regimes. In this work, we introduce a sequential-in-time nonlinear parametrization (STNP) for solving fractional Burgers equations, including models with a fractional Laplacian or with nonlocal nonlinear fluxes. The solution is represented by a nonlinear parametric ansatz, and the parameter evolution is obtained by projecting the governing dynamics onto the tangent space of the parameter manifold through a regularized least-squares formulation at each time step. This yields a well-posed and stable time-marching scheme that preserves causality and avoids global-in-time optimization. We provide a theoretical analysis of the resulting projected dynamics, including a stability estimate and an a posteriori error bound that explicitly decomposes the total error into contributions from initial condition fitting, projection residuals, and discretization of fractional operators. Our analysis clarifies the stabilizing role of regularization and quantifies its interaction with the nonlocal discretization error. Numerical experiments for both fractional Burgers models demonstrate that STNP achieves oscillation-free shock resolution and accurately captures long-time dynamics. The method consistently outperforms high-order spectral schemes augmented with spectral vanishing viscosity, while requiring significantly fewer degrees of freedom and avoiding ad hoc stabilization.", "AI": {"tldr": "STNP method solves fractional Burgers equations using sequential nonlinear parametrization, avoiding Gibbs oscillations and outperforming spectral methods with fewer degrees of freedom.", "motivation": "Classical numerical methods struggle with fractional Burgers equations due to combined nonlocality and shock-forming nonlinear dynamics, suffering from Gibbs oscillations and requiring ad hoc stabilization that degrades in transport-dominated regimes.", "method": "Sequential-in-time nonlinear parametrization (STNP) represents solution via nonlinear parametric ansatz, projects governing dynamics onto tangent space of parameter manifold using regularized least-squares at each time step, yielding causal time-marching scheme.", "result": "STNP achieves oscillation-free shock resolution, accurately captures long-time dynamics, outperforms high-order spectral schemes with spectral vanishing viscosity, requires fewer degrees of freedom, and avoids ad hoc stabilization.", "conclusion": "STNP provides stable, well-posed approach for fractional Burgers equations with theoretical guarantees, overcoming limitations of classical methods through nonlinear parametrization and regularized projection."}}
{"id": "2601.04496", "pdf": "https://arxiv.org/pdf/2601.04496", "abs": "https://arxiv.org/abs/2601.04496", "authors": ["Jie Jiang", "Yuesheng Xu"], "title": "Adaptive Multi-Grade Deep Learning for Highly Oscillatory Fredholm Integral Equations of the Second Kind", "categories": ["math.NA"], "comment": null, "summary": "This paper studies the use of Multi-Grade Deep Learning (MGDL) for solving highly oscillatory Fredholm integral equations of the second kind. We provide rigorous error analyses of continuous and discrete MGDL models, showing that the discrete model retains the convergence and stability of its continuous counterpart under sufficiently small quadrature error. We identify the DNN training error as the primary source of approximation error, motivating a novel adaptive MGDL algorithm that selects the network grade based on training performance. Numerical experiments with highly oscillatory (including wavenumber 500) and singular solutions confirm the accuracy, effectiveness and robustness of the proposed approach.", "AI": {"tldr": "MGDL effectively solves highly oscillatory Fredholm integral equations with rigorous error analysis and adaptive grade selection.", "motivation": "To develop an efficient deep learning approach for solving challenging highly oscillatory Fredholm integral equations of the second kind, which are difficult to solve with traditional numerical methods.", "method": "Multi-Grade Deep Learning (MGDL) models with rigorous error analysis of both continuous and discrete versions. A novel adaptive algorithm that selects network grade based on training performance, with DNN training error identified as the primary approximation error source.", "result": "Discrete MGDL model retains convergence and stability of continuous counterpart under sufficiently small quadrature error. Numerical experiments with highly oscillatory (wavenumber up to 500) and singular solutions confirm accuracy, effectiveness, and robustness.", "conclusion": "The adaptive MGDL approach provides an accurate and robust solution method for highly oscillatory Fredholm integral equations, with theoretical guarantees and practical effectiveness demonstrated through rigorous analysis and numerical experiments."}}
{"id": "2601.04967", "pdf": "https://arxiv.org/pdf/2601.04967", "abs": "https://arxiv.org/abs/2601.04967", "authors": ["Dimitrios Stefas", "Belkacem Menacer", "Alice Remigy", "Nikolaos Chazapis", "Guillaume Lombardi", "Claudia Lazzaroni", "Kristaq Gazeli"], "title": "A Comprehensive multi-species comparison of rotational temperature probes in a DC Ar/N$_2$ micro-hollow cathode discharge", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Accurate gas temperature ($T_{\\rm Gas}$) determination in microplasmas is critical for optimizing their applications, yet isolated diagnostic approaches may yield misleading results, especially under strong non-equilibrium conditions. Here, high resolution rotational spectra of N$_2$(C), OH(A), NH(A) and NO(A), generated in the plasma jet of a DC Ar/N$_2$ microhollow cathode discharge (MHCD), are recorded and their associated rotational temperatures ($T_{\\rm rot}$) are cross compared. A detailed experimental analysis and robust fitting of the rotational spectra are performed, achieving a reliable estimation of $T_{\\rm Gas}$. The dominant formation mechanisms of these species and their corresponding impact on rotational population distributions are also interrogated. Particularly, our findings indicate that the $T_{\\rm rot}$of N$_2$(C) is significantly influenced by energy transfers from argon metastables (Ar$^m$) and spectral interference from NH(A). This makes it unreliable as a thermometric probe in Ar-rich MHCD, unless complex analyses are employed. In contrast, OH(A) rotational population distribution appears to be less sensitive to Ar-induced perturbations across various discharge currents and pressures, providing more straightforward results. For all molecules considered, this study reveals the conditions under which all the measured $T_{\\rm rot}$ can be reliably considered to be in equilibrium with $T_{\\rm Gas}$. This highlights the importance of crossvalidating multiple thermometric probes and investigating relevant excitation kinetics when measuring $T_{\\rm rot}$ in reactive microplasmas.", "AI": {"tldr": "Cross-validation of rotational temperatures from multiple molecular species in microplasmas reveals N\u2082(C) is unreliable for gas temperature measurement in Ar-rich discharges due to energy transfer effects, while OH(A) provides more straightforward results.", "motivation": "Accurate gas temperature determination in microplasmas is critical for applications, but isolated diagnostic approaches can yield misleading results under strong non-equilibrium conditions, necessitating cross-validation of multiple thermometric probes.", "method": "High-resolution rotational spectra of N\u2082(C), OH(A), NH(A) and NO(A) generated in a DC Ar/N\u2082 microhollow cathode discharge plasma jet were recorded and their rotational temperatures were cross-compared through detailed experimental analysis and robust fitting.", "result": "N\u2082(C) rotational temperature is significantly influenced by energy transfers from argon metastables and spectral interference from NH(A), making it unreliable as a thermometric probe in Ar-rich MHCD. OH(A) rotational population distribution is less sensitive to Ar-induced perturbations across various discharge conditions. The study identifies conditions where measured rotational temperatures can be reliably considered in equilibrium with gas temperature.", "conclusion": "Cross-validating multiple thermometric probes and investigating relevant excitation kinetics is essential when measuring rotational temperatures in reactive microplasmas, as different molecular species show varying sensitivities to plasma perturbations."}}
{"id": "2601.04898", "pdf": "https://arxiv.org/pdf/2601.04898", "abs": "https://arxiv.org/abs/2601.04898", "authors": ["Ao Zhou", "Salma Zahran", "Chi Chen", "Zhengyang Zhang", "Yanming Wang"], "title": "A joint voxel flow - phase field framework for ultra-long microstructure evolution prediction with physical regularization", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "comment": "33 pages, 7 figures.Submitted waiting for review", "summary": "Phase-field (PF) modeling is a powerful tool for simulating microstructure evolution. To overcome the high computational cost of PF in solving complex PDEs, machine learning methods such as PINNs, convLSTM have been used to predict PF evolution. However, current methods still face shortages of low flexibility, poor generalization and short predicting time length. In this work, we present a joint framework coupling voxel-flow network (VFN) with PF simulations in an alternating manner for long-horizon temporal prediction of microstructure evolution. The VFN iteratively predicts future evolution by learning the flow of pixels from past snapshots, with periodic boundaries preserved in the process. Periodical PF simulations suppresses nonphysical artifacts, reduces accumulated error, and extends reliable prediction time length. The VFN is about 1,000 times faster than PF simulation on GPU. In validation using grain growth and spinodal decomposition, MSE and SSIM remain 6.76% and 0.911 when predicted 18 frames from only 2 input frames, outperforming similar predicting methods. For an ultra-long grain growth prediction for 82 frames from 2 input frames, grain number decreases from 600 to 29 with NMSE of average grain area remaining 1.64%. This joint framework enables rapid, generalized, flexible and physically consistent microstructure forecasting from image-based data for ultra-long time scales.", "AI": {"tldr": "A joint framework combining voxel-flow network with phase-field simulations enables long-horizon microstructure evolution prediction with high accuracy and physical consistency.", "motivation": "Current machine learning methods for phase-field microstructure evolution prediction suffer from low flexibility, poor generalization, and short prediction time lengths, despite efforts to reduce computational costs.", "method": "A joint framework alternating between voxel-flow network (VFN) for pixel flow prediction from past snapshots and periodic phase-field simulations to suppress artifacts and reduce accumulated errors.", "result": "VFN is 1,000\u00d7 faster than PF simulation on GPU; achieves 6.76% MSE and 0.911 SSIM for 18-frame prediction from 2 inputs; maintains 1.64% NMSE for 82-frame ultra-long prediction.", "conclusion": "The framework enables rapid, generalized, flexible, and physically consistent microstructure forecasting from image-based data for ultra-long time scales."}}
{"id": "2601.04324", "pdf": "https://arxiv.org/pdf/2601.04324", "abs": "https://arxiv.org/abs/2601.04324", "authors": ["Junyuan Fang", "Tuoc Phan"], "title": "On $W^{2,\\varepsilon}$-estimates for a class of singular-degenerate parabolic equations", "categories": ["math.AP"], "comment": "46 pages, comments are welcome", "summary": "We study a class of parabolic equations in non-divergence form with measurable coefficients that are singular, degenerate, or both singular and degenerate through a weight belonging to the $A_{1+\\frac{1}{n}}$ -Muckenhoupt class of weights. Under some smallness assumption on a weighted mean oscillation of the weight, F.-H. Lin type weighted $W^{2,\\varepsilon}$-estimates are proved. To prove the result, we establish a result on local quantitative lower estimates of solutions to the class of equations, which are known as the mean sojourn times of sample paths within sets. This type of estimate was proved by L. C. Evans for the class of linear elliptic equations in non-divergence form with uniformly elliptic and bounded measurable coefficients. A class of weighted parabolic cylinders intrinsically suitable for the class of equations is introduced. The parabolic ABP estimates, and a perturbation method are used to overcome the singularity and degeneracy of the coefficients. Careful analysis on regularization and truncation of the weights is performed. The paper provides foundational ingredients and estimates for the study of fully nonlinear parabolic equations with singular-degenerate coefficients.", "AI": {"tldr": "The paper establishes weighted W^{2,\u03b5}-estimates for parabolic equations with singular/degenerate coefficients using Muckenhoupt weights, perturbation methods, and intrinsic parabolic cylinders.", "motivation": "To study parabolic equations with coefficients that can be singular, degenerate, or both, which arise in various applications and require new analytical tools beyond the classical uniformly elliptic case.", "method": "Introduces weighted parabolic cylinders intrinsically suitable for the equations, uses parabolic ABP estimates and perturbation methods, performs careful regularization and truncation of weights, and establishes local quantitative lower estimates of solutions (mean sojourn times).", "result": "Proves F.-H. Lin type weighted W^{2,\u03b5}-estimates under smallness assumptions on weighted mean oscillation of the weight, extending Evans' results from elliptic to parabolic settings with singular/degenerate coefficients.", "conclusion": "The paper provides foundational ingredients and estimates for studying fully nonlinear parabolic equations with singular-degenerate coefficients, establishing key analytical tools for this challenging class of equations."}}
{"id": "2601.04557", "pdf": "https://arxiv.org/pdf/2601.04557", "abs": "https://arxiv.org/abs/2601.04557", "authors": ["Conor Rowan"], "title": "The explicit constraint force method for optimal experimental design", "categories": ["math.NA"], "comment": null, "summary": "The explicit constraint force method (ECFM) was recently introduced as a novel formulation of the physics-informed solution reconstruction problem, and was subsequently extended to inverse problems. In both solution reconstruction and inverse problems, model parameters are estimated with the help of measurement data. In practice, experimentalists seek to design experiments such that the acquired data leads to the most robust recovery of the missing parameters in a subsequent inverse problem. While there are well-established techniques for designing experiments with standard approaches to the inverse problem, optimal experimental design (OED) has yet to be explored with the ECFM formulation. In this work, we investigate OED with a constraint force objective. First, we review traditional approaches to OED based on the Fisher information matrix, and propose an analogous formulation based on constraint forces. Next, we reflect on the different interpretations of the objective from standard and constraint force-based inverse problems. We then test our method on several example problems. These examples suggest that an experiment which is optimal in the sense of constraint forces tends to position measurements in the stiffest regions of the system. Because the responses -- and thus the measurements -- are small in these regions, this strategy is impractical in the presence of measurement noise and/or finite measurement precision. As such, our provisional conclusion is that ECFM is not a viable approach to OED.", "AI": {"tldr": "The paper investigates optimal experimental design (OED) using the explicit constraint force method (ECFM) formulation and finds it impractical due to measurement noise limitations.", "motivation": "While ECFM has been developed for solution reconstruction and inverse problems, optimal experimental design (OED) has not been explored with this formulation. The authors aim to investigate whether ECFM can be a viable approach for designing experiments that yield robust parameter recovery.", "method": "The authors review traditional OED approaches based on Fisher information matrix and propose an analogous formulation based on constraint forces. They then test this method on several example problems to compare the interpretations and practical implications of standard vs. constraint force-based OED.", "result": "The constraint force-based OED tends to position measurements in the stiffest regions of the system where responses are smallest. This strategy proves impractical in real-world scenarios with measurement noise and finite precision, as small responses in stiff regions are difficult to measure accurately.", "conclusion": "ECFM is not a viable approach for optimal experimental design due to its tendency to place measurements in stiff regions with small responses, making it impractical in the presence of measurement noise and finite measurement precision."}}
{"id": "2601.05155", "pdf": "https://arxiv.org/pdf/2601.05155", "abs": "https://arxiv.org/abs/2601.05155", "authors": ["Gonzague Radureau"], "title": "Machine learning for radiative hydrodynamics in astrophysics", "categories": ["physics.plasm-ph", "astro-ph.IM"], "comment": "212 pages, 52 figures. This is an english translation of the french PhD manuscript available on https://theses.hal.science/tel-05418459", "summary": "Radiation hydrodynamics describes the interaction between high-temperature hypersonic plasmas and the radiation they emit or absorb, a coupling that plays a central role in many astrophysical phenomena related to accretion and ejection processes. The HADES code was developed to model such systems by coupling hydrodynamics with M1-gray or M1-multigroup radiative transfer models, which are well suited to optically intermediate media.\n  Despite its accuracy, radiation hydrodynamics simulations remain extremely demanding in terms of computational cost. Two main limitations are responsible for this. First, the M1-multigroup model relies on a closure relation with no analytic expression, requiring expensive numerical evaluations. Second, the Courant-Friedrichs-Lewy condition strongly restricts the time step of the explicit schemes used in HADES. To overcome these difficulties, two complementary Artificial Intelligence based strategies were developed in this thesis.\n  The first approach consists in training a Multi-Layer Perceptron to approximate the M1-multigroup closure relation. This method achieves excellent accuracy while reducing the computational cost by a factor of 3000, making it the most efficient approach currently available for this task. This performance gain enables high-fidelity simulations of radiative shocks, in which radiation directly influences the shock structure. In particular, increasing spectral resolution slows down the shock and enlarges the radiative precursor.\n  The second approach explores the use of Physics-Informed Neural Networks to directly solve the radiation hydrodynamics equations and extrapolate simulations beyond their initial time range. Tests on purely hydrodynamic shocks show accurate handling of discontinuities, but application to radiative shocks remains challenging and requires further investigation.", "AI": {"tldr": "AI methods accelerate radiation hydrodynamics: MLP approximates M1 closure (3000\u00d7 speedup), PINNs solve equations for time extrapolation.", "motivation": "Radiation hydrodynamics simulations are computationally expensive due to: 1) M1-multigroup closure requiring numerical evaluation, and 2) CFL condition restricting time steps in explicit schemes.", "method": "Two AI strategies: 1) Multi-Layer Perceptron approximates M1-multigroup closure relation; 2) Physics-Informed Neural Networks directly solve radiation hydrodynamics equations for time extrapolation.", "result": "MLP achieves 3000\u00d7 speedup with excellent accuracy, enabling high-fidelity radiative shock simulations. PINNs handle hydrodynamic shock discontinuities well but need refinement for radiative shocks.", "conclusion": "AI methods successfully accelerate radiation hydrodynamics simulations, with MLP providing dramatic speedup for closure evaluation and PINNs showing promise for equation solving and extrapolation."}}
{"id": "2508.15328", "pdf": "https://arxiv.org/pdf/2508.15328", "abs": "https://arxiv.org/abs/2508.15328", "authors": ["Henriette Bast", "Rafael C. Schick", "Thomas Koehler", "Franz Pfeiffer"], "title": "Technical Note: Low-Dose Simulation for Grating-Based X-Ray Dark-Field Radiography Using a Virtually Decreased Irradiation Area", "categories": ["physics.med-ph", "physics.bio-ph", "physics.comp-ph"], "comment": null, "summary": "Background: X-ray dark-field radiography uses small-angle scattering to visualize the structural integrity of lung alveoli. To study the influence of dose reduction on clinical dark-field radiographs, one can simulate low-dose images by virtually reducing the irradiated area. However, these simulations can exhibit stripe artifacts. Purpose: Validation of the low-dose simulation algorithm reported by Schick & Bast et al., PLoS ONE, 2024. Furthermore, we want to demonstrate that stripe artifacts observed in simulated images at very low-dose levels are introduced by limitations of the algorithm and would not appear in actual low-dose dark-field images. Methods: Dark-field radiographs of an anthropomorphic chest phantom were acquired at different tube currents equaling different radiation doses. Based on the measurement with a high radiation dose, dark-field radiographs corresponding to lower radiation doses were simulated by virtually reducing the irradiated area. The simulated low-dose radiographs were evaluated by a quantitative comparison of the dark-field signal using different regions of interests. Results: Dark-field radiographs acquired at one quarter of the standard dose were artifact-free. The dark-field signal differed from the simulated radiographs by up to 10%. Algorithm-induced stripe artifacts decrease the image quality of the simulated radiographs. Conclusions: Virtually reducing the irradiation area is a simple approach to generate low-dose radiographs based on images acquired with scanning-based dark-field radiography. However, as the algorithm creates stripe artifacts in the dark-field images, particularly at higher dose reductions, that are not present in measured low-dose images, simulated images have reduced image quality compared to their measured counterparts.", "AI": {"tldr": "Low-dose simulation algorithm for X-ray dark-field radiography creates stripe artifacts not present in actual low-dose images, reducing simulated image quality compared to measured counterparts.", "motivation": "To validate a low-dose simulation algorithm for dark-field radiography and determine if stripe artifacts in simulated images are algorithm limitations rather than actual imaging phenomena.", "method": "Acquired dark-field radiographs of chest phantom at different radiation doses, simulated low-dose images from high-dose measurements by virtually reducing irradiated area, compared simulated vs. measured images quantitatively using region-of-interest analysis.", "result": "Actual quarter-dose images were artifact-free, with up to 10% dark-field signal difference from simulations. Algorithm-induced stripe artifacts reduced simulated image quality, especially at higher dose reductions.", "conclusion": "Virtual dose reduction is a simple simulation approach but creates stripe artifacts not present in real low-dose images, limiting simulated image quality compared to measured counterparts."}}
{"id": "2601.04385", "pdf": "https://arxiv.org/pdf/2601.04385", "abs": "https://arxiv.org/abs/2601.04385", "authors": ["Giovanni Bellettini", "Virginia Lorenzini", "Matteo Novaga", "Riccardo Scala"], "title": "A fourth-order regularization of the curvature flow of immersed plane curves with Dirichlet boundary conditions", "categories": ["math.AP"], "comment": null, "summary": "We consider a fourth-order regularization of the curvature flow for an immersed plane curve with fixed boundary, using an elastica-type functional depending on a small positive parameter $\\varepsilon$. We show that the approximating flow smoothly converges, as $\\varepsilon \\to 0^+$, to the curvature flow of the curve with Dirichlet boundary conditions for all times before the first singularity of the limit flow.", "AI": {"tldr": "Fourth-order regularization of curvature flow for plane curves with fixed boundary converges to standard curvature flow as regularization parameter \u03b5\u21920.", "motivation": "To develop a regularized version of curvature flow that handles boundary conditions and converges to the classical flow, providing a robust numerical/analytical framework.", "method": "Use elastica-type functional with small parameter \u03b5 as fourth-order regularization of curvature flow for immersed plane curves with fixed boundary conditions.", "result": "The approximating flow smoothly converges to curvature flow with Dirichlet boundary conditions as \u03b5\u21920 for all times before the first singularity of the limit flow.", "conclusion": "The regularization approach provides a valid approximation to curvature flow that maintains smooth convergence up to singularity formation."}}
{"id": "2601.04628", "pdf": "https://arxiv.org/pdf/2601.04628", "abs": "https://arxiv.org/abs/2601.04628", "authors": ["S. M. Mallikarjunaiah"], "title": "An HHT-$\u03b1$-based finite element framework for wave propagation in constitutively nonlinear elastic materials", "categories": ["math.NA"], "comment": null, "summary": "This paper presents a computational framework for modeling wave propagation in geometrically linear elastic materials characterized by algebraically nonlinear constitutive relations. We derive a specific form of the nonlinear wave equation in which the nonlinearity explicitly appears in the time-derivative terms that govern the evolution of the mechanical fields. The numerical solution is established using a fully discrete formulation that combines the standard finite element method for spatial discretization with the implicit Hilber-Hughes-Taylor (HHT)-$\u03b1$ scheme for time integration. To address the nonlinear nature of the discrete system, we employ Newton's method to iteratively solve the linearized equations at each time step. The accuracy and robustness of the proposed framework are rigorously verified through convergence analyses, which demonstrate optimal convergence rates in both space and time. Furthermore, a detailed parametric study is conducted to elucidate the influence of the model's constitutive parameters. The results reveal that the magnitude parameter of the stress-dependent variation in wave speed leads to wavefront steepening and the formation of shock discontinuities. Conversely, the exponent parameter acts as a nonlinearity filter; high values suppress nonlinear effects in small-strain regimes, whereas low values allow significant dispersive behavior. This work provides a validated tool for analyzing shock formation in advanced nonlinear materials.", "AI": {"tldr": "A computational framework for modeling wave propagation in geometrically linear elastic materials with algebraically nonlinear constitutive relations, featuring nonlinear wave equations with explicit nonlinearity in time-derivative terms, solved using FEM spatial discretization and HHT-\u03b1 time integration with Newton's method.", "motivation": "To develop a validated computational tool for analyzing shock formation in advanced nonlinear materials by modeling wave propagation in materials with geometrically linear but algebraically nonlinear constitutive behavior.", "method": "Derived nonlinear wave equation with explicit nonlinearity in time-derivative terms; used fully discrete formulation combining standard finite element method for spatial discretization with implicit HHT-\u03b1 scheme for time integration; employed Newton's method to solve nonlinear discrete system at each time step.", "result": "Framework demonstrated optimal convergence rates in space and time; parametric study showed magnitude parameter causes wavefront steepening and shock discontinuities, while exponent parameter acts as nonlinearity filter (high values suppress nonlinear effects in small strains, low values allow dispersive behavior).", "conclusion": "The work provides a validated computational framework for analyzing shock formation in advanced nonlinear materials, with specific insights into how constitutive parameters influence wave propagation behavior and shock formation."}}
{"id": "2601.04450", "pdf": "https://arxiv.org/pdf/2601.04450", "abs": "https://arxiv.org/abs/2601.04450", "authors": ["Byung Gyu Chae"], "title": "Self-Organized Criticality from Protected Mean-Field Dynamics: Loop Stability and Internal Renormalization in Reflective Neural Systems", "categories": ["nlin.AO", "physics.comp-ph"], "comment": "15 pages, 4 figures", "summary": "The reflective homeostatic dynamics provides a minimal mechanism for self-organized criticality in neural systems. Starting from a reduced stochastic description, we demonstrate within the MSRJD field-theoretic framework that fluctuation effects do not destabilize the critical manifold. Instead, loop corrections are dynamically regularized by homeostatic curvature, yielding a protected mean-field critical surface that remains marginally stable under coarse-graining. Beyond robustness, we show that response-driven structural adaptation generates intrinsic parameter flows that attract the system toward this surface without external fine tuning. Together, these results unify loop renormalization and adaptive response in a single framework and establish a concrete route to autonomous criticality in reentrant neural dynamics.", "AI": {"tldr": "Homeostatic dynamics enables self-organized criticality in neural systems, with fluctuations stabilized by homeostatic curvature and parameter flows naturally attracting systems to critical surfaces without external tuning.", "motivation": "To understand how neural systems can achieve and maintain criticality autonomously through intrinsic mechanisms rather than external fine-tuning, and to unify loop renormalization with adaptive response in a single theoretical framework.", "method": "Uses MSRJD field-theoretic framework starting from reduced stochastic descriptions to analyze fluctuation effects, showing that homeostatic curvature dynamically regularizes loop corrections, and demonstrates how response-driven structural adaptation generates parameter flows.", "result": "Fluctuation effects do not destabilize the critical manifold; homeostatic curvature protects mean-field critical surfaces that remain marginally stable under coarse-graining. Response-driven adaptation creates intrinsic parameter flows that naturally attract systems to critical surfaces without external tuning.", "conclusion": "Reflective homeostatic dynamics provides a concrete mechanism for autonomous criticality in neural systems, unifying loop renormalization and adaptive response, and establishing a route to self-organized criticality in reentrant neural dynamics."}}
{"id": "2601.04489", "pdf": "https://arxiv.org/pdf/2601.04489", "abs": "https://arxiv.org/abs/2601.04489", "authors": ["Hart F. Smith"], "title": "Uniform subelliptic estimates for degenerating Fokker-Planck equations", "categories": ["math.AP"], "comment": null, "summary": "We expand upon recent work of Hernandez-Ranard-Riedel, Galkowski-Zworski, and Li, by proving long time bounds for solutions to certain Fokker-Planck equations with subelliptic diffusion term. We consider the case where the jump operators in the Lindbladian are linear functions of $x$, and place an assumption which implies that the H\u00f6rmander condition holds for the resulting Fokker-Planck equation. By constructing a suitable parametrix for this equation we show that semiclassical derivative estimates established in the above works for elliptic diffusion also hold for subelliptic diffusion, with global bounds in $L^p$ for all $1\\le p\\le \\infty$.", "AI": {"tldr": "Proves long-time bounds for Fokker-Planck equations with subelliptic diffusion using parametrix construction to extend semiclassical derivative estimates from elliptic to subelliptic cases.", "motivation": "Extend recent work on Fokker-Planck equations to handle subelliptic diffusion terms, specifically when jump operators are linear functions of x and the H\u00f6rmander condition holds, addressing cases where elliptic methods don't apply.", "method": "Construct a suitable parametrix for the Fokker-Planck equation with subelliptic diffusion, building on previous work by Hernandez-Ranard-Riedel, Galkowski-Zworski, and Li to extend semiclassical derivative estimates.", "result": "Shows that semiclassical derivative estimates established for elliptic diffusion also hold for subelliptic diffusion, with global bounds in L^p for all 1 \u2264 p \u2264 \u221e, proving long-time bounds for solutions.", "conclusion": "The parametrix construction successfully extends derivative estimates from elliptic to subelliptic Fokker-Planck equations, providing global L^p bounds and long-time solution behavior for this important class of equations."}}
{"id": "2601.04708", "pdf": "https://arxiv.org/pdf/2601.04708", "abs": "https://arxiv.org/abs/2601.04708", "authors": ["Congpei An", "Alvise Sommariva", "Marco Vianello"], "title": "On the role of weak Marcinkiewicz-Zygmund constants in polynomial approximation by orthogonal bases", "categories": ["math.NA"], "comment": null, "summary": "We compute numerically the $L^2$ Marcinkiewicz-Zygmund constants of cubature rules, with a special attention to their role in polynomial approximation by orthogonal bases. We test some relevant rules on domains such as the interval, the square, the disk, the triangle, the cube and the sphere. The approximation power of the corresponding least squares (LS) projection is compared with standard hyperinterpolation and its recently proposed ``exactness-relaxed'' version. The Matlab codes used for these tests are available in open-source form.", "AI": {"tldr": "Numerical computation of L\u00b2 Marcinkiewicz-Zygmund constants for cubature rules and their role in polynomial approximation by orthogonal bases, comparing least squares projection with hyperinterpolation methods across various domains.", "motivation": "To understand how Marcinkiewicz-Zygmund constants affect polynomial approximation quality when using cubature rules, and to compare different approximation methods (least squares projection vs. hyperinterpolation variants) across various geometric domains.", "method": "Numerical computation of L\u00b2 Marcinkiewicz-Zygmund constants for cubature rules on multiple domains (interval, square, disk, triangle, cube, sphere). Comparison of least squares projection approximation power with standard hyperinterpolation and its \"exactness-relaxed\" version using open-source Matlab codes.", "result": "The paper provides computed Marcinkiewicz-Zygmund constants for various cubature rules across different domains, enabling comparison of approximation performance between least squares projection and hyperinterpolation methods.", "conclusion": "Marcinkiewicz-Zygmund constants are crucial for understanding polynomial approximation quality with cubature rules, and the comparison between different approximation methods provides practical insights for numerical applications across various domains."}}
{"id": "2601.04735", "pdf": "https://arxiv.org/pdf/2601.04735", "abs": "https://arxiv.org/abs/2601.04735", "authors": ["Nalin Dhiman"], "title": "sidmkit: A Reproducible Toolkit for SIDM Phenomenology and Galaxy Rotation-Curve Modeling", "categories": ["astro-ph.IM", "physics.comp-ph"], "comment": "12 pages, 13 figures, Methods and software paper; includes a reproducible SPARC rotation-curve fitting pipeline and SIDM phenomenology utilities", "summary": "Self-interacting dark matter (SIDM) is a well-motivated extension of cold dark matter that can modify halo structure on galactic and group scales while remaining consistent with large-scale structure. However, practical SIDM work often requires bridging several layers, including microphysical scattering models, velocity-dependent effective cross sections, phenomenological astrophysical constraints, and (separately) data-driven halo fits, such as rotation curves. In this paper, we describe \\texttt{sidmkit}, a transparent and reproducible Python package designed to support SIDM ``micro$\\rightarrow$macro'' calculations and to provide a robust batch pipeline for fitting rotation curves in the SPARC data. On the SIDM side, \\texttt{sidmkit} implements velocity-dependent momentum-transfer cross sections for a Yukawa interaction using standard analytic approximations (Born, classical, and Hulth\u00e9n-based) with a numerical partial-wave option for spot checks. It also provides consistent velocity-moment averaging for Maxwellian relative speeds, scattering-rate utilities, and curated literature \\emph{summary} constraints for regression tests and exploratory scans. On the rotation-curve side, we implement bounded non-linear least squares fits of NFW and Burkert halo models to SPARC baryonic decompositions, with optional mass-to-light priors and information-criterion summaries (AIC/BIC). For the demonstration dataset, we process 191 \\texttt{rotmod} galaxies (LTG+ETG bundles) and fit both NFW and Burkert models (382 total fits). We find that Burkert is preferred by $\u0394\\mathrm{BIC} > 0$ for $65.4\\%$ of galaxies, with ``strong'' preference ($\u0394\\mathrm{BIC}>6$) in $32.5\\%$ of galaxies;", "AI": {"tldr": "sidmkit is a Python package for self-interacting dark matter (SIDM) calculations and rotation curve fitting, implementing velocity-dependent cross sections for Yukawa interactions and providing batch pipeline for SPARC data analysis.", "motivation": "Self-interacting dark matter is a promising extension to cold dark matter that can address halo structure issues, but practical work requires bridging multiple layers from microphysics to astrophysical constraints and data analysis.", "method": "Developed sidmkit package with: 1) SIDM microphysics tools for velocity-dependent cross sections using Born, classical, and Hulth\u00e9n approximations with partial-wave checks, 2) rotation curve fitting pipeline for SPARC data using bounded non-linear least squares with NFW and Burkert halo models, mass-to-light priors, and information criteria.", "result": "Processed 191 galaxies from SPARC data, performing 382 total fits. Burkert halo model is preferred over NFW in 65.4% of galaxies based on \u0394BIC > 0, with strong preference (\u0394BIC > 6) in 32.5% of galaxies.", "conclusion": "sidmkit provides a comprehensive, reproducible framework for SIDM research bridging microphysics to astrophysical constraints, with rotation curve analysis showing Burkert halos are often preferred over NFW profiles in the SPARC dataset."}}
{"id": "2601.04528", "pdf": "https://arxiv.org/pdf/2601.04528", "abs": "https://arxiv.org/abs/2601.04528", "authors": ["Daniel Alfonso Santiesteban", "Ricardo Abreu Blaya", "Daniel Alpay"], "title": "Hardy decomposition of first order Lipschitz functions by Lam\u00e9-Navier solutions", "categories": ["math.AP", "math-ph"], "comment": "31 pages, 1 figure", "summary": "The Clifford algebra language allows us to rewrite the Lam\u00e9-Navier system in terms of the Euclidean Dirac operator. In this paper, the main question we shall be concerned with is whether or not a higher order Lipschitz function on the boundary $\u0393$ of a Jordan domain $\u03a9\\subset\\mathbb{R}^m$ can be decomposed into a sum of the two boundary values of a solution of the Lam\u00e9-Navier system with jump across $\u0393$. Our main tool are the Hardy projections related to a singular integral operator arising in the context of Clifford analysis, which turns out to be an involution operator on the first order Lipschitz classes.", "AI": {"tldr": "The paper studies whether higher-order Lipschitz functions on domain boundaries can be decomposed into boundary values of Lam\u00e9-Navier system solutions with jump discontinuities across the boundary.", "motivation": "The motivation is to understand the decomposition properties of boundary functions using solutions to the Lam\u00e9-Navier system, leveraging Clifford algebra and Dirac operator formulations to analyze boundary value problems in elasticity theory.", "method": "The method uses Clifford algebra language to rewrite the Lam\u00e9-Navier system via Euclidean Dirac operator. Main tools are Hardy projections related to singular integral operators from Clifford analysis, particularly an involution operator on first-order Lipschitz classes.", "result": "The paper establishes that the singular integral operator arising in Clifford analysis context is an involution operator on first-order Lipschitz classes, providing the mathematical foundation for analyzing boundary decompositions.", "conclusion": "The Clifford algebra framework and associated Hardy projections provide effective tools for studying boundary value decompositions of Lam\u00e9-Navier system solutions, with the singular integral operator's involution property being key to the analysis."}}
{"id": "2601.04839", "pdf": "https://arxiv.org/pdf/2601.04839", "abs": "https://arxiv.org/abs/2601.04839", "authors": ["Abdolreza Amiri", "Gabriel R. Barrenechea", "Tristan Pryer"], "title": "A finite element method preserving the eigenvalue range of symmetric tensor fields", "categories": ["math.NA"], "comment": "29 pages, 8 figures", "summary": "This paper presents a finite element method that preserves (at the degrees of freedom) the eigenvalue range of the solution of tensor-valued time-dependent convection--diffusion equations. Starting from a high-order spatial baseline discretisation (in this case, the CIP stabilised finite element method), our approach formulates the fully discrete problem as a variational inequality posed on a closed convex set of tensor-valued functions that respect the same eigenvalue bounds at their degrees of freedom. The numerical realisation of the scheme relies on the definition of a projection that, at each node, performs the diagonalisation of the tensor and then truncates the eigenvalues to lie within the prescribed bounds. The temporal discretisation is carried out using the implicit Euler method, and unconditional stability and optimal-order error estimates are proven for this choice. Numerical experiments confirm the theoretical findings and illustrate the method's ability to maintain eigenvalue constraints while accurately approximating solutions in the convection-dominated regime.", "AI": {"tldr": "A finite element method that preserves eigenvalue bounds for tensor-valued convection-diffusion equations using variational inequalities and eigenvalue truncation at degrees of freedom.", "motivation": "To develop a numerical method that maintains the eigenvalue range constraints of tensor-valued solutions in time-dependent convection-diffusion equations, which is important for physical consistency and stability in applications.", "method": "Uses a high-order CIP-stabilized finite element baseline, formulates the problem as a variational inequality on a convex set of tensor functions with eigenvalue bounds at DOFs, employs a projection that diagonalizes and truncates eigenvalues at nodes, and uses implicit Euler time discretization.", "result": "Proves unconditional stability and optimal-order error estimates for the method, with numerical experiments confirming theoretical results and demonstrating ability to maintain eigenvalue constraints even in convection-dominated regimes.", "conclusion": "The proposed method successfully preserves eigenvalue bounds while maintaining accuracy, providing a robust approach for tensor-valued convection-diffusion problems with eigenvalue constraints."}}
{"id": "2601.04765", "pdf": "https://arxiv.org/pdf/2601.04765", "abs": "https://arxiv.org/abs/2601.04765", "authors": ["Santiago Acevedo", "Alessandro Laio", "Marco Baroni"], "title": "Differential syntactic and semantic encoding in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.", "AI": {"tldr": "Syntactic and semantic information are partially linearly encoded in DeepSeek-V3's hidden representations, with differential encoding profiles that can be decoupled.", "motivation": "To understand how syntactic and semantic information is encoded in the inner layer representations of large language models, specifically DeepSeek-V3.", "method": "Averaging hidden-representation vectors of sentences sharing syntactic structure or meaning to create syntactic and semantic \"centroids,\" then analyzing the effects of subtracting these centroids on sentence similarity.", "result": "Syntactic and semantic centroids capture significant information; subtracting them strongly affects similarity with matched sentences, suggesting linear encoding. Cross-layer encoding profiles differ, and the two signals can be partially decoupled.", "conclusion": "Syntax and semantics are at least partially linearly encoded in LLM representations, with differential encoding patterns that allow for some decoupling of these linguistic information types."}}
{"id": "2601.04617", "pdf": "https://arxiv.org/pdf/2601.04617", "abs": "https://arxiv.org/abs/2601.04617", "authors": ["Toyohiko Aiki", "Hana Kakiuchi"], "title": "On behavior of free boundaries to generalized two-phase Stefan problems for parabolic partial differential equation systems", "categories": ["math.AP"], "comment": null, "summary": "Recently, we have proposed a new free boundary problem representing the bread baking process in a hot oven. Unknown functions in this problem are the position of the evaporation front, the temperature field and the water content. For solving this problem we observed two difficulties that the growth rate of the free boundary depends on the water content and the boundary condition for the water content contains the temperature. In this paper, by improving the regularity of solutions, we overcome these difficulties and establish existence of a solution locally in time and its uniqueness. Moreover, under some sign conditions for initial data, we derive a result on the maximal interval of existence to solutions.", "AI": {"tldr": "The paper establishes existence and uniqueness of solutions for a free boundary problem modeling bread baking, overcoming difficulties related to the evaporation front growth rate and boundary conditions.", "motivation": "To solve a previously proposed free boundary problem representing bread baking in a hot oven, which had two main difficulties: the growth rate of the evaporation front depends on water content, and the boundary condition for water content involves temperature.", "method": "By improving the regularity of solutions, the authors overcome the difficulties and establish existence of solutions locally in time, along with uniqueness. They also derive results on maximal existence intervals under certain sign conditions for initial data.", "result": "The paper proves local existence and uniqueness of solutions to the bread baking free boundary problem. Additionally, under specific sign conditions on initial data, the authors obtain results about the maximal interval of existence for solutions.", "conclusion": "The authors successfully resolve the mathematical challenges in the bread baking free boundary problem, establishing rigorous existence and uniqueness results with insights into solution behavior over time."}}
{"id": "2601.04866", "pdf": "https://arxiv.org/pdf/2601.04866", "abs": "https://arxiv.org/abs/2601.04866", "authors": ["Paola F. Antonietti", "Louren\u00e7o Beir\u00e3o da Veiga", "Michele Botti", "Andr\u00e9 Harnist", "Giuseppe Vacca", "Marco Verani"], "title": "Virtual Element methods for non-Newtonian shear-thickening fluid flow problems", "categories": ["math.NA"], "comment": null, "summary": "In this work, we present a comprehensive theoretical analysis for Virtual Element discretizations of incompressible non-Newtonian flows governed by the Carreau-Yasuda constitutive law, in the shear-thickening regime (r > 2) including both degenerate (delta = 0) and non-degenerate (delta > 0) cases. The proposed Virtual Element method features two distinguishing advantages: the construction of an exactly divergence-free discrete velocity field and compatibility with general polygonal meshes. The analysis presented in this work extends a previous work, where only shear-thinning behavior (1 < r < 2) was considered. Indeed, the theoretical analysis of the shear-thickening setting requires several novel analytical tools, including: an inf-sup stability analysis of the discrete velocity-pressure coupling in non-Hilbertian norms, a stabilization term specifically designed to address the nonlinear structure as the exponent r > 2; and the introduction of a suitable discrete norm tailored to the underlying nonlinear constitutive relation. Numerical results demonstrate the practical performance of the proposed formulation.", "AI": {"tldr": "Theoretical analysis of Virtual Element Method for incompressible non-Newtonian Carreau-Yasuda flows in shear-thickening regime (r > 2), extending previous shear-thinning work with novel analytical tools.", "motivation": "To develop a comprehensive theoretical framework for Virtual Element discretizations of incompressible non-Newtonian flows governed by Carreau-Yasuda law in the shear-thickening regime, addressing both degenerate and non-degenerate cases where previous work only covered shear-thinning behavior.", "method": "Virtual Element Method with exactly divergence-free discrete velocity field compatible with general polygonal meshes. Novel analytical tools include: inf-sup stability analysis in non-Hilbertian norms, specially designed stabilization term for nonlinear structure (r > 2), and introduction of discrete norm tailored to nonlinear constitutive relation.", "result": "Theoretical analysis successfully extends to shear-thickening regime (r > 2) with comprehensive framework covering both degenerate (delta = 0) and non-degenerate (delta > 0) cases. Numerical results demonstrate practical performance of the proposed formulation.", "conclusion": "The work provides a complete theoretical foundation for Virtual Element discretizations of Carreau-Yasuda non-Newtonian flows in shear-thickening regime, overcoming analytical challenges through novel tools and maintaining key advantages of exactly divergence-free velocity fields and polygonal mesh compatibility."}}
{"id": "2601.05042", "pdf": "https://arxiv.org/pdf/2601.05042", "abs": "https://arxiv.org/abs/2601.05042", "authors": ["Pavel Gol'din", "Gennady Y. Gor"], "title": "PINN-Based Solution for a Diffusion Controlled Droplet Growth", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "We study diffusion-controlled growth of a spherical droplet with a moving boundary using a physics-informed neural network (PINN) formulation. The governing diffusion equation is coupled to the interfacial mass balance, with the droplet radius treated as an additional trainable function of time. The PINN accurately reproduces the self-similar growth law and concentration profiles for a wide range of initial droplet radii, demonstrating convergence toward the asymptotic diffusive regime. The proposed approach provides a flexible and computationally efficient framework for solving moving-boundary diffusion problems and can be readily extended to include additional physical effects.", "AI": {"tldr": "PINN framework for diffusion-controlled droplet growth with moving boundary accurately captures self-similar growth law and concentration profiles across various initial radii.", "motivation": "To develop a flexible and efficient computational framework for solving moving-boundary diffusion problems, specifically diffusion-controlled droplet growth, which traditionally requires complex numerical methods.", "method": "Physics-informed neural network (PINN) formulation that couples the diffusion equation with interfacial mass balance, treating droplet radius as an additional trainable function of time.", "result": "PINN accurately reproduces self-similar growth law and concentration profiles for wide range of initial droplet radii, demonstrating convergence toward asymptotic diffusive regime.", "conclusion": "The proposed PINN approach provides an efficient framework for moving-boundary diffusion problems and can be extended to include additional physical effects."}}
{"id": "2601.04622", "pdf": "https://arxiv.org/pdf/2601.04622", "abs": "https://arxiv.org/abs/2601.04622", "authors": ["Jingwen Han", "Han Li"], "title": "Liouville-type theorems for the stationary non-Newtonian fluids in a slab", "categories": ["math.AP"], "comment": "30 pages", "summary": "In this paper, we investigate Liouville-type theorems for stationary solutions to the shear thickening fluid equations in a slab. We show that the axisymmetric solution must be trivial if its local $L^\\infty$-norm grows mildly as the radius $R$ grows. Also, a bounded general solution $u$ must be trivial if $ru^r$ is bounded. The proof is inspired by the work of Bang, Gui, Wang, and Xie [J. Fluid Mech. 1005 (2025)] for the Navier-Stokes equations, and the key point is to establish a Saint-Venant type estimate that characterizes the growth of the local Dirichlet integral of nontrivial solutions. One new ingredient is the estimate of the constant in Korn's inequality over different domains.", "AI": {"tldr": "Liouville-type theorems for stationary shear thickening fluid equations in a slab: axisymmetric solutions are trivial if L\u221e-norm grows mildly with radius, and bounded general solutions are trivial if ru\u02b3 is bounded.", "motivation": "To establish Liouville-type theorems (non-existence of nontrivial solutions) for stationary shear thickening fluid equations in slab domains, extending similar results from Navier-Stokes equations to more complex non-Newtonian fluid models.", "method": "Inspired by Bang et al.'s work on Navier-Stokes, establishes Saint-Venant type estimates characterizing growth of local Dirichlet integral. Key innovation: estimating constant in Korn's inequality over different domains to handle shear thickening fluid equations.", "result": "Two main results: (1) Axisymmetric solutions must be trivial if local L\u221e-norm grows mildly with radius R; (2) Bounded general solutions must be trivial if ru\u02b3 is bounded. Both establish conditions under which only trivial solutions exist.", "conclusion": "Successfully extends Liouville-type theorems from Navier-Stokes to shear thickening fluid equations using Saint-Venant estimates and improved Korn's inequality analysis, providing conditions for triviality of stationary solutions in slab domains."}}
{"id": "2601.04999", "pdf": "https://arxiv.org/pdf/2601.04999", "abs": "https://arxiv.org/abs/2601.04999", "authors": ["Alessandro Lanza", "Serena Morigi", "Youwei Wen", "Li Yang"], "title": "Guided Variational Network for Image Decomposition", "categories": ["math.NA"], "comment": null, "summary": "Cartoon-texture image decomposition is a critical preprocessing problem bottlenecked by the numerical intractability of classical variational or optimization models and the tedious manual tuning of global regularization parameters.We propose a Guided Variational Decomposition (GVD) model which introduces spatially adaptive quadratic norms whose pixel-wise weights are learned either through local probabilistic statistics or via a lightweight neural network within a bilevel framework.This leads to a unified, interpretable, and computationally efficient model that bridges classical variational ideas with modern adaptive and data-driven methodologies. Numerical experiments on this framework, which inherently includes automatic parameter selection, delivers GVD as a robust, self-tuning, and superior solution for reliable image decomposition.", "AI": {"tldr": "GVD is a self-tuning image decomposition method that combines classical variational models with adaptive data-driven weights learned through statistics or neural networks, eliminating manual parameter tuning.", "motivation": "Classical cartoon-texture decomposition methods suffer from numerical intractability and require tedious manual tuning of global regularization parameters, creating a bottleneck in preprocessing workflows.", "method": "Proposes Guided Variational Decomposition (GVD) using spatially adaptive quadratic norms with pixel-wise weights learned either through local probabilistic statistics or via a lightweight neural network within a bilevel optimization framework.", "result": "GVD provides a unified, interpretable, and computationally efficient model that bridges classical variational approaches with modern adaptive/data-driven methods, delivering robust and superior decomposition performance with automatic parameter selection.", "conclusion": "GVD emerges as a robust, self-tuning solution for reliable image decomposition that overcomes the limitations of traditional variational methods while maintaining interpretability and computational efficiency."}}
{"id": "2601.05120", "pdf": "https://arxiv.org/pdf/2601.05120", "abs": "https://arxiv.org/abs/2601.05120", "authors": ["Itamar Giron", "Menahem Krief", "Nicholas C. Stone", "Elad Steinberg"], "title": "Multigroup Radiation Diffusion on a Moving Mesh: Implementation in RICH and Application to Tidal Disruption Events", "categories": ["astro-ph.HE", "physics.comp-ph"], "comment": null, "summary": "Radiation-hydrodynamics (RHD) determines the bulk evolution and observable emission in a wide variety of high-energy astrophysical phenomena. Due to their complexity, RHD problems must usually be studied through numerical simulation. We have extended the publicly available RICH code, which previously solved the equations of RHD in the limit of grey flux-limited diffusion (FLD), to operate with a multigroup FLD solver. RICH is a semi-Lagrangian code that solves the equations of RHD on an unstructured moving mesh, and is the first multigroup RHD moving mesh code, making it uniquely applicable to problems with extreme dynamic range and dynamically important radiation forces. We validate our multigroup module against multiple analytic benchmarks, including a novel test of the RHD Doppler term. The computational efficiency of the code is aided by a novel scheme to accelerate convergence in optically thick cells. Finally, we apply multigroup RICH in a pilot study of a stellar tidal disruption event (TDE), using a $10^4 M_\\odot$ intermediate-mass black hole. Our simulations self-consistently produce a bright early-time X-ray flash prior to peak optical/UV light, in qualitative agreement with post-processing of (grey) RICH simulations of supermassive black hole TDEs, as well as X-ray observations of the TDE AT 2022dsb.", "AI": {"tldr": "The paper extends the RICH radiation-hydrodynamics code from grey flux-limited diffusion to multigroup FLD, making it the first multigroup RHD moving mesh code, and applies it to study stellar tidal disruption events.", "motivation": "Radiation-hydrodynamics (RHD) is crucial for understanding high-energy astrophysical phenomena, but existing codes often use simplified grey FLD approximations that don't capture frequency-dependent radiation effects. There's a need for more sophisticated multigroup RHD codes that can handle problems with extreme dynamic range and dynamically important radiation forces.", "method": "Extended the publicly available RICH code from grey flux-limited diffusion to multigroup FLD. RICH is a semi-Lagrangian code that solves RHD equations on an unstructured moving mesh. Introduced a novel scheme to accelerate convergence in optically thick cells. Validated the multigroup module against multiple analytic benchmarks, including a novel test of the RHD Doppler term.", "result": "Successfully developed the first multigroup RHD moving mesh code. Validated against analytic benchmarks. Applied to a pilot study of a stellar tidal disruption event around a 10^4 M\u2299 intermediate-mass black hole. The simulations self-consistently produce a bright early-time X-ray flash prior to peak optical/UV light, qualitatively agreeing with post-processing of grey RICH simulations and X-ray observations of the TDE AT 2022dsb.", "conclusion": "The multigroup extension of RICH provides a powerful new tool for studying astrophysical phenomena with frequency-dependent radiation effects, particularly those with extreme dynamic range. The code successfully reproduces observed features in tidal disruption events, demonstrating its practical utility for astrophysical simulations."}}
{"id": "2601.04678", "pdf": "https://arxiv.org/pdf/2601.04678", "abs": "https://arxiv.org/abs/2601.04678", "authors": ["Sebastian Bechtel", "Andreas Ros\u00e9n"], "title": "The Kato square root estimate with Robin boundary conditions", "categories": ["math.AP", "math.CA", "math.FA"], "comment": "23 pages", "summary": "We prove the Kato square root estimate for second-order divergence form elliptic operators $-div(A\\nabla)$ on a bounded, locally uniform domain $D \\subseteq \\mathbb{R}^n$, for accretive coefficients $A \\in L^\\infty(D; \\mathbb{C}^n)$, under the Robin boundary condition $\u03bd\\cdot A\\nabla u + bu = 0$ for a (possibly unbounded) boundary conductivity $b$. In contrast to essentially all previous estimates of Kato square root operators, no first-order approach seems possible for the Robin boundary conditions.", "AI": {"tldr": "The paper proves the Kato square root estimate for second-order divergence form elliptic operators with accretive coefficients on bounded, locally uniform domains under Robin boundary conditions with possibly unbounded boundary conductivity.", "motivation": "The motivation is to extend Kato square root estimates to more general boundary conditions, specifically Robin boundary conditions with potentially unbounded boundary conductivity, which cannot be handled by existing first-order approaches.", "method": "The authors develop a new approach for proving Kato square root estimates for elliptic operators with Robin boundary conditions, moving away from traditional first-order methods that are insufficient for this boundary condition type.", "result": "The main result is the proof of the Kato square root estimate for second-order divergence form elliptic operators with accretive coefficients on bounded, locally uniform domains under Robin boundary conditions with possibly unbounded boundary conductivity.", "conclusion": "The paper successfully extends Kato square root theory to Robin boundary conditions, demonstrating that these estimates hold even with unbounded boundary conductivity, requiring novel techniques beyond standard first-order approaches."}}
{"id": "2601.05146", "pdf": "https://arxiv.org/pdf/2601.05146", "abs": "https://arxiv.org/abs/2601.05146", "authors": ["Jan Bouwe van den Berg", "Maxime Breden"], "title": "A simple rigorous integrator for semilinear parabolic PDEs", "categories": ["math.NA", "math.AP", "math.DS"], "comment": null, "summary": "Simulations of the dynamics generated by partial differential equations (PDEs) provide approximate, numerical solutions to initial value problems. Such simulations are ubiquitous in scientific computing, but the correctness of the results is usually not guaranteed. We propose a new method for the rigorous integration of parabolic PDEs, i.e., the derivation of rigorous and explicit error bounds between the numerically obtained approximate solution and the exact one, which is then proven to exist over the entire time interval considered. These guaranteed error bounds are obtained a posteriori, using a fixed point reformulation based on a piece-wise in time constant approximation of the linearization around the numerical solution. Our setup leads to relatively simple-to-understand estimates, which has several advantages. Most critically, it allows us to optimize various aspects of the proof, and in particular to provide an adaptive time-stepping strategy. In case the solution converges to a stable hyperbolic equilibrium, we are also able to prove this convergence, applying our rigorous integrator with a final, infinitely long timestep. We showcase the ability of our method to rigorously integrate over relatively long time intervals, and to capture non-trivial dynamics, via examples on the Swift--Hohenberg equation, the Ohta--Kawasaki equation and the Kuramoto--Sivashinsky equation. We expect that the simplicity and efficiency of the approach will enable generalization to a wide variety of other parabolic PDEs, as well as applications to boundary value problems.", "AI": {"tldr": "A new method for rigorous integration of parabolic PDEs with guaranteed error bounds between numerical and exact solutions, using a posteriori fixed-point reformulation with adaptive time-stepping.", "motivation": "Current PDE simulations provide approximate numerical solutions without correctness guarantees. There's a need for rigorous integration methods that can prove error bounds and ensure solution existence over entire time intervals.", "method": "Uses a fixed-point reformulation based on piece-wise constant approximation of linearization around numerical solution. Provides a posteriori error bounds with adaptive time-stepping strategy. Can prove convergence to stable hyperbolic equilibria with infinitely long final timestep.", "result": "Method successfully integrates parabolic PDEs over relatively long time intervals and captures non-trivial dynamics. Demonstrated on Swift-Hohenberg, Ohta-Kawasaki, and Kuramoto-Sivashinsky equations with rigorous error bounds.", "conclusion": "The approach is simple, efficient, and generalizable to various parabolic PDEs and boundary value problems, providing mathematically rigorous guarantees for numerical PDE solutions."}}
{"id": "2601.05161", "pdf": "https://arxiv.org/pdf/2601.05161", "abs": "https://arxiv.org/abs/2601.05161", "authors": ["Ioannis Kolotouros", "Adithya Sireesh", "Stuart Ferguson", "Sean Thrasher", "Petros Wallden", "Julien Michel"], "title": "Quantum Elastic Network Models and their Application to Graphene", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "42 pages, 11 figures", "summary": "Molecular dynamics simulations are a central computational methodology in materials design for relating atomic composition to mechanical properties. However, simulating materials with atomic-level resolution on a macroscopic scale is infeasible on current classical hardware, even when using the simplest elastic network models (ENMs) that represent molecular vibrations as a network of coupled oscillators. To address this issue, we introduce Quantum Elastic Network Models (QENMs) and utilize the quantum algorithm of Babbush et al. (PRX, 2023), which offers an exponential advantage when simulating systems of coupled oscillators under some specific conditions and assumptions. Here, we demonstrate how our method enables the efficient simulation of planar materials. As an example, we apply our algorithm to the task of simulating a 2D graphene sheet. We analyze the exact complexity for initial-state preparation, Hamiltonian simulation, and measurement of this material, and provide two real-world applications: heat transfer and the out-of-plane rippling effect. We estimate that an atomistic simulation of a graphene sheet on the centimeter scale, classically requiring hundreds of petabytes of memory and prohibitive runtimes, could be encoded and simulated with as few as $\\sim 160$ logical qubits.", "AI": {"tldr": "Quantum algorithm enables exponential speedup for simulating macroscopic-scale elastic network models of materials using ~160 logical qubits, demonstrated on centimeter-scale graphene sheets.", "motivation": "Classical molecular dynamics simulations are infeasible for simulating materials with atomic-level resolution on macroscopic scales due to prohibitive memory requirements (hundreds of petabytes) and runtime constraints, even with simple elastic network models.", "method": "Introduces Quantum Elastic Network Models (QENMs) using Babbush et al.'s quantum algorithm that offers exponential advantage for simulating coupled oscillators. Applies the method to planar materials like graphene, analyzing complexity for initial-state preparation, Hamiltonian simulation, and measurement.", "result": "Demonstrates efficient simulation of 2D graphene sheets, showing that centimeter-scale atomistic simulations requiring hundreds of petabytes classically could be encoded and simulated with only ~160 logical qubits. Provides real-world applications for heat transfer and out-of-plane rippling effects.", "conclusion": "Quantum Elastic Network Models enable previously infeasible macroscopic-scale materials simulations by leveraging quantum computational advantages, opening new possibilities for materials design and analysis at realistic scales."}}
{"id": "2601.04753", "pdf": "https://arxiv.org/pdf/2601.04753", "abs": "https://arxiv.org/abs/2601.04753", "authors": ["Xavier Lamy", "Riccardo Tione"], "title": "Hyperbolic regularization effects for degenerate elliptic equations", "categories": ["math.AP"], "comment": null, "summary": "This paper investigates the regularity of Lipschitz solutions $u$ to the general two-dimensional equation $\\text{div}(G(Du))=0$ with highly degenerate ellipticity. Just assuming strict monotonicity of the field $G$ and heavily relying on the differential inclusions point of view, we establish a pointwise gradient localization theorem and we show that the singular set of nondifferentiability points of $u$ is $\\mathcal{H}^1$-negligible. As a consequence, we derive new sharp partial $C^1$ regularity results under the assumption that $G$ is degenerate only on curves. This is done by exploiting the hyperbolic structure of the equation along these curves, where the loss of regularity is compensated using tools from the theories of Hamilton-Jacobi equations and scalar conservation laws. Our analysis recovers and extends all the previously known results, where the degeneracy set was required to be zero-dimensional.", "AI": {"tldr": "The paper establishes pointwise gradient localization and shows that the singular set of nondifferentiability points is H\u00b9-negligible for Lipschitz solutions to degenerate elliptic equations in 2D, leading to new sharp partial C\u00b9 regularity results.", "motivation": "To understand regularity properties of Lipschitz solutions to highly degenerate elliptic equations in two dimensions, extending previous results that only handled zero-dimensional degeneracy sets.", "method": "Uses differential inclusions viewpoint, establishes pointwise gradient localization theorem, exploits hyperbolic structure along degeneracy curves, and applies tools from Hamilton-Jacobi equations and scalar conservation laws.", "result": "Proves that singular set of nondifferentiability points is H\u00b9-negligible, derives new sharp partial C\u00b9 regularity results for equations where degeneracy occurs only on curves, and recovers/extends all previously known results.", "conclusion": "The analysis successfully handles higher-dimensional degeneracy sets (curves) using hyperbolic structure and conservation law techniques, providing a more comprehensive regularity theory for degenerate elliptic equations in 2D."}}
{"id": "2601.05224", "pdf": "https://arxiv.org/pdf/2601.05224", "abs": "https://arxiv.org/abs/2601.05224", "authors": ["Delfina B. Comerso Salzer", "Malena I. Espa\u00f1ol", "Gabriela Jeronimo"], "title": "Variable Projection Methods for Solving Regularized Separable Inverse Problems with Applications to Semi-Blind Image Deblurring", "categories": ["math.NA"], "comment": "26 pages", "summary": "Separable nonlinear least squares problems appear in many inverse problems, including semi-blind image deblurring. The variable projection (VarPro) method provides an efficient approach for solving such problems by eliminating linear variables and reducing the problem to a smaller, nonlinear one. In this work, we extend VarPro to solve minimization problems containing a differentiable regularization term on the nonlinear parameters, along with a general-form Tikhonov regularization term on the linear variables. Furthermore, we develop a quasi-Newton method for solving the resulting reduced problem, and provide a local convergence analysis under standard smoothness assumptions, establishing conditions for superlinear or quadratic convergence. For large-scale settings, we introduce an inexact LSQR-based variant and prove its local convergence despite inner-solve and Hessian approximations. Numerical experiments on semi-blind deblurring show that parameter regularization prevents degenerate no-blur solutions and that the proposed methods achieve accurate reconstructions, with the inexact variant offering a favorable accuracy-cost tradeoff consistent with the theory.", "AI": {"tldr": "Extends variable projection method to handle differentiable regularization on nonlinear parameters and general-form Tikhonov regularization on linear variables, with quasi-Newton solver and convergence analysis.", "motivation": "Separable nonlinear least squares problems appear in many inverse problems like semi-blind image deblurring, but existing variable projection methods don't handle regularization on nonlinear parameters well.", "method": "Extends VarPro to include differentiable regularization on nonlinear parameters and general-form Tikhonov on linear variables. Develops quasi-Newton method for reduced problem with convergence analysis. Introduces inexact LSQR-based variant for large-scale problems.", "result": "Establishes local convergence conditions for superlinear/quadratic convergence. For inexact variant, proves convergence despite approximations. Numerical experiments show parameter regularization prevents degenerate solutions and methods achieve accurate reconstructions with favorable accuracy-cost tradeoff.", "conclusion": "The extended VarPro framework with regularization on both parameter types is effective for separable nonlinear least squares problems, with theoretical convergence guarantees and practical efficiency demonstrated in semi-blind deblurring applications."}}
{"id": "2601.04784", "pdf": "https://arxiv.org/pdf/2601.04784", "abs": "https://arxiv.org/abs/2601.04784", "authors": ["Lo\u00efs Delande"], "title": "Hypocoercivity and metastability of degenerate KFP equations at low temperature", "categories": ["math.AP", "math.PR", "math.SP"], "comment": "60 pages, 1 figure", "summary": "We consider Kramers-Fokker-Planck operators with general degenerate coefficients. We prove semiclassical hypocoercivity estimates for a large class of such operators. Then, we manage to prove Eyring-Kramers formulas for the bottom of the spectrum of some particular degenerate operators in the semiclassical regime, and quantify the spectral gap separating these eigenvalues from the rest of the spectrum. The main ingredient is the construction of sharp Gaussian quasimodes through an adaptation of the WKB method.", "AI": {"tldr": "The paper proves semiclassical hypocoercivity estimates for degenerate Kramers-Fokker-Planck operators and establishes Eyring-Kramers formulas for their spectrum, including spectral gap quantification.", "motivation": "To understand the spectral properties of degenerate Kramers-Fokker-Planck operators in the semiclassical regime, particularly for applications in statistical physics and kinetic theory where degenerate coefficients appear naturally.", "method": "Uses semiclassical analysis techniques, proves hypocoercivity estimates for degenerate operators, adapts WKB method to construct sharp Gaussian quasimodes, and employs spectral analysis to derive Eyring-Kramers formulas.", "result": "Successfully proves semiclassical hypocoercivity estimates for a large class of degenerate Kramers-Fokker-Planck operators, establishes Eyring-Kramers formulas for the bottom of their spectrum, and quantifies the spectral gap separating these eigenvalues from the rest of the spectrum.", "conclusion": "The paper provides rigorous spectral analysis tools for degenerate Kramers-Fokker-Planck operators, connecting semiclassical analysis with hypocoercivity theory and offering precise spectral gap estimates through adapted WKB methods."}}
{"id": "2601.04383", "pdf": "https://arxiv.org/pdf/2601.04383", "abs": "https://arxiv.org/abs/2601.04383", "authors": ["Paul Breiding", "John Cobb", "Aviva K. Englander", "Nayda Farnsworth", "Jonathan D. Hauenstein", "Oskar Henriksson", "David K. Johnson", "Jordy Lopez Garcia", "Deepak Mundayur"], "title": "Elimination Without Eliminating: Computing Complements of Real Hypersurfaces Using Pseudo-Witness Sets", "categories": ["math.AG", "math.NA"], "comment": "24 pages, 7 figures", "summary": "Many hypersurfaces in algebraic geometry, such as discriminants, arise as the projection of another variety. The real complement of such a hypersurface partitions its ambient space into open regions. In this paper, we propose a new method for computing these regions. Existing methods for computing regions require the explicit equation of the hypersurface as input. However, computing this equation by elimination can be computationally demanding or even infeasible. Our approach instead derives from univariate interpolation by computing the intersection of the hypersurface with a line. Such an intersection can be done using so-called pseudo-witness sets without computing a defining equation for the hypersurface - we perform elimination without actually eliminating. We implement our approach in a forthcoming Julia package and demonstrate, on several examples, that the resulting algorithm accurately recovers all regions of the real complement of a hypersurface.", "AI": {"tldr": "New method computes regions of real complement of hypersurfaces without needing explicit equations, using pseudo-witness sets and line intersections instead of elimination.", "motivation": "Many hypersurfaces in algebraic geometry arise from projections of other varieties, and computing their real complement regions is important. Existing methods require explicit equations, but computing these equations via elimination can be computationally demanding or infeasible.", "method": "Uses univariate interpolation by computing intersection of hypersurface with a line. Employs pseudo-witness sets to perform elimination without actually eliminating - avoids computing defining equation for hypersurface.", "result": "Implemented in forthcoming Julia package. Demonstrated on several examples that algorithm accurately recovers all regions of real complement of hypersurface.", "conclusion": "Proposed approach successfully computes regions without explicit equations, overcoming computational limitations of elimination-based methods through pseudo-witness sets and line intersection techniques."}}
{"id": "2601.04797", "pdf": "https://arxiv.org/pdf/2601.04797", "abs": "https://arxiv.org/abs/2601.04797", "authors": ["Victor Armegioiu"], "title": "The Semigeostrophic-Euler Limit: Lifespan Lower Bounds and $O(\\varepsilon)$ Velocity Stability", "categories": ["math.AP", "physics.flu-dyn"], "comment": null, "summary": "We study the two-dimensional semigeostrophic (SG$^{\\varepsilon}$) system on the torus in the small-amplitude scaling and its convergence to incompressible Euler in the dual (geostrophic) formulation. Within a natural bootstrap regime for the Poisson/Monge-Amp\u00e8re coupling, we obtain two main results. First, we prove a lifespan lower bound in slow time with a \\emph{log-log} gain; in physical time this yields persistence at least on the scale $\\varepsilon^{-1}|\\log\\log \\varepsilon|$. Second, on any bootstrap window we establish a strong velocity-stability estimate with rate $O(\\varepsilon)$ in $L^2$, complementing Loeper's $O(1/\\varepsilon)$ existence time and $\\varepsilon^{2/3}$ weak convergence rate. The proofs combine the incompressible transport structure with a sharp elliptic control of the velocity gradient and a flow-based stability argument. Overall, the results give a clean quantitative bridge from SG$^{\\varepsilon}$ to Euler that is both longer-lived (by a log-log factor) and quantitatively stable in velocity.", "AI": {"tldr": "The paper studies the 2D semigeostrophic system in small-amplitude scaling, showing it converges to incompressible Euler with improved lifespan (\u03b5\u207b\u00b9|log log \u03b5|) and strong velocity stability (O(\u03b5) in L\u00b2).", "motivation": "To understand the convergence of the semigeostrophic system to incompressible Euler equations in the dual formulation, particularly quantifying the lifespan and stability of this approximation in geophysical fluid dynamics.", "method": "Uses a bootstrap regime for Poisson/Monge-Amp\u00e8re coupling, combines incompressible transport structure with sharp elliptic control of velocity gradient and flow-based stability arguments.", "result": "Two main results: 1) Lifespan lower bound with log-log gain (persistence on scale \u03b5\u207b\u00b9|log log \u03b5|), 2) Strong velocity-stability estimate with O(\u03b5) rate in L\u00b2 on any bootstrap window.", "conclusion": "The results provide a quantitative bridge from semigeostrophic to Euler equations that is both longer-lived (by log-log factor) and quantitatively stable in velocity, improving upon previous bounds."}}
{"id": "2601.04473", "pdf": "https://arxiv.org/pdf/2601.04473", "abs": "https://arxiv.org/abs/2601.04473", "authors": ["Jiaheng Chen", "Daniel Sanz-Alonso"], "title": "Convergence Rates for Learning Pseudo-Differential Operators", "categories": ["math.ST", "cs.LG", "math.NA", "stat.ML"], "comment": "72 pages, 1 figure", "summary": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing.", "AI": {"tldr": "Learning elliptic pseudo-differential operators via wavelet-Galerkin framework with sparse estimator achieves convergence rates and enables efficient data-driven PDE solvers.", "motivation": "To develop efficient learning methods for elliptic pseudo-differential operators, which are fundamental in PDEs and mathematical physics, and bridge operator learning with scientific computing.", "method": "Wavelet-Galerkin framework treating learning as structured infinite-dimensional regression with multiscale sparsity. Uses sparse estimator with novel matrix compression scheme and nested-support strategy to balance approximation and estimation errors.", "result": "Established convergence rates for the estimator. Showed that learned operator induces efficient and stable Galerkin solver with numerical error matching statistical accuracy.", "conclusion": "Successfully integrates operator learning, data-driven solvers, and wavelet methods in scientific computing, providing theoretical guarantees for learning elliptic operators and their application in numerical solvers."}}
{"id": "2601.04804", "pdf": "https://arxiv.org/pdf/2601.04804", "abs": "https://arxiv.org/abs/2601.04804", "authors": ["Thibault Lefeuvre"], "title": "Semiclassical analysis of the magnetic Laplacian on hyperbolic surfaces", "categories": ["math.AP", "math.DG", "math.DS"], "comment": "To appear in Journ\u00e9es \u00e9quations aux d\u00e9riv\u00e9es partielles (2025)", "summary": "The magnetic Laplacian on hyperbolic surfaces provides a rich analytic framework in which a variety of quantum phenomena emerge. The present note, written for the \\emph{Proceedings of the Journ\u00e9es EDP 2025}, is a concise overview of the main results obtained in [arXiv:2505.08584] and work in preparation by the author with L. Charles and A. Chabert.", "AI": {"tldr": "Overview of magnetic Laplacian results on hyperbolic surfaces from arXiv:2505.08584 and ongoing work", "motivation": "To provide a concise overview of quantum phenomena emerging from the magnetic Laplacian on hyperbolic surfaces, presenting results from existing research and work in preparation", "method": "Analytic framework using magnetic Laplacian on hyperbolic surfaces, building on previous work [arXiv:2505.08584] and collaborative research with L. Charles and A. Chabert", "result": "Main results from the referenced paper are summarized, though specific findings are not detailed in this abstract", "conclusion": "This note serves as a concise overview of quantum phenomena in hyperbolic geometry, connecting magnetic Laplacian analysis to quantum effects on curved surfaces"}}
{"id": "2601.04510", "pdf": "https://arxiv.org/pdf/2601.04510", "abs": "https://arxiv.org/abs/2601.04510", "authors": ["Christophe Bonneville", "Nathan Bieberdorf", "Pieterjan Robbe", "Mark Asta", "Habib Najm", "Laurent Capolungo", "Cosmin Safta"], "title": "Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks", "categories": ["cs.CE", "cs.AI", "cs.CV", "cs.LG", "math.NA"], "comment": null, "summary": "Phase-field simulations of liquid metal dealloying (LMD) can capture complex microstructural evolutions but can be prohibitively expensive for large domains and long time horizons. In this paper, we introduce a fully convolutional, conditionally parameterized U-Net surrogate designed to extrapolate far beyond its training data in both space and time. The architecture integrates convolutional self-attention, physically informed padding, and a flood-fill corrector method to maintain accuracy under extreme extrapolation, while conditioning on simulation parameters allows for flexible time-step skipping and adaptation to varying alloy compositions. To remove the need for costly solver-based initialization, we couple the surrogate with a conditional diffusion model that generates synthetic, physically consistent initial conditions. We train our surrogate on simulations generated over small domain sizes and short time spans, but, by taking advantage of the convolutional nature of U-Nets, we are able to run and extrapolate surrogate simulations for longer time horizons than what would be achievable with classic numerical solvers. Across multiple alloy compositions, the framework is able to reproduce the LMD physics accurately. It predicts key quantities of interest and spatial statistics with relative errors typically below 5% in the training regime and under 15% during large-scale, long time-horizon extrapolations. Our framework can also deliver speed-ups of up to 36,000 times, bringing the time to run weeks-long simulations down to a few seconds. This work is a first stepping stone towards high-fidelity extrapolation in both space and time of phase-field simulation for LMD.", "AI": {"tldr": "A U-Net surrogate model with diffusion-based initialization enables fast, accurate phase-field simulations of liquid metal dealloying, achieving up to 36,000\u00d7 speedup while maintaining physics fidelity during extreme spatiotemporal extrapolation.", "motivation": "Phase-field simulations of liquid metal dealloying are computationally expensive for large domains and long time horizons, limiting practical applications. There's a need for efficient surrogate models that can extrapolate beyond training data while maintaining physical accuracy.", "method": "Developed a fully convolutional, conditionally parameterized U-Net surrogate with convolutional self-attention and physically informed padding. Coupled with a conditional diffusion model for synthetic initial condition generation. Trained on small-domain, short-time simulations but leverages convolutional architecture for extrapolation to larger scales and longer time horizons.", "result": "Achieves relative errors below 5% in training regime and under 15% during large-scale extrapolation. Predicts key quantities of interest and spatial statistics accurately. Delivers up to 36,000\u00d7 speedup, reducing weeks-long simulations to seconds. Framework works across multiple alloy compositions.", "conclusion": "The framework enables high-fidelity extrapolation of phase-field simulations for liquid metal dealloying in both space and time, representing a significant advancement in computational efficiency while maintaining physical accuracy for materials science applications."}}
{"id": "2601.04845", "pdf": "https://arxiv.org/pdf/2601.04845", "abs": "https://arxiv.org/abs/2601.04845", "authors": ["Zhiguang Zhang", "Yuxiang Li"], "title": "Boundedness in a two-dimensional doubly degenerate nutrient taxis system with logistic source", "categories": ["math.AP"], "comment": null, "summary": "We are concerned with the following doubly degenerate nutrient taxis system \\begin{align} \\begin{cases}\\tag{$\\star$}\\label{eq-0.1} u_t=\\nabla\\cdot(u v\\nabla u)-\\nabla\\cdot(u^{2} v\\nabla v)+u-u^2,\\\\[1mm] v_t=\u0394v-u v, \\end{cases} \\end{align} posed in a bounded smooth domain $\u03a9\\subset\\mathbb{R}^2$ under homogeneous Neumann boundary conditions. This model was introduced to describe the aggregation patterns of colonies of \\emph{Bacillus subtilis} observed on thin agar plates. Previous results have established global boundedness in one space dimension and, in two dimensions, under additional assumptions such as small initial data or convex domains (see, e.g., M. Winkler, \\textit{Trans. Amer. Math. Soc.}, 2021; M. Winkler, \\textit{J. Differ. Equ.}, 2024). In the presence of the quadratic degradation term in the logistic growth, which markedly enhances the dissipative structure of the system, and by employing a weighted energy method, we prove that for arbitrary smooth initial data the problem \\eqref{eq-0.1} admits a global weak solution that remains uniformly bounded in time.", "AI": {"tldr": "The paper proves global existence and uniform boundedness of weak solutions for a doubly degenerate nutrient taxis system in 2D bounded domains, overcoming previous limitations that required small initial data or convex domains.", "motivation": "The model describes Bacillus subtilis aggregation patterns on thin agar plates. Previous results only established global boundedness in 1D or in 2D with restrictive assumptions (small initial data or convex domains). The authors aim to remove these restrictions and prove global boundedness for arbitrary smooth initial data in 2D.", "method": "The authors leverage the quadratic degradation term in the logistic growth, which enhances the dissipative structure of the system. They employ a weighted energy method to establish global existence and uniform boundedness of weak solutions.", "result": "The main result proves that for arbitrary smooth initial data in bounded smooth domains in \u211d\u00b2, the doubly degenerate nutrient taxis system admits a global weak solution that remains uniformly bounded in time.", "conclusion": "The quadratic degradation term in the logistic growth provides sufficient dissipation to overcome the degeneracy and establish global boundedness without restrictive assumptions on initial data or domain geometry, advancing the mathematical understanding of this biological pattern formation model."}}
{"id": "2601.04513", "pdf": "https://arxiv.org/pdf/2601.04513", "abs": "https://arxiv.org/abs/2601.04513", "authors": ["Abigail G. M\u00e1rquez-Hern\u00e1ndez", "V\u00edctor A. Vicente-Ben\u00edtez"], "title": "Neumann series of Bessel functions for the solutions of the Sturm-Liouville equation in impedance form and related boundary value problems", "categories": ["math.CA", "math-ph", "math.NA"], "comment": "34 pages, 7 figures", "summary": "We present a Neumann series of spherical Bessel functions representation for solutions of the Sturm--Liouville equation in impedance form \\[ (\u03ba(x)u')' + \u03bb\u03ba(x)u = 0,\\quad 0 < x < L, \\] in the case where $\u03ba\\in W^{1,2}(0,L)$ and has no zeros on the interval of interest. The $x$-dependent coefficients of this representation can be constructed explicitly by means of a simple recursive integration procedure. Moreover, we derive bounds for the truncation error, which are uniform whenever the spectral parameter $\u03c1=\\sqrt\u03bb$ satisfies a condition of the form $|\\operatorname{Im}\u03c1|\\leq C$. Based on these representations, we develop a numerical method for solving spectral problems that enables the computation of eigenvalues with non-deteriorating accuracy.", "AI": {"tldr": "Neumann series representation using spherical Bessel functions for Sturm-Liouville impedance form solutions, with explicit recursive construction and uniform error bounds for spectral parameter in strip |Im \u03c1| \u2264 C.", "motivation": "To develop an efficient numerical method for solving spectral problems with Sturm-Liouville equations in impedance form, enabling computation of eigenvalues with non-deteriorating accuracy.", "method": "Construct Neumann series representation using spherical Bessel functions for solutions of (\u03ba(x)u')' + \u03bb\u03ba(x)u = 0. Coefficients are built via recursive integration procedure. Derive uniform truncation error bounds for spectral parameter \u03c1 = \u221a\u03bb satisfying |Im \u03c1| \u2264 C.", "result": "Successfully developed explicit representation for solutions with x-dependent coefficients constructible via simple recursive integration. Derived uniform error bounds enabling development of numerical method for spectral problems.", "conclusion": "The Neumann series representation provides a foundation for accurate numerical computation of eigenvalues for Sturm-Liouville impedance problems, with guaranteed error control in specified spectral parameter regions."}}
{"id": "2601.04894", "pdf": "https://arxiv.org/pdf/2601.04894", "abs": "https://arxiv.org/abs/2601.04894", "authors": ["Hector Bouton"], "title": "Improved convergence rates in the fast-reaction approximation of the triangular Shigesada-Kawasaki-Teramoto system", "categories": ["math.AP"], "comment": null, "summary": "We consider the fast-reaction approximation to the triangular Shigesada-Kawasaki-Teramoto model on a bounded domain in the physical dimension $d\\le 3$. We provide explicit convergence rates on the whole domain in $\\textnormal{L}^\\infty\\textnormal{L}^2\\cap\\textnormal{L}^2\\textnormal{H}^1$ and in the interior we prove convergence with an explicit rate in any $\\textnormal{L}^\\infty\\textnormal{H}^l$ for all $l > 0$.", "AI": {"tldr": "The paper analyzes convergence rates for the fast-reaction approximation of the triangular Shigesada-Kawasaki-Teramoto model on bounded domains in dimensions d\u22643.", "motivation": "The motivation is to provide rigorous mathematical analysis of convergence rates for the fast-reaction approximation to the triangular SKT model, which is important for understanding pattern formation in reaction-diffusion systems.", "method": "The authors use analytical methods to study the fast-reaction limit of the triangular SKT model on bounded domains in physical dimensions d\u22643, providing explicit convergence rates in various function spaces.", "result": "The paper provides explicit convergence rates: globally in L\u221eL\u00b2\u2229L\u00b2H\u00b9 spaces, and interior convergence with explicit rates in any L\u221eH\u02e1 for all l>0.", "conclusion": "The fast-reaction approximation to the triangular SKT model converges with explicit rates on bounded domains in dimensions d\u22643, with stronger interior convergence in higher-order Sobolev spaces."}}
{"id": "2601.04570", "pdf": "https://arxiv.org/pdf/2601.04570", "abs": "https://arxiv.org/abs/2601.04570", "authors": ["Jidu Yu", "Jidong Zhao"], "title": "A Virtual Heat Flux Method for Simple and Accurate Neumann Thermal Boundary Imposition in the Material Point Method", "categories": ["math-ph", "math.NA"], "comment": null, "summary": "In the Material Point Method (MPM), accurately imposing Neumann-type thermal boundary conditions, particularly convective heat flux boundaries, remains a significant challenge due to the inherent nonconformity between complex evolving material boundaries and the fixed background grid. This paper introduces a novel Virtual Heat Flux Method (VHFM) to overcome this limitation. The core idea is to construct a virtual flux field on an auxiliary domain surrounding the physical boundary, which exactly satisfies the prescribed boundary condition. This transforms the surface integral in the weak form into an equivalent, and easily computed, volumetric integral. Consequently, VHFM eliminates the need for explicit boundary tracking, specialized boundary particles, or complex surface reconstruction. A unified formulation is presented, demonstrating the method's straightforward extension to general scalar, vector, and tensor Neumann conditions. The accuracy, robustness, and convergence of VHFM are rigorously validated through a series of numerical benchmarks, including 1D transient analysis, 2D and 3D curved boundaries, and problems with large rotations and complex moving geometries. The results show that VHFM achieves accuracy comparable to conforming node-based imposition and significantly outperforms conventional particle-based approaches. Its simplicity, computational efficiency, and robustness make it an attractive solution for integrating accurate thermal boundary conditions into thermo-mechanical and other multiphysics MPM frameworks.", "AI": {"tldr": "A novel Virtual Heat Flux Method (VHFM) is introduced for accurately imposing Neumann-type thermal boundary conditions in MPM without explicit boundary tracking.", "motivation": "Accurately imposing Neumann-type thermal boundary conditions (especially convective heat flux) in MPM is challenging due to nonconformity between evolving material boundaries and fixed background grids.", "method": "VHFM constructs a virtual flux field on an auxiliary domain surrounding the physical boundary that exactly satisfies prescribed boundary conditions, transforming surface integrals into easily computed volumetric integrals.", "result": "VHFM achieves accuracy comparable to conforming node-based imposition and significantly outperforms conventional particle-based approaches in 1D, 2D, and 3D benchmarks with complex geometries.", "conclusion": "VHFM provides a simple, computationally efficient, and robust solution for accurate thermal boundary conditions in thermo-mechanical and multiphysics MPM frameworks."}}
{"id": "2601.04944", "pdf": "https://arxiv.org/pdf/2601.04944", "abs": "https://arxiv.org/abs/2601.04944", "authors": ["Tahar Zam\u00e8ne Boulmezaoud", "Nabil Kerdid", "Amel Kourta"], "title": "On Navier-Stokes equations arising from the rotation of an obstacle in a fluid", "categories": ["math.AP"], "comment": null, "summary": "We consider the modified Navier-Stokes equations in R3 describing the motion of a fluid in the presence of a rotating rigid body. Weighted Sobolev spaces are used to describe the behavior of solutions at large distances. Under suitable assumptions, w e prove the existence and regularity of solutions satisfying appropriate conditions at infinity.", "AI": {"tldr": "Existence and regularity of solutions for modified Navier-Stokes equations describing fluid motion with a rotating rigid body in R3, using weighted Sobolev spaces to handle behavior at large distances.", "motivation": "To mathematically analyze fluid-structure interaction problems involving rotating bodies, which have important applications in engineering and physics. The challenge lies in handling the behavior of solutions at large distances from the rotating body.", "method": "Uses modified Navier-Stokes equations in R3 with weighted Sobolev spaces to describe solution behavior at infinity. The approach involves proving existence and regularity under suitable assumptions with appropriate boundary conditions at large distances.", "result": "Proves existence and regularity of solutions satisfying appropriate conditions at infinity for the fluid motion problem with a rotating rigid body.", "conclusion": "The paper establishes rigorous mathematical foundations for studying fluid-structure interaction with rotating bodies, providing existence and regularity results using weighted Sobolev spaces to handle the infinite domain."}}
{"id": "2601.05029", "pdf": "https://arxiv.org/pdf/2601.05029", "abs": "https://arxiv.org/abs/2601.05029", "authors": ["Evie Nielen", "Oliver Tse"], "title": "Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems", "categories": ["math.OC", "math.FA", "math.NA", "math.PR"], "comment": "32 pages, 9 figures", "summary": "Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous-time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piecewise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$-functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments", "AI": {"tldr": "Paper proposes stochastic framework for greedy sampling methods using Markov processes, enabling convergence analysis under mild assumptions, with applications to interpolation and randomized polytope division.", "motivation": "Greedy Sampling Methods (GSMs) are widely used for Configuration Optimization Problems but deterministic convergence analyses are often restrictive and difficult to verify. Need a more flexible framework for analyzing convergence.", "method": "Formulate greedy-type methods as continuous-time Markov processes on configuration space. Analyze convergence in expectation and probability under mild structural assumptions. Study stochastic greedy sampling for 1D piecewise linear interpolation and introduce Randomized Polytope Division Method (R-PDM).", "result": "Derive explicit convergence rates (logarithmic, polynomial, exponential decay) depending on improvement condition. Prove exponential convergence of L\u00b9-interpolation error for C\u00b2-functions. Demonstrate effectiveness and variance reduction of R-PDM in numerical experiments.", "conclusion": "Stochastic framework provides flexible convergence analysis for greedy-type algorithms under mild assumptions, with practical applications showing improved performance through randomization."}}
{"id": "2601.04994", "pdf": "https://arxiv.org/pdf/2601.04994", "abs": "https://arxiv.org/abs/2601.04994", "authors": ["Ziyue Zeng", "Yuxiang Li"], "title": "Critical blow-up lines in a two-species quasilinear chemotaxis system with two chemicals", "categories": ["math.AP"], "comment": null, "summary": "In this study, we explore the quasilinear two-species chemotaxis system with two chemicals \\begin{align}\\tag{$\\star$} \\begin{cases} u_t = \\nabla \\cdot(D(u)\\nabla u) - \\nabla \\cdot \\left(S(u) \\nabla v\\right), & x \\in \u03a9, \\ t > 0, \\\\ 0 = \u0394v - \u03bc_w + w, \\quad \u03bc_w=\\fint_\u03a9w, & x \\in \u03a9, \\ t > 0, \\\\ w_t = \u0394w - \\nabla \\cdot \\left(w \\nabla z\\right), & x \\in \u03a9, \\ t > 0, \\\\ 0 = \u0394z - \u03bc_u + u, \\quad \u03bc_u=\\fint_\u03a9u, & x \\in \u03a9, \\ t > 0, \\\\ \\frac{\\partial u}{\\partial \u03bd} = \\frac{\\partial v}{\\partial \u03bd} = \\frac{\\partial w}{\\partial \u03bd} = \\frac{\\partial z}{\\partial \u03bd} = 0, & x \\in \\partial \u03a9, \\ t > 0, \\\\ u(x, 0) = u_0(x), \\quad w(x, 0) = w_0(x), & x \\in \u03a9, \\end{cases} \\end{align} where $\u03a9\\subset \\mathbb{R}^n$ ($n \\geq3$) is a smooth bounded domain. The functions $D(s)$ and $S(s)$ exhibit asymptotic behavior of the form \\begin{align*} D(s) \\simeq k_D s^p \\ \\text {and} \\ S(s) \\simeq k_S s^q, \\quad s \\gg 1 \\end{align*} with $p,q \\in \\mathbb{R}$. We prove that \\begin{itemize}\n  \\item when $\u03a9$ is a ball, if $q-p>2-\\frac{n}{2}$ and $q>1-\\frac{n}{2}$, there exist radially symmetric initial data $u_0$ and $w_0$, such that the corresponding solutions blow up in finite time;\n  \\item for any general smooth bounded domain $\u03a9\\subset \\mathbb{R}^n$, if $q-p<2-\\frac{n}{2}$, all solutions are globally bounded;\n  \\item for any general smooth bounded domain $\u03a9\\subset \\mathbb{R}^n$, if $q<1-\\frac{n}{2}$, all solutions are global. \\end{itemize} We point out that our results implies that the system ($\\star$) possess two critical lines $ q-p=2-\\frac{n}{2}$ and $q=1-\\frac{n}{2}$ to classify three dynamics among global boundedness, finite-time blow-up, and global existence of solutions to system ($\\star$).", "AI": {"tldr": "The paper analyzes a quasilinear two-species chemotaxis system with two chemicals, establishing critical parameter conditions that determine solution behavior: finite-time blow-up vs. global boundedness vs. global existence.", "motivation": "To understand the dynamics of a two-species chemotaxis system with two chemicals, where each species produces a chemical that attracts the other species. The system involves nonlinear diffusion and sensitivity functions with power-law asymptotics, and the goal is to determine parameter regimes leading to different solution behaviors.", "method": "Mathematical analysis of the quasilinear PDE system using asymptotic behavior assumptions on diffusion D(s) and sensitivity S(s) functions (D(s) \u2243 k_D s^p, S(s) \u2243 k_S s^q for large s). The analysis involves establishing critical parameter conditions through rigorous PDE techniques, including radial symmetry arguments for blow-up results and energy estimates for global boundedness.", "result": "Three main results: 1) On a ball domain, if q-p > 2-n/2 and q > 1-n/2, there exist radially symmetric initial data leading to finite-time blow-up. 2) On any smooth bounded domain, if q-p < 2-n/2, all solutions are globally bounded. 3) On any smooth bounded domain, if q < 1-n/2, all solutions exist globally. These reveal two critical lines: q-p = 2-n/2 and q = 1-n/2 that classify the three dynamical regimes.", "conclusion": "The two-species chemotaxis system exhibits a rich dynamical structure with precisely defined critical parameter thresholds that separate finite-time blow-up, global boundedness, and global existence regimes. The critical lines q-p = 2-n/2 and q = 1-n/2 provide a complete classification of solution behaviors for this class of quasilinear chemotaxis systems."}}
{"id": "2601.05071", "pdf": "https://arxiv.org/pdf/2601.05071", "abs": "https://arxiv.org/abs/2601.05071", "authors": ["Mrityunjoy Mandal", "Jan Nordstr\u00f6m", "Arnaud G Malan"], "title": "A high order accurate and provably stable fully discrete continuous Galerkin framework on summation-by-parts form for advection-diffusion equations", "categories": ["math-ph", "math.NA"], "comment": null, "summary": "We present a high-order accurate fully discrete numerical scheme for solving Initial Boundary Value Problems (IBVPs) within the Continuous Galerkin (CG)-based Finite Element framework. Both the spatial and time approximation in Summation-By-Parts (SBP) form are considered here. The initial and boundary conditions are imposed weakly using the Simultaneous Approximation Term (SAT) technique. The resulting SBP-SAT formulation yields an energy estimate in terms of the initial and external boundary data, leading to an energy-stable discretization in both space and time. The proposed method is evaluated numerically using the Method of Manufactured Solutions (MMS). The scheme achieves super-convergence in both spatial and temporal direction with accuracy $\\mathcal{O}(p+2)$ for $p\\geq 2$, where $p$ refers to the degree of the Lagrange basis. In an application case, we show that the fully discrete formulation efficiently captures space-time variations even on coarse meshes, demonstrating the method's computational effectiveness.", "AI": {"tldr": "High-order accurate fully discrete SBP-SAT scheme for IBVPs achieves super-convergence O(p+2) with energy stability in both space and time.", "motivation": "To develop a fully discrete numerical scheme for Initial Boundary Value Problems that combines high-order accuracy with energy stability in both spatial and temporal dimensions within the Continuous Galerkin Finite Element framework.", "method": "Uses SBP (Summation-By-Parts) form for both spatial and temporal approximations, with weak imposition of initial and boundary conditions via SAT (Simultaneous Approximation Term) technique, resulting in an SBP-SAT formulation that provides energy estimates.", "result": "The scheme achieves super-convergence with accuracy O(p+2) for p\u22652 (where p is Lagrange basis degree), demonstrates energy stability, and efficiently captures space-time variations even on coarse meshes as validated by Method of Manufactured Solutions.", "conclusion": "The proposed SBP-SAT formulation provides an energy-stable, high-order accurate fully discrete method for IBVPs that achieves super-convergence and computational effectiveness in capturing space-time variations."}}
{"id": "2601.05008", "pdf": "https://arxiv.org/pdf/2601.05008", "abs": "https://arxiv.org/abs/2601.05008", "authors": ["Ziyue Zeng", "Yuxiang Li"], "title": "Critical blow-up curve in a two-species chemotaxis system with two chemicals involving flux-limitation", "categories": ["math.AP"], "comment": null, "summary": "We investigate the following two-species chemotaxis system with two chemicals involving flux-limitation \\begin{align}\\tag{$\\star$} \\begin{cases} u_t = \u0394u - \\nabla \\cdot \\left(u(1+|\\nabla v|^2)^{-\\frac{p}{2}}\\nabla v\\right), & x \\in \u03a9, \\ t > 0, \\\\ 0 = \u0394v - \u03bc_w + w, \\quad \u03bc_{w}=f_\u03a9 w, & x \\in \u03a9, \\ t > 0, \\\\ w_t = \u0394w - \\nabla \\cdot \\left(w (1+|\\nabla z|^2)^{-\\frac{q}{2}} \\nabla z\\right), & x \\in \u03a9, \\ t > 0, \\\\ 0 = \u0394z - \u03bc_u + u, \\quad \u03bc_{u}=f_\u03a9 u, & x \\in \u03a9, \\ t > 0, \\\\ \\frac{\\partial u}{\\partial \u03bd} = \\frac{\\partial v}{\\partial \u03bd} = \\frac{\\partial w}{\\partial \u03bd} = \\frac{\\partial z}{\\partial \u03bd} = 0, & x \\in \\partial \u03a9, \\ t > 0, \\\\ u(x, 0) = u_0(x), \\quad w(x, 0) = w_0(x), & x \\in \u03a9, \\end{cases} \\end{align} where $p,q \\in \\mathbb{R}$ and $\u03a9\\subset \\mathbb{R}^n$ is a smooth bounded domain. In this paper, we identify a critical blow-up curve ( i.e $p=\\frac{n-2}{n-1}$ and $q=\\frac{n-2}{n-1}$ in the square $(0,\\frac{n-2}{n-1}] \\times (0,\\frac{n-2}{n-1}]$) for system ($\\star$) with $n\\geq 3$ and $p,q>0$. Specifically, \\begin{itemize}\n  \\item when $\u03a9=B_R(0) \\subset \\mathbb{R}^n$ with $n\\geq 3$, if $0<p<\\frac{n-2}{n-1}$ and $0<q<\\frac{n-2}{n-1}$, there exist radially symmetric initial data such that the corresponding solution blows up in finite time;\n  \\item for any general smooth bounded domain, if either $n=1$ ( with $p,q \\in \\mathbb{R}$ arbitrary) or $n\\geq 2$ with $p>\\frac{n-2}{n-1}$ or $q>\\frac{n-2}{n-1}$, then solutions exist globally and remain bounded. \\end{itemize}", "AI": {"tldr": "This paper analyzes a two-species chemotaxis system with flux-limitation, identifying a critical blow-up curve at p=q=(n-2)/(n-1) that separates finite-time blow-up from global bounded existence.", "motivation": "The motivation is to understand the blow-up behavior and global existence conditions for a two-species chemotaxis system with flux-limitation, which generalizes classical Keller-Segel models by incorporating saturation effects in the chemotactic sensitivity.", "method": "The authors study a PDE system with two species (u,w) and two chemicals (v,z) coupled through chemotaxis with flux-limitation terms (1+|\u2207v|\u00b2)^{-p/2} and (1+|\u2207z|\u00b2)^{-q/2}. They use mathematical analysis techniques to establish critical thresholds for blow-up versus global existence.", "result": "The main result identifies a critical curve p=q=(n-2)/(n-1) in the parameter space: for p,q below this threshold on a ball domain, finite-time blow-up occurs; for p,q above this threshold (or in 1D), solutions exist globally and remain bounded.", "conclusion": "The flux-limitation parameters p and q crucially determine the system's behavior: strong flux-limitation (large p,q) prevents blow-up, while weak flux-limitation (small p,q) allows for finite-time blow-up, with a sharp threshold at p=q=(n-2)/(n-1)."}}
{"id": "2601.05015", "pdf": "https://arxiv.org/pdf/2601.05015", "abs": "https://arxiv.org/abs/2601.05015", "authors": ["Sanghoon Lee", "Taehun Lee"], "title": "Nodal set comparison for Allen--Cahn solutions with conical asymptotics", "categories": ["math.AP", "math.DG"], "comment": "12 pages", "summary": "We establish a comparison principle for entire solutions of the Allen--Cahn equation whose nodal sets, possibly singular, are asymptotic to a regular minimizing hypercone. We show that inclusion of the positive phases enforces a global ordering of the solutions. As a consequence, the positive phase uniquely determines the solution, and strict phase inclusion implies that the corresponding nodal sets are disjoint. Our analysis relies on a maximum principle for the linearized operator on unbounded domains that are not necessarily smooth, and yields an Allen--Cahn analogue of the strong maximum principle for minimal hypersurfaces.", "AI": {"tldr": "The paper establishes a comparison principle for entire solutions of the Allen-Cahn equation with nodal sets asymptotic to minimizing hypercones, showing that inclusion of positive phases enforces global ordering and unique determination of solutions.", "motivation": "To understand the global ordering properties of entire solutions to the Allen-Cahn equation, particularly when nodal sets are asymptotic to minimizing hypercones, and to establish relationships between phase inclusion and solution uniqueness.", "method": "Develops a maximum principle for the linearized operator on unbounded domains that are not necessarily smooth, creating an Allen-Cahn analogue of the strong maximum principle for minimal hypersurfaces.", "result": "Shows that inclusion of positive phases enforces global ordering of solutions, positive phase uniquely determines the solution, and strict phase inclusion implies corresponding nodal sets are disjoint.", "conclusion": "Establishes a comparison principle for Allen-Cahn solutions with nodal sets asymptotic to minimizing hypercones, providing important tools for analyzing solution ordering and uniqueness in this geometric PDE context."}}
{"id": "2601.05023", "pdf": "https://arxiv.org/pdf/2601.05023", "abs": "https://arxiv.org/abs/2601.05023", "authors": ["Mingzhang Cai", "Yuxiang Li", "Ziyue Zeng"], "title": "Finite-time blow-up in a quasilinear two-species chemotaxis system with two chemicals", "categories": ["math.AP"], "comment": null, "summary": "This paper investigates the finite-time blow-up phenomena to a quasilinear two-species chemotaxis system with two chemicals \\begin{align}\\tag{$\\star$}\n  \\begin{cases}\n  u_t = \\nabla \\cdot \\left(D_1(u) \\nabla u\\right) - \\nabla \\cdot \\left(u \\nabla v\\right), & x \\in \u03a9, \\ t > 0,\n  0 = \u0394v - \u03bc_2 + w, \\quad \u03bc_2=\\fint_\u03a9w, & x \\in \u03a9, \\ t > 0,\n  w_t = \\nabla \\cdot \\left(D_2(w) \\nabla w\\right) - \\nabla \\cdot \\left(w \\nabla z\\right), & x \\in \u03a9, \\ t > 0,\n  0 = \u0394z - \u03bc_1 + u, \\quad \u03bc_1=\\fint_\u03a9u, & x \\in \u03a9, \\ t > 0,\n  \\frac{\\partial u}{\\partial \u03bd} = \\frac{\\partial v}{\\partial \u03bd} = \\frac{\\partial w}{\\partial \u03bd} = \\frac{\\partial z}{\\partial \u03bd} = 0, & x \\in \\partial \u03a9, \\ t > 0,\n  u(x, 0) = u_0(x), \\quad w(x, 0) = w_0(x), & x \\in \u03a9,\n  \\end{cases} \\end{align} where $\u03a9\\subset \\mathbb{R}^n$ $(n \\geqslant 3)$ is a smoothly bounded domain. The nonlinear diffusion functions \\( D_1(s) \\) and \\( D_2(s) \\) are of the following forms: \\begin{align*}\n  D_1(s)\\simeq s^{m_1-1} \\quad \\text{and}\\quad D_2(s) \\simeq s^{m_2-1}, \\quad m_1,m_2> 1 \\end{align*} for $s\\geqslant 1$.\n  For the classical two-species chemotaxis system with two chemicals (i.e. the second and fourth equations are replaced by $0 = \u0394v - v + w$ and $0 = \u0394z - z + u$ ), Zhong [J. Math. Anal. Appl., 500 (2021), Paper No. 125130, pp. 22.] showed that the system possesses a globally bounded classical solution in the case that \\[ m_1 + m_2 < \\max\\left\\{m_1m_2 + \\frac{2m_1}{ n},\\ m_1m_2 + \\frac{2m_2 }{ n}\\right\\}. \\]\n  Complementing the boundedness result, we prove that the system ($\\star$) admits solutions that blow up in finite time, if \\[ m_1 + m_2 > \\max\\left\\{ m_1m_2 + \\frac{2m_1}{ n},\\ m_1m_2 + \\frac{2m_2}{ n}\\right\\} \\] with $n\\geqslant 3$.", "AI": {"tldr": "The paper proves finite-time blow-up for a quasilinear two-species chemotaxis system with two chemicals when the diffusion exponents satisfy certain conditions, complementing previous boundedness results.", "motivation": "To investigate blow-up phenomena in a two-species chemotaxis system with nonlinear diffusion and two chemicals, complementing existing boundedness results for similar systems.", "method": "Analysis of a quasilinear chemotaxis system with two species (u,w) and two chemicals (v,z), where chemical equations are of elliptic type with nonlocal terms. The diffusion functions D\u2081(s)\u2243s^{m\u2081-1} and D\u2082(s)\u2243s^{m\u2082-1} are nonlinear.", "result": "Proves that solutions blow up in finite time when m\u2081 + m\u2082 > max{m\u2081m\u2082 + 2m\u2081/n, m\u2081m\u2082 + 2m\u2082/n} for n\u22653, establishing a blow-up condition that complements previous boundedness results.", "conclusion": "The paper establishes a threshold condition for blow-up in the two-species chemotaxis system, showing that when diffusion is sufficiently weak relative to chemotactic coupling, finite-time blow-up occurs."}}
{"id": "2601.05054", "pdf": "https://arxiv.org/pdf/2601.05054", "abs": "https://arxiv.org/abs/2601.05054", "authors": ["Kousuke Kuto", "Kazuhiro Oeda"], "title": "On the effects of protection zone and directed population flux in prey-predator dynamics", "categories": ["math.AP"], "comment": null, "summary": "We study a spatial predator-prey model in which prey can enter a protection zone (refuge) inaccessible to predators, while predators exhibit directed movement toward prey-rich regions. The directed movement is modeled by a far-sighted population flux motivated by classical movement rules, in contrast to the more commonly analyzed near-sighted chemotaxis-type mechanisms. We first establish local-in-time well-posedness for the corresponding nonstationary problem under Neumann boundary conditions, despite the discontinuity induced by the refuge interface. We then investigate the stationary problem, focusing on how the coexistence states emerge and organize globally in parameter space. In particular, we identify the bifurcation threshold for positive steady states from semitrivial predator-only equilibria, and describe the global continuation of the resulting branches. Our analysis reveals that strong directed movement can induce turning-point structures and multiplicity of coexistence steady states, highlighting a nontrivial interplay between spatial protection and predator movement behavior.", "AI": {"tldr": "A spatial predator-prey model with prey refuge zones and predator directed movement shows that strong predator movement can create multiple coexistence states through turning-point bifurcations.", "motivation": "To understand how spatial protection zones (refuges) for prey interact with predator movement behavior, particularly far-sighted directed movement rather than near-sighted chemotaxis, in predator-prey dynamics.", "method": "Developed a spatial predator-prey model with refuge zones inaccessible to predators, using far-sighted population flux for predator movement. Analyzed both nonstationary (local well-posedness) and stationary problems, focusing on bifurcation analysis of coexistence states from predator-only equilibria.", "result": "Established local-in-time well-posedness despite refuge interface discontinuity, identified bifurcation threshold for positive steady states, and showed that strong directed movement induces turning-point structures and multiplicity of coexistence steady states.", "conclusion": "The interplay between spatial protection (refuges) and predator movement behavior creates complex dynamics, with far-sighted directed movement leading to multiple stable coexistence states through bifurcation structures, highlighting nontrivial spatial ecological interactions."}}
{"id": "2601.05080", "pdf": "https://arxiv.org/pdf/2601.05080", "abs": "https://arxiv.org/abs/2601.05080", "authors": ["Pascal Auscher", "Sebastian Bechtel"], "title": "Non-linear parabolic PDEs with rough data and coefficients: existence, uniqueness and regularity of weak solutions in critical spaces", "categories": ["math.AP", "math.CA", "math.FA"], "comment": "50 pages", "summary": "This article investigates the well-posedness of weak solutions to non-linear parabolic PDEs driven by rough coefficients with rough initial data in critical homogeneous Besov spaces. Well-posedness is understood in the sense of existence and uniqueness of maximal weak solutions in suitable weighted $Z$-spaces in the absence of smallness conditions. We showcase our theory with an application to rough reaction--diffusion equations. Subsequent articles will treat further classes of equations, including equations of Burgers-type and quasi-linear problems, using the same approach. Our toolkit includes a novel theory of hypercontractive singular integral operators (SIOs) on weighted $Z$-spaces and a self-improving property for super-linear reverse H\u00f6lder inequalities.", "AI": {"tldr": "The paper establishes well-posedness of weak solutions for nonlinear parabolic PDEs with rough coefficients and initial data in critical Besov spaces, without smallness conditions, using weighted Z-spaces and novel SIO theory.", "motivation": "To develop a robust theory for nonlinear parabolic PDEs with rough coefficients and rough initial data in critical homogeneous Besov spaces, overcoming the limitations of smallness conditions typically required in such analyses.", "method": "Uses maximal weak solutions in weighted Z-spaces, develops novel theory of hypercontractive singular integral operators on weighted Z-spaces, and employs self-improving property for super-linear reverse H\u00f6lder inequalities.", "result": "Establishes existence and uniqueness of maximal weak solutions for nonlinear parabolic PDEs with rough coefficients and rough initial data in critical Besov spaces without requiring smallness conditions.", "conclusion": "The developed framework successfully handles rough reaction-diffusion equations and provides a foundation for treating other classes of equations (Burgers-type, quasi-linear problems) in subsequent work using the same approach."}}
{"id": "2601.05130", "pdf": "https://arxiv.org/pdf/2601.05130", "abs": "https://arxiv.org/abs/2601.05130", "authors": ["Rishabh S. Gvalani", "Lukas Koch"], "title": "Sparsity and uniform regularity for regularised optimal transport", "categories": ["math.AP"], "comment": "27 pages, no figures", "summary": "We consider regularised quadratic optimal transport with subquadratic polynomial or entropic regularisation. In both cases, we prove interior Lipschitz-estimates on a transport-like map and interior gradient Lipschitz-estimates on the potentials, under the assumption that the transport map solving the unregularised problem is bi-$C^{1,\u03b1}$-regular. For strictly subquadratic and entropic regularisation, the estimates improve to interior $C^1$ and $C^2$ estimates for the transport-like map and the potentials, respectively. Our estimates are uniform in the regularisation parameter. As a consequence of this, we obtain convergence of the transport-like map (resp. the potentials) to the unregularised transport map (resp. Kantorovich potentials) in $C^{0,1-}_{\\mathrm{loc}}$ (resp. $C^{1,1-}_{\\mathrm{loc}}$).\n  Central to our approach are sharp local bounds on the size of the support for regularised optimal transport which we derive for a general convex, superlinear regularisation term. These bounds are of independent interest and imply global bias bounds for the regularised transport plans. Our global bounds, while not necessarily sharp, improve on the best known results in the literature for quadratic regularisation.", "AI": {"tldr": "The paper proves interior regularity estimates for regularized optimal transport with subquadratic polynomial or entropic regularization, showing uniform convergence to unregularized solutions.", "motivation": "To establish interior regularity estimates for regularized optimal transport problems that are uniform in the regularization parameter, enabling convergence analysis of regularized solutions to unregularized ones.", "method": "The authors develop sharp local bounds on support size for regularized optimal transport with general convex, superlinear regularization. They prove interior Lipschitz estimates for transport-like maps and gradient Lipschitz estimates for potentials, assuming the unregularized transport map is bi-C^{1,\u03b1}-regular.", "result": "For subquadratic polynomial or entropic regularization: interior Lipschitz estimates on transport-like maps and gradient Lipschitz estimates on potentials. For strictly subquadratic and entropic regularization: improved interior C\u00b9 and C\u00b2 estimates respectively. All estimates are uniform in regularization parameter, leading to convergence of regularized solutions to unregularized ones in appropriate local H\u00f6lder spaces.", "conclusion": "The paper establishes uniform interior regularity estimates for regularized optimal transport, with applications to convergence analysis. The derived support bounds are of independent interest and improve existing global bias bounds for quadratic regularization."}}
