<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 16]
- [math.AP](#math.AP) [Total: 15]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 8]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [math.CV](#math.CV) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [math.DG](#math.DG) [Total: 2]
- [q-bio.OT](#q-bio.OT) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [hep-ex](#hep-ex) [Total: 1]
- [math-ph](#math-ph) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Scattered Data Histopolation in Averaging Kernel Hilbert Spaces](https://arxiv.org/abs/2601.07967)
*Ludovico Bruni Bruno,Giacomo Cappellazzo,Wolfgang Erb,Mohammad Karimnejad Esfahani*

Main category: math.NA

TL;DR: The paper introduces averaging kernel Hilbert spaces (AKHS's) as a kernel-based framework for histopolation problems where data consists of interval averages rather than pointwise samples.


<details>
  <summary>Details</summary>
Motivation: Histopolation problems involve reconstructing functions from interval averages rather than pointwise samples, which occurs in many practical applications. Classical interpolation requires continuity, but histopolation can work in larger function spaces. Kernel methods provide a flexible mathematical framework for addressing these problems.

Method: The authors introduce averaging kernel Hilbert spaces (AKHS's) as a kernel-based framework for histopolation. They develop systematic construction principles for averaging kernels and provide characterizations based on the Fourier-Plancherel transform. They analyze histopolation scenarios to study properties like unisolvence and error estimates.

Result: The paper presents a mathematical framework for histopolation using AKHS's, including construction principles, Fourier-based characterizations, analysis of histopolation scenarios with conditions for unisolvence and error estimates, and numerical experiments demonstrating convergence behavior and practical effectiveness.

Conclusion: Kernel-based methods using averaging kernel Hilbert spaces provide an effective mathematical framework for histopolation problems, offering systematic construction principles, theoretical characterizations, and practical numerical performance for reconstructing functions from interval averages.

Abstract: Kernel-based methods offer a powerful and flexible mathematical framework for addressing histopolation problems. In histopolation, the available input data does not consist of pointwise function samples but of averages taken over intervals or higher-dimensional regions, and these mean values serve as a basis for reconstructing or approximating the target function. While classical interpolation requires continuity of the underlying function, histopolation can be performed in larger function spaces. In the framework of kernel methods, we will introduce and study the so-called averaging kernel Hilbert spaces (AKHS's) for this purpose. Within this setting, we develop systematic construction principles for averaging kernels and provide characterizations based on the Fourier-Plancherel transform. In addition, we analyze several representative histopolation scenarios in order to highlight properties of this approximation method, including conditions for unisolvence and possible error estimates. Finally, we present numerical experiments that shed some light on the convergence behavior of the presented approach and demonstrate its practical effectiveness.

</details>


### [2] [Operator learning for models of tear film breakup](https://arxiv.org/abs/2601.08001)
*Qinying Chen,Arnab Roy,Tobin A. Driscoll*

Main category: math.NA

TL;DR: Neural operator learning replaces computationally expensive inverse solvers for tear film analysis from fluorescence imaging, enabling rapid data-driven assessment of tear film dynamics.


<details>
  <summary>Details</summary>
Motivation: Traditional methods for estimating tear film thickness and osmolarity from fluorescence imaging require solving computationally expensive inverse problems, which limits practical clinical application and analysis speed.

Method: Proposed an operator learning framework that replaces traditional inverse solvers with neural operators trained on simulated tear film dynamics data.

Result: The approach provides a scalable solution for rapid, data-driven analysis of tear film dynamics, overcoming computational bottlenecks of traditional methods.

Conclusion: Neural operator learning offers a practical alternative to computationally intensive inverse problem solving for tear film analysis, potentially enabling faster clinical assessment of dry eye disease.

Abstract: Tear film (TF) breakup is a key driver of understanding dry eye disease, yet estimating TF thickness and osmolarity from fluorescence (FL) imaging typically requires solving computationally expensive inverse problems. We propose an operator learning framework that replaces traditional inverse solvers with neural operators trained on simulated TF dynamics. This approach offers a scalable path toward rapid, data-driven analysis of tear film dynamics.

</details>


### [3] [A Structure-Preserving Penalization Method for the Single-species Rosenbluth-Fokker-Planck Equation](https://arxiv.org/abs/2601.08006)
*Hamad El Kahza,Luis Chacón,William Taitano,Jingmei Qiu,Jingwei Hu*

Main category: math.NA

TL;DR: A structure-preserving penalization scheme for the stiff Rosenbluth-Fokker-Planck equation that conserves mass, momentum, energy, and preserves positivity with unconditional stability.


<details>
  <summary>Details</summary>
Motivation: The Rosenbluth-Fokker-Planck equation is crucial for modeling Coulomb collisions in plasmas but is numerically challenging due to nonlinearity, stiffness, and the need to preserve structural properties like conservation laws and entropy dissipation.

Method: Three novel components: 1) Generalized Chang-Cooper discretization for equilibrium preservation and positivity while conserving mass, momentum, energy; 2) Isotropic variable-coefficient penalization operator for temporal stiffness without full implicitness; 3) Adaptive timestepping strategy for positivity preservation.

Result: The scheme strictly conserves mass, momentum, and energy, is unconditionally stable, and robustly positivity preserving. Demonstrated successfully with linear/nonlinear anisotropic diffusion examples and single-species RFP cases.

Conclusion: The proposed structure-preserving penalization scheme effectively handles the numerical challenges of the stiff RFP equation while maintaining essential physical properties, providing a reliable computational tool for plasma physics simulations.

Abstract: The Rosenbluth-Fokker-Planck (RFP) equation describes Coulomb collisional dynamics within and across species in plasmas. It belongs to the broader class of anisotropic-diffusion-advection equations, whose numerical approximation is highly-nontrivial due to its nonlinearity, stiffness, and structural properties such as conservation and entropy dissipation (hence with the Maxwellian distribution as the equilibrium state). In this paper, we propose a structure-preserving penalization scheme for the stiff, single-species RFP equation. The scheme features three novel components: 1) a novel generalization of the well-known Chang-Cooper discretization for the RFP equation that is equilibrium-preserving and enables positivity while preserving mass, momentum, and energy; 2) an easy-to-invert isotropic variable-coefficient penalization operator to deal with the temporal stiffness without resorting to a fully implicit scheme, borrowing ideas from explicit-implicit-null (EIN) methods, and 3) an adaptive timestepping strategy that preserves the positivity of the full penalized scheme. The resulting scheme conserves mass, momentum, and energy strictly, is unconditionally stable, and robustly positivity preserving. The scheme is demonstrated with linear and nonlinear anisotropic diffusion examples of increasing complexity, including several single-species RFP examples.

</details>


### [4] [Reliable eigenspace error estimation using source error estimators](https://arxiv.org/abs/2601.08051)
*Jay Gopalakrishnan,Gabriel Pinochet-Soto*

Main category: math.NA

TL;DR: A framework for repurposing error estimators from source problems to compute estimators for the gap between eigenspaces and their discretizations, applicable to nonselfadjoint operators with compact resolvent.


<details>
  <summary>Details</summary>
Motivation: To develop computable error estimators for eigenspace approximations of nonselfadjoint operators, enabling adaptive refinement that targets eigenvalue clusters as a whole rather than individual eigenfunctions.

Method: Repurposes existing error estimators for source problems to bound eigenspace approximation gaps. Requires convergence of resolvent approximations in operator norm and global reliability of source problem estimators. Applied to FOSLS and DPG discretizations.

Result: Theoretical framework shows eigenspace gap can be bounded by globally reliable and computable error estimators. Numerical experiments demonstrate adaptive algorithms using new estimators target eigenvalue clusters as a whole.

Conclusion: The framework successfully enables adaptive refinement for eigenspace approximations of nonselfadjoint operators, with applications to FOSLS and DPG discretizations yielding practical error estimators.

Abstract: We introduce a framework for repurposing error estimators for source problems to compute an estimator for the gap between eigenspaces and their discretizations. Of interest are eigenspaces of finite clusters of eigenvalues of unbounded nonselfadjoint linear operators with compact resolvent. Eigenspaces and eigenvalues of rational functions of such operators are studied as a first step. Under an assumption of convergence of resolvent approximations in the operator norm and an assumption on global reliability of source problem error estimators, we show that the gap in eigenspace approximations can be bounded by a globally reliable and computable error estimator. Also included are applications of the theoretical framework to first-order system least squares (FOSLS) discretizations and discontinuous Petrov-Galerkin (DPG) discretizations, both yielding new estimators for the error gap. Numerical experiments with a selfadjoint model problem and with a leaky nonselfadjoint waveguide eigenproblem show that adaptive algorithms using the new estimators give refinement patterns that target the cluster as a whole instead of individual eigenfunctions.

</details>


### [5] [Numerical analysis of spatiotemporal high-index saddle dynamics for finding multiple solutions of semilinear elliptic problems](https://arxiv.org/abs/2601.08188)
*Lei Zhang,Xiangcheng Zheng,Shangqin Zhu*

Main category: math.NA

TL;DR: A rigorous numerical framework for computing multiple solutions of semilinear elliptic problems using spatiotemporal high-index saddle dynamics with full space-time accuracy analysis.


<details>
  <summary>Details</summary>
Motivation: To develop a rigorous numerical method for finding multiple solutions of semilinear elliptic problems, extending traditional saddle dynamics to continuous-in-space settings while preserving mathematical properties.

Method: Spatiotemporal high-index saddle dynamics (HiSD) with fully discrete retraction-free orthonormality-preserving scheme that explicitly incorporates spatial differential operators and avoids analytical complications of retraction-based updates.

Result: Established gradient stability and error estimates, ensuring preservation of Morse index for computed saddle points. Successfully applied to semilinear elliptic problems and extended to advection-reaction-diffusion equations.

Conclusion: The framework provides first rigorous full space-time accuracy analysis of HiSD, revealing connections between saddle-search algorithms and PDE numerical methods, enhancing compatibility for broad problem classes.

Abstract: This paper presents a rigorous numerical framework for computing multiple solutions of semilinear elliptic problems by spatiotemporal high-index saddle dynamics (HiSD), which extends the traditional HiSD to the continuous-in-space setting, explicitly incorporating spatial differential operators. To enforce the Stiefel manifold constraint without introducing the analytical complications of retraction-based updates, we design a fully discrete retraction-free orthonormality-preserving scheme for spatiotemporal HiSD. This scheme exhibits favorable structural properties that substantially reduce the difficulties arising from coupling and gradient nonlinearities in spatiotemporal HiSD. Exploiting these properties, we establish gradient stability and error estimates, which consequently ensure the preservation of the Morse index for the computed saddle points. The framework is further extended to the semilinear advection-reaction-diffusion equation. Numerical experiments demonstrate the efficiency of the proposed method in finding multiple solutions and constructing the solution landscape of semilinear elliptic problems. To the best of our knowledge, this work presents the first rigorous full space--time accuracy analysis of the HiSD system. It reveals intrinsic connections between saddle-search algorithms and numerical methods for PDEs, enhancing their mutual compatibility for a broad range of problems.

</details>


### [6] [Second-Generation Wavelet-inspired Tensor Product with Applications in Hyperspectral Imaging](https://arxiv.org/abs/2601.08228)
*Aneesh Panchal,Ratikanta Behera*

Main category: math.NA

TL;DR: The paper introduces the w-product, a wavelet-based tensor multiplication scheme that achieves linear transformation complexity while preserving algebraic properties, enabling fast tensor decompositions with significant speedups over existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing tensor multiplication approaches have high computational complexity, limiting their scalability for multidimensional data analysis. There's a need for faster, more efficient tensor operations that maintain essential algebraic properties for practical applications like hyperspectral image processing.

Method: The paper proposes the w-product, a novel wavelet-based tensor multiplication scheme using second-generation wavelet transforms. It introduces w-svd and its sparse variant sp-w-svd for efficient low-rank approximations, and discusses the Moore-Penrose inverse of tensors based on the w-product.

Result: Experiments show up to 92.21x speedup for low-rank hyperspectral image reconstruction compared to state-of-the-art t-svd, with comparable PSNR and SSIM metrics. Hyperspectral image deblurring shows up to 27.88x speedup with improved image quality. The w-product exhibits exponentially increasing acceleration with decomposition level compared to traditional t-product.

Conclusion: The w-product provides a scalable framework for multidimensional data analysis with significant computational advantages. Future research directions include adaptive wavelet designs, higher-order tensor extensions, and real-time implementations.

Abstract: This paper introduces the $w$-product, a novel wavelet-based tensor multiplication scheme leveraging second-generation wavelet transforms to achieve linear transformation complexity while preserving essential algebraic properties. The $w$-product outperforms existing tensor multiplication approaches by enabling fast and numerically stable tensor decompositions by proposing ``$w$-svd'' and its sparse variant ``sp-$w$-svd'', for efficient low-rank approximations with significantly reduced computational costs. Experiments on low-rank hyperspectral image reconstruction demonstrate up to a $92.21$ times speedup compared to state-of-the-art ``$t$-svd'', with comparable PSNR and SSIM metrics. We discuss the Moore-Penrose inverse of tensors based on the $w$-product and examine its essential properties. Numerical examples are provided to support the theoretical results. Then, hyperspectral image deblurring experiments demonstrate up to $27.88$ times speedup with improved image quality. In particular, the $w$-product and the sp-$w$-product exhibit exponentially increasing acceleration with the decomposition level compared to the traditional approach of the $t$-product. This work provides a scalable framework for multidimensional data analysis, with future research directions including adaptive wavelet designs, higher-order tensor extensions, and real-time implementations.

</details>


### [7] [A multi-mesh adaptive finite element method for solving the Gross-Pitaevskii equation](https://arxiv.org/abs/2601.08299)
*Mingzhe Li,Yang Kuang,Zhicheng Hu*

Main category: math.NA

TL;DR: Multi-mesh adaptive FEM for Gross-Pitaevskii equation reduces computational cost by using separate meshes for different solution components instead of a single adaptive mesh.


<details>
  <summary>Details</summary>
Motivation: GPE wave functions vary significantly across spatial regions - some components are sharp/oscillatory while others are smooth. Using a single adaptive mesh leads to excessive computational costs because it must accommodate the most oscillatory solution everywhere.

Method: 1) Convert GPE to time-dependent equation via imaginary time propagation method. 2) Temporal discretization using backward Euler method. 3) Spatial discretization using multi-mesh adaptive finite element method (different meshes for different solution components).

Result: Numerical experiments show the multi-mesh adaptive method achieves same numerical accuracy as single-mesh adaptive method but with less computational consumption.

Conclusion: Multi-mesh adaptive FEM is an efficient approach for solving GPE problems where wave functions exhibit different spatial variation characteristics, providing computational savings while maintaining accuracy.

Abstract: It is found that the wave functions of the Gross-Pitaevskii equation (GPE) often vary significantly in different spatial regions, with some components exhibiting sharp variations while others remain smooth. Solving the GPE on a single mesh, even with adaptive refinement, can lead to excessive computational costs due to the need to accommodate the most oscillatory solution. To address this issue, we present a multi-mesh adaptive finite element method for solving the GPE. To this end, we first convert it into a time-dependent equation through the imaginary time propagation method. Then the equation is discretized by the backward Euler method temporally and the multi-mesh adaptive finite element method spatially. The proposed method is compared with the single-mesh adaptive method through a series of numerical experiments, which demonstrate that the multi-mesh adaptive method can achieve the same numerical accuracy with less computational consumption.

</details>


### [8] [A whole-brain model of amyloid beta accumulation and cerebral hypoperfusion in Alzheimer's disease](https://arxiv.org/abs/2601.08478)
*Mattia Corti,Andrew Ahern,Alain Goriely,Ellen Kuhl,Paola F. Antonietti*

Main category: math.NA

TL;DR: A whole-brain model coupling amyloid beta pathology and cerebrovascular dynamics shows that multistability exists in Alzheimer's disease, requiring a critical pathogenic seed size to trigger disease outbreak, and localized hypoperfusion can destabilize healthy states.


<details>
  <summary>Details</summary>
Motivation: To understand the mutual reinforcement between amyloid beta accumulation and cerebrovascular pathology in Alzheimer's disease, particularly how amyloid beta suppresses perfusion and hypoperfusion promotes amyloid beta production.

Method: Developed a hybrid whole-brain model combining reaction-diffusion system for amyloid beta protein dynamics with porous-medium model of blood flow across arterial, capillary and venous networks. Used high-order discontinuous Galerkin method for spatial discretization and implicit Euler scheme for time integration.

Result: Simulations in realistic brain geometries revealed multistability, indicating a critical threshold of pathogenic protein seeds is required to trigger disease outbreak. Localized hypoperfusion (as per the "two-hit vascular hypothesis") can destabilize healthy steady states and trigger brain-wide disease spread.

Conclusion: The model demonstrates how amyloid beta and cerebrovascular pathology form a vicious cycle in Alzheimer's disease, with multistability explaining why sufficient pathogenic seeds or vascular insults are needed to trigger disease progression.

Abstract: Accumulation of amyloid beta proteins is a defining feature of Alzheimer's disease, and is usually accompanied by cerebrovascular pathology. Evidence suggests that amyloid beta and cerebrovascular pathology are mutually reinforcing; in particular, amyloid beta suppresses perfusion by constricting capillaries, and hypoperfusion promotes the production of amyloid beta. Here, we propose a whole-brain model coupling amyloid beta and blood vessel through a hybrid model consisting of a reaction-diffusion system for the protein dynamics and porous-medium model of blood flow within and between vascular networks: arterial, capillary and venous. We discretize the resulting parabolic--elliptic system of PDEs by means of a high-order discontinuous Galerkin method in space and an implicit Euler scheme in time. Simulations in realistic brain geometries demonstrate the emergence of multistability, implying that a sufficiently large pathogenic protein seeds is necessary to trigger disease outbreak. Motivated by the "two-hit vascular hypothesis" of Alzheimer's disease that hypoperfusive vascular damage triggers amyloid beta pathology, we also demonstrate that localized hypoperfusion, in response to injury, can destabilize the healthy steady state and trigger brain-wide disease outbreak.

</details>


### [9] [A Structure Preserving Finite Volume Scheme for the Navier-Stokes-Korteweg Equations](https://arxiv.org/abs/2601.08498)
*Jan Giesselmann,Philipp Öffner,Robert Sauerborn*

Main category: math.NA

TL;DR: Semi-discrete finite volume scheme for Navier-Stokes-Korteweg/Euler-Korteweg systems that conserves mass/momentum and is energy stable, with first-order convergence.


<details>
  <summary>Details</summary>
Motivation: Existing methods for these systems often use approximations or extended systems; this work aims to develop a scheme that works directly on the original system while maintaining conservation properties and stability.

Method: Semi-discrete finite volume scheme applicable to equidistant Cartesian meshes in 1D and 2D, operating directly on the original Navier-Stokes-Korteweg/Euler-Korteweg systems without approximations or auxiliary variables.

Result: The scheme conserves mass and momentum, is energy stable, and numerical experiments show first-order convergence with both explicit and implicit time discretization.

Conclusion: The proposed finite volume scheme provides a direct, stable, and conservative approach for solving Korteweg-type fluid systems with proven theoretical properties and demonstrated numerical performance.

Abstract: We present a semi-discrete finite volume scheme for the local NavierStokes-Korteweg and Euler-Korteweg systems. Our scheme is applicable for equidistant Cartesian meshes in one and two space dimensions. In contrast to other works, which employ, for example, hyperbolic approximations of the equations or auxiliary-variable approaches leading to extended systems, our scheme operates directly on the original system. We prove that it conserves mass and momentum and is energy stable. Numerical experiments complement our theoretical findings, showing that the scheme is convergent of order one if employed with explicit or implicit time discretisation.

</details>


### [10] [Sampling via Stochastic Interpolants by Langevin-based Velocity and Initialization Estimation in Flow ODEs](https://arxiv.org/abs/2601.08527)
*Chenguang Duan,Yuling Jiao,Gabriele Steidl,Christian Wald,Jerry Zhijian Yang,Ruizhe Zhang*

Main category: math.NA

TL;DR: Proposes a novel sampling method for unnormalized Boltzmann densities using probability-flow ODEs with linear stochastic interpolants, enhanced by Langevin samplers for efficient simulation.


<details>
  <summary>Details</summary>
Motivation: Need efficient methods for sampling from complex, multimodal unnormalized Boltzmann distributions, which are challenging for traditional sampling techniques, especially in Bayesian inference applications.

Method: Uses probability-flow ODE derived from linear stochastic interpolants, enhanced by a sequence of Langevin samplers to: (1) generate samples from interpolant distribution at intermediate times, and (2) construct robust estimators of the velocity field governing the flow ODE.

Result: Establishes convergence guarantees for both applications of Langevin diffusions. Extensive numerical experiments show efficiency on challenging multimodal distributions across various dimensions and effectiveness in Bayesian inference tasks.

Conclusion: The proposed method provides an effective and theoretically-grounded approach for sampling from complex unnormalized distributions, with proven convergence properties and demonstrated practical performance on challenging problems.

Abstract: We propose a novel method for sampling from unnormalized Boltzmann densities based on a probability-flow ordinary differential equation (ODE) derived from linear stochastic interpolants. The key innovation of our approach is the use of a sequence of Langevin samplers to enable efficient simulation of the flow. Specifically, these Langevin samplers are employed (i) to generate samples from the interpolant distribution at intermediate times and (ii) to construct, starting from these intermediate times, a robust estimator of the velocity field governing the flow ODE. For both applications of the Langevin diffusions, we establish convergence guarantees. Extensive numerical experiments demonstrate the efficiency of the proposed method on challenging multimodal distributions across a range of dimensions, as well as its effectiveness in Bayesian inference tasks.

</details>


### [11] [A note on condition numbers for generalized inverse C^‡_A and their statistical estimation](https://arxiv.org/abs/2601.08553)
*Mahvish Samar,Abdual Shahkoor*

Main category: math.NA

TL;DR: The paper analyzes condition numbers for generalized inverse C^‡_A, derives explicit expressions for normwise and componentwise condition numbers, and develops estimation algorithms with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous analysis of condition numbers for the generalized inverse C^‡_A, which has applications in indefinite least squares problems with equality constraints, enabling better understanding of numerical stability and reliability.

Method: Derived explicit expressions for normwise mixed and componentwise condition numbers using classical methods without Kronecker products; developed three estimation algorithms using probabilistic spectral norm estimator and small-sample statistical condition estimation.

Result: Obtained explicit formulas for condition numbers, recovered expressions for indefinite least squares problems, and created reliable estimation algorithms validated through numerical experiments.

Conclusion: The paper successfully establishes comprehensive condition number analysis for generalized inverse C^‡_A, provides practical estimation methods, and demonstrates applicability to indefinite least squares problems with numerical verification.

Abstract: In this paper, we consider the condition number for the generalized inverse C^‡_A. We first present the explicit expression of normwise mixed and componentwise condition numbers. Then, we derive the explicit expression of normwise condition number without Kronecker product using the classical method for condition numbers. With the intermediate result, i.e., the derivative of C^‡_A, we can recover the explicit expressions of condition numbers for solution of Indefinite least squares problem with equality constraint. To estimate these condition numbers with high reliability, we choose the probabilistic spectral norm estimator and the small-sample statistical condition estimation method and devise three algorithms. Numerical experiments are provided to illustrate the obtained results

</details>


### [12] [Sampling recovery on classes defined by integral operators and sparse approximation with adaptive dictionaries](https://arxiv.org/abs/2601.08561)
*V. Temlyakov*

Main category: math.NA

TL;DR: The paper studies asymptotic error behavior of sampling recovery for collections of smoothness classes defined by integral operators, connecting it to sparse approximation with adaptive dictionaries.


<details>
  <summary>Details</summary>
Motivation: To develop a general approach for studying sampling recovery errors not for individual smoothness classes (as traditionally done), but for collections of classes defined by integral operators with kernels from a given function class.

Method: Extends previous work on Kolmogorov widths and entropy numbers to sampling recovery, establishing connections between sampling recovery problems and sparse nonlinear approximation with adaptive dictionaries.

Result: The sampling recovery problem is shown to be closely related to sparse approximation with respect to adaptive dictionaries, where the dictionary depends on the function being approximated.

Conclusion: The paper establishes a connection between asymptotic error analysis of sampling recovery for collections of smoothness classes and sparse approximation theory with adaptive dictionaries, extending previous width-based approaches.

Abstract: In this paper we continue to develop the following general approach. We study asymptotic behavior of the errors of sampling recovery not for an individual smoothness class, how it is usually done, but for the collection of classes, which are defined by integral operators with kernels coming from a given class of functions. Earlier, such approach was realized for the Kolmogorov widths and very recently for the entropy numbers. It turns out that the above problem is closely related to the sparse approximation problem with respect to different redundant dictionaries. Specifically, the problem of sampling recovery is connected with sparse nonlinear approximation with respect to adaptive dictionaries, which means that the dictionary depends on the function under approximation.

</details>


### [13] [Differentiating through Stochastic Differential Equations: A Primer](https://arxiv.org/abs/2601.08594)
*Rishi Leburu,Levon Nurbekyan,Lars Ruthotto*

Main category: math.NA

TL;DR: A primer on numerical differentiation of stochastic differential equations (SDEs) covering two approaches: discretize-optimize (differentiating through discretized SDEs) and optimize-discretize (continuous limit analysis), with guidance on computing gradients correctly in both Itô and Stratonovich calculus.


<details>
  <summary>Details</summary>
Motivation: Dynamical systems modeling requires parameter sensitivity analysis across physics, finance, economics, and machine learning. While deterministic system differentiation is well-covered, stochastic systems like SDEs present subtle challenges due to noise-discretization interplay that are less comprehensively treated in curricula.

Method: Two-tale narrative approach: Tale 1 examines discretize-optimize approach (differentiating through discretized SDEs), Tale 2 investigates optimize-discretize approach (continuous limit of backward equations). The paper provides guidance on computing gradients correctly in both Itô and Stratonovich settings.

Result: The discretize-optimize approach is reliable for both Itô and Stratonovich calculus. The paper clarifies when discretize-optimize and optimize-discretize approaches agree or diverge, and develops intuition for reasoning about stochastic differentiation beyond explicitly covered cases.

Conclusion: Provides a clear guide for numerical differentiation of SDEs, equipping readers with understanding of gradient computation in stochastic settings, comparison of different approaches, and intuition for reasoning about stochastic differentiation in various applications.

Abstract: Dynamical systems are essential to model various phenomena in physics, finance, economics, and are also of current interest in machine learning. A central modeling task is investigating parameter sensitivity, whether tuning atmospheric coefficients, computing financial Greeks, or optimizing neural networks. These sensitivities are mathematically expressed as derivatives of an objective function with respect to parameters of interest and are rarely available analytically, necessitating numerical methods for approximating them. While the literature for differentiation of deterministic systems is well-covered, the treatment of stochastic systems, such as stochastic differential equations (SDEs), in most curricula is less comprehensive than the subtleties arising from the interplay of noise and discretization require.
  This paper provides a primer on numerical differentiation of SDEs organized as a two-tale narrative. Tale 1 demonstrates differentiating through discretized SDEs, known the discretize-optimize approach, is reliable for both Itô and Stratonovich calculus. Tale 2 examines the optimize-discretize approach, investigating the continuous limit of backward equations from Tale 1 corresponding to the desired gradients. Our aim is to equip readers with a clear guide on the numerical differentiation of SDEs: computing gradients correctly in both Itô and Stratonovich settings, understanding when discretize-optimize and optimize-discretize agree or diverge, and developing intuition for reasoning about stochastic differentiation beyond the cases explicitly covered.

</details>


### [14] [Multi-Preconditioned LBFGS for Training Finite-Basis PINNs](https://arxiv.org/abs/2601.08709)
*Marc Salvadó-Benasco,Aymane Kssim,Alexander Heinlein,Rolf Krause,Serge Gratton,Alena Kopaničáková*

Main category: math.NA

TL;DR: MP-LBFGS algorithm improves training of physics-informed neural networks with domain decomposition by combining local quasi-Newton corrections through optimal subspace minimization.


<details>
  <summary>Details</summary>
Motivation: To enhance training efficiency and accuracy of finite-basis physics-informed neural networks (FBPINNs) by exploiting their domain-decomposition architecture and reducing communication overhead compared to standard LBFGS.

Method: Multi-preconditioned LBFGS algorithm inspired by nonlinear additive Schwarz method; constructs parallel, subdomain-local quasi-Newton corrections on local neural networks; uses novel nonlinear multi-preconditioning mechanism to optimally combine corrections through low-dimensional subspace minimization.

Result: MP-LBFGS improves convergence speed and model accuracy over standard LBFGS while incurring lower communication overhead, as demonstrated in numerical experiments.

Conclusion: The proposed MP-LBFGS algorithm effectively leverages the domain-decomposition structure of FBPINNs to achieve better training performance with reduced communication costs compared to conventional optimization methods.

Abstract: A multi-preconditioned LBFGS (MP-LBFGS) algorithm is introduced for training finite-basis physics-informed neural networks (FBPINNs). The algorithm is motivated by the nonlinear additive Schwarz method and exploits the domain-decomposition-inspired additive architecture of FBPINNs, in which local neural networks are defined on subdomains, thereby localizing the network representation. Parallel, subdomain-local quasi-Newton corrections are then constructed on the corresponding local parts of the architecture. A key feature is a novel nonlinear multi-preconditioning mechanism, in which subdomain corrections are optimally combined through the solution of a low-dimensional subspace minimization problem. Numerical experiments indicate that MP-LBFGS can improve convergence speed, as well as model accuracy over standard LBFGS while incurring lower communication overhead.

</details>


### [15] [Convergence analysis and adaptive computation of a Banach-space mixed finite element method for generalized bioconvective flows](https://arxiv.org/abs/2601.08759)
*Eligio Colmenares,Ricardo Ruiz-Baier,Dalidet Sanhueza*

Main category: math.NA

TL;DR: Adaptive mixed finite element method for bioconvective flows with concentration-dependent viscosity, featuring auxiliary variables, Banach space formulation, optimal convergence rates, and reliable/efficient a posteriori error estimator.


<details>
  <summary>Details</summary>
Motivation: To develop a robust numerical method for modeling bioconvective flows where swimming microorganisms affect fluid viscosity, requiring accurate treatment of coupled Navier-Stokes equations with concentration-dependent viscosity and microorganism conservation laws.

Method: Mixed finite element method with auxiliary variables (trace-free velocity gradient, symmetric pseudo-stress tensor, concentration gradient, semi-advective microorganism flux), Banach space formulation, Raviart--Thomas elements on macroelement-structured meshes, fixed-point operator approach, and residual-based a posteriori error estimation.

Result: Existence/uniqueness proofs via Schauder/Brouwer theorems, optimal a priori convergence rates, reliable/efficient a posteriori error estimator using inf-sup conditions and Helmholtz decompositions, numerical validation in 2D/3D showing adaptive refinement effectiveness for singular solutions and complex geometries.

Conclusion: The developed adaptive mixed finite element method successfully handles generalized bioconvective flows with concentration-dependent viscosity, providing rigorous mathematical foundations, optimal convergence, and effective adaptive capabilities for complex biological flow simulations.

Abstract: We develop and analyse an adaptive fully mixed finite element method for stationary generalized bioconvective flows, where the Navier--Stokes equations with concentration-dependent viscosity are coupled with a conservation law for swimming microorganisms. The formulation introduces auxiliary variables including the trace-free velocity gradient, a symmetric pseudo-stress tensor, the concentration gradient, and a semi-advective microorganism flux, which also allows for a consistent treatment of Robin-type boundary condition. The variational problem is posed within a Banach space framework and reformulated as a fixed-point operator. Existence of solutions follows from Schauder's theorem, while uniqueness is obtained under suitable data assumptions. The discrete problem is constructed using Raviart--Thomas finite element spaces together with piecewise polynomial approximations on macroelement-structured meshes, and existence of discrete solutions is established via Brouwer's theorem. An a priori error analysis yields optimal convergence rates. We further derive a residual-based a posteriori error estimator and prove its reliability using global inf-sup conditions, Helmholtz decompositions, and suitable projection operators, while efficiency is ensured through localization techniques and bubble functions. Numerical experiments in two and three dimensions confirm the theoretical results, demonstrate the effectiveness of adaptive refinement for singular solutions and complex geometries with inclusions, and illustrate the robustness of the method for a bioconvective benchmark with plume formation governed by an Einstein--Batchelor-type viscosity law.

</details>


### [16] [A survey on sampling recovery](https://arxiv.org/abs/2601.08787)
*F. Dai,V. Temlyakov*

Main category: math.NA

TL;DR: Survey on sampling recovery algorithms, their accuracy, and connections to nonlinear approximation and Kolmogorov widths, highlighting superior performance of nonlinear methods for certain multivariate function classes.


<details>
  <summary>Details</summary>
Motivation: The fundamental challenge of reconstructing unknown functions from finite samples in pure and applied mathematics, and the need to understand relationships between optimal recovery errors, nonlinear approximation, and Kolmogorov widths.

Method: Three algorithmic frameworks: 1) weighted least squares and ℓ_p minimization, 2) sparse approximation methods, and 3) greedy algorithms (WOMP in Hilbert spaces and WCGA in Banach spaces). These are applied to function classes with structural conditions like A_β^r, Wiener-type classes, and Sobolev-type classes with dominated mixed derivatives.

Result: Recent findings show that nonlinear sampling recovery can provide superior error guarantees compared to linear methods for certain multivariate function classes. The survey highlights synergy between universal sampling discretization theory and Lebesgue-type inequalities for greedy algorithms.

Conclusion: Comprehensive overview of sampling recovery developments reveals important connections between algorithmic frameworks, approximation theory concepts, and the advantage of nonlinear methods over linear approaches for specific multivariate function classes.

Abstract: The reconstruction of unknown functions from a finite number of samples is a fundamental challenge in pure and applied mathematics. This survey provides a comprehensive overview of recent developments in sampling recovery, focusing on the accuracy of various algorithms and the relationship between optimal recovery errors, nonlinear approximation, and the Kolmogorov widths of function classes. A central theme is the synergy between the theory of universal sampling discretization and Lebesgue-type inequalities for greedy algorithms. We discuss three primary algorithmic frameworks: weighted least squares and $\ell_p$ minimization, sparse approximation methods, and greedy algorithms such as the Weak Orthogonal Matching Pursuit (WOMP) in Hilbert spaces and the Weak Tchebychev Greedy Algorithm (WCGA) in Banach spaces. These methods are applied to function classes defined by structural conditions, like the $A_β^r$ and Wiener-type classes, as well as classical Sobolev-type classes with dominated mixed derivatives. Notably, we highlight recent findings showing that nonlinear sampling recovery can provide superior error guarantees compared to linear methods for certain multivariate function classes.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [17] [The Fractional Korn Inequality on Uniform Domains and New Korn Inequalities for Truncated Seminorms](https://arxiv.org/abs/2601.08096)
*Gabriel Acosta,Irene Drelichman,Ricardo Durán,Fernando López-García,Ignacio Ojea*

Main category: math.AP

TL;DR: The paper proves the second case of fractional Korn inequality for uniform domains using a novel truncated seminorm approach that works for John domains, with weighted estimates involving boundary distance powers.


<details>
  <summary>Details</summary>
Motivation: To establish fractional Korn inequalities for broader classes of domains beyond uniform domains, specifically extending to John domains, and to obtain weighted versions with boundary distance dependence.

Method: Develops a novel fractional Korn-type inequality using truncated seminorms, which enables extension to John domains. Applies this to prove the second case of fractional Korn inequality for uniform domains. Includes weighted estimates with powers of distance to boundary based on fractional exponent and Assouad codimension.

Result: Successfully proves the second case of fractional Korn inequality for uniform domains. Establishes a more general fractional Korn-type inequality valid for John domains. Obtains weighted estimates with boundary distance dependence.

Conclusion: The truncated seminorm approach provides a powerful framework for extending fractional Korn inequalities to broader domain classes (John domains), with applications to uniform domains and weighted estimates that incorporate geometric boundary properties.

Abstract: We prove the so-called second case of the fractional Korn inequality for uniform domains. We obtain this result as an application of a novel fractional Korn-type inequality formulated in terms of truncated seminorms, which turns out to be valid for the broader class of John domains. We also obtain weighted estimates in which the weights are certain powers of the distance to the boundary that depend on the fractional exponent and the Assouad codimension of the boundary of the domain.

</details>


### [18] [Generalized Pohozhaev's identity for radial solutions of $p$-Laplace equations](https://arxiv.org/abs/2601.08098)
*Philip Korman*

Main category: math.AP

TL;DR: Generalized Pohozhaev identity for radial p-Laplace equations using approach from reference [5], extending Brezis-Nirenberg work on Laplace equation.


<details>
  <summary>Details</summary>
Motivation: To extend the Pohozhaev identity (originally developed for Laplace equations by Brezis and Nirenberg) to the more general p-Laplace equations for radial solutions.

Method: Using the approach from reference [5] to derive a generalized Pohozhaev identity specifically for radial solutions of p-Laplace equations.

Result: Successfully derived a generalized Pohozhaev identity applicable to radial solutions of p-Laplace equations.

Conclusion: Extended the work of Brezis and Nirenberg on Pohozhaev identities from Laplace equations to the broader class of p-Laplace equations for radial solutions.

Abstract: We derive a generalized Pohozhaev's identity for radial solutions of $p$-Laplace equations, by using the approach in [5], thus extending the work of H. Brézis and L. Nirenberg [2], where this identity was implicitly used for the Laplace equation.

</details>


### [19] [Global Existence for General Systems of Isentropic Gas Dynamics via a Weighted Pressure Perturbation Approach](https://arxiv.org/abs/2601.08157)
*Kewang Chen*

Main category: math.AP

TL;DR: Global existence of bounded entropy solutions for 1D isentropic gas dynamics with general pressure laws and vacuum states, using a novel weighted pressure regularization that preserves mass conservation.


<details>
  <summary>Details</summary>
Motivation: To establish global existence of bounded entropy solutions for compressible Euler equations with general pressure laws and vacuum states, overcoming limitations of previous methods that modify continuity equations.

Method: Introduces novel weighted pressure perturbation regularization: $\tilde{P}(ρ,δ) = \int_δ^ρs^{-2}(s^2P'(s) - δ^2 P'(δ)) \, ds$. Preserves mass conservation while creating degenerate hyperbolic boundary at cut-off density $ρ=δ$. Uses vanishing viscosity method with invariant regions for uniform bounds, and compensated compactness theory for vacuum-free limit.

Result: Proves perturbed pressure inherits convexity properties of original state equation ($2\tilde{P}'+ρ\tilde{P}'' = 2P'+ρP''$), ensuring strict convexity of mechanical energy entropy. Establishes uniform $L^\infty$ bounds via invariant regions and $H^{-1}_{\mathrm{loc}}$ compactness of entropy dissipation measures. Proves global existence for vacuum-free limit.

Conclusion: Successfully establishes global existence of bounded entropy solutions for 1D isentropic gas dynamics with general pressure laws and vacuum states using novel regularization that preserves mass conservation and inherits convexity properties, enabling rigorous analysis through compensated compactness.

Abstract: This paper establishes the global existence of bounded entropy solutions to the one-dimensional system of isentropic gas dynamics with general pressure laws, allowing for the presence of vacuum states. We introduce a novel regularization scheme based on a weighted pressure perturbation of the form $\tilde{P}(ρ,δ) = \int_δ^ρs^{-2}(s^2P'(s) - δ^2 P'(δ)) \, ds$. Unlike previous methods that modify the continuity equation, our approach strictly preserves mass conservation while creating a degenerate hyperbolic boundary at the cut-off density $ρ=δ$. We provide a rigorous derivation of the eigenstructure and Riemann invariants for the perturbed system. A key theoretical contribution is the proof that the perturbed pressure exactly inherits the convexity properties of the original state equation ($2\tilde{P}'+ρ\tilde{P}'' = 2P'+ρP''$), thereby ensuring the strict convexity of the mechanical energy entropy without additional assumptions. Using the method of vanishing viscosity, we derive uniform $L^\infty$ bounds via invariant regions and establish the $H^{-1}_{\mathrm{loc}}$ compactness of entropy dissipation measures. The global existence for the vacuum-free limit is then proved using the theory of compensated compactness and singular perturbation analysis of the entropy equations.

</details>


### [20] [Phase-Textured Complex Viscosity in Linear Viscous Flows: Non-Normality Without Advection, Corner Defects, and 3D Mode Coupling](https://arxiv.org/abs/2601.08231)
*Lillian St. Kleess*

Main category: math.AP

TL;DR: The paper analyzes time-harmonic incompressible flow with spatially varying complex viscosity, showing how phase texture creates linear constitutive effects that generate sidebands and non-normal amplification.


<details>
  <summary>Details</summary>
Motivation: To understand how spatially varying complex viscosity in time-harmonic flows creates linear constitutive effects, particularly how phase texture leads to mode coupling and non-normal amplification even without advection.

Method: Mathematical analysis using operator-valued Toeplitz/Laurent coupling for spanwise Fourier modes, m-sectorial operator theory for oscillatory Stokes/Oseen operators, and resolvent geometry to study amplification in non-normal viscous operators.

Result: Spatially varying viscosity phase texture converts uniform forcing into non-uniform harmonic response with sidebands; viscous operators become intrinsically non-normal, making amplification dependent on resolvent geometry rather than eigenvalues alone.

Conclusion: Phase texture in complex viscosity creates fundamental linear constitutive effects in time-harmonic flows, including mode coupling and non-normal amplification, with texture strength quantified by viscosity magnitude times phase gradient.

Abstract: We consider time-harmonic incompressible flow with a spatially resolved complex viscosity field $μ^*(\mathbf{x},ω)$ and, at fixed forcing frequency $ω>0$, its constitutive phase texture $\varphi(\mathbf{x})=\argμ^*(\mathbf{x},ω)$. In three-dimensional domains periodic in a spanwise direction $z$, $z$-dependence of $μ^*$ converts coefficient multiplication into convolution in spanwise Fourier index, yielding an operator-valued Toeplitz/Laurent coupling of modes. Consequently, even spanwise-uniform forcing generically produces $κ\neq 0$ sidebands in the harmonic response as a \emph{linear, constitutive} effect.
  We place $μ^*$ at the closure level $\hat{\boldsymbolτ}=2\,μ^*(\mathbf{x},ω)\mathbf{D}(\hat{\mathbf{v}})$, as the boundary value of the Laplace transform of a causal stress-memory kernel. Under the passivity condition $\Reμ^*(\mathbf{x},ω)\ge μ_{\min}>0$, the oscillatory Stokes/Oseen operators are realized as m-sectorial operators associated with coercive sectorial forms on bounded Lipschitz (including cornered) domains, yielding existence, uniqueness, and frequency-dependent stability bounds.
  Spatial variation of $\varphi$ renders the viscous operator intrinsically non-normal even in the absence of advection, so amplification is governed by resolvent geometry (and associated pseudospectra), not by eigenvalues alone. In the pure-phase class $μ^*(\mathbf{x},ω)=μ_0(ω)e^{i\varphi(\mathbf{x})}$, the texture strength is quantified by $μ_0(ω)\|\nabla\varphi\|_{L^\infty}$.

</details>


### [21] [Electromagnetic Scattering by a Cluster of Hybrid Dielectric-Plasmonic Dimers](https://arxiv.org/abs/2601.08242)
*Xinlin Cao,Ahcene Ghandriche,Mourad Sini*

Main category: math.AP

TL;DR: Derivation of Foldy-Lax approximation for electromagnetic scattering by clusters of hybrid dielectric-plasmonic dimers, showing each dimer behaves as co-located electric and magnetic dipoles with identifiable polarizability matrix.


<details>
  <summary>Details</summary>
Motivation: To develop efficient discrete models for electromagnetic scattering by clusters of hybrid dielectric-plasmonic nanoparticles suitable for fast simulations, inverse problems, and effective-medium descriptions, particularly for generating negative permittivity/permeability and hyperbolic media.

Method: Mathematical analysis of time-harmonic Maxwell scattering by clusters of small hybrid dimers (dielectric+plasmonic nanoparticles) with subwavelength separations. Derivation of Foldy-Lax type approximation using asymptotic expansions near electric and magnetic resonances, with error estimates uniform in dimer count.

Result: Scattered field admits asymptotic expansions in terms of four moments per dimer solving explicit finite-dimensional linear system. Each dimer behaves as co-located electric and magnetic dipole with identifiable 6×6 polarizability matrix. System invertibility proven under contrast and density conditions.

Conclusion: Provides discrete model for hybrid dimer clusters enabling fast simulations, inverse schemes, and effective-medium descriptions. Identifies parameter regimes for generating double-negative materials, bi-anisotropic laws, and hyperbolic media.

Abstract: We consider time-harmonic electromagnetic scattering by a cluster of hybrid dielectric-plasmonic dimers in $\mathbb{R}^3$. Each dimer consists of a high-contrast dielectric nanoparticle and a moderately contrasting plasmonic nanoparticle separated by a subwavelength distance. The cluster is assumed to contain many such dimers whose size $a$ is small compared to the wavelength, with intra-dimer and inter-dimer distances scaling like $a^{t_1}$ and $a^{t_2}$, and the frequency is tuned near suitable electric and magnetic resonances of the associated Newtonian and magnetization operators on the reference shapes.
  Under these geometric, contrast and spectral assumptions, we derive a Foldy--Lax type approximation for the Maxwell system. We show that the scattered field and its far field admit asymptotic expansions in terms of four moments attached to each dimer, which solve an explicit finite-dimensional linear system. We prove invertibility of this system under quantitative smallness conditions on the contrast and the dimer density, and we obtain error estimates uniform in the number of dimers.
  By extracting the dominant components, we further show that each hybrid dimer behaves, at leading order, as a co-located electric and magnetic dipole driven by the local fields, and we identify the corresponding $6\times 6$ polarizability matrix. This provides a discrete model for clusters of hybrid dimers that is suitable for fast forward simulations, inverse schemes, and as input for effective-medium descriptions. In particular, it suggests parameter regimes where clusters of hybrid dimers can generate (double) negative effective permittivity and permeability and bi-anisotropic constitutive laws and eventually hyperbolic media.

</details>


### [22] [Global compressible Euler-Poisson limit of the ionic Vlasov-Poisson-Boltzmann system for all cutoff potentials](https://arxiv.org/abs/2601.08409)
*Qin Ye,Fujun Zhou,Weijun Wu*

Main category: math.AP

TL;DR: The paper proves global convergence of the ionic Vlasov-Poisson-Boltzmann system to the compressible ionic Euler-Poisson system using a novel analytical framework.


<details>
  <summary>Details</summary>
Motivation: The ionic Vlasov-Poisson-Boltzmann system is fundamental for modeling dilute collisional plasmas, but establishing rigorous convergence to its hydrodynamic limit (Euler-Poisson system) is mathematically challenging, especially for the full range of cutoff potentials (-3 < γ ≤ 1).

Method: Uses a truncated Hilbert expansion combined with a novel weighted H¹_x,v-W^{1,∞}_x,v analytical framework to establish convergence.

Result: Proves global-in-time convergence of the ionic Vlasov-Poisson-Boltzmann solution to the smooth global solution of the compressible ionic Euler-Poisson system for the full range of cutoff potentials.

Conclusion: Successfully establishes the rigorous hydrodynamic limit from kinetic to fluid equations for ionic plasmas, providing a solid mathematical foundation for using Euler-Poisson models in plasma physics applications.

Abstract: The ionic Vlasov-Poisson-Boltzmann system is a fundamental model in dilute collisional plasmas. In this work, we study the compressible ionic Euler-Poisson limit of the ionic Vlasov-Poisson-Boltzmann system for the full range of cutoff potentials $-3 < γ\leq 1$. By employing a truncated Hilbert expansion together with a novel weighted $H^1_{x,v}$-$W^{1,\infty}_{x,v}$ framework, we prove that the solution of the ionic Vlasov-Poisson-Boltzmann converges globally in time to the smooth global solution of the compressible ionic Euler-Poisson system.

</details>


### [23] [Regularity theory for sub-critical $p$-parabolic systems with measurable coefficients](https://arxiv.org/abs/2601.08466)
*Verena Bögelein,Frank Duzaar,Ugo Gianazza,Naian Liao*

Main category: math.AP

TL;DR: Develops quantitative regularity theory for weak solutions to parabolic p-Laplacian systems with measurable coefficients in sub-critical range 1<p≤2N/(N+2), proving local boundedness and higher gradient integrability.


<details>
  <summary>Details</summary>
Motivation: To establish quantitative regularity results for weak solutions to parabolic systems with p-Laplacian structure and measurable coefficients, addressing the challenging sub-critical range where standard techniques may fail.

Method: Develops a quantitative regularity theory using functional analysis and PDE techniques, starting from L^r-control of solutions and deriving scale-invariant estimates through careful analysis of the parabolic system structure.

Result: Two main results: (1) Local boundedness - from L^r-control with r>N(2-p)/p, obtain sharp scale-invariant L^∞ estimates; (2) Higher gradient integrability - |Du| self-improves from L^p_loc to L^{p(1+ε)}_loc for some ε>0 depending only on data.

Conclusion: Establishes quantitative regularity theory for parabolic p-Laplacian systems in sub-critical range, with results extending to cases with proper source terms, providing important tools for analyzing such degenerate parabolic equations.

Abstract: A quantitative regularity theory is developed for weak solutions to the parabolic system $$ \partial_t u-\mathrm{div}\,{\boldsymbol{\mathsf A}}(x,t,Du)=0 \quad\text{in }E_T\subset \mathbb{R}^N\times\mathbb{R}, $$ which features the $p$-Laplacian with measurable coefficients. We focus on the sub-critical range $1<p\le \tfrac{2N}{N+2}$ and obtain two main results. \emph{Local boundedness:} starting from an $L^{\boldsymbol{\mathsf r}}$-control of $u$ with ${\boldsymbol{\mathsf r}}>\frac{N(2-p)}{p}$, we derive sharp, scale-invariant $L^\infty$-estimates. \emph{Higher integrability of the gradient:} $|Du|$ self-improves from $L^p_{\mathrm{loc}}$ to $L^{p(1+\varepsilon)}_{\mathrm{loc}}$ for some $\varepsilon>0$ depending only on the data. The same results still hold given proper source terms.

</details>


### [24] [Non-local singular perturbations of non-convex functionals -- recent results](https://arxiv.org/abs/2601.08573)
*Andrea Braides*

Main category: math.AP

TL;DR: Overview of recent results on singular perturbations using fractional and higher-order seminorms for selecting solutions in variational problems with multiple minimizers, connecting phase transitions, free-discontinuity problems, and Gamma-convergence theory.


<details>
  <summary>Details</summary>
Motivation: To address the problem of selecting solutions in non-convex variational problems with multiple minimizers, building on Modica's gradient theory of phase transitions and extending it to more general perturbation frameworks.

Method: Using singular perturbations with fractional and higher-order seminorms within the framework of Gamma-convergence, connecting to Bourgain-Brezis-Mironescu and Maz'ya-Shaposhnikova limit analysis for fractional Sobolev seminorms.

Result: Recent results demonstrate how fractional and higher-order perturbations can select solutions in both phase transition and free-discontinuity problems, establishing connections between different mathematical frameworks.

Conclusion: The approach extends classical singular perturbation methods to fractional and higher-order settings, providing a unified perspective on solution selection in variational problems with multiple minimizers through Gamma-convergence theory.

Abstract: Singular perturbations have been used to select solutions of (non-convex) variational problems with a multiplicity of minimizers. The prototype of such an approach is the gradient theory of phase transitions by L. Modica, who specialized some earlier Gamma-convergence results by himself and S. Mortola contained in a seminal paper, validating the so-called minimal-interface criterion. I will give an overview of some recent results on perturbations with fractional and higher-order seminorms both in the framework of phase transitions and of free-discontinuity problems, relating these results with the Bourgain-Brezis-Mironescu and Maz'ya-Shaposhnikova limit analysis for fractional Sobolev seminorms, and with the theory of Gamma-expansions.

</details>


### [25] [Dynamic representation of the Weyl solution for the Schrödinger operator on the semi-axis](https://arxiv.org/abs/2601.08575)
*A. S. Mikhaylov,V. S. Mikhaylov*

Main category: math.AP

TL;DR: The paper derives a representation formula for the Weyl solution to the Schrödinger operator on the semi-axis for certain potential classes, using connections with wave equation initial-boundary value problems.


<details>
  <summary>Details</summary>
Motivation: To establish explicit representation formulas for Weyl solutions to Schrödinger operators on semi-infinite domains, which are important in spectral theory and quantum mechanics applications.

Method: The approach connects the Schrödinger operator problem with the initial-boundary value problem for the wave equation on the half-line, leveraging relationships between these two types of differential equations.

Result: A representation formula is derived for the Weyl solution to the Schrödinger operator on the semi-axis for specific classes of potentials.

Conclusion: The wave equation approach provides an effective method for obtaining representation formulas for Weyl solutions to Schrödinger operators on semi-infinite domains.

Abstract: We derive a representation formula for the Weyl solution to the Schrödinger operator on the semi-axis for certain classes of potentials. Our approach is based on relations with the initial-boundary value problem for the wave equation with the same potential on the half-line.

</details>


### [26] [Energy-variational solutions for geodynamical two-phase flows -- From logarithmic to double-obstacle potentials by variational convergence](https://arxiv.org/abs/2601.08625)
*Fan Cheng,Robert Lasarzik,Marita Thomas*

Main category: math.AP

TL;DR: The paper compares dissipative solutions and energy-variational solutions for a Cahn-Hilliard two-phase viscoelastoplastic flow model, showing energy-variational solutions are better for variational convergence methods, especially when transitioning from logarithmic to double-obstacle potentials.


<details>
  <summary>Details</summary>
Motivation: To establish well-posedness for geodynamical two-phase flow models using different solution concepts and compare their suitability for variational convergence methods, particularly when dealing with different phase-field potentials.

Method: Introduces energy-variational solutions featuring an additional scalar energy variable and variational inequality, compares with previous dissipative solutions, and studies variational limits from logarithmic potentials to double-obstacle potentials.

Result: Energy-variational solutions are shown to be better suited for variational convergence methods than dissipative solutions, enabling analysis of transitions between different phase-field potentials including emergence of pure phases.

Conclusion: The energy-variational solution concept provides a more robust framework for studying variational convergence in two-phase flow models, particularly when considering different phase-field potentials and the emergence of pure phases.

Abstract: In [Cheng, Lasarzik, Thomas 2025 ARXIV-Preprint 2509.25508], we studied a Cahn--Hilliard two-phase model describing the flow of two viscoelastoplastic fluids in the framework of dissipative solutions using a logarithmic potential for the phase-field variable. This choice of potential has the effect that the fluid mixture cannot fully separate into two pure phases. The notion of dissipative solutions is based on a relative energy-dissipation inequality featuring a suitable regularity weight. In this way, this is a very weak solution concept. In the present work, we study the well-posedness of the geodynamical two-phase flow in the notion of energy-variational solutions. They feature an additional scalar energy variable that majorizes the system energy along solutions and they are further characterized by a variational inequality that combines an energy-dissipation estimate with the weak formulation of the system adding an error term that accounts for the mismatch between the energy variable and the system energy multiplied by a suitable regularity weight. We give a comparison of these two concepts. We further study different phase-field potentials for the geodynamical two-phase flow model. In particular, we address the variational limit from a potential with a logarithmic contribution to a double-obstacle potential, then also allowing for the emergence of pure phases. This study underlines that, thanks to its structure, the energy-variational solution is better suited for variational convergence methods than the dissipative solution.

</details>


### [27] [A selection principle for 2D steady Euler flows via the vanishing viscosity limit](https://arxiv.org/abs/2601.08647)
*Changfeng Gui,Chunjing Xie,Huan Xu*

Main category: math.AP

TL;DR: The paper classifies vanishing viscosity limits of steady Navier-Stokes solutions to Euler flows in specific planar domains, showing only constant-vorticity flows in bounded domains and three specific flows in periodic strips.


<details>
  <summary>Details</summary>
Motivation: To identify which of the infinitely many steady Euler solutions are physically realizable by investigating which ones can be obtained as limits of steady Navier-Stokes solutions as viscosity vanishes, addressing the question of boundary layer persistence.

Method: Analyzes the vanishing viscosity limit of steady Navier-Stokes system to Euler system with slip boundary conditions, using L∞_loc∩H^1_loc convergence. Proves classification theorems for bounded connected domains and periodic strips, leveraging a rigidity theorem for non-shear steady Euler flows in periodic strips.

Result: In bounded connected domains, only constant-vorticity flows are vanishing viscosity limits. In periodic strips, only constant flow, Couette flow, and Poiseuille flow are vanishing viscosity limits. The bounded domain result doesn't require the nested closed streamlines assumption of Prandtl-Batchelor theorem.

Conclusion: The vanishing viscosity approach severely restricts which steady Euler flows are physically realizable, with only very specific flows emerging as limits from viscous solutions, providing a selection mechanism among infinitely many inviscid steady states.

Abstract: The 2D Euler system, governing inviscid incompressible flow, admits infinitely many steady solutions. To identify which are physically realizable, we investigate the vanishing viscosity limit of the steady Navier-Stokes system. Here, a steady Euler flow with a slip boundary condition is called a vanishing viscosity limit if it is the $L^\infty_{\textup{loc}}\cap H^1_{\textup{loc}}$ limit of steady Navier-Stokes solutions (it is known that strong boundary layers can persist). We then completely classify the vanishing viscosity limit in specific planar domains.
  In a bounded connected domain, we show that the only vanishing viscosity limit is the constant-vorticity flow. This result does not require the approximating Navier-Stokes solutions to have nested closed streamlines, an essential assumption in the century-old Prandtl-Batchelor theorem. In a strip where the Navier-Stokes velocity (but not the pressure) is periodic in the strip direction, we show that the only vanishing viscosity limits are constant flow, Couette flow, and Poiseuille flow. The proof of the latter result relies on the former and on a powerful rigidity theorem, which asserts that any non-shear steady Euler flow in a periodic strip must have contractible closed streamlines.

</details>


### [28] [Subdiffusive fractional limit of a jump-renewal equation](https://arxiv.org/abs/2601.08650)
*Hugues Berry,Pierre Gabriel,Thomas Lepoutre,Nathan Quiblier*

Main category: math.AP

TL;DR: Age-structured jump model with infinite mean waiting times converges to time fractional subdiffusion equation under rescaling.


<details>
  <summary>Details</summary>
Motivation: To understand the connection between continuous time random walks with infinite mean waiting times (heavy-tailed distributions) and fractional diffusion equations, particularly how microscopic jump processes lead to macroscopic fractional dynamics.

Method: Analyze an age-structured jump model describing continuous time random walks with infinite mean waiting times. Apply suitable rescaling and prove convergence in the long time large scale limit using mathematical analysis techniques.

Result: The age-structured jump model converges to a time fractional subdiffusion equation under appropriate rescaling, establishing a rigorous connection between microscopic jump processes with heavy-tailed waiting times and macroscopic fractional diffusion.

Conclusion: The work provides a mathematical foundation showing how continuous time random walks with infinite mean waiting times naturally lead to time fractional subdiffusion equations in the hydrodynamic limit, bridging microscopic stochastic processes and macroscopic fractional dynamics.

Abstract: In this paper, we consider an age-structured jump model that arises as a description of continuous time random walks with infinite mean waiting time between jumps. We prove that under a suitable rescaling, this equation converges in the long time large scale limit to a time fractional subdiffusion equation.

</details>


### [29] [Non-local planelike minimizers and $Γ$-convergence of periodic energies to a local anisotropic perimeter](https://arxiv.org/abs/2601.08677)
*Serena Dipierro,Matteo Novaga,Enrico Valdinoci,Riccardo Villa*

Main category: math.AP

TL;DR: The paper studies homogenization of non-local interface energies with periodic forcing, proving existence of planelike minimizers and Γ-convergence to anisotropic perimeter.


<details>
  <summary>Details</summary>
Motivation: To understand homogenization problems for non-local interface energies with periodic forcing terms, extending classical results for local energies to the non-local setting.

Method: Analyze non-local interface energy with periodic forcing, prove existence of planelike minimizers, establish auxiliary results including minimality of level sets, oscillation bounds, density estimates, and non-local perimeter estimates, then prove Γ-convergence to anisotropic perimeter.

Result: Existence of planelike minimizers proven; rescaled energies Γ-converge to local anisotropic perimeter; anisotropy defined as limit of normalized energy of planelike minimizers in increasingly larger cubes (stable norm).

Conclusion: Non-local interface energies with periodic forcing homogenize to local anisotropic perimeter energies, with anisotropy given by stable norm from planelike minimizers.

Abstract: We investigate a homogenization problem related to a non-local interface energy with a periodic forcing term. We show the existence of planelike minimizers for such energy. Moreover, we prove that, under suitable assumptions on the non-local kernel and the external field, the sequence of rescaled energies $Γ$-converges to a suitable local anisotropic perimeter, where the anisotropy is defined as the limit of the normalized energy of a planelike minimizer in larger and larger cubes (i.e., what is called in jargon "stable norm"). To obtain this, we also establish several auxiliary results, including: the minimality of the level sets of the minimizers, explicit bounds on the oscillations of the minimizers, density estimates for almost minimizers, and non-local perimeter estimates in the large.

</details>


### [30] [A free boundary problem in accretive growth](https://arxiv.org/abs/2601.08755)
*Ulisse Stefanelli*

Main category: math.AP

TL;DR: Existence proof for free boundary problem modeling accretive growth using level-set approach and coupling with elliptic equation.


<details>
  <summary>Details</summary>
Motivation: Model accretive growth processes mathematically, particularly focusing on free boundary problems that arise in growth phenomena where boundaries evolve over time.

Method: Level-set approach to formulate growth as Hamilton-Jacobi equation within constraining set, coupled with elliptic equation for activation field. Existence proved via iterative procedure.

Result: Proved existence of solutions to fully coupled free boundary problem, established variational representability and regularity for growth subproblem.

Conclusion: Successfully developed mathematical framework for accretive growth modeling with rigorous existence results for coupled free boundary problems.

Abstract: We prove an existence result for a free boundary problem inspired by the modelization of accretive growth. The growth process is formulated through a level-set approach, leading to a boundary-value problem for a Hamilton-Jacobi equation within a prescribed constraining set. Existence, variational representability, and regularity of solutions to the growth subproblem are investigated. The full system arises from coupling the growth dynamics with an elliptic equation for the activation field. Existence of solutions to the fully coupled free boundary problems is obtained via an iterative procedure.

</details>


### [31] [Failure of uniqueness for scalar conservation laws](https://arxiv.org/abs/2601.08771)
*Shyam Sundar Ghoshal,Abraham Sylla,Parasuram Venkatesh*

Main category: math.AP

TL;DR: First negative results for scalar conservation laws showing L∞ blow-up from bounded initial data, failure of Kružkov entropy equalities for uniqueness, and necessity of L∞ assumption for uniqueness. Positive contributions include new theory for spatially heterogeneous conservation laws using front tracking with Lax-type conditions.


<details>
  <summary>Details</summary>
Motivation: To investigate the limitations of existing theory for scalar conservation laws, particularly exploring what happens when the standard L∞ assumption is relaxed, and to understand whether Kružkov's entropy conditions alone guarantee uniqueness for bounded initial data.

Method: 1) Construct explicit examples showing L∞ blow-up from bounded initial data despite flux regularity. 2) Build infinitely many entropy solutions to a single Cauchy problem with bounded initial data to demonstrate failure of uniqueness. 3) Develop novel theory for spatially heterogeneous conservation laws using adapted front tracking method with additional Lax-type conditions. 4) Analyze existence of global weak solutions in natural classes.

Result: 1) L∞ blow-up occurs from bounded initial data even with regular flux. 2) Kružkov entropy equalities alone fail to ensure uniqueness - infinitely many entropy solutions exist for single Cauchy problem. 3) L∞ assumption is essential for uniqueness via doubling of variables argument. 4) Unbounded Kružkov solutions may not satisfy weak formulation; global weak solutions may not exist even when entropy solutions exist. 5) Constructed explicit example of global ill-posedness with bounded initial datum.

Conclusion: The L∞ assumption is crucial for the standard theory of scalar conservation laws. Without it, uniqueness fails even with Kružkov entropy conditions, and new theory with additional conditions (like Lax-type conditions) is needed, especially for spatially heterogeneous problems. The paper establishes fundamental limitations of existing theory while developing new approaches for more general settings.

Abstract: In this article, we develop what are, to the best of our knowledge, the first negative results for scalar conservation laws. We begin with explicit examples where bounded initial data leads to $L^{\infty}$ blow-up despite flux regularity. More strikingly, we demonstrate that Kružkov's entropy equalities alone fail to ensure uniqueness in this regime by constructing infinitely many entropy solutions to a single Cauchy problem with bounded initial datum, each continuous in time with respect to the $L^{1}$ norm. Thus, we demonstrate that the $L^{\infty}$ assumption is essential for the doubling of variables argument, and hence for the uniqueness of entropy solutions to scalar conservation laws. On the positive side, we develop a novel theory for scalar conservation laws with spatial heterogeneity by adapting the front tracking method. We recover uniqueness by imposing a Lax-type condition in addition to the entropy inequality, motivated by the properties of our front tracking approximations. Unbounded Kružkov solutions do not necessarily satisfy the weak formulation; we show that global weak solutions may not even exist in a natural class for some Cauchy problems of this form, even when Kružkov entropy solutions exist. Finally, we construct an explicit example of global ill-posedness with bounded initial datum.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [32] [ChemXDyn: Dynamics-informed species and reaction detection methodology from atomistic simulations](https://arxiv.org/abs/2601.08385)
*Raj Maddipati,Dhruthi Boddapati,Elangannan Arunan,Phani Motamarri,Konduri Aditya*

Main category: physics.comp-ph

TL;DR: ChemXDyn is a dynamics-aware method that uses time-resolved interatomic distance signatures to identify chemically consistent bonds in MD trajectories, improving reaction pathway identification and rate estimation over static distance-based methods.


<details>
  <summary>Details</summary>
Motivation: Current MD trajectory analysis methods use instantaneous distance thresholds that misclassify transient encounters as bonds, leading to spurious intermediates, distorted reaction networks, and biased rate estimates.

Method: ChemXDyn propagates molecular connectivity through time while enforcing atomic valence and coordination constraints to distinguish genuine bond-breaking/forming events from transient nonreactive encounters, using time-resolved interatomic distance signatures.

Result: ChemXDyn suppresses unphysical species, recovers experimentally consistent reaction pathways, improves rate constant estimation, removes unphysical intermediates in ammonia oxidation, and reconstructs canonical progression from CH4 to CO2 in methane oxidation.

Conclusion: ChemXDyn provides a transferable foundation for MD-derived reaction networks and kinetics with potential utility in combustion, catalysis, plasma chemistry, and electrochemical environments by linking atomistic dynamics to chemically consistent reaction identification.

Abstract: Accurate identification of chemical species and reaction pathways from molecular dynamics (MD) trajectories is a prerequisite for deriving predictive chemical-kinetic models and for mechanistic discovery in reactive systems. However, state-of-the-art trajectory analysis methods infer bonding from instantaneous distance thresholds, which can misclassify transient, nonreactive encounters as bonds and thereby introduce spurious intermediates, distorted reaction networks, and biased rate estimates. Here, we introduce ChemXDyn, a dynamics-aware computational methodology that leverages time-resolved interatomic distance signatures as a core principle to robustly identify chemically consistent bonded interactions and, consequently, extract meaningful reaction pathways. In particular, ChemXDyn propagates molecular connectivity through time while enforcing atomic valence and coordination constraints to distinguish genuine bond-breaking and bond-forming events from transient, nonreactive encounters. We evaluate ChemXDyn on ReaxFF MD simulations of hydrogen and ammonia oxidation and on neural-network potential MD simulations of methane oxidation, and benchmark its performance against widely used trajectory analysis methods. Across these cases, ChemXDyn suppresses unphysical species prevalent in static analyses, recovers experimentally consistent reaction pathways, and improves the fidelity of rate constant estimation. In ammonia oxidation, ChemXDyn removes unphysical intermediates and resolves key NOx- and N2O-forming and -consuming routes. In methane oxidation, it reconstructs the canonical progression from CH4 to CO2. By linking atomistic dynamics to chemically consistent reaction identification, ChemXDyn provides a transferable foundation for MD-derived reaction networks and kinetics, with potential utility spanning combustion, catalysis, plasma chemistry, and electrochemical environments.

</details>


### [33] [Multi-Task Fine-Tuning Enables Robust Out-of-Distribution Generalization in Atomistic Models](https://arxiv.org/abs/2601.08486)
*Chengqian Zhang,Duo Zhang,Anyang Peng,Mingyu Guo,Yuzhi Zhang,Lei Wang,Guolin Ke,Linfeng Zhang,Tiejun Li,Han Wang*

Main category: physics.comp-ph

TL;DR: Multi-task fine-tuning (MFT) prevents representation collapse in atomistic models, improving out-of-distribution generalization by preserving pretrained chemical priors while adapting to downstream tasks.


<details>
  <summary>Details</summary>
Motivation: Standard fine-tuning of pretrained atomistic models causes representation collapse, erasing valuable chemical and structural priors learned during pretraining, which severely degrades out-of-distribution (OOD) performance - a critical limitation for reliable molecular and materials design.

Method: Proposes multi-task fine-tuning (MFT) that jointly optimizes downstream property prediction with a physically grounded force-field objective inherited from pretraining, preserving essential chemical priors while enabling task-specific adaptation.

Result: MFT consistently improves OOD generalization across molecular and materials benchmarks, approaching theoretical limits set by in-distribution accuracy, while outperforming standard fine-tuning, training from scratch, and state-of-the-art task-specific models.

Conclusion: Safe adaptation is established as a central requirement for large atomistic models, with MFT positioned as a practical and data-efficient pathway toward robust molecular and materials discovery by preventing representation collapse during fine-tuning.

Abstract: Accurate de novo molecular and materials design requires structure-property models that generalize beyond known regimes. Although pretrained atomistic models achieve strong in-distribution accuracy after fine-tuning, their reliability under out-of-distribution (OOD) conditions remains unclear. We identify a critical failure mode in downstream adaptation: standard fine-tuning induces representation collapse, erasing pretrained chemical and structural priors and severely degrading OOD performance. To address this limitation, we propose multi-task fine-tuning (MFT), which jointly optimizes downstream property prediction with a physically grounded force-field objective inherited from pretraining. This approach preserves essential chemical priors while enabling task-specific adaptation. Across molecular and materials benchmarks, MFT consistently improves OOD generalization, approaching the theoretical limit set by in-distribution accuracy, while outperforming standard fine-tuning, training from scratch, and state-of-the-art task-specific models. These results establish safe adaptation as a central requirement for large atomistic models and position MFT as a practical and data-efficient pathway toward robust molecular and materials discovery.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [34] [Synergistic Bioactivity of Neem and Tulsi Infusions Treated with Plasma-Activated Water](https://arxiv.org/abs/2601.07843)
*Punit Kumar,Abhishek Kumar Singh,Priti Saxena*

Main category: physics.plasm-ph

TL;DR: PAW treatment of neem and tulsi infusions enhances phytochemical bioactivity, improving antioxidant and antimicrobial properties with optimal 10-minute exposure.


<details>
  <summary>Details</summary>
Motivation: To develop a sustainable approach for enhancing functional bioactivity of plant-derived compounds by integrating plasma activated water with herbal infusions, creating eco-friendly food safety and healthcare applications.

Method: Neem and tulsi infusions were treated with PAW generated using atmospheric pressure gliding arc discharge system. Analyzed using spectroscopic (UV-Vis, FTIR) and chromatographic (HPLC) techniques. Evaluated phytochemical modifications, antioxidant capacity (DPPH, ABTS, FRAP assays), and antimicrobial effects against E. coli and S. aureus.

Result: 10-minute PAW treatment significantly increased total phenolic content and flavonoid levels, while 15-minute exposure caused partial degradation. Structural alterations in polyphenolic constituents were observed. Enhanced antioxidant capacity and synergistic antimicrobial effects with reduced MIC values were demonstrated.

Conclusion: PAW effectively modulates herbal bioactives, extending their efficacy in natural preservation and biomedical applications. The plasma-herbal synergy offers a promising green pathway for eco-friendly food safety and healthcare solutions.

Abstract: The integration of plasma activated water (PAW) with herbal infusions offers a sustainable approach to enhancing the functional bioactivity of plant derived compounds. In this study, neem (Azadirachta indica) and tulsi (Ocimum sanctum) infusions were treated with PAW generated using an atmospheric pressure gliding arc discharge system. The aim was to investigate plasma induced modifications in phytochemicals and their subsequent effects on antimicrobial and antioxidant properties. Spectroscopic (UV Vis, FTIR) and chromatographic (HPLC) analyses demonstrated structural alterations in key polyphenolic constituents, accompanied by mild acidification and changes in redox potential. Total phenolic content (TPC) and flavonoid levels increased significantly following 10 min PAW treatment, while prolonged exposure (15 min) led to partial degradation, suggesting an optimum treatment window. Antioxidant assays (DPPH, ABTS, FRAP) confirmed improved radical scavenging capacity, correlating with enhanced reducing power of modified phytochemicals. Antimicrobial evaluation against Escherichia coli and Staphylococcus aureus revealed synergistic inhibitory effects, with reduced minimum inhibitory concentrations (MIC) for PAW-treated infusions. Collectively, the results highlight the potential of PAW to modulate herbal bioactives, extending their efficacy in natural preservation systems and biomedical formulations. This green plasma-herbal synergy provides a promising pathway toward eco-friendly food safety and healthcare applications.

</details>


### [35] [Understanding microfabricated nanocalorimeter performance and responses to the energy fluxes from low-temperature plasma discharges](https://arxiv.org/abs/2601.08009)
*Carles Corbella,Feng Yi,Andrei Kolmakov*

Main category: physics.plasm-ph

TL;DR: A novel nanocalorimeter sensor for fast, sensitive measurement of energy fluxes from RF glow discharges, using ultrathin membrane with Pt thermometer for rapid temperature response and bias capability to discriminate ion/electron fluxes.


<details>
  <summary>Details</summary>
Motivation: There is a shortage of fast and sensitive calorimetric sensors for tracking substrate temperature during plasma-assisted microfabrication, particularly for measuring low-energy plasma fluxes on surfaces.

Method: Developed a nanocalorimeter sensor with ultrathin SiNx membrane (100 nm) and lithographically defined Pt micro-strip (100 nm) as calibrated resistance thermometer. Reduced heat capacity and thermal conductance enable fast response. Sensor can be biased at negative/positive potentials to discriminate ion and electron fluxes.

Result: Sensor can increase from room temperature to several hundred degrees within a second upon plasma exposure. Enables sensitive detection of low-energy plasma fluxes and discrimination of ion/electron fluxes through biasing. Measurements compared with Langmuir probe and RFEA data.

Conclusion: The nanocalorimeter provides fast, sensitive calorimetric measurements for plasma diagnostics, with capability to discriminate different energy flux components. Robustness aspects (baseline drifts, degradation, longevity) are discussed for practical applications.

Abstract: Plasma diagnostics have a shortage of fast and sensitive calorimetric sensors that can track substrate temperature during plasma-assisted microfabrication. In this work, energy fluxes from argon and oxygen radiofrequency (RF) glow discharges have been probed using a novel nanocalorimeter sensor. The probe consists of an ultrathin SiNx membrane (100 nm) with a lithographically defined Pt micro-strip (100 nm) that serves as a calibrated resistance thermometer. The sensor temperature can increase from room temperature to several hundred degrees within a second upon exposure to RF plasma, depending on the experiment's geometry and plasma parameters. Such sensitivity and response time are due to the pre-designed reduced heat capacity of the sensor and significantly reduced thermal conductance of the cooling channels. These features enable the sensitive detection of low-energy plasma fluxes on surfaces and their rapid discrimination, as in the case of ion and electron fluxes, by biasing the sensor at negative or positive potentials. These biased nanocalorimeter energy readings have been compared with ion and electron kinetic energy dissipations assessed using a Langmuir probe and retarding field energy analyzer (RFEA). Finally, the robustness of the plasma nanocalorimeter is discussed in terms of its baseline drifts, degradation, and longevity.

</details>


### [36] [The Topological Origin of Bohm Resistivity in Magnetic Reconnection](https://arxiv.org/abs/2601.08054)
*Magnus F Ivarsen*

Main category: physics.plasm-ph

TL;DR: The paper derives Bohm diffusion scaling from first principles by modeling magnetized electron fluid as an overdamped spintronic condensate, showing that frozen-in condition breakdown is a topological phase transition (Adler-Ohmic bifurcation) leading to Bohm-limited resistivity.


<details>
  <summary>Details</summary>
Motivation: The physical origin of 'anomalous' resistivity in magnetic reconnection has been a long-standing problem in space plasma physics. While Bohm diffusion scaling is widely used to explain fast reconnection rates, it lacks rigorous derivation from first principles.

Method: Model magnetized electron fluid as an overdamped spintronic condensate governed by Landau-Lifshitz-Gilbert equation. Map breakdown of adiabatic invariance to electron gyro axis slippage on unit sphere. Use numerical simulations of XY universality class to study the resistive state onset.

Result: Breakdown of frozen-in condition is identified as Adler-Ohmic bifurcation (topological phase transition). Resulting resistivity naturally saturates at Bohm limit. Onset is explosive following logistic trigger consistent with solar flare impulsive phase. Topological defects decay via t^{-0.75} power law, identifying magnetic island coalescence as anomalous transport mechanism.

Conclusion: Bohm resistivity is a universal topological property of magnetized matter at the critical point of reconnection, derived from first principles through topological phase transition framework.

Abstract: The physical origin of 'anomalous' resistivity in magnetic reconnection remains one of the longest-standing problems in space plasma physics. While the empirical Bohm diffusion scaling ($η~\propto~T/B$) is widely invoked to explain fast reconnection rates, it lacks a rigorous derivation from first principles. Here, we derive this scaling by modeling the magnetized electron fluid as an overdamped spintronic condensate governed by the Landau-Lifshitz-Gilbert equation. We demonstrate that the breakdown of the "frozen-in" condition is rigorously identified as an Adler-Ohmic bifurcation: a topological phase transition where electron gyro-axes lose synchronization with the magnetic field. By rigorously mapping the breakdown of adiabatic invariance to electron gyro axis slippage on the unit sphere, we show that the resulting resistivity naturally saturates at the Bohm limit. Numerical simulations of the $XY$ universality class confirm that the onset of this resistive state is explosive, following a logistic trigger consistent with the impulsive phase of solar flares. Furthermore, the topological defects in the condensate decay via a $t^{-0.75}$ power law, identifying magnetic island coalescence as the mechanism of anomalous transport. These results suggest that Bohm resistivity is a universal topological property of magnetized matter at the critical point of reconnection.

</details>


### [37] [The effect of surface quenching coefficients of $O_2(a^{1}Δg)$ and $O_2(b^{1}Σg^{+})$ on capacitively coupled $Ar$/$O_2$ discharge: A global/equivalent circuit model study](https://arxiv.org/abs/2601.08138)
*Wan Dong,Yi Wang,Yi-Fan Zhang,Yuan-Hong Song*

Main category: physics.plasm-ph

TL;DR: Study shows O₂(b¹Σg⁺) metastable species significantly affects Ar/O₂ discharge characteristics through surface quenching coefficients, impacting plasma properties in capacitive discharges.


<details>
  <summary>Details</summary>
Motivation: Ar/O₂ discharges are widely used in plasma etching and deposition, but previous models often neglect the role of O₂(b¹Σg⁺) metastable species. Understanding how surface quenching of both O₂(a¹Δg) and O₂(b¹Σg⁺) affects discharge characteristics is crucial for optimizing plasma processes.

Method: Developed a global/equivalent circuit model for Ar/O₂ discharges that incorporates both O₂(a¹Δg) and O₂(b¹Σg⁺) metastable species and their associated reactions. Independently adjusted surface quenching coefficients for both species to analyze their effects on discharge characteristics.

Result: Surface quenching coefficients significantly affect discharge characteristics. O₂(b¹Σg⁺) cannot be neglected as it impacts particle species densities, plasma impedance, voltage drops across sheaths, and plasma power absorption. Different wall materials affect these metastable quenching rates.

Conclusion: Both O₂(a¹Δg) and O₂(b¹Σg⁺) metastable species play important roles in Ar/O₂ discharges through their surface quenching coefficients. Accurate modeling must include O₂(b¹Σg⁺) to properly predict plasma behavior, especially for different wall materials used in plasma processing applications.

Abstract: Capacitively coupled discharges operated in mixtures of $Ar$ and $O_2$ are extensively utilized in plasma etching and deposition processes due to the oxidative properties and precursor functionality of the reactive species produced in the discharge. In $Ar$/$O_2$ discharges, the surface quenching coefficient of $O_2(a^{1}Δg)$ is known to affect this metastable density, which, in turn, affects the electronegativity and other important plasma characteristics. In this work, in addition to $O_2(a^{1}Δg)$, $O_2(b^{1}Σg^{+})$ and its associated reactions are incorporated into a global/equivalent circuit model of an $Ar$/$O_2$ discharge. By independently adjusting the quenching coefficients of both metastable species, changes of these surface coefficients are found to significantly affect the discharge characteristics, indicating that the role of $O_2(b^{1}Σg^{+})$ cannot be neglected. The effects of their respective surface quenching coefficients of these metastables based on various wall materials on the discharge are revealed including their effects on different particle species densities, plasma impedance, voltage drops across the sheaths, as well as plasma power absorption.

</details>


### [38] [Interstellar Medium Modulation of Nonlinear Kinetic Alfvén Morphology in Structured Galactic Environments](https://arxiv.org/abs/2601.08313)
*Manpreet Singh,Siming Liu,N. S. Saini*

Main category: physics.plasm-ph

TL;DR: A framework for nonlinear kinetic Alfvén structures in the ISM shows how plasma conditions and ISM morphology affect soliton properties, revealing exclusion zones in certain regions.


<details>
  <summary>Details</summary>
Motivation: To understand how macroscopic interstellar medium morphology and plasma conditions influence the existence and propagation of nonlinear kinetic Alfvén structures, which have implications for various astrophysical phenomena.

Method: Developed a spatially dependent multi-component analytical model incorporating warm ionized medium with localized regions (H II, supernova remnants, stellar-wind bubbles). Applied reductive perturbation method to derive KdV equations for soliton characterization under realistic astrophysical conditions.

Result: Numerical analysis reveals how superthermality, plasma β, temperature, and density gradients modulate soliton properties. Identified distinct exclusion zones for KA solitons in high-β HII regions and SWB/SNR interiors, as well as ultra low-β regions near pulsar wind nebulae. Complex morphologies of SWBs and SNRs create sharp spatial variations in soliton properties.

Conclusion: Establishes a direct link between ISM morphology, ion-kinetic scale dissipation, and coherent Alfvénic activity, with implications for radio scattering, pulsar scintillation, and fine-scale astrophysical observations.

Abstract: We present a spatially dependent framework for the existence and propagation of nonlinear kinetic Alfvén (KA) structures in the interstellar medium (ISM). Using a multi-component analytical model that incorporates the diffuse warm ionized medium together with localized H II regions, supernova remnants (SNR), and stellar-wind bubbles (SWB), we derive location-dependent coefficients governing KA dispersion and nonlinearity. The reductive perturbation method is applied to obtain Korteweg-de Vries (KdV) equations, enabling the characterization of solitons under realistic astrophysical conditions. Numerical analysis demonstrates how superthermality, plasma $β$, temperature, and density gradients modulate soliton amplitude, width, and stability. Our results reveal distinct exclusion zones (EZs) for KA solitons in high-$β$ HII regions and SWB/SNR interiors, as well as ultra low-$β$ regions near central pulsar wind nebulae. While H II regions exhibit simple Gaussian-driven depletions, the complex ``hole-and-shell" morphologies of SWBs and SNRs imprint sharp spatial variations and discontinuities on soliton properties. This study establishes a direct link between macroscopic ISM morphology, ion-kinetic scale dissipation, and the emergence of coherent Alfvénic activity, with implications for radio scattering, pulsar scintillation, and fine-scale signatures in astrophysical observations.

</details>


### [39] [Velocity-Space Signatures of Energy Transfer for Ion-Acoustic Instabilities](https://arxiv.org/abs/2601.08329)
*Mahmoud Saad Afify,Kristopher G. Klein,Mihailo M. Martinović,Maria Elena Innocenti*

Main category: physics.plasm-ph

TL;DR: The paper applies field-particle correlation technique to kinetic simulations of ion-ion-acoustic instability to identify observational signatures for future solar wind missions.


<details>
  <summary>Details</summary>
Motivation: Electrostatic instabilities like ion-ion-acoustic instability (IIAI) observed by Parker Solar Probe appear important for plasma heating and particle acceleration in the inner heliosphere, but current missions lack sufficient sampling rates to detect IIAI signatures.

Method: Applied field-particle correlation (FPC) technique to fully kinetic simulations of IIAI in solar wind-compatible parameter regimes to characterize energy conversion between electric fields and particle species, differentiating oscillatory vs secular energy transfer.

Result: Identified characteristic IIAI signatures for proton and electron distributions that would enable efficient recognition of IIAI in observations, though current mission sampling rates are too slow to detect these fast-developing signatures.

Conclusion: The study provides diagnostic tools for identifying IIAI in future solar wind missions, bridging simulation insights with observational capabilities for understanding plasma heating mechanisms in the inner heliosphere.

Abstract: Context. Observations by Parker Solar Probe (PSP) of electrostatic waves suggest that electrostatic instabilities, including the ion-ion-acoustic instability (IIAI) frequently observed in the inner heliosphere, play an important role in plasma heating and particle acceleration. Aims. Our aim is to explore the application of single spacecraft diagnostics to the IIAI, in anticipation of application to the current missions operating in the inner heliosphere, e.g. PSP and Solar Orbiter. Methods. We apply the field-particle correlation (FPC) technique to fully kinetic simulations of IIAI. We characterize the conversion of energy between the electric field and particle species, allowing the differentiation between oscillatory and secular energy transfer to and from the particles and highlighting the role of resonant energy exchange. We then identify the characteristic IIAI signatures for the proton and electron distributions, and relate them to our previous knowledge of IIAI onset and energy exchange mechanisms. Results. Applying the FPC technique to our simulations run in parameters regime compatible with solar wind conditions, we have identified IIAI signatures that would enable efficient recognition of IIAI in observations. This task is left for future missions, since the time scale over which IIAI signatures develop is too fast for the sampling rates of current missions.

</details>


### [40] [Electric field-driven Rayleigh-Taylor-like instability in binary complex plasma](https://arxiv.org/abs/2601.08384)
*Priya Deshwal,Hitendra K. Malik*

Main category: physics.plasm-ph

TL;DR: 2D molecular dynamics simulations study Rayleigh-Taylor-like instability in strongly coupled binary complex plasma with heavier dust particles above lighter ones, analyzing growth rates and mixing behavior.


<details>
  <summary>Details</summary>
Motivation: To understand Rayleigh-Taylor-like instability in strongly coupled binary complex plasmas where heavier charged dust particles are positioned above lighter ones, and to investigate how this instability leads to mixing between different charged species under external electric fields and charge density gradients.

Method: Used two-dimensional molecular dynamics simulations with Langevin dynamics to study perturbation evolution at the interface between two dust particle species with same charge-to-mass ratio. Performed analytical calculations to determine instability growth rates for both strongly coupled and weakly coupled regimes, then validated theoretical predictions through molecular dynamics simulations.

Result: Successfully reproduced Rayleigh-Taylor-like instability in strongly coupled binary complex plasma, showing that the instability ultimately causes mixing among charged species. Comprehensive analysis of growth rate as function of various system parameters provided deeper insight into underlying physical mechanisms.

Conclusion: The study demonstrates that Rayleigh-Taylor-like instability can occur in strongly coupled binary complex plasmas, leading to mixing between different charged dust species. The combination of analytical calculations and molecular dynamics simulations provides a robust framework for understanding these instabilities in dusty plasma systems.

Abstract: This study uses two-dimensional molecular dynamics simulations to explore Rayleigh-Taylor-like instability in a strongly coupled binary complex plasma, when heavier dust particles are positioned above the lighter ones, having the same charge-to-mass ratio, in a planar configuration. Langevin dynamics simulations are used to study the evolution of perturbations at the interface between these two distinct species of charged dust particles, subject to an externally applied electric field and an equilibrium charge density gradient. We have performed analytical calculations to determine the growth rate of instability under both strongly coupled and weakly coupled dusty plasma regimes. These theoretical predictions are subsequently validated through molecular dynamics simulations, enabling the reproduction of the instability in a strongly coupled binary complex plasma. The instability in these cases ultimately causes mixing among the charged species. The study comprehensively analyzes the growth rate as a function of various system parameters, and it offers deeper insight into the underlying physical mechanisms.

</details>


### [41] [Near-axis quasi-isodynamic database](https://arxiv.org/abs/2601.08400)
*Eduardo Rodriguez,Gabriel G. Plunk*

Main category: physics.plasm-ph

TL;DR: Researchers create a massive database of 800,000+ stable quasi-isodynamic stellarator configurations using near-axis expansion, analyze them with various physics metrics, and use statistical/ML methods to understand optimization tendencies.


<details>
  <summary>Details</summary>
Motivation: To systematically explore the quasi-isodynamic stellarator design space by creating a comprehensive database of stable configurations that can serve as baselines and tailored initial conditions for optimization.

Method: Use near-axis expansion of magnetic field to construct database of 800,000+ stable quasi-isodynamic vacuum configurations spanning various geometric parameters (field period numbers, axis shape, plasma elongation). Evaluate configurations using multiple physics measures including effective ripple, Shafranov shift sensitivity, maximum-J trapped particles, and Rosenbluth-Hinton residual.

Result: Created comprehensive database enabling exhaustive quantitative characterization of quasi-isodynamic stellarators. Applied statistical analysis and machine learning to identify correlations, key descriptors, and heuristics that govern numerical optimization behavior.

Conclusion: This work initiates a long-term program for systematic exploration of quasi-isodynamic stellarator design space, providing valuable baseline configurations and insights into optimization tendencies through data-driven analysis.

Abstract: In this work, we investigate the landscape of quasi-isodynamic stellarators using the near-axis expansion of the magnetic field. Building on recent theoretical developments, we construct a database of more than 800,000 stable, approximately quasi-isodynamic vacuum magnetic configurations. These configurations span a range of field period numbers and other geometric control parameters, including the magnetic axis shape and plasma elongation. To evaluate each configuration, we use a broad set of measures, including effective ripple, sensitivity of the Shafranov shift to changes in plasma beta, the prevalence of maximum-J trapped particles, and the Rosenbluth-Hinton residual, among others. This enables an exhaustive, thorough and quantitative characterization of the database. Statistical analysis and modern machine learning techniques are then employed to find correlations, and identify key descriptors and heuristics to help understand tendencies that govern the behaviour of numerical optimization. The database provides baseline configurations for further studies, and to serve as tailored initial conditions for optimization. With this work we initiate a long term program to complete a systematic exploration of quasi-isodynamic stellarator design space.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [42] [Lattice Boltzmann methods for simulating non-Newtonian fluids: A comprehensive review](https://arxiv.org/abs/2601.08206)
*Vedad Dzanic,Qiuxiang Huang,Christopher S. From,Emilie Sauret*

Main category: physics.flu-dyn

TL;DR: A comprehensive review of lattice Boltzmann method techniques for simulating non-Newtonian fluids, covering shear-dependent viscosity, viscoplasticity, and viscoelasticity, with validation benchmarks and future directions.


<details>
  <summary>Details</summary>
Motivation: Non-Newtonian fluids exhibit complex nonlinear behaviors (shear-thinning, shear-thickening, viscoplasticity, viscoelasticity) that cannot be captured by constant viscosity models. These fluids are ubiquitous in everyday life and industrial applications, requiring accurate computational simulations to predict their behavior under various flow conditions.

Method: The paper presents a comprehensive review of different lattice Boltzmann method (LBM) techniques for solving non-Newtonian fluid systems. LBM is chosen due to its ability to handle intricate boundary conditions, ease of including additional multiphysics, and computational efficiency for parallel simulations.

Result: The review covers significant advancements in LBM for non-Newtonian fluids over the past decade, specifically addressing shear-dependent viscosity, viscoplasticity, and viscoelasticity. It discusses various benchmark cases that validate these approaches and highlights their growing application to realistic complex flow problems.

Conclusion: The review addresses outstanding issues in current lattice Boltzmann models and provides future directions for numerical advancement and application, positioning LBM as a powerful tool for simulating complex non-Newtonian fluid flows in various practical domains.

Abstract: Non-Newtonian fluids encompass a large family of fluids with additional nonlinear material properties, contributing to non-trivial flow behaviour that cannot be captured through a single constant viscosity term. Common non-Newtonian characteristics include shear-thinning, shear-thickening, viscoplasticity, and viscoelasticity, commonly encountered in everyday fluids, such as ketchup, blood, toothpaste, mud, etc., as well as practical applications involving porous media, cosmetics, food processing, and pharmaceuticals. Due to the complex nature of these fluids, accurate computational fluid dynamics simulations are essential for predicting their behaviour under various flow conditions. Recent advancements have highlighted the growing trend of using the lattice Boltzmann method to solve such complex flows, owing to its ability to handle intricate boundary conditions, ease of including additional multiphysics, and providing computationally efficient parallel simulations. Since the initial review over a decade ago [Phillips & Roberts, IMA J. Appl. Math. 76, 790-816 (2011)], significant advancements have been made to the lattice Boltzmann method to simulate non-Newtonian fluids. Here, we present a comprehensive review of different lattice Boltzmann techniques used to solve non-Newtonian fluid systems, specifically dealing with shear-dependent viscosity, viscoplasticity, and viscoelasticity. In addition, we discuss various benchmark cases that validate these approaches and highlight their growing application to realistic and challenging complex flow problems. We further address outstanding issues in current lattice Boltzmann models, as well as future directions for numerical advancement and application.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [43] [Low energy excitations in a long prism geometry: computing the lower critical dimension of the Ising spin glass](https://arxiv.org/abs/2601.07926)
*Massimo Bernaschi,Luis Antonio Fernández,Isidoro González-Adalid Pemartín,Víctor Martín-Mayor,Giorgio Parisi,Federico Ricci-Tersenghi*

Main category: cond-mat.dis-nn

TL;DR: A new method using rectangular prism geometry to study systems with low-energy excitations, applied to 3D Ising spin glasses to compute lower critical dimension and multifractal spectrum.


<details>
  <summary>Details</summary>
Motivation: To develop a general approach for studying systems with arbitrarily low-energy excitations in their low-temperature phase, particularly to address the challenging problem of determining the lower critical dimension in spin glasses where traditional methods struggle.

Method: Use rectangular prism geometry with longitudinal dimension much larger than transverse size. Study correlation decay along longitudinal dimension and analyze scaling of correlation length with transverse size. Apply to 3D Ising spin glasses with technical innovations including Houdayer's cluster method and open boundary conditions, enabling study of prisms with transverse dimensions up to L=24.

Result: Computed lower critical dimension and multifractal spectrum for correlation function. Found lower critical dimension value consistent with both Replica Symmetry Breaking theory and Droplet model predictions. The method successfully studied 3D prisms with effectively infinite longitudinal dimensions down to low temperatures.

Conclusion: The novel prism geometry approach provides a promising framework for clarifying which theory (Replica Symmetry Breaking vs Droplet model) more accurately describes 3D spin glasses, as it yields results consistent with both theories while offering new technical capabilities for studying these challenging systems.

Abstract: We propose a general method for studying systems that display excitations with arbitrarily low energy in their low-temperature phase. We argue that in a rectangular right prism geometry, with longitudinal size much larger than the transverse size, correlations decay exponentially (at all temperatures) along the longitudinal dimension, but the scaling of the correlation length with the transverse size carries crucial information from which the lower critical dimension can be inferred. The method is applied in the particularly demanding context of Ising spin glasses at zero magnetic field. The lower critical dimension and the multifractal spectrum for the correlation function are computed from large-scale numerical simulations. Several technical novelties (such as the unexpectedly crucial performance of Houdayer's cluster method or the convenience of using open - rather than periodic - boundary conditions) allow us to study three-dimensional prisms with transverse dimensions up to $L=24$ and effectively infinite longitudinal dimensions down to low temperatures. The value that we find for the lower critical dimension turns out to be in agreement with expectations from both the Replica Symmetry Breaking theory and the Droplet model for spin glasses. We argue that our novel setting holds promise in clarifying which of the two competing theories more accurately describes three-dimensional spin glasses.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [44] [Optimal Dirac controls for time-periodic bistable ODEs, application to population replacement](https://arxiv.org/abs/2601.08630)
*Grégoire Nadin,David Nahmani,Nicolas Vauchelet*

Main category: math.OC

TL;DR: Optimal timing for releasing B-type individuals to replace A-type population in time-varying environment, with application to Wolbachia biocontrol of mosquitoes.


<details>
  <summary>Details</summary>
Motivation: Optimize population replacement strategies in time-varying environments, particularly relevant for biocontrol applications like using Wolbachia-infected mosquitoes to prevent virus transmission.

Method: Formulate optimal control problem with nonlinear differential equation having bistable time-periodic nonlinearity, analyze properties of the dynamics, determine optimal release time minimizing release effort.

Result: Optimal release time is minimizer of function involving environmental carrying capacity and threshold periodic solution; convergence of optimal release strategy characterized.

Conclusion: Theoretical framework provides optimal timing strategy for population replacement, validated through application to Wolbachia biocontrol for mosquito populations to prevent virus transmission.

Abstract: This work addresses an optimal control problem on a dynamics governed by a nonlinear differential equation with a bistable time-periodic nonlinearity. This problem, relevant in population dynamics, models the strategy of replacing a population of A-type individuals by a population of B-type individuals in a time-varying environment, focusing on the evolution of the proportion of B-type individuals among the whole population. The control term accounts for the instant release of B-type individuals. Our main goal, after noting some interesting properties on the differential equation, is to determine the optimal time at which this release should be operated to ensure population replacement while minimizing the release effort. The results establish that the optimal release time appears to be the minimizer of a function involving the carrying capacity of the environment and the threshold periodic solution of the dynamics; they also describe the convergence of the whole optimal release strategy. An application to the biocontrol of mosquito populations using Wolbachia-infected individuals illustrates the relevance of the theoretical results. Wolbachia is a bacterium that helps preventing the transmission of some viruses from mosquitoes to humans, making the optimization of Wolbachia propagation in a mosquito population a crucial issue.

</details>


<div id='math.CV'></div>

# math.CV [[Back]](#toc)

### [45] [On octonionic Monge-Ampère equation and pluripotential theory associated to octonionic plurisubharmonic functions of two variables](https://arxiv.org/abs/2601.08437)
*Wei Wang*

Main category: math.CV

TL;DR: Generalizes pluripotential theory to octonionic plurisubharmonic functions, proving key results like comparison principle, quasicontinuity, and solving Dirichlet problem with C¹,¹-regularity despite octonion non-associativity.


<details>
  <summary>Details</summary>
Motivation: Extend pluripotential theory to octonionic setting, overcoming challenges from octonion non-associativity to establish fundamental properties analogous to complex pluripotential theory.

Method: Develop integration by parts formula for mixed octonionic Monge-Ampère operator; use weak associativity forms; apply Bedford-Taylor method; create weighted transformation formula for OPSH functions under automorphisms.

Result: Proved comparison principle for continuous OPSH functions; established quasicontinuity of locally bounded OPSH functions; solved Dirichlet problem for homogeneous octonionic Monge-Ampère equation on unit ball with C¹,¹-regularity.

Conclusion: Successfully generalized core pluripotential theory to octonionic setting despite non-associativity, establishing fundamental tools and results that parallel complex pluripotential theory.

Abstract: Several aspects of pluripotential theory are generalized to octonionic plurisubharmonic (OPSH) functions of two variables. We prove the comparison principle for continuous OPSH functions and the quasicontinuity of locally bounded ones. An important tool is a formula of integration by parts for mixed octonionic Monge-Ampère operator. Various useful properties of octonionic relative extremal functions and octonionic capacity are established. The main difficulty is the non-associativity of octonions. However, some weak form of associativity can be used to covercome this difficulty. Another important ingredient in pluripotential theory is the solution to the Dirichlet problem for the homogeneous octonionic Monge-Ampère equation on the unit ball, for which we show the $C_{loc}^{1,1}$-regularity by applying Bedford-Taylor's method. The obstacle to do so is that an OPSH function is usually not OPSH under automorphisms of the unit ball. This issue can be solved by finding a weighted transformation formula of OPSH functions.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [46] [Excitonic Landscape of Monolayer Transition-Metal Dichalcogenides: Experimental Discrepancies, Theoretical Advances, and Strain Dependence](https://arxiv.org/abs/2601.08585)
*Cem Sevik,Purushothaman Manivannan,Fulvio Paleari,Milorad V. Milosevic*

Main category: physics.optics

TL;DR: Comprehensive review of exciton properties in monolayer TMDs, addressing literature discrepancies through integrated experimental/theoretical analysis and strain engineering studies.


<details>
  <summary>Details</summary>
Motivation: Despite significant attention to excitons in monolayer TMDs due to their large binding energies and potential for optoelectronic/quantum devices, reported values for exciton properties show substantial variation across studies, creating confusion in the field.

Method: Critical assessment integrating ARPES, PL measurements, and other experimental techniques with first-principles GW-BSE calculations, including both equilibrium and laterally strained systems to analyze direct/indirect excitons.

Result: Demonstrates strain as a tunable control variable for engineering excitonic properties, clarifies sources of discrepancies in literature, and provides cross-validation against prior theoretical predictions and experimental findings.

Conclusion: Offers a unified perspective on excited-state engineering strategies in 2D TMDs by reconciling experimental discrepancies and providing systematic analysis of exciton behavior under strain.

Abstract: Excitons in monolayer transition-metal dichalcogenides (TMDs) have garnered significant attention because of their large binding energies due to weakly screened Coulomb interaction, and direct bandgap at the K/K$^\prime$ point in the hexagonal Brillouin zone featuring spin-polarised bands due to spin-orbit coupling and lack of inversion symmetry. This makes them prospective for next-generation optoelectronic and quantum devices. However, despite the intense research activity, the reported values for exciton binding energies, quasiparticle gaps, and spectral features exhibit substantial variation across both experimental and theoretical studies. In this article, we present a comprehensive and critical assessment of the current understanding of excitonic properties in single-layer TMDs, integrating results from the angle-resolved photoemission spectroscopy (ARPES), photoluminescence (PL) measurements, and other experimental techniques with first-principles theoretical insights. Special emphasis is placed on the comparison and reconciliation of discrepancies observed across different experimental setups and sample qualities. Furthermore, we highlight our state-of-the-art GW-BSE calculations, which include both equilibrium and laterally strained systems, to systematically analyse the behaviour of direct and indirect excitons. By evaluating the effect of strain as a tunable control variable, we demonstrate its potential to engineer excitonic properties, supported by cross-validation against prior theoretical predictions and experimental findings. In doing so, we clarify the sources of discrepancies in the literature and offer a unified perspective on excited-state engineering strategies in two-dimensional TMDs.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [47] [Three Bernstein type theorems for hypersurfaces with zero Gaussian curvature](https://arxiv.org/abs/2601.08124)
*Slawomir Dinew,Mengru Guo,Heming Jiao*

Main category: math.DG

TL;DR: Bernstein type theorems for entire convex graphical hypersurfaces with zero Gaussian curvature in Euclidean and Minkowski spaces, showing they must be hyperplanes under certain conditions.


<details>
  <summary>Details</summary>
Motivation: To establish Bernstein-type results for hypersurfaces with zero Gaussian curvature, extending classical Bernstein theorems to more general settings in both Euclidean and Minkowski geometries.

Method: Mathematical proof techniques for Bernstein type theorems, analyzing entire convex graphical hypersurfaces with zero Gaussian curvature, with supplementary examples to illustrate necessary conditions.

Result: Proved that zero Gaussian curvature convex hypersurfaces must be hyperplanes if mean curvature goes to zero at infinity; similar results for Minkowski hypersurfaces without timelike points; provided counterexample showing additional conditions are necessary.

Conclusion: Bernstein-type theorems hold for zero Gaussian curvature hypersurfaces under appropriate asymptotic conditions, with important distinctions between Euclidean and Minkowski contexts requiring careful consideration of additional geometric constraints.

Abstract: In this paper, we prove Bernstein type theorems for entire convex graphical hypersurfaces with zero Gaussian curvature in both Euclidean and Minkowski context. A supplementary example illustrates that zero Gaussian convex spacelike hypersurfaces are not necessary hyperplanes without additional conditions. We show that a zero Gaussian curvature convex hypersurface must be a hyperplane if the mean curvature goes to zero at infinity. In the Minkowski context, we prove similar results for hypersurface without timelike points.

</details>


### [48] [Half-space theorems for translating solitons of the r-mean curvature flow](https://arxiv.org/abs/2601.08661)
*Hilário Alencar,G. Pacelli Bessa,Gregório Silva Neto*

Main category: math.DG

TL;DR: Nonexistence results for complete translating solitons of r-mean curvature flow under growth conditions on curvature and second fundamental form.


<details>
  <summary>Details</summary>
Motivation: To establish geometric constraints on translating solitons of r-mean curvature flow by proving nonexistence results under certain curvature growth conditions and spatial constraints.

Method: The authors use geometric analysis techniques to prove three main nonexistence theorems: 1) solitons cannot be contained in complement of rotational cones aligned with translation direction, 2) properly immersed solitons cannot be confined to certain half-spaces opposite to translation direction, 3) solitons cannot lie within intersection of two transversal vertical half-spaces.

Result: Three main nonexistence results are established for complete translating solitons under appropriate growth conditions on (r-1)-mean curvature and norm of second fundamental form, providing geometric restrictions on their possible configurations in space.

Conclusion: Complete translating solitons of r-mean curvature flow are subject to significant geometric constraints, particularly regarding their spatial confinement relative to the translation direction, when curvature growth conditions are satisfied.

Abstract: In this paper, we establish nonexistence results for complete translating solitons of the r-mean curvature flow under suitable growth conditions on the (r-1)-mean curvature and on the norm of the second fundamental form. We first show that such solitons cannot be entirely contained in the complement of a right rotational cone whose axis of symmetry is aligned with the translation direction. We then relax the growth condition on the (r-1)-mean curvature and prove that properly immersed translating solitons cannot be confined to certain half-spaces opposite to the translation direction. We conclude the paper by showing that complete, properly immersed translating solitons satisfying appropriate growth conditions on the (r-1)-mean curvature cannot lie completely within the intersection of two transversal vertical half-spaces.

</details>


<div id='q-bio.OT'></div>

# q-bio.OT [[Back]](#toc)

### [49] [Plasma-Activated Zn, Fe, Mn Micronutrient Solutions for Crop Biofortification](https://arxiv.org/abs/2601.07847)
*Punit Kumar,Priti Saxena,Abhishek Kumar Singh*

Main category: q-bio.OT

TL;DR: PAW enriched with micronutrients enhances crop growth, nutrient uptake, and soil health without toxicity.


<details>
  <summary>Details</summary>
Motivation: Micronutrient deficiency in soils reduces crop productivity and nutritional quality, while conventional fertilizers have low bioavailability and environmental issues.

Method: Generated PAW using gliding arc plasma system, prepared ion-enriched solutions, analyzed physicochemical parameters, and applied treatments to wheat and chickpea seeds in greenhouse conditions.

Result: Significant improvements in germination, chlorophyll content, biomass, and micronutrient content in grains; soil showed no toxicity with mild stimulatory effects.

Conclusion: PAW provides a green, scalable method for delivering micronutrients through irrigation, linking plasma chemistry with sustainable agriculture and nutritional security.

Abstract: Micronutrient deficiency in soils limits crop productivity and reduces the nutritional quality of cereals and pulses. Conventional fertilizer supplementation often suffers from low bioavailability and environmental losses. In this study, we investigate the use of Plasma Activated Water (PAW) enriched with divalent micronutrient ions as a sustainable alternative to enhance nutrient uptake, soil fertility, and seed vigor. The PAW was generated using a gliding arc plasma system in air, and ion-enriched solutions were prepared at controlled concentrations. The physicochemical parameters (pH, ORP, conductivity, RONS species) were analyzed to assess the plasma induced reactivity. Treatments were applied to micronutrient deficient soils for wheat (Triticum aestivum) and chickpea (Cicer arietinum) seeds under greenhouse conditions. Results demonstrated significant enhancement in germination index, chlorophyll content, and shoot root biomass compared to controls. PAW and ionic treatments notably increased the micronutrient content in grains, indicating effective biofortification. Soil microbial activity and enzyme assays showed no toxicity and a mild stimulatory effect due to reactive nitrogen species. This study establishes a green, scalable method of delivering micronutrients through plasma-activated irrigation water, linking plasma chemistry with sustainable agronomy and nutritional security.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [50] [Autonomous Materials Exploration by Integrating Automated Phase Identification and AI-Assisted Human Reasoning](https://arxiv.org/abs/2601.08185)
*Ming-Chiang Chang,Maximilian Amsler,Duncan R. Sutherland,Sebastian Ament,Katie R. Gann,Lan Zhou,Louisa M. Smieska,Arthur R. Woll,John M. Gregoire,Carla P. Gomes,R. Bruce van Dover,Michael O. Thompson*

Main category: cond-mat.mtrl-sci

TL;DR: Autonomous materials synthesis extension to SARA with human-in-the-loop (SARA-H) accelerates materials discovery by combining AI, robotics, and human expertise to efficiently explore combinatorial chemical spaces and identify targeted phases.


<details>
  <summary>Details</summary>
Motivation: To accelerate materials development by combining AI with robotic platforms for autonomous experimentation, enabling exploration of extensive combinatorial chemical spaces while incorporating human domain expertise to improve search efficiency and target user-defined objectives.

Method: Extended SARA to SARA-H (Scientific Autonomous Reasoning Agent with human-in-the-loop) using automated probabilistic phase labeling, robotic processing of thin-film samples via lateral-gradient laser spike annealing, and experimental active learning campaigns on oxide systems including Bi₂O₃, SnOₓ, and Bi-Ti-O.

Result: Demonstrated improved sampling efficiency with human input, identified extensive processing domains stabilizing δ-Bi₂O₃ and Bi₂Ti₂O₇, explored dwell-dependent ternary oxide phase behavior, and confirmed predictions that Bi doping inhibits anatase-to-rutile transformation in TiO₂.

Conclusion: The developed autonomous methods enable discovery of new materials and new understanding of materials synthesis and properties, showcasing the utility of human-in-the-loop autonomous experimentation for accelerating materials research.

Abstract: Autonomous experimentation holds the potential to accelerate materials development by combining artificial intelligence (AI) with modular robotic platforms to explore extensive combinatorial chemical and processing spaces. Such self-driving laboratories can not only increase the throughput of repetitive experiments, but also incorporate human domain expertise to drive the search towards user-defined objectives, including improved materials performance metrics. We present an autonomous materials synthesis extension to SARA, the Scientific Autonomous Reasoning Agent, utilizing phase information provided by an automated probabilistic phase labeling algorithm to expedite the search for targeted phase regions. By incorporating human input into an expanded SARA-H (SARA with human-in-the-loop) framework, we enhance the efficiency of the underlying reasoning process. Using synthetic benchmarks, we demonstrate the efficiency of our AI implementation and show that the human input can contribute to significant improvement in sampling efficiency. We conduct experimental active learning campaigns using robotic processing of thin-film samples of several oxide material systems, including Bi$_2$O$_3$, SnO$_x$, and Bi-Ti-O, using lateral-gradient laser spike annealing to synthesize and kinetically trap metastable phases. We showcase the utility of human-in-the-loop autonomous experimentation for the Bi-Ti-O system, where we identify extensive processing domains that stabilize $δ$-Bi$_2$O$_3$ and Bi$_2$Ti$_2$O$_7$, explore dwell-dependent ternary oxide phase behavior, and provide evidence confirming predictions that cationic substitutional doping of TiO$_2$ with Bi inhibits the unfavorable transformation of the metastable anatase to the ground-state rutile phase. The autonomous methods we have developed enable the discovery of new materials and new understanding of materials synthesis and properties.

</details>


### [51] [Cyclic- and helical-symmetry-adapted phonon formalism within density functional perturbation theory](https://arxiv.org/abs/2601.08745)
*Abhiraj Sharma,Phanish Suryanarayana*

Main category: cond-mat.mtrl-sci

TL;DR: First-principles framework for calculating phonons in nanostructures with cyclic/helical symmetry, implemented with DFT perturbation theory and finite-difference discretization, validated on carbon nanotubes.


<details>
  <summary>Details</summary>
Motivation: Need for efficient and accurate phonon calculations in nanostructures with cyclic/helical symmetry (like nanotubes) that can't be easily handled by conventional periodic plane-wave methods.

Method: Developed cyclic- and helical-symmetry-adapted representation of dynamical matrix within variationally formulated symmetry-adapted density functional perturbation theory, with high-order finite-difference discretization implementation.

Result: Excellent agreement with periodic plane-wave results for carbon nanotubes; computed Young's and shear moduli matching previous DFT and experimental results; derived phonon scaling laws showing qualitative agreement with atomistic simulations.

Conclusion: Framework enables accurate phonon calculations in nanostructures with cyclic/helical symmetry, validated on carbon nanotubes with applications to elastic properties and phonon scaling laws.

Abstract: We present a first-principles framework for the calculation of phonons in nanostructures with cyclic and/or helical symmetry. In particular, we derive a cyclic- and helical-symmetry-adapted representation of the dynamical matrix at arbitrary phonon wavevectors within a variationally formulated, symmetry-adapted density functional perturbation theory framework. In so doing, we also derive the acoustic sum rules for cylindrical geometries, which include a rigid-body rotational mode in addition to the three translational modes. We implement the cyclic- and helical-symmetry-adapted formalism within a high-order finite-difference discretization. Using carbon nanotubes as representative systems, we demonstrate the accuracy of the framework through excellent agreement with periodic plane-wave results. We further apply the framework to compute the Young's and shear moduli of carbon nanotubes, as well as the scaling laws governing the dependence of ring and radial breathing mode phonon frequencies on nanotube diameter. The elastic moduli are found to be in agreement with previous density functional theory and experimental results, while the phonon scaling laws show qualitative agreement with previous atomistic simulations.

</details>


<div id='hep-ex'></div>

# hep-ex [[Back]](#toc)

### [52] [MinGLE: A Minimalist, Configurable, and Pedagogical Geant4 Application Template](https://arxiv.org/abs/2601.08469)
*Jing Liu*

Main category: hep-ex

TL;DR: MinGLE is a minimal Geant4 learning template with <70 lines of core C++ code, using modern Geant4 features and Git tags for incremental learning.


<details>
  <summary>Details</summary>
Motivation: Geant4 has a steep learning curve for new developers due to complex, experiment-specific introductory examples. There's a need for a universal, flexible educational starting point.

Method: Created MinGLE (Mini Geant4 Learning Example) as a minimal application template using contemporary Geant4 features: factory classes for run management/physics, Text Geometry format for detector definition, and Git tags to document incremental development of 11 core components.

Result: Achieved a complete, functional simulation kernel with fewer than 70 lines of core C++ code. Each Git-tagged version is fully compilable, executable, and testable, providing clear step-by-step learning.

Conclusion: MinGLE provides an effective educational tool that simplifies Geant4 learning through minimalism, modern features, and structured incremental development documentation.

Abstract: The Geant4 toolkit is the leading software for the simulation of particle transport through matter, widely used in nuclear physics, high-energy physics, and medical physics. However, the initial learning curve for new developers can be steep, often due to the complexity and experiment-specific nature of many introductory examples. This paper introduces MinGLE (Mini Geant4 Learning Example), a dedicated application template designed to be a universal, flexible, and educational starting point for Geant4 projects. MinGLE achieves a complete, functional simulation kernel using fewer than 70 lines of core C++ code. This minimalism is realized by leveraging contemporary Geant4 features, including factory classes for run management and physics, and the Text Geometry format for detector definition. Furthermore, MinGLE employs a unique pedagogical structure, using Git tags to document the incremental development of eleven core Geant4 components, with each tagged version being fully compilable, executable, and testable, providing a clear, step-by-step learning resource.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [53] [Conservation laws and exact solutions of a nonlinear acoustics equation by classical symmetry reduction](https://arxiv.org/abs/2601.08548)
*Almudena del Pilar Marquez,Elena Recio,Maria Luz Gandarias*

Main category: math-ph

TL;DR: Analysis of symmetries and conservation laws for a generalized Westervelt equation used in nonlinear acoustics, with classification of point symmetries, derivation of conservation laws, potential systems, and study of travelling wave solutions.


<details>
  <summary>Details</summary>
Motivation: The Westervelt equation models sound wave propagation in compressible media and is important for biomedical applications like ultrasound imaging. Understanding its symmetries and conservation laws can lead to useful developments in solution properties and applications.

Method: Applied modern methods to uncover point symmetries and conservation laws. Used multiplier method to obtain local low-order conservation laws related to net mass of sound waves. Derived two potential systems yielding potential symmetries and nonlocal conservation laws. Studied travelling wave solutions for the physical case.

Result: Complete classification of point symmetries for the arbitrary function. Obtained local low-order conservation laws. Derived two potential systems with potential symmetries and nonlocal conservation laws. Travelling wave solutions lead to shock waves in the physical case.

Conclusion: The analysis provides comprehensive understanding of symmetries and conservation laws for the generalized Westervelt equation, which can facilitate solution development and property analysis, especially relevant for biomedical applications like ultrasound imaging.

Abstract: Symmetries and conservation laws are studied for a generalized Westervelt equation which is a nonlinear partial differential equation modelling the propagation of sound waves in a compressible medium. This nonlinear wave equation is widely used in nonlinear acoustics and it is especially important in biomedical applications such as ultra-sound imaging in human tissue. Modern methods are applied to uncover point symmetries and conservation laws that can lead to useful developments concerning solutions and their properties. A complete classification of point symmetries is shown for the arbitrary function. Local low-order conservation laws related to net mass of sound waves are obtained by the multiplier method. Two potential systems are derived yielding potential symmetries and nonlocal conservation laws. For the physical case interesting for this equation, travelling wave solutions are studied leading to shock waves.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [54] [An open-source computational framework for immersed fluid-structure interaction modeling using FEBio and MFEM](https://arxiv.org/abs/2601.08266)
*Ryan T. Black,Steve A. Maas,Wensi Wu,Jalaj Maheshwari,Tzanio Kolev,Jeffrey A. Weiss,Matthew A. Jolley*

Main category: q-bio.QM

TL;DR: A new open-source immersed FSI framework combines MFEM (GPU-ready fluid solver) and FEBio (biomechanics solid solver) for simulating complex biological systems like heart valves with large deformations and contact mechanics.


<details>
  <summary>Details</summary>
Motivation: Traditional ALE methods struggle with large structural deformations and contact mechanics in biological systems (like heart valves) due to mesh distortion problems, creating a need for immersed techniques that can handle these challenges.

Method: Coupling two mature finite element libraries: MFEM for GPU-ready fluid solving with distributed-memory parallelization, and FEBio for nonlinear solid mechanics with hyperelastic/viscoelastic models. Uses fictitious domain methodology with variational multiscale stabilization for immersed FSI, and implements a fully implicit monolithic scheme for robust coupling.

Result: Developed a modular open-source framework that successfully demonstrates capabilities through several test problems, including a 3D semilunar heart valve simulation, combining advanced biomechanics modeling with high-performance computing infrastructure.

Conclusion: This framework addresses a critical need for open-source immersed FSI software that can handle complex biomechanical applications with large deformations and contact mechanics while leveraging modern HPC capabilities.

Abstract: Fluid-structure interaction (FSI) simulation of biological systems presents significant computational challenges, particularly for applications involving large structural deformations and contact mechanics, such as heart valve dynamics. Traditional ALE methods encounter fundamental difficulties with such problems due to mesh distortion, motivating immersed techniques. This work presents a novel open-source immersed FSI framework that strategically couples two mature finite element libraries: MFEM, a GPU-ready and scalable library with state-of-the-art parallel performance developed at Lawrence Livermore National Laboratory, and FEBio, a nonlinear finite element solver with sophisticated solid mechanics capabilities designed for biomechanics applications developed at the University of Utah. This coupling creates a unique synergy wherein the fluid solver leverages MFEM's distributed-memory parallelization and pathway to GPU acceleration, while the immersed solid exploits FEBio's comprehensive suite of hyperelastic and viscoelastic constitutive models and advanced solid mechanics modeling targeted for biomechanics applications. FSI coupling is achieved using a fictitious domain methodology with variational multiscale stabilization for enhanced accuracy on under-resolved grids expected with unfitted meshes used in immersed FSI. A fully implicit, monolithic scheme provides robust coupling for strongly coupled FSI characteristic of cardiovascular applications. The framework's modular architecture facilitates straightforward extension to additional physics and element technologies. Several test problems are considered to demonstrate the capabilities of the proposed framework, including a 3D semilunar heart valve simulation. This platform addresses a critical need for open-source immersed FSI software combining advanced biomechanics modeling with high-performance computing infrastructure.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [55] [Stochastic search with space-dependent diffusivity](https://arxiv.org/abs/2601.08740)
*Hwai-Ray Tung,Sean D Lawley*

Main category: cond-mat.stat-mech

TL;DR: The paper analyzes how stochastic search times depend on the Itô vs Stratonovich interpretation of multiplicative noise when diffusion coefficients vary in space, deriving general formulas for search time distributions and splitting probabilities.


<details>
  <summary>Details</summary>
Motivation: While stochastic search problems are well-studied for constant diffusivity, little is known for space-dependent (heterogeneous) diffusion where the interpretation of multiplicative noise (Itô-Stratonovich dilemma) becomes crucial. The paper aims to understand how search dynamics depend on this interpretation.

Method: Derived general formulas for probability distribution and moments of stochastic search time and splitting probabilities using asymptotic analysis. Assumes targets are small or weakly reactive, valid for general space-dependent diffusivities in general domains of any dimension with targets of general shape (interior or boundary). Verified with stochastic simulations.

Result: Obtained general asymptotic formulas that show stochastic search can depend strongly and counterintuitively on the multiplicative noise interpretation (Itô vs Stratonovich). The theory works for various domain geometries and target configurations.

Conclusion: The interpretation of multiplicative noise (Itô-Stratonovich dilemma) significantly impacts stochastic search dynamics with space-dependent diffusivity, with potentially strong and counterintuitive effects that must be considered in modeling heterogeneous diffusion processes.

Abstract: The canonical model of stochastic search tracks a randomly diffusing "searcher" until it finds a "target." Owing to its many applications across science and engineering, this perennially popular problem has been thoroughly investigated in a variety of models. However, aside from some exactly solvable one-dimensional examples, very little is known if the searcher diffusivity varies in space. For such space-dependent or "heterogeneous" diffusion, one must specify the interpretation of the multiplicative noise, which is termed the Itô-Stratonovich dilemma. In this paper, we investigate how stochastic search with space-dependent diffusivity depends on this interpretation. We obtain general formulas for the probability distribution and all the moments of the stochastic search time and the so-called splitting probabilities assuming that the targets are small or weakly reactive. These asymptotic results are valid for general space-dependent diffusivities in general domains in any space dimension with targets of general shape which may be in the interior or on the boundary of the domain. We illustrate our theory with stochastic simulations. Our analysis predicts that stochastic search can depend strongly and counterintuitively on the multiplicative noise interpretation.

</details>
