<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 10]
- [math.AP](#math.AP) [Total: 13]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 4]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math.FA](#math.FA) [Total: 1]
- [physics.ed-ph](#physics.ed-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [nucl-ex](#nucl-ex) [Total: 1]
- [math.SP](#math.SP) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Space-time spectral element method for topology optimization of transient heat conduction](https://arxiv.org/abs/2601.08979)
*Sarah Nataj,Magnus Appel,Joe Alexandersen*

Main category: math.NA

TL;DR: Space-time spectral element method for topology optimization of transient heat conduction using SBP-SAT discretization with dual-consistent adjoint scheme.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient and accurate method for large-scale topology optimization of time-dependent thermal systems that reduces computational cost and memory requirements compared to existing approaches.

Method: Space-time spectral element method with SBP operators for discretization, SAT for weak imposition of interface/boundary and initial/terminal conditions, and discrete space-time adjoint scheme for design sensitivities.

Result: The method achieves high accuracy with fewer space-time degrees of freedom, remains stable, reduces time-to-solution and memory compared to alternative all-at-once solvers, and produces validated optimal designs.

Conclusion: The proposed SBP-SAT space-time scheme is a promising candidate for large-scale topology optimization of time-dependent thermal systems due to its efficiency, accuracy, and stability.

Abstract: We develop a space-time spectral element method for topology optimization of transient heat conduction. The forward problem is discretized with summation-by-parts (SBP) operators, and interface/boundary and initial/terminal conditions are imposed weakly via simultaneous approximation terms (SAT), yielding a stable monolithic space-time scheme on heterogeneous domains. Stability is proven under specific conditions on the SAT parameters, scaled with the spatial mesh resolution and material properties. We compute design sensitivities using a discrete space-time adjoint scheme that is dual-consistent with the primal SBP-SAT scheme. Dual consistency ensures that the discrete adjoint consistently approximates the continuous dual problem and, under standard smoothness assumptions, yields superconvergent functional estimates. We validate the resulting optimal designs by comparison with an independently computed reference optimal design and report time-to-solution and cost-of-accuracy curves, comparing against low-order time-marching and all-at-once solvers for the forward and adjoint systems. The proposed scheme attains high accuracy with fewer space-time degrees of freedom and remains stable, reducing time-to-solution and memory compared with an alternative all-at-once solver. This makes it a future candidate for large-scale topology optimization of time-dependent thermal systems.

</details>


### [2] [Nonlinear Inverse Iterations for Spin-Orbit Coupled Quantum Gases](https://arxiv.org/abs/2601.08990)
*Patrick Henning,Laura Huynh*

Main category: math.NA

TL;DR: The paper presents a nonlinear inverse iteration method (J-method) for computing ground states of spin-orbit coupled Bose-Einstein condensates, achieving faster convergence than conventional approaches through spectral shifting techniques.


<details>
  <summary>Details</summary>
Motivation: Spin-orbit coupled BECs exhibit fascinating phenomena like supersolid-like phases, but conventional numerical methods (generalized inverse iterations, gradient descent) converge very slowly for these complex systems.

Method: Apply the J-method to construct a nonlinear inverse iteration scheme with spectral shifting acceleration, analogous to techniques used for linear eigenproblems. Use adaptive shift parameter selection.

Result: For fixed shift parameters, local linear convergence rates are established based on spectral gaps near quasi-unique ground states. With adaptive shifts, superlinear convergence is observed and verified through numerical experiments.

Conclusion: The J-method with spectral shifting provides an effective approach for computing ground states of spin-orbit coupled BECs, overcoming the slow convergence limitations of conventional numerical methods.

Abstract: This work concerns the computation of ground states of two-component spin-orbit coupled Bose-Einstein condensates (SO-coupled BECs), modelled by a coupled nonlinear eigenvalue problem of Gross-Pitaevskii type. Spin-orbit coupling gives rise to fascinating phenomena, including supersolid-like phases with spatially modulated densities. However, in such complex settings, conventional numerical approaches, such as generalized inverse iterations or gradient descent, often converge very slowly. To overcome this issue, we apply the concept of the J-method [E.~Jarlebring, S.~Kvaal, W.~Michiels. SIAM~J.~Sci.~Comput.~36-4,~2014] to construct a nonlinear inverse iteration scheme whose convergence can be accelerated through spectral shifting, analogous to techniques used for linear eigenproblems. For a fixed shift parameter, we establish local linear convergence rates determined by spectral gaps in the neighbourhood of each quasi-unique ground state. With adaptively chosen shifts, superlinear convergence is observed, which we verify through numerical experiments.

</details>


### [3] [On the unmapped tent pitching for the heterogeneous wave equation](https://arxiv.org/abs/2601.09337)
*Marcella Bonazzoli,Gabriele Ciaramella,Ilario Mazzieri*

Main category: math.NA

TL;DR: UTP algorithm extended to heterogeneous media with piecewise constant wave speeds, using space-time subdomains sized by maximum propagation speed for computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Extend the Unmapped Tent Pitching (UTP) algorithm, originally developed for homogeneous media, to handle heterogeneous media where wave propagation speeds vary across different subregions of the domain.

Method: Investigated several strategies for extending UTP to heterogeneous media with piecewise constant wave speeds. The most efficient approach uses space-time subdomains with identical spatial and temporal dimensions in both regions, determined by the maximum propagation speed.

Result: Successfully extended UTP to heterogeneous media, with the approach using uniform space-time subdomains based on maximum propagation speed proving most computationally efficient.

Conclusion: UTP can be effectively extended to heterogeneous media, and the strategy using space-time subdomains sized by maximum wave speed provides the best computational performance for parallel solution of hyperbolic problems in piecewise constant media.

Abstract: The Unmapped Tent Pitching (UTP) algorithm is a space--time domain decomposition method for the parallel solution of hyperbolic problems. It was originally introduced for the homogeneous one-dimensional wave equation in [Ciaramella, Gander, Mazzieri, 2024]. UTP is inspired by the Mapped Tent Pitching (MTP) algorithm [Gopalakrishnan, Sch{ö}berl, Wintersteiger, 2017], which constructs the solution by iteratively building polytopal space--time subdomains, referred to as tents. In MTP, each physical tent is mapped onto a space--time rectangle, where local problems are solved before being mapped back to the original domain. In contrast, UTP avoids the nonlinear and potentially singular mapping step by computing the solution directly on a physical space--time rectangle that contains the tent, at the expense of redundant computations in the region outside the tent. In this work, we investigate several strategies to extend UTP to heterogeneous media, where the wave propagation speed is piecewise constant over two subregions of the domain. Among the considered approaches, the most efficient in terms of computational time is the one employing space--time subdomains with identical spatial and temporal dimensions in both regions, determined by the maximum propagation speed.

</details>


### [4] [Thermodynamically consistent phase-field modeling and numerical simulation for two-phase fluid-solid dynamics](https://arxiv.org/abs/2601.09383)
*Cedric Riethmüller,Lars von Wolff,Dominik Göddeke,Christian Rohde*

Main category: math.NA

TL;DR: A thermodynamically consistent coupled Cahn-Hilliard Navier-Stokes model for fluid-solid two-phase systems with a fully-discrete finite element method that preserves energy dissipation.


<details>
  <summary>Details</summary>
Motivation: To develop a thermodynamically consistent model for fluid-solid two-phase systems that can handle complex geometries and chemically reacting flows, while providing reliable numerical methods that preserve the physical energy dissipation property.

Method: A coupled Cahn-Hilliard Navier-Stokes model with continuous finite element discretization and semi-implicit time-stepping. Includes preprocessing for complex geometries and comparison of monolithic vs partitioned solution strategies.

Result: Theoretical proof of thermodynamic consistency and discrete free energy dissipation inequality. Numerical experiments confirm theoretical findings and demonstrate applicability to realistic settings including chemically reacting flows in complex geometries.

Conclusion: The proposed model and numerical method provide a thermodynamically consistent framework for fluid-solid two-phase systems with practical applicability to complex geometries and chemical reactions, supported by both theoretical guarantees and numerical validation.

Abstract: We introduce a coupled Cahn-Hilliard Navier-Stokes model that governs the two-phase dynamics of a system that consists of a fluid and a solid phase and prove its thermodynamic consistency. Moreover, we present an associated fully-discrete numerical method that relies on a continuous finite element approach and a semi-implicit time-stepping method. As the main theoretical result we show that the fully-discrete method satisfies a discrete analog of the free energy dissipation inequality. Numerical experiments confirm the theoretical findings and show the applicability of the method for realistic settings including an extension to chemically reacting flow. In this context, we provide a preprocessing strategy that enables computing fluid flow in complex geometries given a sharp-interface formulation of the initial phase distribution. Moreover, we briefly introduce different solution strategies for the novel discretization based on the monolithic and partitioned solution paradigms and assess these in a comparative study.

</details>


### [5] [A Randomized Milstein Scheme for SDEs with Superlinear Drift Coefficient](https://arxiv.org/abs/2601.09437)
*Sani Biswas*

Main category: math.NA

TL;DR: Randomized-tamed Milstein scheme for SDEs with superlinear drift growth and limited temporal regularity achieves optimal strong convergence rate of order one.


<details>
  <summary>Details</summary>
Motivation: To develop numerical methods for stochastic differential equations where the drift has both superlinear growth in state variable and limited temporal regularity (β-Hölder continuity), which pose challenges for standard numerical schemes.

Method: Combines taming mechanism to control superlinear state dependence with drift randomization strategy to handle low temporal regularity, creating a randomized-tamed Milstein scheme.

Result: Under suitable assumptions on temporal smoothness, the scheme achieves optimal strong ℒ^p-convergence rate of order one.

Conclusion: The proposed randomized-tamed Milstein scheme effectively handles both superlinear drift growth and limited temporal regularity while maintaining optimal convergence properties.

Abstract: This work presents a randomized-tamed Milstein scheme for stochastic differential equations whose drift coefficient exhibits superlinear growth in the state variable and limited temporal regularity, quantified by $β$-Hölder continuity with $β\in (0,1]$. The scheme combines a taming mechanism to control the superlinear state dependence with a drift randomization strategy designed to address the challenges posed by low temporal regularity. Under suitable assumptions on temporal smoothness, the scheme achieves an optimal strong $\mathscr{L}^p$-convergence rate of order one.

</details>


### [6] [A new class of entropy stable fluctuations for the discontinuous Galerkin method with application to the Saint-Venant-Exner model](https://arxiv.org/abs/2601.09450)
*Patrick Ersing,Andrew R. Winters*

Main category: math.NA

TL;DR: New entropy stable DG methods for nonconservative hyperbolic systems with novel entropy conservative fluctuations and blending procedure for entropy stable dissipation.


<details>
  <summary>Details</summary>
Motivation: Need entropy stable discontinuous Galerkin methods for nonconservative hyperbolic systems, addressing challenges in entropy symmetrization loss and system-specific derivations.

Method: Introduce new class of entropy conservative fluctuations; propose blending procedure to construct entropy stable dissipation terms from general numerical viscosity matrices.

Result: Developed high-order, entropy stable, well-balanced approximation for Saint-Venant-Exner system; verified through numerical tests demonstrating performance and robustness.

Conclusion: Novel methodology enables construction of entropy stable schemes for nonconservative systems without system-specific derivations, with practical application to sediment transport modeling.

Abstract: In this work we consider entropy stable discontinuous Galerkin methods applied to nonconservative hyperbolic systems. We introduce a new class of entropy conservative fluctuations that allow us to construct entropy conservative schemes without any system-specific derivations. We demonstrate that a loss of entropy symmetrization for nonconservative systems restricts the design of entropy stable fluctuations and propose a novel blending procedure to construct entropy stable dissipation terms from general numerical viscosity matrices. The resulting methodology is applied to develop a high-order, entropy stable, and well-balanced approximation for the Saint-Venant-Exner system. Numerical tests are presented to verify the theoretical findings and demonstrate the performance and robustness of the proposed scheme.

</details>


### [7] [Qualitative and Numerical Simulation of a Time-Fractional SEIR Mpox Model Arising in Population Epidemiology](https://arxiv.org/abs/2601.09479)
*Gaurav Saini,Bappa Ghosh,Sunita Chand,Jugal Mohapatra*

Main category: math.NA

TL;DR: A time-fractional SEIR model for Mpox transmission with memory effects, analyzed qualitatively and solved numerically using L1 finite difference scheme with Newton-Raphson, showing superior accuracy over FMEM.


<details>
  <summary>Details</summary>
Motivation: To develop a more accurate epidemiological model that captures memory effects in disease transmission dynamics, specifically for Mpox, using fractional calculus to better represent real-world epidemic behavior.

Method: Developed a time-fractional SEIR model incorporating memory effects via fractional derivatives. Performed qualitative analysis proving unique solution existence and Hyers-Ulam stability. Implemented L1 finite difference scheme for Caputo derivative approximation and solved nonlinear system using Newton-Raphson technique with detailed error analysis.

Result: The L1 scheme achieves algebraic convergence and demonstrates superior accuracy and stability compared to Fractional Modified Euler method (FMEM). Numerical simulations show the impact of non-integer order and vaccination rate on disease progression.

Conclusion: Fractional order models effectively capture epidemic memory effects, and the L1 scheme is a robust numerical tool for simulating such dynamics, providing better accuracy than existing methods like FMEM.

Abstract: Epidemiological modeling is vital in understanding disease dynamics and guiding public health interventions. This study presents a time-fractional SEIR model to describe the transmission dynamics of Mpox, incorporating memory effects via the fractional derivative. We perform an extensive qualitative investigation, proving that there is a unique solution and that the solutions are Hyers-Ulam stable. To approximate the model numerically, we implement the L1 finite difference scheme for the Caputo derivative and solve the resulting nonlinear system using the Newton-Raphson technique. A detailed error analysis is provided, demonstrating that the scheme achieves algebraic convergence. Comparative results with the Fractional Modified Euler method (FMEM) confirm the superior accuracy and stability of the proposed approach. Numerical simulations under biologically relevant parameters illustrate the impact of the non-integer order and vaccination rate on disease progression. The study underscores the effectiveness of fractional order models in capturing epidemic memory effects and positions the L1 scheme as a robust numerical tool for simulating such dynamics.

</details>


### [8] [Two continuous extensions of the Neural Approximated Virtual Element Method](https://arxiv.org/abs/2601.09595)
*Stefano Berrone,Moreno Pintore,Gioana Teora*

Main category: math.NA

TL;DR: Two neural-based variants of NAVEM (B-NAVEM and P-NAVEM) are proposed that construct globally continuous basis functions using pre-trained neural networks, with different approaches to defining local basis functions.


<details>
  <summary>Details</summary>
Motivation: To develop neural network-based virtual element methods that ensure exact continuity across mesh elements while leveraging the flexibility of neural networks for basis function construction.

Method: Two approaches: B-NAVEM uses Physics-Informed Neural Networks to solve local Laplace problems for basis functions; P-NAVEM enforces polynomial reproducibility directly via a tailored loss function without requiring harmonicity.

Result: Numerical experiments assess computational cost, memory usage, and accuracy during both training and testing phases (specific results not provided in abstract).

Conclusion: The paper presents two novel neural-based VEM variants that achieve global continuity while offering different trade-offs in how basis functions are constructed and constrained.

Abstract: We propose two globally continuous neural-based variants of the Neural Approximated Virtual Element Method (NAVEM), termed B-NAVEM and P-NAVEM. Both approaches construct local basis functions using pre-trained fully connected neural networks while ensuring exact continuity across adjacent mesh elements. B-NAVEM leverages a Physics-Informed Neural Network to approximately solve the local Laplace problem that defines the virtual element basis functions, whereas P-NAVEM directly enforces polynomial reproducibility via a tailored loss function, without requiring harmonicity within the element interior. Numerical experiments assess the methods in terms of computational cost, memory usage, and accuracy during both training and testing phases.

</details>


### [9] [Introduction to the Combination of Reduced Order Models and Domain Decomposition: State of the Art and Perspectives](https://arxiv.org/abs/2601.09623)
*Shenhui Ruan,Andreas G. Class,Gianluigi Rozza*

Main category: math.NA

TL;DR: A review paper categorizing and analyzing methods that combine Reduced Order Models (ROMs) with Domain Decomposition (DD) techniques for computational fluid dynamics applications.


<details>
  <summary>Details</summary>
Motivation: ROMs offer computational efficiency for engineering design/optimization, while DD is well-suited for industrial geometries with repeating subdomains or distinct physical regions. Combining ROM and DD can further reduce computational costs by constructing local ROMs and assembling global solutions.

Method: Categorizes existing methods into intrusive (projection-based) and non-intrusive (data-driven) frameworks. Reviews strategies for generating local reduced bases and coupling them across subdomains, with emphasis on intrusive techniques including equations, algorithms, and implementations.

Result: Provides a concise overview of existing methodologies combining ROM and DD, illustrating various coupling strategies and highlighting both intrusive and non-intrusive frameworks with their respective formulations and principles.

Conclusion: Summarizes the state of literature, identifies open challenges, and presents perspectives on future implementation from an engineering viewpoint regarding ROM-DD integration.

Abstract: Reduced Order Models (ROMs) have been regarded as an efficient alternative to conventional high-fidelity Computational Fluid Dynamics (CFD) for accelerating the design and optimization processes in engineering applications. Many industrial geometries feature repeating subdomains or contain sub-regions governed by distinct physical phenomena, making them well-suited to Domain Decomposition (DD) techniques. The integration of ROM and DD is promising to further reduce computational costs by constructing local ROMs and assembling them into global solutions. Due to the complexity and necessity of coupling ROMs, many approaches have been proposed in recent years. This review provides a concise overview of existing methodologies combining ROM and DD. We categorize existing methods into intrusive (projection-based) and non-intrusive (data-driven) frameworks. Various strategies for generating local reduced bases and coupling them across subdomains are illustrated. Particular emphasis is placed on intrusive techniques, including equations, numerical algorithms, and practical implementations. The non-intrusive framework is also discussed, highlighting its general procedures, basic formulations, and underlying principles. Finally, we summarise the state of the literature, identify open challenges, and present perspectives on future implementation from an engineering viewpoint.

</details>


### [10] [Explaining oscillatory behavior in convection-diffusion discretization](https://arxiv.org/abs/2601.09657)
*Constantin Bacuta*

Main category: math.NA

TL;DR: The paper analyzes oscillatory solutions in convection-diffusion problems, proposes methods to eliminate oscillations, introduces a new error analysis approach requiring optimal discrete infinity error, and emphasizes that 2D discretization benefits from efficient 1D discretization along streamlines.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the presence of oscillatory discrete solutions in convection-diffusion problems and studies difficulties in recovering standard approximation results. Non-physical oscillations in numerical solutions are a common problem in convection-dominated flows that needs to be resolved.

Method: The authors justify the presence of non-physical oscillations and propose ways to eliminate them. They introduce a new approach for error analysis that requires establishing optimal discrete infinity error as a first step. The method emphasizes that discretization of 2D convection-dominated problems benefits from efficient discretization of the corresponding 1D problem along each streamline.

Result: The paper provides justification for oscillation presence and proposes oscillation elimination methods. It introduces a novel error analysis framework and demonstrates that efficient 1D discretization along streamlines improves 2D convection-dominated problem solutions.

Conclusion: The results are useful for building new and robust discretizations for multi-dimensional convection-dominated problems. The streamline-based approach and new error analysis methodology provide foundations for developing more stable and accurate numerical methods for convection-diffusion equations.

Abstract: For a model convection-diffusion problem, we address the presence of oscillatory discrete solutions, and study difficulties in recovering standard approximation results for its solution. We justify the presence of non-physical oscillations and propose ways to eliminate oscillations. A new approach for error analysis that requires establishing optimal discrete infinity error as a first step is introduced and justified. We emphasize that the discretization of two dimensional convection dominated problems benefit from the efficient discretization of the corresponding one dimensional problem along each stream line. Our results are useful in building new and robust discretizations for multi-dimensional convection dominated problems.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [11] [Single exponential $H^1$-upper bounds for the primitive equations](https://arxiv.org/abs/2601.09183)
*Takahito Kashiwabara*

Main category: math.AP

TL;DR: The paper establishes improved a priori bounds for 3D primitive equations with full viscosity, showing single exponential growth instead of double exponential bounds previously reported.


<details>
  <summary>Details</summary>
Motivation: Existing literature reports double exponential upper bounds for strong solutions of 3D primitive equations with full viscosity. The authors aim to improve these bounds to single exponential growth, which is more realistic and mathematically optimal. Additionally, they address the challenge of uniform-in-time estimates for Neumann boundary conditions where Poincaré inequality is unavailable.

Method: The authors consider the three dimensional primitive equations with full viscosity in a horizontally periodic box with either homogeneous Neumann or Dirichlet boundary conditions on the top and bottom. They analyze strong solutions and establish a priori bounds using mathematical analysis techniques for partial differential equations, focusing on energy estimates and functional analysis in Sobolev spaces.

Result: The paper establishes a priori bounds in L∞(0,∞; H¹(Ω)) ∩ L²(0,∞; Ḣ²(Ω)) with exponential growth of exp(C‖a‖²_{L²(Ω)}), which is single exponential rather than the double exponential bounds previously reported. The uniform-in-time estimate for Neumann boundary conditions appears to be new.

Conclusion: The authors significantly improve the known bounds for 3D primitive equations with full viscosity, reducing them from double exponential to single exponential growth. This provides more realistic estimates and advances the mathematical understanding of these important geophysical equations, particularly for Neumann boundary conditions where previous techniques were insufficient.

Abstract: The three dimensional primitive equations with full viscosity are considered in a horizontally periodic box $Ω$, which are subject to either the homogeneous Neumann or Dirichlet conditions on the upper and bottom parts of the boundary. For a strong solution $v$ with initial data $a$, we establish \emph{a priori} bounds in $L^\infty(0, \infty; H^1(Ω)) \cap L^2(0, \infty; \dot H^2(Ω))$, the exponential part of which is $\exp(C \|a\|_{L^2(Ω)}^2)$. This is in contrast to the upper bounds reported in the existing literature that are double exponential. Furthermore, the uniform-in-time estimate for the Neumann condition case, in which the Poincaré inequality is unavailable for $v$, seems to be new.

</details>


### [12] [Local-in-time strong solvability of Navier--Stokes type variational inequalities by Rothe's method](https://arxiv.org/abs/2601.09190)
*Takahito Kashiwabara*

Main category: math.AP

TL;DR: This paper proves existence and uniqueness of local-in-time strong solutions for parabolic variational inequalities with Navier-Stokes type nonlinearities, using time discretization (Rothe's method).


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the theory of parabolic variational inequalities to include non-monotone nonlinearities of Navier-Stokes type, allowing for broader boundary conditions than existing literature by not requiring the cancellation property ⟨B(u,v),v⟩=0.

Method: The method uses time discretization (Rothe's method) to prove existence and uniqueness of solutions in maximal-L²-regularity and Kiselev-Ladyzhenskaya classes, assuming the corresponding stationary Stokes problem has better-than-V regularity structure (typically H²-regularity for Navier-Stokes).

Result: The paper proves existence and uniqueness of local-in-time strong solutions for parabolic variational inequalities with Navier-Stokes type bilinear operators and monotone nonlinearities, without requiring the cancellation property, thus allowing more general boundary conditions.

Conclusion: The approach successfully extends solution theory for parabolic variational inequalities to include Navier-Stokes type nonlinearities with broader applicability to boundary conditions, using time discretization methods under appropriate regularity assumptions.

Abstract: We consider parabolic variational inequalities in a Hilbert space $V$, which have a non-monotone nonlinearity of Navier--Stokes type represented by a bilinear operator $B: V \times V \to V'$ and a monotone type nonlinearity described by a convex, proper, and lower-semicontinuous functional $\varphi : V \to (-\infty, +\infty]$. Existence and uniqueness of a local-in-time strong solution in a maximal-$L^2$-regularity class and in a Kiselev--Ladyzhenskaya class are proved by discretization in time (also known as Rothe's method), provided that a corresponding stationary Stokes problem admits a regularity structure better than $V$ (which is typically $H^2$-regularity in case of the Navier--Stokes equations). Since we do not assume the cancelation property $\left< B(u, v), v \right> = 0$, in applications we may allow for broader boundary conditions than those treated by the existing literature.

</details>


### [13] [A new asymptotic model of multilayer tumor growth](https://arxiv.org/abs/2601.09315)
*Rafael Granero-Belinchón,Martina Magliocca*

Main category: math.AP

TL;DR: Derives a weakly nonlinear asymptotic model for multilayer tumor growth from near-flat initial conditions, focusing on finite-time interface collisions and well-posedness analysis.


<details>
  <summary>Details</summary>
Motivation: To understand how multilayer tumors grow from near-flat initial conditions (like bone tumors in femurs) and to develop mathematical models that can capture the complex growth dynamics, particularly focusing on potential finite-time collisions between tumor interfaces.

Method: Develops a new weakly nonlinear asymptotic model of multilayer tumor growth, resulting in a nonlinear and nonlocal high-order system of PDEs. The method involves deriving asymptotic approximations from the full tumor growth equations for near-flat initial configurations.

Result: Obtains a mathematical model in the form of a nonlinear, nonlocal high-order PDE system that describes multilayer tumor growth. The paper then analyzes the well-posedness of this system, motivated by the possibility of finite-time interface collisions.

Conclusion: The study provides a new mathematical framework for analyzing multilayer tumor growth from near-flat initial conditions, with particular attention to the well-posedness issues arising from potential finite-time collisions between tumor interfaces.

Abstract: In this paper we study the growth of a tumor colony of multilayer type and focus on how the tumor grows from a near flat (when compared to the length of the tumor as, for instance, in the case of a bone tumor in a femur) initial colony. In particular we derive and study a new weakly nonlinear asymptotic model of multilayer tumor growth. The model takes the form of a nonlinear and nonlocal high order system of PDEs. Finally, motivated by the possibility of a finite time collision of the interfaces, we study the well-posedness of this system.

</details>


### [14] [Well-posedness results for superlinear Fokker-Planck equations](https://arxiv.org/abs/2601.09341)
*Stefano Buccheri,Fernando Farroni,Gabriella Zecca*

Main category: math.AP

TL;DR: Existence of distributional solutions for nonlinear Fokker-Planck equations with superlinear growth terms


<details>
  <summary>Details</summary>
Motivation: Study nonlinear Fokker-Planck equations with superlinear growth terms, which arise in various physical contexts but present mathematical challenges for existence and regularity of solutions.

Method: Analyze the equation ∂_t u - div(M∇u + E h(u)) = 0 with elliptic matrix M, vector field E in Lebesgue spaces, and superlinear h(u). Provide existence results for distributional solutions in C([0,T), L^1) spaces.

Result: Establish existence of distributional solutions to initial-boundary value problems for this class of equations, along with qualitative properties of the obtained solutions.

Conclusion: Successfully prove existence and qualitative properties for distributional solutions to nonlinear Fokker-Planck equations with superlinear growth, advancing the mathematical understanding of such PDEs.

Abstract: In this manuscript we deal with a class of nonlinear Fokker-Planck equations with the following structure \[ \partial_t u - ÷\big(M\nabla u+ E h(u)\big)=0, \] with $M$ a bounded elliptic matrix, $E$ a vector field in a suitable Lebesgue space, and $h(u)$ featuring a superlinear growth for $u$ large. We provide existence results of $C([0,T),L^1)$ distributional solutions to initial-boundary value problems related to the equation above together with some qualitative properties of solutions.

</details>


### [15] [Existence and uniqueness of minimizers for axisymmetric nematic films](https://arxiv.org/abs/2601.09348)
*Giulia Bevilacqua,Chiara Lonati,Luca Lussardi,Alfredo Marzocchi*

Main category: math.AP

TL;DR: Study of nematic surfaces with in-plane orientational order on axisymmetric surfaces, focusing on existence, uniqueness, and geometric characterization of minimizers.


<details>
  <summary>Details</summary>
Motivation: To understand the equilibrium shapes of nematic surfaces where liquid crystal orientation is constrained to the tangent plane of axisymmetric surfaces, combining surface tension and nematic elasticity effects.

Method: Use variational model with surface gradient operator, restrict to revolution surfaces spanning coaxial rings, assume nematic director aligned along parallels, reducing to 1D variational problem.

Result: Rigorous proof of existence and uniqueness of minimizers, complete geometric characterization of equilibrium shapes, supplemented by numerical simulations.

Conclusion: The constrained nematic director alignment on axisymmetric surfaces leads to well-defined equilibrium shapes with unique minimizers that can be fully characterized geometrically.

Abstract: Nematic surfaces are thin liquid films endowed with in-plane orientational order. We study a variational model in which the nematic director is constrained to lie in the tangent space of an axisymmetric surface, and the associated surface energy accounts for both surface tension and elastic nematic contributions. Here we adopt the surface gradient as the differential operator on the surface, we restrict our analysis to revolution surfaces spanning two coaxial rings, and we assume that the nematic director is aligned along parallels. In this setting, the energy functional reduces to a one-dimensional variational problem. We rigorously prove the existence and uniqueness of minimizers and we provide their complete geometric characterization. Finally, we run some numerical simulations.

</details>


### [16] [Thin-film limit of the parabolic $p$-Laplace equation in a moving thin domain](https://arxiv.org/abs/2601.09386)
*Tatsu-Hiko Miura*

Main category: math.AP

TL;DR: The paper studies the parabolic p-Laplace equation in shrinking thin domains, deriving a limit problem on a moving hypersurface as the thickness goes to zero.


<details>
  <summary>Details</summary>
Motivation: To understand how solutions to parabolic p-Laplace equations behave when the domain becomes extremely thin and shrinks to a moving hypersurface, particularly under mass conservation boundary conditions.

Method: Analyze the parabolic p-Laplace equation (p>2) in moving thin domains with Neumann boundary conditions ensuring total mass conservation. Show weak convergence of weighted averages of solutions as domain thickness approaches zero, and characterize the limit function as a unique weak solution to the derived limit problem.

Result: Successfully derived a limit problem consisting of a system: a nonlinear PDE coupled with an algebraic equation on the moving hypersurface. This system represents a new kind of local mass conservation law on the moving hypersurface with normal flux.

Conclusion: The limit problem obtained is a novel system that can be interpreted as a local mass conservation law on moving hypersurfaces, providing rigorous mathematical justification for thin-domain approximations in parabolic p-Laplace equations with mass conservation.

Abstract: We consider the parabolic $p$-Laplace equation with $p>2$ in a moving thin domain under a Neumann type boundary condition corresponding to the total mass conservation. When the moving thin domain shrinks to a given closed moving hypersurface as its thickness tends to zero, we rigorously derive a limit problem by showing the weak convergence of the weighted average of a weak solution to the thin-domain problem and characterizing the limit function as a unique weak solution to the limit problem. The limit problem obtained in this paper is a system of a nonlinear partial differential equation and an algebraic equation on the moving hypersurface. This seems to be somewhat strange, but we also find that the limit problem can be seen as a new kind of local mass conservation law on the moving hypersurface with a normal flux.

</details>


### [17] [Gradient estimates for the $p$-Laplacian perfect conductivity problem with partially flat and $C^{1,γ}$ inclusions](https://arxiv.org/abs/2601.09435)
*Hongjie Dong,Longjuan Xu*

Main category: math.AP

TL;DR: Gradient estimates for p-Laplacian perfect conductivity problem with two closely spaced conductors: bounded gradient for partially flat boundaries, blow-up rates for C^{1,γ} boundaries, with asymptotic expansions.


<details>
  <summary>Details</summary>
Motivation: To understand gradient behavior in perfect conductivity problems with closely spaced conductors, particularly contrasting cases where gradient remains bounded versus blows up, which has practical implications for electrical field concentration and material failure.

Method: Analyze p-Laplacian elliptic equations modeling perfect conductivity with two closely spaced conductors. Prove gradient boundedness for partially flat boundaries, establish upper/lower bounds with optimal blow-up rates for C^{1,γ} boundaries, and derive asymptotic expansions in special cases.

Result: 1) Gradient remains bounded when conductors have partially flat boundaries. 2) For C^{1,γ} boundaries, optimal blow-up rates established with both upper and lower bounds. 3) Precise asymptotic expansions provided for special cases.

Conclusion: The geometry of conductor boundaries critically determines gradient behavior: partially flat boundaries prevent blow-up while C^{1,γ} boundaries lead to optimal blow-up rates, with complete characterization provided through bounds and asymptotic expansions.

Abstract: In this paper, we investigate the gradient estimates for solutions to the perfect conductivity problem with two closely spaced perfect conductors embedded in a homogeneous matrix, modeled by $p$-Laplacian elliptic equations. We first prove that the gradient of the solution remains bounded when the conductors possess partially ``flat" boundaries. This contrasts with the case involving strictly convex inclusions, where the gradient can blow up. Second, for conductors with $C^{1,γ}$ boundaries ($γ\in(0,1)$), we establish both upper and lower bounds on the gradient, with optimal blow-up rates. Furthermore, we provide precise asymptotic expansions in some special cases.

</details>


### [18] [Note on Boundary Stabilization of Degenerate Schrödinger Equations](https://arxiv.org/abs/2601.09475)
*Abdelkader Benaissa,Abbes Benaissa*

Main category: math.AP

TL;DR: Analysis of polynomial energy decay rates for degenerate Schrödinger equations with singular fractional integral damping acting on different boundary types.


<details>
  <summary>Details</summary>
Motivation: To study degenerate Schrödinger equations with singular, non-integrable fractional integral damping, particularly examining damping effects on both degenerate and nondegenerate boundaries, which presents mathematical challenges due to the damping's singular nature.

Method: Uses resolvent estimates to analyze the degenerate Schrödinger equation with fractional integral damping, examining two cases: damping acting on degenerate boundary and damping acting on nondegenerate boundary.

Result: Establishes polynomial energy decay rates for the degenerate Schrödinger equation under both boundary damping scenarios.

Conclusion: The paper successfully demonstrates polynomial energy decay for degenerate Schrödinger equations with singular fractional integral damping using resolvent estimates, addressing both boundary damping configurations.

Abstract: A degenerate Schrödinger equation under fractional integral damping is considered. Here the damping term is singular and not integrable and we consider the two cases when damping acting on the degenerate boundary and nondegenerate boundary. In this paper, we establish polynomial energy decay rates for the degenerate Schrödinger equation by using resolvent estimates.

</details>


### [19] [A note on critical problems involving the $p$-Grushin Operator: existence of infinitely many solutions](https://arxiv.org/abs/2601.09488)
*Paolo Malanchini,Giovanni Molica Bisci,Simone Secchi*

Main category: math.AP

TL;DR: The paper proves existence of infinitely many solutions for a critical problem involving the p-Grushin operator using truncation and Krasnoselskii's genus theory.


<details>
  <summary>Details</summary>
Motivation: To extend previous results by García Azorero and Peral Alonso from the classical setting to the p-Grushin operator, addressing critical problems in bounded domains.

Method: Uses truncation argument and Krasnoselskii's genus theory to obtain infinitely many solutions, with key verification of Palais-Smale condition for the associated functional below a certain energy level.

Result: Successfully extends previous results to the p-Grushin operator, obtaining infinitely many solutions to the critical problem in bounded domains.

Conclusion: The p-Grushin operator critical problem admits infinitely many solutions, extending known results from classical operators to this more general setting.

Abstract: We consider a critical problem in a bounded domain involving the $p$-Grushin operator $Δ_α^p$. After a truncation argument, we obtain infinitely many solutions to our problem via Krasnoselskii's genus, extending a previous result of García Azorero and Peral Alonso to the $p$-Grushin operator. A central part of our analysis is the verification of the Palais-Smale condition of the associated functional under a certain level.

</details>


### [20] [Normal trace inequalities and decay of solutions to the nonlinear Maxwell system with absorbing boundary](https://arxiv.org/abs/2601.09490)
*Richard Nutt,Roland Schnaubelt*

Main category: math.AP

TL;DR: Study of quasilinear Maxwell system with state-dependent boundary conductivity, showing global existence and exponential decay for small data under nontrapping condition.


<details>
  <summary>Details</summary>
Motivation: To analyze the long-time behavior of quasilinear Maxwell systems with boundary conductivity, which has applications in electromagnetism and wave propagation with nonlinear boundary conditions.

Method: Develops new trace estimate for non-autonomous linear problem, uses observability-type estimate, and performs detailed regularity analysis. For linear autonomous case, employs Helmholtz decomposition in Sobolev spaces of negative order.

Result: For small data, solution exists for all times and decays exponentially to zero under nontrapping condition. Results are improved in linear autonomous case.

Conclusion: The paper establishes global existence and exponential decay for quasilinear Maxwell systems with state-dependent boundary conductivity, providing new analytical tools and improved results for linear cases.

Abstract: We study the quasilinear Maxwell system with a strictly positive, state dependent boundary conductivity. For small data we show that the solution exists for all times and decays exponentially to $0$. As in related literature we assume a nontrapping condition. Our approach relies on a new trace estimate for the corresponding non-autonomous linear problem, an observability-type estimate, and a detailed regularity analysis. The results are improved in the linear autonomous case, using properties of the Helmholtz decomposition in Sobolev spaces of (small) negative order.

</details>


### [21] [Exponential decay of the linear Maxwell system due to conductivity near the boundary](https://arxiv.org/abs/2601.09502)
*Richard Nutt,Roland Schnaubelt*

Main category: math.AP

TL;DR: The paper proves exponential decay for damped anisotropic Maxwell systems with boundary damping, using Helmholtz decomposition and observability estimates via Morawetz multipliers.


<details>
  <summary>Details</summary>
Motivation: To establish exponential stability for anisotropic Maxwell systems with boundary damping, addressing the decay behavior of electromagnetic fields under specific charge conditions.

Method: Uses Helmholtz decomposition to split solutions, applies observability-type estimates for related second-order systems without charges, and employs Morawetz multipliers for analysis.

Result: Proves exponential decay to zero for solutions when fields have no magnetic charges on Ω and no electric charges off the damping support σ. Also establishes exact observability and controllability results.

Conclusion: The anisotropic Maxwell system with boundary damping exhibits exponential stability under appropriate charge conditions, with the method providing both decay estimates and controllability results.

Abstract: We study the anisotropic linear Maxwell system on a bounded domain $Ω$ with perfectly conducting boundary conditions. It is damped via a conductivity $σ$ which is strictly positive on a collar at the boundary. We prove that solutions decay exponentially to 0, if the fields have no magnetic charges on $Ω$ and no electric charges off the support of $σ$. Our approach relies on a splitting of the solution via a Helmholtz decomposition and an observability-type estimate for a related second-order system without charges, shown using Morawetz multipliers. Corresponding exact observability and controllability results are also established.

</details>


### [22] [On the classification of Serrin planar domains](https://arxiv.org/abs/2601.09649)
*Alberto Cerezo,Isabel Fernandez,Pablo Mira*

Main category: math.AP

TL;DR: Smooth ring domains solving Serrin's problem with constant boundary conditions correspond to algebro-geometric mKdV potentials, forming finite-dimensional moduli spaces with elliptic functions giving explicit families.


<details>
  <summary>Details</summary>
Motivation: To characterize all smooth ring domains that admit solutions to Serrin's classical overdetermined boundary value problem and understand their geometric structure and classification.

Method: Connect Serrin's problem to algebro-geometric potentials of the mKdV hierarchy, represent domains via holomorphic data on algebraic curves, and study elliptic function solutions to construct explicit families.

Result: All such domains are described by mKdV potentials; space of solutions has finite-dimensional complexity levels; elliptic level yields: (i) 1-parameter family interpolating between flat band and disk chain, (ii) 2D moduli spaces T_n of dihedral-symmetric non-radial ring domains.

Conclusion: Serrin ring domains form structured moduli spaces with algebro-geometric characterization, enabling explicit construction of symmetric solutions and revealing connections between PDEs and integrable systems.

Abstract: We show that all smooth ring domains $Ω\subset \mathbb{R}^2$ that admit a solution to Serrin's classical problem $Δu+2=0$ with locally constant overdetermined boundary conditions along $\partial Ω$ can be described as algebro-geometric potentials of the mKdV hierarchy. The same result holds for periodic unbounded domains with two boundary components. In particular, any such domain is determined by suitable holomorphic data in some algebraic curve. As a consequence, the space of all Serrin ring domains, or periodic Serrin bands, can be ordered into a sequence of finite-dimensional complexity levels. By studying the first non-trivial level, given by elliptic functions, we construct: $(i)$ a global $1$-parameter family of periodic solutions to Serrin's problem that interpolates between a flat band and a chain of disks along an axis, following an unduloid pattern, and $(ii)$ for any $n>1$, a two-dimensional moduli space ${\bf T}_n$ of non-radial Serrin ring domains with a dihedral symmetry group of order $2n$. This moduli space ${\bf T}_n$ is geometrically a triangle, and has radial bands on one side of ${\bf T}_n$, and a necklace of $n$ pairwise tangent disks distributed along the unit circle at its opposite vertex in ${\bf T}_n$.

</details>


### [23] [Asymptotics of variational eigenvalues for a general nonlocal $p$-Laplacian with varying horizon](https://arxiv.org/abs/2601.09700)
*Guillermo García-Sáez*

Main category: math.AP

TL;DR: The paper introduces a new nonlocal p-Laplacian operator using finite-horizon kernels and studies its eigenvalue problem, with stability results showing convergence to local p-Laplacian and fractional p-Laplacian in limiting cases.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework connecting local and nonlocal p-Laplacian operators through finite-horizon kernels, and to study the stability of eigenvalue solutions as the horizon parameter varies between extreme cases.

Method: Introduces a new nonlocal p-Laplacian based on general kernels with finite horizon δ > 0, studies its eigenvalue problem, and uses Γ-convergence arguments to analyze stability as δ → 0⁺ and δ → ∞.

Result: Establishes stability results showing that solutions converge to those of the local p-Laplacian eigenvalue problem when δ → 0⁺, and to those of the H^{s,p}-Laplacian (fractional p-Laplacian) when δ → ∞.

Conclusion: The proposed nonlocal p-Laplacian provides a bridge between local and fractional p-Laplacian operators, with Γ-convergence ensuring solution stability across the entire range of horizon parameters.

Abstract: From the recent developing of nonlocal gradients with finite horizon $δ>0$ based on general kernels, we introduce a new nonlocal $p$-Laplacian and study the eigenvalue problem associated with it. Furthermore, by virtue of $Γ$-convergence arguments, we establish stability results of the solutions for varying horizon in the extreme cases $δ\to 0^+$ and $δ\to\infty$, recovering the solutions for the local eigenvalue problem associated with the $p$-Laplacian, and the ones associated with the $H^{s,p}$-Laplacian, respectively.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [24] [An $O(\log N)$ Monte Carlo method for periodic Coulomb systems](https://arxiv.org/abs/2601.09288)
*Xuanzhao Gao,Shidong Jiang,Jiuyang Liang,Qi Zhou*

Main category: physics.comp-ph

TL;DR: DMK-MC is an O(log N) Monte Carlo method for many-body systems with long-range electrostatics that adapts dual-space multilevel kernel-splitting to single-particle Metropolis updates, outperforming previous FMM-based methods.


<details>
  <summary>Details</summary>
Motivation: Monte Carlo sampling of many-body systems with long-range electrostatics is computationally expensive due to the cost of per-move energy-difference evaluation under periodic boundary conditions, limiting simulation efficiency.

Method: DMK-MC adapts the dual-space multilevel kernel-splitting (DMK) framework to single-particle Metropolis updates. It decomposes the Coulomb kernel into three components: a global periodized smooth part, multilevel smooth difference kernels with same-level colleague box interactions, and a singular residual kernel for short-range direct evaluation. The method computes energy changes and updates stored plane-wave fields with O(1) work per tree level.

Result: DMK-MC achieves O(log N) expected work per trial move for fixed accuracy. Benchmarks on uniform, nonuniform, and implicit-solvent electrolyte/colloidal configurations show DMK-MC consistently outperforms recent FMM-based O(log N) Monte Carlo methods, delivering several-fold speedups at comparable tolerances.

Conclusion: DMK-MC provides an efficient accelerated Monte Carlo method for systems with long-range electrostatics, offering significant computational advantages over existing approaches while maintaining accuracy.

Abstract: Efficient Monte Carlo (MC) sampling of many-body systems with long-range electrostatics is often limited by the cost of per-move energy-difference evaluation under periodic boundary conditions. We present DMK-MC, an accelerated MC method that adapts the dual-space multilevel kernel-splitting (DMK) framework to single-particle Metropolis updates. DMK-MC computes the energy change and, upon acceptance, updates the stored incoming plane-wave fields with $O(1)$ work per tree level, yielding an overall $O(\log N)$ expected work per trial move for fixed accuracy. The method decomposes the Coulomb kernel into three components: a global, periodized smooth part; a multilevel sequence of smooth difference kernels whose interactions are restricted to same-level colleague boxes; and a singular residual kernel whose short-range interactions are evaluated directly. Benchmarks on uniform, highly nonuniform, and implicit-solvent electrolyte and colloidal configurations show that DMK-MC consistently outperforms a recent FMM-based $O(\log N)$ Monte Carlo method, delivering several-fold speedups at comparable tolerances.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [25] [Unperturbed-orbit integration and the 3D kinetic dispersion relation of the electron cyclotron drift instability](https://arxiv.org/abs/2601.09047)
*Yinjian Zhao*

Main category: physics.plasm-ph

TL;DR: Derivation of magnetized-electron density perturbation for crossed-field plasma instabilities, connecting previous dispersion relation formulations and clarifying mathematical foundations.


<details>
  <summary>Details</summary>
Motivation: High-frequency instabilities in crossed-field plasmas cause anomalous electron transport in Hall thrusters, requiring better understanding of the fundamental kinetic theory.

Method: Provides concise derivation of magnetized-electron density perturbation using linearized Vlasov equation with retarded integration along unperturbed orbits, including finite-Larmor-radius effects and cyclotron harmonics.

Result: Clarifies mapping between Ducrocq's Poisson-form and Lafleur's dielectric-form representations of dispersion relations, with mathematical identities collected in appendices.

Conclusion: Paper establishes missing theoretical link for crossed-field plasma instabilities, discusses assumptions, and suggests extensions for more realistic configurations.

Abstract: High-frequency instabilities in crossed-field ($\bm E\times\bm B$) plasmas are widely implicated in anomalous cross-field electron transport in Hall thrusters and related devices. Building on the fully kinetic 3D electrostatic dispersion relations reported by Ducrocq \emph{et al.} and later by Lafleur \emph{et al.}, we provide a concise, self-contained derivation of the key missing step: the magnetized-electron density perturbation $n_{e1}$ obtained from the linearized Vlasov equation via a retarded integration along unperturbed orbits, including finite-Larmor-radius effects and cyclotron harmonics. We collect the required mathematical identities in appendices and clarify the mapping between the Ducrocq Poisson-form and the Lafleur dielectric-form representations, including ion closures (cold-fluid versus kinetic Landau response). We conclude with a brief discussion of the assumptions and possible extensions toward more realistic configurations.

</details>


### [26] [Analysis of wave processes using beam-driven Langmuir/$\mathcal{Z}$-mode waveforms generated in Particle-In-Cell simulations](https://arxiv.org/abs/2601.09368)
*Francisco Javier Polanco-Rodríguez,Catherine Krafft,Philippe Savoini*

Main category: physics.plasm-ph

TL;DR: The paper investigates wave conversion mechanisms in Type III solar radio bursts, focusing on nonlinear decay vs. linear transformations of plasma waves in inhomogeneous plasmas using 2D PIC simulations with virtual satellites.


<details>
  <summary>Details</summary>
Motivation: To understand the relative roles and interplay of nonlinear decay and linear transformations of Langmuir/Z-mode waves in generating electromagnetic emissions during Type III solar radio bursts, and to bridge the gap between numerical simulations and spacecraft observations.

Method: Two-dimensional Particle-In-Cell simulations with a diagnostic approach using large ensembles of virtual satellites that record local waveforms, enabling detailed temporal and spatial characterization of wave processes in randomly inhomogeneous plasmas.

Result: The study quantifies the occurrence rate of wave decay under varying physical conditions and shows how developed plasma density turbulence can significantly alter the balance between nonlinear wave-wave interactions and linear wave transformations.

Conclusion: The findings provide new insights into electromagnetic emission mechanisms during Type III radio bursts and strengthen the connection between simulations and solar wind measurements, offering a valuable framework for interpreting future space-based waveform observations.

Abstract: During Type III solar radio bursts, beam-driven upper-hybrid wave turbulence is converted into electromagnetic emissions at the fundamental plasma frequency and its harmonic, through a chain of various linear and nonlinear wave processes. In this work, we mainly investigate the relative roles and interplay of two key mechanisms: the nonlinear decay of Langmuir/$\mathcal Z$-mode waves and their linear transformations on random density fluctuations and, in particular, their mode conversion at constant frequency into electromagnetic waves. Using two-dimensional Particle-In-Cell simulations, we employ a diagnostic approach based on large ensembles of virtual satellites that record local waveforms, enabling detailed temporal and spatial characterization of wave processes in randomly inhomogeneous plasmas. This method allows robust statistical analysis and direct comparison with spacecraft observations. The study focuses on the dependence of wave dynamics on the average level of density fluctuations and the plasma magnetization. Our results quantify the occurrence rate of decay under varying physical conditions and demonstrate how developed plasma density turbulence can significantly alter the balance between nonlinear wave-wave interactions and linear wave transformations. These findings provide new insights into the mechanisms responsible for electromagnetic emissions during type III radio bursts and strengthen the connection between numerical simulations and in situ solar wind measurements, offering a valuable framework for the interpretation of future space-based waveform observations.

</details>


### [27] [Plasma wakes driven by Compton scattering: Non-linear regime and particle acceleration](https://arxiv.org/abs/2601.09596)
*Thomas Grismayer,Fabrizio Del Gaudio,Luís O. Silva*

Main category: physics.plasm-ph

TL;DR: Plasma wake generation via Compton scattering from photon bursts enables relativistic electron acceleration, with potential applications in laboratory and astrophysical settings around luminous compact objects.


<details>
  <summary>Details</summary>
Motivation: The paper investigates a non-ponderomative plasma wake generation mechanism using Compton scattering from photon bursts, which is relevant when photon wavelength is between Compton wavelength and interparticle distance. This regime allows electrons to reach relativistic velocities and has applications in both laboratory settings and astrophysical scenarios around highly luminous compact objects like pulsars and gamma-ray bursts.

Method: The authors extend linear theory to the nonlinear regime for Compton scattering-driven plasma wakes. They analyze both perfectly collimated drivers (producing light-speed wakes) and non-collimated drivers (producing subluminal phase velocities). They conduct two-dimensional simulations to study transverse field structures and compare them with laser wakefields.

Result: Plasma waves can reach the wave-breaking limit in this regime. Perfectly collimated drivers create wakes propagating at light speed, enabling electron phase-locking (limited by driver depletion). Non-collimated drivers produce subluminal phase velocities that limit acceleration via dephasing. Simulations reveal unique transverse field structures compared to laser wakefields, including a DC magnetic field that provides consistent focusing.

Conclusion: Compton-dominated wakefield acceleration is feasible in conditions where photon wavelengths are smaller than interparticle distances but larger than Compton wavelengths. This mechanism has observational prospects in both laboratory experiments and astrophysical environments around luminous compact objects interacting with tenuous plasmas, offering a distinct acceleration mechanism compared to traditional laser wakefield acceleration.

Abstract: We investigate plasma wake generation via Compton scattering from photon bursts, a non-ponderomotive process relevant when the photon wavelength is smaller than the interparticle distance but larger than the Compton wavelength. In this regime, electrons can reach relativistic velocities. We extend linear theory to the nonlinear regime, showing that plasma waves can reach the wave-breaking limit. Perfectly collimated drivers produce wakes propagating at the speed of light, allowing electron phase-locking (limited by driver depletion). Non-collimated drivers induce subluminal phase velocities, limiting acceleration via dephasing. Two-dimensional simulations reveal unique transverse fields compared to laser wakefields, with a DC magnetic field leading to consistent focusing. The work considers observational prospects in laboratory and astrophysical scenarios such as around highly luminous compact objects (e.g., pulsars, gamma-ray bursts) interacting with tenuous interstellar or intergalactic plasmas, where conditions favor Comptondominated wakefield acceleration.

</details>


### [28] [Comparison of plasma response models for RMP effects on the divertor and scrape-off layer in KSTAR](https://arxiv.org/abs/2601.09617)
*H. Frerichs,J. Van Blarcum,T. Cote,S. K. Kim,Y. Q. Liu,S. M. Yang*

Main category: physics.plasm-ph

TL;DR: RMPs control ELMs but create helical striations on divertor targets; plasma response significantly affects footprint size; simulations overestimate striations compared to measurements; agreement only achieved with smallest footprints under specific conditions.


<details>
  <summary>Details</summary>
Motivation: To understand how plasma response to RMPs affects magnetic footprints and heat load striations on divertor targets, and to reconcile discrepancies between simulations and experimental measurements.

Method: Used FLARE to compute magnetic footprints based on plasma response from GPEC, MARS-F, M3D-C1 and JOREK codes; performed EMC3-EIRENE simulations of heat loads; compared with IRTV measurements at KSTAR.

Result: Substantial differences in footprint sizes (2-14 cm) from different plasma response models; simulations overestimated striation peak values or extent compared to IRTV measurements; reasonable agreement only achieved with smallest footprints under specific conditions (lower power/transport or higher density/radiative losses).

Conclusion: Plasma response modeling significantly impacts predicted magnetic footprints and heat load striations; current simulations tend to overestimate striation effects; achieving agreement with measurements requires careful consideration of plasma response models and operating conditions.

Abstract: Resonant magnetic perturbations (RMPs) are beneficial for control of edge localized modes (ELMs) in tokamaks. Nevertheless, a side effect is the appearance of a helical striations in the particle and heat loads onto divertor targets. The extent and field line connection of these striations is significantly altered by the plasma response to external perturbations. For an ELM suppressed H-mode plasma at KSTAR, magnetic footprints are computed by FLARE based on plasma response from GPEC, MARS-F, M3D-C1 and JOREK with substantial differences in the resulting footprints (from 2 cm to 14 cm). This is reflected in EMC3-EIRENE simulations of the resulting heat loads: it is found that either the peak value or the extent of the striations appear to be overestimated compared to IRTV measurements. Reasonable agreement can only be achieved for the smallest footprint for lower input power and lower cross-field transport, or for higher upstream density and radiative power losses.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [Discrete Solution Operator Learning for Geometry-Dependent PDEs](https://arxiv.org/abs/2601.09143)
*Jinshuai Bai,Haolin Li,Zahra Sharif Khodaei,M. H. Aliabadi,YuanTong Gu,Xi-Qiao Feng*

Main category: cs.LG

TL;DR: DiSOL learns discrete solution procedures for PDEs on varying geometries, handling topological changes and boundary discontinuities that break continuous operator learning assumptions.


<details>
  <summary>Details</summary>
Motivation: Neural operator learning assumes smooth geometry variations, but many engineering problems involve discrete structural changes like topological changes, abrupt boundary condition changes, and computational domain changes that break this assumption.

Method: DiSOL factorizes the solver into learnable stages mirroring classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, preserving procedure-level consistency while adapting to geometry-dependent discrete structures.

Result: Across geometry-dependent Poisson, advection-diffusion, linear elasticity, and spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes.

Conclusion: DiSOL highlights the need for procedural operator representations in geometry-dominated regimes and positions discrete solution operator learning as a distinct, complementary direction in scientific machine learning.

Abstract: Neural operator learning accelerates PDE solution by approximating operators as mappings between continuous function spaces. Yet in many engineering settings, varying geometry induces discrete structural changes, including topological changes, abrupt changes in boundary conditions or boundary types, and changes in the effective computational domain, which break the smooth-variation premise. Here we introduce Discrete Solution Operator Learning (DiSOL), a complementary paradigm that learns discrete solution procedures rather than continuous function-space operators. DiSOL factorizes the solver into learnable stages that mirror classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, thereby preserving procedure-level consistency while adapting to geometry-dependent discrete structures. Across geometry-dependent Poisson, advection-diffusion, linear elasticity, as well as spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes. These results highlight the need for procedural operator representations in geometry-dominated regimes and position discrete solution operator learning as a distinct, complementary direction in scientific machine learning.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [30] [Determination of active forces in actomyosin systems as inverse source problems for the Stokes equation](https://arxiv.org/abs/2601.09356)
*Emily Klass,Tram Thi Ngoc Nguyen,Nilay Cicek,Yoav G. Pollack,Sarah Köster,Andreas Janshoff,Anne Wald*

Main category: physics.flu-dyn

TL;DR: This paper develops methods to identify forces generated by actomyosin networks from fluid flow measurements using inverse source problems with incomplete data.


<details>
  <summary>Details</summary>
Motivation: Force identification is crucial for understanding biological systems that convert energy into mechanical work, particularly in active systems like actomyosin networks that generate forces causing fluid flows.

Method: Uses Stokes equation with incompressibility condition and boundary conditions as theoretical model, formulates force identification as an inverse source problem, provides rigorous analysis of forward problems and missing data impact, derives adjoint operators for regularization.

Result: Developed methods are demonstrated on both synthetic and experimentally measured optical microscopy data from confined and non-confined active gels.

Conclusion: The paper provides a comprehensive framework for identifying forces in actomyosin networks from fluid flow measurements, addressing experimental limitations with incomplete data through rigorous mathematical analysis and regularization techniques.

Abstract: The identification of forces and stresses is a central task in biophysics research: Knowledge on forces is key to understanding dynamic processes in active biological systems that are able to self-organize and display emergent properties by converting energy into mechanical work. The aim of this paper is to identify forces generated by a filament-motor network of F-actin and myosin -- actomyosin -- and exerted on the surrounding fluid, therefore causing a fluid flow. In particular, we evaluate optical microscopy data stemming from two different physical settings, confined and non-confined active gels. As a theoretical model, we use the Stokes equation together with an incompressibility condition and suitable boundary conditions reflecting the physical settings. The problem of determining the forces from knowledge on the fluid flow is formulated as an inverse source problem. Due to experimental limitations, only incomplete data are available. We provide a rigorous analysis of the forward problems and the impact of missing data, derive the adjoints of the forward operators needed for regularization, and demonstrate our methods on both synthetic and experimentally measured data.

</details>


### [31] [Mathematical Theorems on Turbulence](https://arxiv.org/abs/2601.09619)
*Theodore D. Drivas*

Main category: physics.flu-dyn

TL;DR: The paper focuses on rigorous mathematical theorems about turbulent fluid motion rather than theoretical frameworks, examining constraints on predictions by prominent 20th century scientists.


<details>
  <summary>Details</summary>
Motivation: To provide mathematical rigor to the study of turbulence by focusing on provable theorems that constrain theoretical predictions, rather than relying on unproven theories.

Method: Emphasizes theorems over theories, analyzing mathematical constraints on turbulent fluid motion predictions by notable scientists like Onsager, Kolmogorov, Landau, and Richardson.

Result: The approach yields rigorous mathematical constraints that challenge or validate theoretical expectations about turbulence from major 20th century scientific figures.

Conclusion: Mathematical theorems provide essential constraints on turbulence theories, offering a more rigorous foundation than purely theoretical approaches and challenging predictions by prominent scientists.

Abstract: In these notes, we emphasize Theorems rather than Theories concerning turbulent fluid motion. Such theorems can be viewed as constraints on the theoretical predictions and expectations of some of the greatest scientific minds of the 20th century: Lars Onsager, Andrey Kolmogorov, Lev Landau, Lewis Fry Richardson among others.

</details>


<div id='math.FA'></div>

# math.FA [[Back]](#toc)

### [32] [A Sharp Localized Weighted Inequality Related to Gagliardo and Sobolev Seminorms and Its Applications](https://arxiv.org/abs/2601.09094)
*Pingxu Hu,Yinqin Li,Dachun Yang,Wen Yuan*

Main category: math.FA

TL;DR: Paper establishes nearly sharp localized weighted inequalities for Gagliardo and Sobolev seminorms with optimal weight constants, with applications to Muckenhoupt weights characterization and various inequalities in ball Banach function spaces.


<details>
  <summary>Details</summary>
Motivation: To develop sharp weighted inequalities for Gagliardo and Sobolev seminorms with optimal weight constants, extending classical results to weighted settings with precise constants.

Method: Establishes localized weighted inequalities with sharp A₁-weight constant for p=1 and specific Aₚ-weight constants for p>1, then applies these to characterize Muckenhoupt weights and derive various inequalities in ball Banach function spaces.

Result: Obtains nearly sharp localized weighted inequalities, new characterization of Muckenhoupt weights, Gagliardo-Sobolev inequalities on cubes, Gagliardo-Nirenberg interpolation inequality, and Bourgain-Brezis-Mironescu formula, all with wide generality.

Conclusion: The results provide comprehensive and nearly sharp weighted inequalities with optimal constants, corrected for the p=1 case, with broad applications in analysis and function spaces.

Abstract: In this article, we establish a nearly sharp localized weighted inequality related to Gagliardo and Sobolev seminorms, respectively, with the sharp $A_1$-weight constant or with the specific $A_p$-weight constant when $p\in (1,\infty)$. As applications, we further obtain a new characterization of Muckenhoupt weights and, in the framework of ball Banach function spaces, an inequality related to Gagliardo and Sobolev seminorms on cubes, a Gagliardo--Nirenberg interpolation inequality, and a Bourgain--Brezis--Mironescu formula. All these obtained results have wide generality and are proved to be (nearly) sharp.
  The original version of this article was published in [Adv. Math. 481 (2025), Paper No. 110537]. In this revised version, we correct an error appeared in Theorem 1.1 in the case where $p=1$, which was pointed out to us by Emiel Lorist.

</details>


<div id='physics.ed-ph'></div>

# physics.ed-ph [[Back]](#toc)

### [33] [Experimental verification of the conservation of the magnetic moment and the longitudinal invariant](https://arxiv.org/abs/2601.09189)
*Juan Carlos Agurto,Felipe Darmazo,Amanda Guerra,Erick Burgos-Parra*

Main category: physics.ed-ph

TL;DR: Experimental demonstration of adiabatic invariants (magnetic moment μ and longitudinal invariant J) using educational electron e/m apparatus configured as magnetic bottle, with quantitative verification through photographic analysis.


<details>
  <summary>Details</summary>
Motivation: Adiabatic invariants are fundamental but often remain theoretical in undergraduate education due to experimental difficulty; need to bridge theory-experiment gap using accessible equipment.

Method: Configured standard educational electron charge-to-mass ratio apparatus as magnetic bottle, analyzed long-exposure photographs of electron beam trajectory to reconstruct helical motion and calculate invariants under different magnetic field configurations.

Result: Verified conservation of longitudinal invariant (J) with ratio of 0.98 between configurations; magnetic moment (μ) showed ~7% coefficient of variation, consistent with collisional effects in tube.

Conclusion: Complex plasma dynamics can be effectively studied using accessible laboratory equipment, providing valuable bridge between theory and experiment for physics students.

Abstract: Adiabatic invariants are fundamental to plasma physics but are often treated as purely theoretical concepts in undergraduate courses due to the difficulty of experimentally demonstrating them. This paper presents a pedagogical experiment to visualize and quantitatively verify the conservation of the magnetic moment ($μ$) and the longitudinal invariant ($J$) using a standard educational electron charge-to-mass ratio apparatus configured as a magnetic bottle. By analyzing long-exposure photographs of the electron beam trajectory, we reconstructed the helical motion and calculated the invariants under different magnetic field configurations. Our results verify the conservation of the longitudinal invariant ($J$) with a ratio of 0.98 between configurations. The magnetic moment ($μ$) exhibited a coefficient of variation of approximately 7\%, a deviation consistent with the presence of collisional effects in the tube. These findings demonstrate that complex plasma dynamics can be effectively studied using accessible laboratory equipment, providing a valuable bridge between theory and experiment for physics students.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [34] [Classification of ancient ovals in higher dimensional mean curvature flow](https://arxiv.org/abs/2601.09441)
*Beomjun Choi,Wenkui Du,Ziyi Zhao*

Main category: math.DG

TL;DR: Classification of k-ovals in mean curvature flow: all ancient non-selfsimilar solutions with cylindrical blow-down ℝᵏ×Sⁿ⁻ᵏ belong to Haslhofer-Hershkovits family, modulo symmetries.


<details>
  <summary>Details</summary>
Motivation: To classify ancient non-selfsimilar solutions to mean curvature flow called ancient ovals, specifically k-ovals characterized by cylindrical blow-down ℝᵏ×Sⁿ⁻ᵏ and quadratic bending asymptotics.

Method: Alternative argument based on different spectral parametrization for classification of k-ovals, independent of Bamler-Lai's recent breakthrough classification of all ancient asymptotically cylindrical flows.

Result: Any k-oval belongs, up to space-time rigid motions and parabolic dilations, to the family of ancient ovals constructed by Haslhofer and Hershkovits. Moduli space modulo symmetries is an open (k-1)-simplex modulo simplex symmetry.

Conclusion: Complete classification of k-ovals in arbitrary dimensions, providing alternative proof to Bamler-Lai's result. With nonexistence of exotic ovals (proved by Bamler-Lai), this yields classification of all ancient ovals.

Abstract: We study compact non-selfsimilar ancient noncollapsed solutions to the mean curvature flow in $\mathbb{R}^{n+1}$, called ancient ovals. Our main result is the classification of $k$-ovals: any $k$-oval (characterized by having cylindrical blow down $\mathbb{R}^k\times S^{n-k}$ and the quadratic bending asymptotics) belongs, up to space-time rigid motions and parabolic dilations, to the family of ancient ovals constructed by Haslhofer and the second author. Assuming the nonexistence of exotic ovals (recently proved by Bamler-Lai), this yields a classification of all ancient ovals and identifies the moduli space, modulo symmetries, with an open $(k-1)$-simplex modulo the symmetry of simplex. Although these conclusions are contained in the recent breakthrough of Bamler-Lai classifying all ancient asymptotically cylindrical flows and resolving the mean convex neighborhood conjecture, we give an alternative argument for the independently obtained classification of $k$-ovals in arbitrary dimensions based on a different spectral parametrization.

</details>


<div id='nucl-ex'></div>

# nucl-ex [[Back]](#toc)

### [35] [Breakeven in Nuclear Fusion via Electron-Free Target](https://arxiv.org/abs/2601.09458)
*Tadafumi Kishimoto*

Main category: nucl-ex

TL;DR: The paper proposes an alternative fusion approach using beam-target interactions with electron-free targets, offering a simpler pathway to fusion energy without complex plasma confinement systems.


<details>
  <summary>Details</summary>
Motivation: Traditional nuclear fusion approaches require extreme plasma conditions and complex confinement systems to achieve breakeven. The authors seek an alternative pathway that avoids these challenges while still achieving practical fusion energy generation.

Method: The paper introduces a beam-target interaction approach with electron-free targets. By removing electrons from targets, stopping power is drastically reduced, enabling conditions where fusion energy generation can surpass beam energy deposition. The authors propose a simple energy-based criterion to compare fusion energy output with energy loss.

Result: The proposed approach shows that under practical scenarios, fusion energy can exceed beam energy deposition when using electron-free targets. This suggests a viable alternative pathway to fusion energy without requiring high-temperature plasma confinement systems.

Conclusion: The beam-target approach with electron-free targets offers a promising alternative to traditional fusion methods, warranting further experimental investigation as it could provide a simpler pathway to practical fusion energy generation.

Abstract: Nuclear fusion promises a nearly limitless energy source, but achieving breakeven-where fusion output exceeds input-requires extreme plasma conditions and complex confinement systems. Here we propose an alternative approach based on beam-target interactions, introducing a simple energy-based criterion that compares fusion energy generation with energy loss. By creating electron-free targets, stopping power is drastically reduced, enabling conditions where fusion energy surpasses beam energy deposition under practical scenarios. This approach offers a viable alternative pathway to fusion energy without high-temperature plasma confinement and warrants further experimental investigation.

</details>


<div id='math.SP'></div>

# math.SP [[Back]](#toc)

### [36] [On some functionals involving torsional rigidity, principal eigenvalue and perimeter](https://arxiv.org/abs/2601.09592)
*Vincenzo Amato,Carlo Nitsch,Cristina Trombetti,Federico Villone*

Main category: math.SP

TL;DR: Study of relationships between first Dirichlet eigenvalue Λ(Ω) and torsional rigidity T(Ω), optimizing their product under perimeter constraints for open sets with finite perimeter and convex domains.


<details>
  <summary>Details</summary>
Motivation: Investigate the interplay between two fundamental geometric quantities - the first Dirichlet eigenvalue (related to vibration frequencies) and torsional rigidity (related to torsion resistance) - to understand their combined behavior under geometric constraints.

Method: Mathematical analysis approach using variational methods and optimization theory to study the product Λ(Ω)T(Ω) under perimeter constraints, examining both general open sets with finite perimeter and the more restrictive class of convex domains.

Result: Presents optimization results for the product Λ(Ω)T(Ω) with prescribed perimeter, and local results for the quantity Λ(Ω)T(Ω)^q (with q>0) under either volume or perimeter constraints.

Conclusion: The paper establishes mathematical relationships between Dirichlet eigenvalues and torsional rigidity, providing optimization results that contribute to understanding how these fundamental geometric quantities interact under various constraints.

Abstract: In this paper we study some relationships between the first Dirichlet eigenvalue $Λ(Ω)$ and the torsional rigidity $T(Ω)$ of a domain $Ω$. We consider the problem of optimizing the product $Λ(Ω)T(Ω)$ among sets with prescribed perimeter, both in the class of open sets with finite perimeter and within the class of convex domains.
  We also present local results for the quantity $Λ(Ω)T(Ω)^q$, with $q>0$, under either a volume or a perimeter constraint.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [37] [Sharp estimates for the Laplacian torsional rigidity with negative Robin boundary conditions](https://arxiv.org/abs/2601.09559)
*Nunzia Gavitone,David Krejcirik,Gloria Paoli*

Main category: math.OC

TL;DR: The paper establishes sharp inequalities for Robin-Laplacian torsional rigidity with negative boundary parameter, proving that balls maximize this quantity among convex domains under perimeter or volume constraints when |α| is sufficiently small.


<details>
  <summary>Details</summary>
Motivation: Motivated by pioneering works of Bandle and Wagner, the authors aim to solve an open problem regarding sharp inequalities for Robin-Laplacian torsional rigidity τ_α(Ω) with negative boundary parameter α in bounded Lipschitz domains.

Method: The authors consider the Robin-Laplacian torsional rigidity τ_α(Ω) with negative boundary parameter α and establish conditions under which sharp inequalities hold. They focus on the case when |α| is smaller than the first non-trivial Steklov-Laplacian eigenvalue.

Result: The main results prove that: 1) When |α| is smaller than the first non-trivial Steklov-Laplacian eigenvalue, the ball maximizes τ_α(Ω) among all convex domains under perimeter or volume constraints (solving Bandle and Wagner's open problem). 2) The same result holds in the planar case among simply connected sets under perimeter constraint.

Conclusion: The paper successfully solves an open problem in geometric analysis by establishing sharp inequalities for Robin-Laplacian torsional rigidity, showing that balls are optimal shapes under certain constraints when the boundary parameter is sufficiently small in magnitude.

Abstract: Motivated by pioneering works of Bandle and Wagner, given a bounded Lipschitz domain $Ω\subset \mathbb R^d$ with $d\ge3$, we consider the Robin-Laplacian torsional rigidity $τ_α(Ω)$ with negative boundary parameter $α$ and we show that sharp inequalities for $τ_α(Ω)$ hold if $|α|$ is small enough. In particular, we prove that, if $|α|$ is smaller than the first non-trivial Steklov-Laplacian eigenvalue, then the ball maximises $τ_α(Ω)$ among all convex domains under perimeter or volume constraints.This solves an open problem raised by Bandle and Wagner. We also prove the result in the planar case among simply connected sets and under perimeter constraint.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [38] [Divergent Fluctuations from an Infrared 2D-Mode Catastrophe](https://arxiv.org/abs/2601.09009)
*Richard G. Hennig,Clotilde S. Cucinotta*

Main category: cond-mat.stat-mech

TL;DR: 2D periodic boundary conditions in molecular simulations of interfacial polar media cause artificial divergence of electrostatic potential variance with slab thickness, which is an artifact rather than true material response.


<details>
  <summary>Details</summary>
Motivation: To understand why molecular simulations of interfacial polar media using periodic boundary conditions parallel to interfaces show problematic behavior in electrostatic potential calculations, and to identify the root cause of these artifacts.

Method: Theoretical analysis showing that 2D periodic boundary conditions inject a uniform plane mode (q∥=0) that converts plane-averaged electrostatic potential into a cumulative sum of plane-dipole increments, behaving like a random walk in z-direction.

Result: The variance of plane-averaged potential grows linearly with depth in semi-infinite slabs and follows parabolic Brownian-bridge profiles in finite cells, with amplitude inversely proportional to lateral area. This leads to divergence of variance with slab thickness at any finite area - a "2D-mode catastrophe." In contrast, pure 1D chains and fully 3D nonperiodic media show bounded fluctuations.

Conclusion: The apparent growth and divergence in potential fluctuation are artifacts of 2D periodic boundary conditions rather than true material response. The paper provides a simple scaling criterion for choosing slab sizes to keep these artifacts under quantitative control.

Abstract: Molecular simulations of interfacial polar media routinely employ periodic boundary conditions parallel to the interface. We show that this geometry injects a uniform plane mode ($q_{\parallel}=0$) that converts the plane-averaged electrostatic potential into a cumulative sum of plane-dipole increments, a random walk in $z$. Consequently, the variance of the plane-averaged potential grows linearly with depth in semi-infinite slabs and follows a parabolic Brownian-bridge profile in finite cells with both ends fixed, with an amplitude inversely proportional to the cell's lateral area. Hence, at any finite area, the variance diverges with slab thickness, a 2D-mode catastrophe. In contrast, a pure 1D chain (no lateral replication) and a fully 3D, nonperiodic medium both exhibit bounded fluctuations that saturate with distance. The mechanism is generic to any solver of Poisson's equation with 2D periodicity, so the apparent growth and ultimate divergence in potential fluctuation are artifacts of boundary conditions rather than material response, and we provide a simple scaling criterion for choosing slab sizes that keeps these artifacts under quantitative control.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [39] [Global polynomial-time estimation in statistical nonlinear inverse problems via generalized stability](https://arxiv.org/abs/2601.09007)
*Sven Wang*

Main category: math.ST

TL;DR: Proposes computationally tractable estimators for non-linear inverse problems that avoid expensive PDE solves, achieve optimal statistical rates, and are globally computable in polynomial time.


<details>
  <summary>Details</summary>
Motivation: Non-linear statistical inverse problems present major computational challenges: likelihood-based methods lead to non-convex optimization landscapes, and MCMC methods suffer from slow mixing. There's a need for computationally tractable estimators that can handle these difficulties while maintaining statistical efficiency.

Method: Introduces plug-in and PDE-penalized M-estimators that replace exact PDE constraints with weakly enforced relaxations. This yields conditionally convex, nested quadratic optimization problems that avoid evaluating the forward map G(f) and don't require PDE solvers. The approach is applied to elliptic PDEs like Darcy flow and steady-state Schrödinger models.

Result: The estimators achieve best known statistical convergence rates while being globally computable in polynomial time. For Darcy model, explicit sub-quadratic o(N²) arithmetic runtime bound is obtained for estimating f from N noisy samples. Also provides adaptive rates and principled warm-start initializations for Bayesian computation.

Conclusion: The proposed estimators offer a blueprint for designing provably polynomial-time statistical algorithms for broad classes of non-linear inverse problems, addressing both computational and statistical challenges through novel weakly enforced PDE constraints and stability analysis.

Abstract: Non-linear statistical inverse problems pose major challenges both for statistical analysis and computation. Likelihood-based estimators typically lead to non-convex and possibly multimodal optimization landscapes, and Markov chain Monte Carlo (MCMC) methods may mix exponentially slowly. We propose a class of computationally tractable estimators--plug-in and PDE-penalized M-estimators--for inverse problems defined through operator equations of the form $L_f u = g$, where $f$ is the unknown parameter and $u$ is the observed solution. The key idea is to replace the exact PDE constraint by a weakly enforced relaxation, yielding conditionally convex and, in many PDE examples, nested quadratic optimization problems that avoid evaluating the forward map $G(f)$ and do not require PDE solvers. For prototypical non-linear inverse problems arising from elliptic PDEs, including the Darcy flow model $L_f u = \nabla\!\cdot(f\nabla u)$ and a steady-state Schrödinger model, we prove that these estimators attain the best currently known statistical convergence rates while being globally computable in polynomial time. In the Darcy model, we obtain an explicit sub-quadratic $o(N^2)$ arithmetic runtime bound for estimating $f$ from $N$ noisy samples. Our analysis is based on new generalized stability estimates, extending classical stability beyond the range of the forward operator, combined with tools from nonparametric M-estimation. We also derive adaptive rates for the Darcy problem, providing a blueprint for designing provably polynomial-time statistical algorithms for a broad class of non-linear inverse problems. Our estimators also provide principled warm-start initializations for polynomial-time Bayesian computation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [40] [Transient fields in oblique scattering from an infinite planar dielectric interface -- a qubit lattice simulation](https://arxiv.org/abs/2601.09135)
*Min Soe,George Vahala,Linda Vahala,Efstratios Koukoutsis,Abhay K. Ram,Kyriakos Hizanidis*

Main category: quant-ph

TL;DR: QLA algorithm simulates oblique scattering of Gaussian pulses from dielectric interface, showing energy conservation and Huygen-like wavefronts in transmitted pulses.


<details>
  <summary>Details</summary>
Motivation: To study time-dependent evolution of electromagnetic fields from oblique scattering of bounded pulses from an infinite planar dielectric interface using a unitary algorithm that conserves energy.

Method: Uses qubit lattice algorithm (QLA), an almost fully unitary initial value algorithm, to simulate scattering of various Gaussian envelope pulses at incident angles below total internal reflection threshold.

Result: Reflected pulses retain Gaussian shape, while transmitted pulses show combination of Gaussian envelope with Huygen-like emitted wavefronts from collision point; wavefront strength depends on incident pulse width; excellent electromagnetic energy conservation achieved.

Conclusion: QLA effectively models electromagnetic pulse scattering, revealing complex transmitted pulse structure with Huygen wavefronts that depend on pulse width, while maintaining energy conservation due to its unitary nature.

Abstract: An initial value algorithm is utilized to examine the time dependent evolution of the electromagnetic fields arising from oblique scattering of bounded pulses from an infinite planar dielectric interface. Since the qubit lattice algorithm (QLA) is almost fully unitary, one finds excellent conservation of electromagnetic energy. Various Gaussian envelope pulses are considered in regimes where the incident angle is below that needed for total internal reflection. While the reflected pulse retains its overall Gaussian shape, the transmitted pulse exhibits a combination of a Gaussian envelope along with Huygen-like emitted wave fronts from the collision point of the initial pulse with the infinite dielectric interface. The strength of these Huygen wavefronts depends on the width of the incident pulse.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [41] [W-DUALMINE: Reliability-Weighted Dual-Expert Fusion With Residual Correlation Preservation for Medical Image Fusion](https://arxiv.org/abs/2601.08920)
*Md. Jahidul Islam*

Main category: eess.IV

TL;DR: W-DUALMINE is a reliability-weighted dual-expert fusion framework that resolves the trade-off between global statistical similarity (CC/MI) and local structural fidelity in medical image fusion through architectural constraints and theoretically grounded loss design.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning methods for medical image fusion, including recent spatial-frequency frameworks like AdaFuse and ASFE-Fusion, suffer from a fundamental trade-off between global statistical similarity (measured by correlation coefficient and mutual information) and local structural fidelity.

Method: The method introduces: 1) dense reliability maps for adaptive modality weighting, 2) a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, 3) a soft gradient-based arbitration mechanism, and 4) a residual-to-average fusion paradigm that guarantees preservation of global correlation while enhancing local details.

Result: Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics.

Conclusion: W-DUALMINE successfully resolves the trade-off between global statistical similarity and local structural fidelity in medical image fusion through its reliability-weighted dual-expert framework with architectural constraints and theoretically grounded loss design.

Abstract: Medical image fusion integrates complementary information from multiple imaging modalities to improve clinical interpretation. However, existing deep learningbased methods, including recent spatial-frequency frameworks such as AdaFuse and ASFE-Fusion, often suffer from a fundamental trade-off between global statistical similaritymeasured by correlation coefficient (CC) and mutual information (MI)and local structural fidelity. This paper proposes W-DUALMINE, a reliability-weighted dual-expert fusion framework designed to explicitly resolve this trade-off through architectural constraints and a theoretically grounded loss design. The proposed method introduces dense reliability maps for adaptive modality weighting, a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, and a soft gradient-based arbitration mechanism. Furthermore, we employ a residual-to-average fusion paradigm that guarantees the preservation of global correlation while enhancing local details. Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics while

</details>
