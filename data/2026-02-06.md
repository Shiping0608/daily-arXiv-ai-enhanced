<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [math.AP](#math.AP) [Total: 22]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [math.NT](#math.NT) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [stat.ML](#stat.ML) [Total: 3]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 2]
- [stat.ME](#stat.ME) [Total: 1]
- [math.PR](#math.PR) [Total: 2]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A uniformly accurate multiscale time integrator for the nonlinear Klein-Gordon equation in the nonrelativistic regime via simplified transmission conditions](https://arxiv.org/abs/2602.04988)
*Weizhu Bao,Caoyi Liu*

Main category: math.NA

TL;DR: A new multiscale time integrator Fourier pseudospectral method for nonlinear Klein-Gordon equation achieves uniform first-order accuracy in time in nonrelativistic regime, with super-resolution property allowing time steps much larger than oscillation wavelength.


<details>
  <summary>Details</summary>
Motivation: The nonlinear Klein-Gordon equation in nonrelativistic regime (0<ε<<1) has highly oscillatory solutions with O(ε²)-wavelength, making traditional numerical methods inefficient. Existing methods struggle with uniform accuracy across ε values, requiring extremely small time steps to resolve oscillations.

Method: MTI-FP method combines: (1) multiscale decomposition by frequency in each time interval with simplified transmission conditions, (2) exponential wave integrator for temporal discretization, and (3) Fourier pseudospectral method for spatial discretization. Uses linear interpolation of micro variables for uniform accuracy.

Result: Achieves uniform first-order accuracy in time with error bounds O(h^{m0}+τ) independent of ε. Demonstrates super-resolution property: accurate solutions even when time step τ >> O(ε²)-wavelength. Numerical results confirm error bounds and super-resolution capability.

Conclusion: The MTI-FP method provides an efficient, uniformly accurate numerical approach for highly oscillatory nonlinear Klein-Gordon equations in nonrelativistic regime, overcoming traditional limitations and enabling study of convergence to limiting models.

Abstract: We propose a new and simplified multiscale time integrator Fourier pseudospectral (MTI-FP) method for the nonlinear Klein-Gordon equation (NKGE) with a dimensionless parameter epsilon in (0,1] inversely proportional to the speed of light, and establish its uniform first-order accuracy in time in the nonrelativistic regime, i.e. 0 < epsilon << 1. In this regime, the solution of the NKGE is highly oscillatory in time with O(epsilon^2)-wavelength, which brings significant difficulties in designing uniformly accurate numerical methods. The MTI-FP is based on (i) a multiscale decomposition by frequency of the NKGE in each time interval with simplified transmission conditions, and (ii) an exponential wave integrator for temporal discretization and a Fourier pseudospectral method for spatial discretization. By adapting the energy method and the mathematical induction, we obtain two error bounds in H1-norm at O(h^{m0}+tau^2/epsilon^2) and O(h^{m0}+tau+epsilon^2) with mesh size h, time step tau and m0 an integer dependent on the regularity of the solution, which immediately implies a uniformly accurate error bound O(h^{m0}+tau) with respect to epsilon in (0,1]. In addition, by adopting a linear interpolation of the micro variables with the multiscale decomposition in each time interval, we obtain a uniformly accurate numerical solution for any time t larger than zero. Thus the proposed MTI-FP method has a super resolution property in time in terms of the Shannon sampling theory, i.e. accurate numerical solutions can be obtained even when the time step is much bigger than the O(epsilon^2)-wavelength. Extensive numerical results are reported to confirm our error bounds and demonstrate their super resolution in time. Finally the proposed MTI-FP method is applied to study numerically convergence rates of the NKGE to its different limiting models in the nonrelativistic regime.

</details>


### [2] [Acoustic scattering by fractal inhomogeneities via geometry-conforming Galerkin methods for the Lippmann-Schwinger equation](https://arxiv.org/abs/2602.05005)
*Joshua Bannister,David P. Hewett,Andrew Gibbs*

Main category: math.NA

TL;DR: Numerical method for acoustic scattering by fractal-boundary inhomogeneities using Galerkin discretization of Lippmann-Schwinger equation with geometry-conforming fractal meshes.


<details>
  <summary>Details</summary>
Motivation: To develop accurate numerical methods for time-harmonic acoustic scattering problems involving inhomogeneities with fractal boundaries, which are challenging for traditional approaches that approximate fractals with smoother prefractals.

Method: Galerkin discretization of Lippmann-Schwinger volume integral equation using discontinuous piecewise-polynomial approximation on geometry-conforming meshes with fractal-boundary elements. Includes h- and p-versions, with special treatment for n-attractor fractals using their self-similarity for mesh generation.

Result: Proved well-posedness and error analysis for arbitrary inhomogeneities, convergence estimates for integral equation solutions, superconvergence for scattered field evaluations. Developed singular quadrature rules for practical implementation. Numerical results in 2D show method significantly more accurate than prefractal approximation approaches.

Conclusion: The proposed method effectively handles acoustic scattering by fractal-boundary inhomogeneities using geometry-conforming meshes, providing superior accuracy compared to prefractal approximations, with rigorous theoretical foundation and practical implementation capabilities.

Abstract: We propose and analyse a numerical method for time-harmonic acoustic scattering in $\mathbb{R}^n$, $n=2,3$, by a class of inhomogeneities (penetrable scatterers) with fractal boundary. Our method is based on a Galerkin discretisation of the Lippmann-Schwinger volume integral equation, using a discontinuous piecewise-polynomial approximation space on a geometry-conforming mesh comprising elements which themselves have fractal boundary. We first provide a semi-discrete well-posedness and error analysis for both the $h$- and $p$-versions of our method for completely arbitrary inhomogeneities (without any regularity assumption on the boundary of the inhomogeneity or of the mesh elements). We prove convergence estimates for the integral equation solution and superconvergence estimates for linear functionals such as scattered field and far-field pattern evaluations, and elucidate how the regularity of the inhomogeneity boundary and the regularity of the refractive index affect the rates of convergence predicted. We then specialise to the case where the inhomogeneity is an ``$n$-attractor'', i.e.\ the fractal attractor of an iterated function system satisfying the open set condition with non-empty interior, showing how in this case the self-similarity of the inhomogeneity can be used to generate geometry-conforming meshes. For the $h$-version with piecewise constant approximation we also present singular quadrature rules, supported by a fully discrete error analysis, permitting practical implementation of our method. We present numerical results for two-dimensional examples, which validate our theoretical results and show that our method is significantly more accurate than a comparable method involving replacement of the fractal inhomogeneity by a smoother prefractal approximation.

</details>


### [3] [Scalable Fixed-Point Framework for High-Dimensional Hamilton-Jacobi Equations](https://arxiv.org/abs/2602.05124)
*Yesom Park,Stanley Osher*

Main category: math.NA

TL;DR: Novel mesh-free, gradient-free fixed-point method for solving high-dimensional Hamilton-Jacobi equations using Hopf-Lax formula and Picard iteration, achieving dimension-independent computational times up to 100D.


<details>
  <summary>Details</summary>
Motivation: Need efficient methods for solving high-dimensional Hamilton-Jacobi equations without relying on grids, characteristics, or differentiation, which are computationally expensive in high dimensions.

Method: Fixed-point approach leveraging Hopf-Lax formula to iteratively solve variational problems via Picard iteration, enabling mesh-free and gradient-free computation of solutions and controls.

Result: Method achieves high accuracy, high efficiency, and computational times largely independent of dimensionality, demonstrated through numerical experiments up to 100 dimensions including control problems and non-smooth solutions.

Conclusion: The proposed scheme is highly suitable for high-dimensional Hamilton-Jacobi problems, offering a practical and scalable alternative to traditional grid-based or characteristic-based methods.

Abstract: We propose a novel, mesh-free, and gradient-free fixed-point approach for computing viscosity solutions of high-dimensional Hamilton-Jacobi (HJ) equations. By leveraging the Hopf-Lax formula, our approach iteratively solves the associated variational problem via a Picard iteration, enabling efficient evaluation of both the solution and its corresponding control without relying on grids, characteristics, or differentiation. We demonstrate the practical efficacy and scalability of the approach through numerical experiments in up to 100 dimensions, including control problems and non-smooth solutions. Our results show that the proposed scheme achieves high accuracy, is highly efficient, and exhibits computational times that are largely independent of dimensionality, highlighting its suitability for high-dimensional problems.

</details>


### [4] [Numerically Informed Convolutional Operator Network with Subproblem Decomposition for Poisson Equations](https://arxiv.org/abs/2602.05341)
*Kyoungjin Jung,Jae Yong Lee,Dongwook Shin*

Main category: math.NA

TL;DR: NICON is a numerically informed convolutional operator network that couples classical finite difference/element methods with neural operators through residual-based training, providing theoretical error estimates and optimal convergence strategies under grid refinement.


<details>
  <summary>Details</summary>
Motivation: Neural operators show strong performance for PDE approximation but lack theoretical understanding of their convergence behavior under grid refinement from a numerical analysis perspective.

Method: Proposes NICON with two variants: FD-CON (finite difference-based) and FE-CON (finite element-based) that use residual-based loss functions derived from corresponding numerical methods, enabling theoretical error analysis.

Result: Derived error estimates showing direct relation between convergence behavior and training loss decay rate, established training strategies guaranteeing optimal convergence rates under grid refinement, validated with numerical experiments.

Conclusion: NICON successfully bridges neural operators with classical numerical methods, providing theoretical foundations for convergence analysis and practical training strategies for optimal performance on fine grids.

Abstract: Neural operators have shown remarkable performance in approximating solutions of partial differential equations. However, their convergence behavior under grid refinement is still not well understood from the viewpoint of numerical analysis. In this work, we propose a numerically informed convolutional operator network, called NICON, that explicitly couples classical finite difference and finite element methods with operator learning through residual-based training loss functions. We introduce two types of networks, FD-CON and FE-CON, which use residual-based loss functions derived from the corresponding numerical methods. We derive error estimates for FD-CON and FE-CON using finite difference and finite element analysis. These estimates show a direct relation between the convergence behavior and the decay rate of the training loss. From these analyses, we establish training strategies that guarantee optimal convergence rates under grid refinement. Several numerical experiments are presented to validate the theoretical results and show performance on fine grids.

</details>


### [5] [Linear Systems and Eigenvalue Problems: Open Questions from a Simons Workshop](https://arxiv.org/abs/2602.05394)
*Noah Amsel,Yves Baumann,Paul Beckman,Peter Bürgisser,Chris Camaño,Tyler Chen,Edmond Chow,Anil Damle,Michal Derezinski,Mark Embree,Ethan N. Epperly,Robert Falgout,Mark Fornace,Anne Greenbaum,Chen Greif,Diana Halikias,Zhen Huang,Elias Jarlebring,Yiannis Koutis,Daniel Kressner,Rasmus Kyng,Jörg Liesen,Jackie Lok,Raphael A. Meyer,Yuji Nakatsukasa,Kate Pearce,Richard Peng,David Persson,Eliza Rebrova,Ryan Schneider,Rikhav Shah,Edgar Solomonik,Nikhil Srivastava,Alex Townsend,Robert J. Webber,Jess Williams*

Main category: math.NA

TL;DR: This paper presents open questions in matrix computations arising from discussions between theoretical computer science and numerical analysis researchers, organized into five categories of linear algebra problems.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between theoretical computer science and numerical analysis by identifying important open problems in matrix computations through collaborative discussions between researchers from both fields.

Method: The paper is based on working group discussions at the "Linear Systems and Eigenvalue Problems" workshop during the Simons Institute's "Complexity and Linear Algebra" program in Fall 2025, where researchers from theoretical computer science and numerical analysis collaborated to formulate open questions.

Result: A collection of open questions organized into five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas including tensors, quantum systems, and matrix functions.

Conclusion: The paper serves as a roadmap for future research at the intersection of theoretical computer science and numerical analysis, highlighting important unsolved problems in matrix computations that emerged from interdisciplinary collaboration.

Abstract: This document presents a series of open questions arising in matrix computations, i.e., the numerical solution of linear algebra problems. It is a result of working groups at the workshop \emph{Linear Systems and Eigenvalue Problems}, which was organized at the Simons Institute for the Theory of Computing program on \emph{Complexity and Linear Algebra} in Fall 2025. The complexity and numerical solution of linear algebra problems %in matrix computations and related fields is a crosscutting area between theoretical computer science and numerical analysis. The value of the particular problem formulations here is that they were produced via discussions between researchers from both groups.
  The open questions are organized in five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas including tensors, quantum systems, and matrix functions.

</details>


### [6] [Taylor-Accelerated Neural Network Interpolation Operators on Irregular Grids with Higher Order Approximation](https://arxiv.org/abs/2602.05589)
*Sachin Saini*

Main category: math.NA

TL;DR: Taylor-accelerated neural network interpolation operators improve existing methods by incorporating Taylor polynomials at sampling nodes, achieving higher-order convergence on irregular grids.


<details>
  <summary>Details</summary>
Motivation: Existing neural network interpolation operators on irregular grids have limitations in exploiting the smoothness of target functions. The paper aims to develop more accurate interpolation operators that can leverage higher smoothness properties through Taylor polynomial acceleration.

Method: Introduces Taylor-accelerated neural network interpolation operators on quasi-uniform irregular grids. The method incorporates Taylor polynomials at sampling nodes to exploit higher smoothness of target functions. The operators are designed to be well-defined, uniformly bounded, and satisfy exact interpolation at grid points with polynomial reproduction up to a prescribed degree.

Result: Theoretical analysis shows the operators are well-defined, uniformly bounded, and satisfy exact interpolation. Direct approximation estimates are derived using higher-order moduli of smoothness, yielding enhanced convergence rates for smooth functions. Numerical experiments demonstrate significant accuracy improvement, higher-order convergence on irregular grids, and outperformance of existing neural network interpolation operators including Lagrange-based schemes.

Conclusion: Taylor-accelerated neural network interpolation operators provide a superior approach for interpolation on irregular grids, achieving higher-order convergence by effectively exploiting function smoothness through Taylor polynomial incorporation, outperforming existing methods.

Abstract: In this paper, a new class of \emph{Taylor-accelerated neural network interpolation operators} is introduced on quasi-uniform irregular grids. These operators improve existing neural network interpolation operators by incorporating Taylor polynomials at the sampling nodes, thereby exploiting the higher smoothness of the target function. The proposed operators are shown to be well defined, uniformly bounded, and to satisfy an exact interpolation property at the grid points. In addition, polynomial reproduction up to a prescribed degree is established. Direct approximation estimates are derived in terms of higher-order moduli of smoothness, yielding enhanced convergence rates for sufficiently smooth functions. Numerical experiments are presented to support the theoretical analysis and to demonstrate the significant accuracy improvement achieved through the Taylor-accelerated construction. In particular, higher-order convergence on irregular grids is obtained, and the proposed approach outperforms existing neural network interpolation operators on irregular partitions, including Lagrange-based schemes.

</details>


### [7] [Numerical stationary states for nonlocal Fokker-Planck equations via fixed points of consistency maps](https://arxiv.org/abs/2602.05632)
*José A. Carrillo,Yurij Salmaniw,Antonio León Villares*

Main category: math.NA

TL;DR: A fixed-point numerical framework for computing stationary states of nonlocal Fokker-Planck equations using matrix-free Newton-Krylov methods, capable of detecting both stable and unstable states without time evolution.


<details>
  <summary>Details</summary>
Motivation: Need efficient methods to compute stationary states of nonlocal Fokker-Planck equations that can detect both stable and unstable states, avoiding limitations of time-evolution approaches that are sensitive to dynamical stability.

Method: Reformulate stationary problem as nonlinear fixed-point map from PDE and nonlocal interaction terms, solve with matrix-free Newton-Krylov method. Compare analytic Frechet derivative with central-difference approximation. Accuracy depends on convolution and quadrature treatment rather than differentiation stencils.

Result: Method successfully applied to three model problems with linear diffusion, verified against analytical results. Reproduced known bifurcation diagrams and discovered new bifurcation behavior not previously observed in this type of problem.

Conclusion: The fixed-point approach provides an effective framework for computing stationary states of nonlocal Fokker-Planck equations, capable of detecting both stable and unstable states without relying on time evolution, with accuracy determined by convolution/quadrature treatment rather than differentiation schemes.

Abstract: We propose a fixed-point-based numerical framework for computing stationary states of nonlocal Fokker-Planck-type equations. Instead of discretising the differential operators directly, we reformulate the stationary problem as a nonlinear fixed-point map built from the original PDE and its nonlocal interaction terms, and solve the resulting finite-dimensional problem with a matrix-free Newton-Krylov method. We compare implementations using the analytic Frechet derivative of this map with a simple central-difference approximation. Because the method does not rely on time evolution, it is agnostic to dynamical stability and can detect both stable and unstable stationary states. Its accuracy is determined mainly by the numerical treatment of convolutions and quadrature, rather than by differentiation stencils. We apply the approach to three model problems with linear diffusion, use existing analytical results to verify the outputs, and reproduce known bifurcation diagrams, as well as new bifurcation behaviour not previously observed in this kind of problem.

</details>


### [8] [A penalized φ-FEM scheme for the Poisson Dirichlet problem](https://arxiv.org/abs/2602.05698)
*Raphaël Bulle,Michel Duprez,Vanessa Lleras,Killian Vuillemot*

Main category: math.NA

TL;DR: Penalized φ-FEM scheme for Poisson equation with Dirichlet BCs using level-set geometry, avoiding fitted meshes, with boundary enforcement via penalization and ghost penalty stabilization.


<details>
  <summary>Details</summary>
Motivation: To develop an unfitted finite element method for Poisson equation with Dirichlet boundary conditions that avoids boundary-fitted meshes while reducing computational requirements by only needing level-set function near boundaries.

Method: Penalized variant of φ-FEM using level-set geometry description, enforcing boundary conditions through penalization term (only requiring level-set function on cells adjacent to boundary), stabilized with ghost penalty technique.

Result: Derived a priori error estimates showing optimal convergence in H1 semi-norm and quasi-optimal convergence in L2 norm under suitable regularity assumptions. Numerical experiments validate theoretical results and compare with original φ-FEM and standard fitted FEM.

Conclusion: The penalized φ-FEM scheme successfully provides an efficient unfitted finite element method with reduced computational requirements while maintaining optimal/quasi-optimal convergence rates comparable to original φ-FEM and standard fitted methods.

Abstract: In this work, we analyze a penalized variant of the φ-FEM scheme for the Poisson equation with Dirichlet boundary conditions. The φ-FEM is a recently introduced unfitted finite element method based on a level-set description of the geometry, which avoids the need for boundary-fitted meshes. Unlike the original φ-FEM formulation, the method proposed here enforces boundary conditions through a penalization term. This approach has the advantage that the level-set function is required only on the cells adjacent to the boundary in the variational formulation. The scheme is stabilized using a ghost penalty technique. We derive a priori error estimates, showing optimal convergence in the H1 semi-norm and quasi-optimal convergence in the L2 norm under suitable regularity assumptions. Numerical experiments are presented to validate the theoretical results and to compare the proposed method with both the original φ-FEM and the standard fitted finite element method.

</details>


### [9] [Finite element approximation for a reformulation of a 3D fluid-2D plate interaction system](https://arxiv.org/abs/2602.05701)
*Lander Besabe,Hyesuk Lee*

Main category: math.NA

TL;DR: A finite element method for 3D fluid-2D plate interaction using second-order reformulation and Lagrange multipliers for coupling, with proven stability and error estimates.


<details>
  <summary>Details</summary>
Motivation: To develop a practical finite element method for fluid-structure interaction problems that avoids the complexity of H²-conforming or nonconforming plate elements, making the implementation more feasible while maintaining accuracy.

Method: Reformulates fourth-order plate equation into coupled second-order equations using auxiliary variable, enforces coupling via Lagrange multiplier for fluid pressure trace, uses partitioned domain decomposition with fixed-point iteration for numerical solution.

Result: Establishes well-posedness and stability for time-discrete and fully-discrete problems, derives a priori error estimates, verifies theoretical convergence rates via manufactured solutions, demonstrates applicability to physical problems.

Conclusion: The proposed method successfully avoids complex plate elements while maintaining mathematical rigor and practical applicability for fluid-structure interaction problems, with proven convergence and stability properties.

Abstract: We study a finite element approximation of a coupled fluid-structure interaction consisting of a three-dimensional incompressible viscous fluid governed by the unsteady Stokes equations and a two-dimensional elastic plate. To avoid the use of $H^2-$conforming or nonconforming $\mathbb{P}_2$-Morley plate elements, the fourth-order plate equation is reformulated into a system of coupled second-order equations using an auxiliary variable. The coupling condition is enforced using a Lagrange multiplier representing the trace of the mean-zero fluid pressure on the interface.
  We establish well-posedness and stability results for the time-discrete and fully-discrete problems, and derive a priori error estimates. A partitioned domain decomposition algorithm based on a fixed-point iteration is employed for the numerical solution. Numerical experiments verify the theoretical rates of convergence in space and time using manufactured solutions, and demonstrate the applicability of the method to a physical problem.

</details>


### [10] [Optimal boundary closures for diagonal-norm upwind SBP operators](https://arxiv.org/abs/2602.05727)
*Ken Mattsson,David Niemelä,Andrew R. Winters*

Main category: math.NA

TL;DR: Boundary-optimized upwind finite-difference operators (orders up to 9) using non-equispaced boundary grids within SBP framework, with SAT or projection method for boundary conditions, showing improved accuracy/efficiency over equidistant SBP operators.


<details>
  <summary>Details</summary>
Motivation: To develop more accurate and computationally efficient finite-difference operators for hyperbolic problems by optimizing boundary treatments, addressing limitations of traditional SBP operators on equidistant grids.

Method: Develop boundary-optimized upwind finite-difference operators (up to 9th order) using non-equispaced grid points near boundaries within diagonal-norm SBP framework. Apply weak boundary enforcement via SAT or strong enforcement via projection method on piecewise curvilinear multiblock grids.

Result: Proposed operators yield significantly improved accuracy and computational efficiency compared to SBP operators on equidistant grids. Both SBP-SAT and SBP-projection discretizations produce fully explicit ODE systems, with demonstrated accuracy and stability in numerical experiments.

Conclusion: Boundary-optimized SBP operators with non-equispaced boundary grids provide superior performance for hyperbolic problems, offering practical advantages for compressible flow simulations while maintaining stability on complex curvilinear multiblock grids.

Abstract: By employing non-equispaced grid points near boundaries, boundary-optimized upwind finite-difference operators of orders up to nine are developed. The boundary closures are constructed within a diagonal-norm summation-by-parts (SBP) framework, ensuring linear stability on piecewise curvilinear multiblock grids. Boundary and interface conditions are imposed using either weak enforcement through simultaneous approximation terms (SAT) or strong enforcement via the projection method.
  The proposed operators yield significantly improved accuracy and computational efficiency compared with SBP operators constructed on equidistant grids. The resulting SBP--SAT and SBP--projection discretizations produce fully explicit systems of ordinary differential equations. The accuracy and stability properties of the proposed operators are demonstrated through numerical experiments for linear hyperbolic problems in one spatial dimension and for the compressible Euler equations in two spatial dimensions.

</details>


### [11] [A Perturbation-Correction Method Based on Local Randomized Neural Networks for Quasi-Linear Interface Problems](https://arxiv.org/abs/2602.05800)
*Siyuan Lang,Zhiyue Zhang*

Main category: math.NA

TL;DR: Proposes perturbation-correction framework using Local Randomized Neural Networks to overcome optimization stagnation in quasi-linear interface problems with discontinuous diffusion coefficients.


<details>
  <summary>Details</summary>
Motivation: Randomized neural networks struggle with optimization stagnation when dealing with nonconvex objective functionals in quasi-linear interface problems with discontinuous diffusion coefficients.

Method: Two-step framework: 1) Initialization step minimizes original nonconvex residual to get base approximation, 2) Correction step solves convex subproblem via perturbation expansion around base approximation to determine correction term.

Result: Method overcomes optimization plateau, achieves 4-6 order magnitude improvement in L^2 accuracy, works on nonlinear diffusion problems with irregular moving interfaces, gradient-dependent diffusivities, and high-contrast media.

Conclusion: Perturbation-correction framework with LRaNNs effectively solves quasi-linear interface problems by transforming nonconvex optimization into convex subproblem, with rigorous error analysis showing total error controlled by residual norm, quadrature error, and truncation error.

Abstract: For quasi-linear interface problems with discontinuous diffusion coefficients, the nonconvex objective functional often leads to optimization stagnation in randomized neural network approximations. This paper Proposes a perturbation-correction framework based on Loacal Randomized Neural Networks(LRaNNs) to overcome this limitation. In the initialization step, a satisisfactory based approximation is obtained by minimizing the original nonconvex residual, typically stagnating at a moderate accuracy level. Subsequently, in the correction step, a correction term is determined by solving a subproblem governed by a perturbation expansion around the base approximation. This reformulation yields a convex optimization problem for the output coefficients, which guarantees rapic convergence. We rigorously derive an a posteriori error estitmate, demonstrating that the total generalization error is governed by the discrete residual norm, quadrature error, and a controllable truncation error. Numerical experiments on nonlinear diffusion problems with irregular moving interfaces, gradient-dependent diffusivities, and high-contrast media demonstrate that the proposed method effectively overcomes the optimization plateau. The correction step yields a significant improvement of 4-6 order of magnitude in L^2 accuracy.

</details>


### [12] [Spectral Analysis of Block Diagonally Preconditioned Multiple Saddle-Point Matrices with Inexact Schur Complements](https://arxiv.org/abs/2602.05952)
*Marco Pilotto,Luca Bergamaschi,Angeles Martinez*

Main category: math.NA

TL;DR: Eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices, with analysis for arbitrary blocks and approximate Schur complements.


<details>
  <summary>Details</summary>
Motivation: To extend eigenvalue analysis for preconditioned multiple saddle-point systems beyond existing results, allowing for arbitrary number of blocks and handling approximate Schur complements.

Method: Derive eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices, generalizing previous work to arbitrary blocks and approximate Schur complements.

Result: Proposed eigenvalue bounds are validated through numerical experiments, confirming the theoretical estimates work for systems with arbitrary number of blocks and when Schur complements are approximated.

Conclusion: The analysis successfully extends eigenvalue bounds to more general multiple saddle-point systems, providing theoretical foundation for preconditioning strategies with practical applicability through approximate Schur complements.

Abstract: We derive eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices. This analysis applies to an arbitrary number of blocks and accounts for the case where the Schur complements are approximated, generalizing the findings in [Bergamaschi et al., Linear Algebra and its Applications, 2026]. Numerical experiments are carried out to validate the proposed estimates.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [13] [$\bf{S^1}$-index theory for the Lorentz force equation](https://arxiv.org/abs/2602.05015)
*Cristian Bereanu,Alexandru Pîrvuceanu*

Main category: math.AP

TL;DR: The paper proves existence of multiple periodic solutions to the Lorentz force equation using S^1-invariance of the Poincaré action functional and Lusternik-Schnirelman theory with S^1-index.


<details>
  <summary>Details</summary>
Motivation: To establish existence of multiple periodic solutions for the Lorentz force equation by exploiting the S^1-invariance of the associated Poincaré action functional, extending previous work by Ekeland and Lasry that used Fadell-Rabinowitz index.

Method: Develops an abstract multiplicity result using Lusternik-Schnirelman method with S^1-index, allowing consideration of nonsmooth functionals with weak compactness conditions. Applies this to the Poincaré action functional for the Lorentz force equation.

Result: Proves existence of multiple critical points (periodic solutions with fixed period) for the Lorentz force equation by leveraging S^1-invariance of the Poincaré functional.

Conclusion: The S^1-invariance of the Poincaré action functional enables application of Lusternik-Schnirelman theory with S^1-index to obtain multiple periodic solutions for the Lorentz force equation, generalizing previous results to nonsmooth functionals with weaker compactness.

Abstract: In this paper we prove that the $S^1$-invariance of the Poincaré action functional associated to the Lorentz force equation gives the existence of multiple critical points which are periodic solutions with a fixed period. To do this, we prove an abstract multiplicity result which is based upon the Lusternik-Schnirelman method with the $S^1$-index. The corresponding result in the context of the Fadell-Rabinowitz index is proved in Ekeland and Lasry (Ann. Math., 112 (1980)). The main feature of our abstract result is that it allows us to consider nonsmooth functionals satisfying only a weak compactness condition well adapted to the Poincaré functional.

</details>


### [14] [Painlevé Universality classes for the maximal amplitude solution of the Focusing Nonlinear Schrödinger Equation with randomness](https://arxiv.org/abs/2602.05101)
*Aikaterini Gkogkou,Guido Mazzuca,Kenneth D. T-R McLaughlin*

Main category: math.AP

TL;DR: Universality established for extremal NLS solutions with random eigenvalues - two Painlevé-type rogue wave classes emerge regardless of eigenvalue distribution specifics.


<details>
  <summary>Details</summary>
Motivation: To understand the universal behavior of extremal (maximal amplitude) solutions in focusing nonlinear Schrödinger equation with random eigenvalue distributions, and determine whether rogue wave formation is robust to randomness.

Method: Analyze extremal N-soliton solutions with eigenvalues randomly drawn from sub-exponential distributions, considering two spectral structures: eigenvalues λ_j = v_j + iμ_j (Painlevé-III class) and λ_j = -ζj + v_j + iμ_j with 0<ζ<1 (Painlevé-V class).

Result: Identified two distinct universality classes: rescaled solutions converge locally to deterministic profiles governed by Painlevé-III equation in first regime, and Painlevé-V equation in second regime, independent of specific eigenvalue distributions.

Conclusion: Painlevé-type rogue wave formation is a universal phenomenon robust to randomness in extremal NLS solutions, with universal profiles emerging from two distinct spectral structures.

Abstract: We establish universality for extremal solutions of the focusing nonlinear Schrödinger equation. Extremal solutions are $N$-soliton solutions that achieve the theoretical maximal amplitude and diverge as $N \to \infty$. We consider extremal solutions with the discrete eigenvalues randomly drawn from sub-exponential distributions, and identify two distinct universality classes, determined by the macroscopic structure of the spectrum: the Painlevé--III rogue-wave solution, where the eigenvalues take the form $λ_j = v_j + i μ_j$, and the Painlevé--V rogue wave solution, where $λ_j = -ζ\, j + v_j + i μ_j$, with $0 < ζ< 1$. (In both cases, $μ_{j}$ and $v_{j}$ are subexponential random variables.) Universality can then be summarized as follows: independently of the specific distribution of the eigenvalues, the rescaled solutions converge locally to a deterministic profile governed by the Painlevé-III equation in the first regime, and the Painlevé-V equation in the second. These results demonstrate that the formation of Painlevé-type rogue waves is a universal phenomenon robust to randomness.

</details>


### [15] [Existence and symmetry of extremals for the high order Hardy-Sobolev-Maz'ya inequalities](https://arxiv.org/abs/2602.05203)
*Guozhen Lu,Chunxia Tao*

Main category: math.AP

TL;DR: Existence of extremal functions for k-th order critical Hardy-Sobolev-Maz'ya inequalities on upper half space via hyperbolic space equivalence and novel duality theory.


<details>
  <summary>Details</summary>
Motivation: The paper aims to establish existence of extremal functions for higher-order critical Hardy-Sobolev-Maz'ya inequalities on the upper half space, which is challenging due to higher-order derivatives, lack of translation invariance, inapplicability of rearrangement techniques, and Hardy singularity along the boundary.

Method: Instead of directly tackling the HSM inequality on upper half space, the authors prove existence of extremals for its equivalent Poincaré-Sobolev inequality on hyperbolic space. They develop novel duality theory for minimizing sequences, concentration-compactness principle for radial functions in hyperbolic setting, combined with Helgason-Fourier analysis and Riesz rearrangement inequality on hyperbolic space to resolve compactness issues.

Result: Established existence of extremal function for k-th order critical HSM inequalities on upper half space when k≥2 and n≥2k+2. Also obtained existence of positive symmetric solutions for high-order Brezis-Nirenberg equation on entire hyperbolic space associated with GJMS operators at critical parameter values.

Conclusion: The paper successfully overcomes technical challenges in higher-order critical Hardy-Sobolev-Maz'ya inequalities by working on hyperbolic space equivalence and developing new analytical tools for hyperbolic setting, with applications to Brezis-Nirenberg equations on hyperbolic space.

Abstract: In this article, we establish the existence of an extremal function for the k-th order critical Hardy-Sobolev-Maz'ya (HSM) inequalities on the upper half space $\mathbb{R}^{n+1}_{+}$ when $k\ge 2$ and $n\geq 2k+2$:
  $$\int_{\mathbb{R}^{n}_{+}}|\nabla^{k}u|^2dx-\prod_{i=1}^{k}\frac{\left(2i-1\right)^2}{4}\int_{\mathbb{R}^{n}_{+}}\frac{u^2}{x_1^{2k}}dx\geq C_{n,k,\frac{2n}{n-2k}} \left(\int_{\mathbb{R}^{n}_{+}}|u|^{\frac{2n}{n-2k}}dx\right)^{\frac{n-2k}{n}}. $$
  The analysis of this extremal problem is challenging due to the presence of the higher order derivatives, the lack of translation invariance, the inapplicability of rearrangement techniques on the upper half-space, and the presence of a Hardy singularity along the boundary. To overcome these difficulties, instead of directly considering the HSM inequality on the upper half space, we establish the existence of an extremal for its equivalent version: Poincaré-Sobolev inequality on the hyperbolic space. We develop a novel duality theory of the minimizing sequences, the concentration-compactness principle for radial functions in the hyperbolic setting, which combines with the Helgason-Fourier analysis and the Riesz rearrangement inequality on the hyperbolic space, to resolve the lack of compactness issue. As an application, we also obtain the existence of positive symmetric solutions for the high order Brezis-Nirenberg equation on the entire hyperbolic space associated with the GJMS operators $P_k$ (i.e., when $k\ge 2$): $$ P_{k}\left(f\right)-αf=|f|^{p-2}f $$ at the critical situation $α=\prod\limits_{i=1}^{k}\frac{\left(2i-1\right)^2}{4}$ when either $2k+2\leq n$ and $p=\frac{2n}{n-2k}$ or $2k<n$ and $2<p<\frac{2n}{n-2k}$.

</details>


### [16] [Strong solutions to the initial-boundary-value problem of compressible MHD equations with degenerate viscosities and far field vacuum in 3D exterior domains](https://arxiv.org/abs/2602.05264)
*Jiaxu Li,Boqiang Lü,Bing Yuan*

Main category: math.AP

TL;DR: Local existence and uniqueness of strong solutions for compressible MHD equations in 3D exterior domains with vacuum at infinity, density-dependent viscosities, and large initial data.


<details>
  <summary>Details</summary>
Motivation: Study the compressible MHD equations with vacuum at far-field and density-dependent viscosities, which create singularities. Need to understand how magnetic field affects solution behavior compared to compressible Navier-Stokes equations.

Method: Analyze initial-boundary-value problem in 3D exterior domains with Navier-slip boundary conditions for velocity and perfect conducting conditions for magnetic field. Consider viscosities as power functions of density (ρ^δ, 0<δ<1). Establish local existence and uniqueness theory.

Result: Prove local existence and uniqueness of strong solutions for regular large initial data. Show magnetic field maintains faster decay rate than density throughout time evolution, unlike compressible Navier-Stokes case.

Conclusion: Magnetic field plays crucial role in handling singularities from density-dependent viscosities by preserving its initial faster decay properties, distinguishing MHD from pure Navier-Stokes behavior.

Abstract: This paper concerns the initial-boundary-value problem (IBVP) of the compressible Magnetohydrodynamic (MHD) equations in 3D exterior domains with Navier-slip boundary conditions for the velocity and perfect conducting conditions for the magnetic field. For the case that the density approaches far-field vacuum initially and the viscosities are power functions of the density (ρ}δ with 0 < δ < 1), the local existence and uniqueness of strong solutions to the IBVP is established for regular large initial data. In particular, in contrast to the local theory of compressible Navier-Stokes equation Li-Lü-Yuan [24], we show that the magnetic field maintains the initial quality of decaying faster rate than density throughout the time evolution, which reveals the role of the magnetic field in handling singularities arising from density-dependent viscosities.

</details>


### [17] [Infinitely many new solutions for a nonlinear coupled Schrödinger system](https://arxiv.org/abs/2602.05283)
*Qingfang Wang,Mingxue Zhai*

Main category: math.AP

TL;DR: The paper studies a nonlinear Schrödinger system with two components, proving existence of new synchronized and segregated solutions that concentrate both in bounded domains and near infinity, and establishing non-degeneracy of these solutions.


<details>
  <summary>Details</summary>
Motivation: To investigate new types of solutions for coupled nonlinear Schrödinger systems that exhibit both synchronized and segregated behavior, addressing the challenge of interspecies interactions that don't appear in single equations.

Method: Uses finite dimensional reduction method to construct solutions, applies local Pohozaev identities and point-wise error estimates to prove non-degeneracy, and verifies non-degeneracy of previously established solutions.

Result: Proves existence of new synchronized and segregated solutions that concentrate both in bounded domains and near infinity with special structure, and establishes that these synchronized solutions are non-degenerate.

Conclusion: The paper successfully constructs novel solutions for coupled Schrödinger systems and proves their non-degeneracy, addressing the unique challenges posed by interspecies interactions in multi-component systems.

Abstract: We revisit the following nonlinear Schrödinger system \begin{align*}\begin{cases} -ε^{2}Δu +P(x) u= μ_1 u^3 +βuv^2, &~\text{in}\;\mathbb {R}^3,\\ -ε^{2}Δv+Q(x) v= μ_2 v^3 +βu^2v, &~\text{in}\;\mathbb{ R}^3, \end{cases} \end{align*} where $ε$ is a positive parameter, $P(x),\,Q(x)$ are the potential functions, $μ_1>0$, $μ_2>0$ and $β\in\mathbb R$ is a coupling constant. Employing the finite dimensional reduction method, we prove that there are new kind of synchronized and segregated solutions, which concentrate both in a bounded domain and near infinity, and present a special structure. Moreover, by applying the local Pohozaev identities and some point-wise estimates of the errors, we prove that the new kind of synchronized solutions are non-degenerate, which is of great interest independently. One of the main difficulties of Schrödinger system come from the interspecies interaction between the components, which never appear in the study of single equation. Secondly, prior to the construction of new solutions, we shall verify the non-degeneracy of the solutions established in [Peng-Pi, Discrete Contin. Dyn. Syst., 2016] for the Schrödinger systems.

</details>


### [18] [Precise propagation profile for some monostable free boundary problems in time-periodic media](https://arxiv.org/abs/2602.05328)
*Yihong Du,Zhuo Ma,Zhi-Cheng Wang*

Main category: math.AP

TL;DR: This paper establishes sharp convergence results for reaction-diffusion equations with free boundaries in heterogeneous environments, extending previous work beyond autonomous or strongly KPP cases.


<details>
  <summary>Details</summary>
Motivation: Previous results for free boundary models were limited to autonomous cases or required strong KPP conditions. There was a need to understand propagation phenomena in general monostable settings with time-periodic heterogeneity, without relying on special KPP conditions.

Method: The authors study reaction-diffusion equations with free boundaries subject to "preferred population density" conditions. They analyze semi-wave solutions (analogous to traveling waves in Cauchy problems) and develop methods to prove existence, uniqueness, and convergence properties in general monostable settings.

Result: The paper proves existence and uniqueness of semi-wave solutions for general monostable free boundary problems with time-periodic heterogeneity. It obtains precise descriptions of solution convergence toward semi-waves as time goes to infinity, without requiring special KPP conditions.

Conclusion: This work provides the first sharp convergence result for general monostable free boundary problems in heterogeneous environments. The developed methods should apply to related free boundary problems with nonlinearities more general than KPP type.

Abstract: We consider reaction-diffusion equations of the form \begin{equation*} u_t - d u_{xx} = f(t,u), \quad t>0,\ \ x \in [g(t), h(t)], \end{equation*} where $f(t,u)$ is periodic in $t$ and monostable in $u$, and the interval $[g(t), h(t)]$ represents the one dimensional population range of a species with density $u(t,x)$ at time $t$ and spatial location $x$. The free boundaries $x=g(t)$ and $x=h(t)$ evolve subject to a ``preferred population density" condition at the habitat edges. Analogous to the traveling wave solutions in the corresponding Cauchy problem, semi-wave solutions play a fundamental role in understanding the propagation phenomena governed by the free boundary problem here. But in contrast to the Cauchy problem, where the KPP condition plays a subtle role in the precise approximation of its solution (with compactly supported initial function) by the traveling wave solution with minimal speed, here we prove the existence and uniqueness of a semi-wave in a general monostable setting, and obtain a precise description of the convergence of the solution toward the semi-wave as time goes to infinity, where the KPP condition plays no special role. Previously, such a sharp result was proved for a free boundary model only when $f$ is autonomous ($f=f(u)$, see \cite{D} or \cite{DL15} for a related free boundary model), or a less precise result was obtained in the time-periodic case under an extra strong KPP condition on $f$ (see \cite{MDW}, or \cite{DGP} for a related free boundary model). This work appears to be the first to prove the sharp convergence result for a general monostable free boundary problem in a heterogeneous environment, and we believe the methods developed here should have applications to related free boundary problems in heterogeneous media with nonlinearities more general than those of KPP type.

</details>


### [19] [Dynamics of a nonlocal epidemic model with a new free boundary condition, part 1: Spreading-vanishing dichotomy](https://arxiv.org/abs/2602.05331)
*Yao Chen,Yihong Du,Wan-Tong Li,Rong Wang*

Main category: math.AP

TL;DR: This paper proposes a new free boundary condition for a nonlocal epidemic model, proves well-posedness, and establishes a spreading-vanishing dichotomy with sharp thresholds.


<details>
  <summary>Details</summary>
Motivation: To develop a more realistic epidemic model that incorporates both pathogen flux and infected population effects in determining the expansion rate of epidemic regions, improving upon existing free boundary conditions.

Method: Proposes a new free boundary condition combining outward pathogen flux and weighted total infected population. Uses mathematical analysis including well-posedness proofs, eigenvalue problems, and asymptotic analysis to characterize long-time dynamics.

Result: Proves the system is well-posed and exhibits spreading-vanishing dichotomy. Obtains sharp criteria for this dichotomy in terms of initial data and diffusion rates through eigenvalue analysis.

Conclusion: The new free boundary condition yields a mathematically tractable model with clear spreading-vanishing behavior characterized by sharp thresholds, setting the foundation for Part 2 which will study spreading speeds.

Abstract: This paper investigates the long-time dynamics of a nonlocal epidemic model with free boundaries, where a pathogen with density $u(t,x)$ and the infected humans with density $v(t,x)$ evolve according to a reaction-diffusion system with nonlocal diffusion over a one dimensional interval $[g(t), h(t)]$, which represents the epidemic region expanding through its boundaries $x=g(t)$ and $x=h(t)$, known as free boundaries. Such a model with free boundary conditions based on those of Cao et al. \cite{fb27} was considered by several works. Inspired by recent works of Feng et al. \cite{fb20} and Long et al. \cite{fb5}, we propose a new free boundary condition, where the expansion rate of the epidemic region, determined by $h'(t)$ and $g'(t)$, is proportional to a linear combination of the outward flux of the pathogen \(u\) through the range boundary (as in \cite{fb27}) and the weighted total population of infected individuals \(v\) within the region (as in \cite{fb5}). We prove that the system under this new free boundary condition is well-posed, and its long-time dynamical behavior is characterized by a spreading-vanishing dichotomy. Moreover, we obtain sharp criteria for this dichotomy, including a sharp threshold in terms of the initial data $(u_0,v_0)$; and by studying a related eigenvalue problem, we also find a sharp threshold in terms of the diffusion rate, which complements related results in Nguyen and Vo \cite{fb7}. This is Part $1$ of a two part series. In Part $2$, we will determine the spreading speed of the model when spreading occurs, and for some typical classes of kernel functions, we will obtain the precise rates of accelerated spreading.

</details>


### [20] [Lipschitz regularity of harmonic quasiconformal maps between Lyapunov domains in $\mathbb{R}^n$](https://arxiv.org/abs/2602.05436)
*Anton Gjokaj,David Kalaj*

Main category: math.AP

TL;DR: Harmonic K-quasiconformal homeomorphisms between Lyapunov domains in ℝⁿ are globally Lipschitz up to the boundary.


<details>
  <summary>Details</summary>
Motivation: To establish global Lipschitz regularity for sense-preserving harmonic quasiconformal homeomorphisms between smooth domains, extending boundary regularity results to the entire closure of the domain.

Method: Boundary iteration scheme: start with Hölder modulus from quasiconformality, improve via C¹,α boundary representation to get higher regularity for normal component, convert to near-boundary gradient bound using harmonic-measure bounds, propagate control via quasiconformality, and iterate to bound |Df| up to boundary.

Result: Every sense-preserving harmonic K-quasiconformal homeomorphism between Lyapunov domains in ℝⁿ is globally Lipschitz on the closure of the domain.

Conclusion: The paper proves strong global regularity for harmonic quasiconformal mappings between smooth domains, establishing Lipschitz continuity up to the boundary through an iterative boundary improvement scheme.

Abstract: We prove that every sense-preserving harmonic $K$--quasiconformal homeomorphism $f\colon D\toΩ$ between Lyapunov domains (equivalently, bounded $C^{1,α}$ domains) in $\mathbb{R}^n$, $α\in(0,1]$, is globally Lipschitz on $\overline D$. The argument is based on a boundary iteration scheme: an initial Hölder modulus for the boundary trace (coming from quasiconformality) is improved via the $C^{1,α}$ graph representation of $\partialΩ$, yielding higher Hölder regularity for the normal component. This boundary gain is converted into a near-boundary gradient bound for harmonic functions through a basepoint boundary Hölder-to-gradient estimate obtained by flattening the boundary and using local harmonic-measure bounds. Quasiconformality then propagates the resulting control from one component to the full differential, and iteration gives boundedness of $|Df|$ up to the boundary. Along the way we briefly survey several standard tools from the theory of quasiconformal harmonic mappings (QCH), including boundary Hölder continuity, distortion of derivatives, and boundary-to-interior propagation principles that enter the iteration.

</details>


### [21] [Convergence of the PML method for thermoelastic wave scattering problems](https://arxiv.org/abs/2602.05497)
*Qianyuan Yin,Changkun Wei,Bo Zhang*

Main category: math.AP

TL;DR: First analysis of PML method for 3D thermoelastic obstacle scattering with exponential convergence proof.


<details>
  <summary>Details</summary>
Motivation: Need to solve unbounded thermoelastic scattering problems efficiently; PML methods are effective for truncating unbounded domains but haven't been analyzed for thermoelastic scattering.

Method: Introduces uniaxial perfectly matched layer (PML) method to truncate unbounded domain; uses analytic Fredholm theory to prove well-posedness; employs PML extension technique and analyzes exponential decay of modified fundamental solution.

Result: Proves well-posedness of truncated PML problem except for discrete frequency set; establishes exponential convergence of PML method in terms of layer thickness and absorbing parameters.

Conclusion: First convergence result for PML method in thermoelastic scattering; provides rigorous mathematical foundation for numerical simulations of thermoelastic scattering problems.

Abstract: This paper is concerned with the thermoelastic obstacle scattering problem in three dimensions. A uniaxial perfectly matched layer (PML) method is firstly introduced to truncate the unbounded scattering problem, leading to a truncated PML problem in a bounded domain. Under certain constraints on model parameters, the well-posedness for the truncated PML problem is then proved except possibly for a discrete set of frequencies, based on the analytic Fredholm theory. Moreover, the exponential convergence of the uniaxial PML method is established in terms of the thickness and absorbing parameters of PML layer. The proof is based on the PML extension technique and the exponential decay properties of the modified fundamental solution. As far as we know, this is the first convergence result of the PML method for the time-harmonic thermoelastic scattering problem.

</details>


### [22] [Regularity results for linear parabolic equations on Carnot tori via mollifier kernel construction](https://arxiv.org/abs/2602.05498)
*Yiming Jiang,Yawei Wei,Yiyun Yang*

Main category: math.AP

TL;DR: Proves existence, uniqueness, and regularity for linear backward parabolic equations on Carnot tori, then applies results to Fokker-Planck-Kolmogorov equations.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for parabolic equations on non-commutative Carnot groups, which are important sub-Riemannian manifolds with applications in control theory and stochastic processes.

Method: 1) Construct specialized mollifiers adapted to Hörmander vector fields on Carnot groups, tori, and dual spaces; 2) Use singular integral operator theory to establish a priori regularity; 3) Apply results to dual Fokker-Planck-Kolmogorov equations.

Result: Proves existence, uniqueness, and regularity for solutions to linear backward parabolic equations on Carnot tori, and extends these results to weak solutions of the corresponding Fokker-Planck-Kolmogorov equations.

Conclusion: Develops comprehensive regularity theory for parabolic equations on Carnot groups using specialized analytical tools, establishing foundations for studying evolution equations on sub-Riemannian manifolds.

Abstract: This paper first proves the existence, uniqueness and regularity of the solution to a class of linear backward parabolic equations on Carnot tori, namely the periodic linear parabolic equation on Carnot groups. Such groups are non-commutative and typical examples of sub-Riemannian manifolds. Moreover, we apply the results for this equation to its dual equation (i.e., the Fokker-Planck-Kolmogorov equation in the general form), and derive the existence, uniqueness and regularity of its weak solution. To obtain the regularity results for solutions to the linear parabolic equation and its dual equation, firstly, we construct several families of mollifiers adapted respectively to the Hörmander vector fields generating Carnot groups, Carnot tori and dual spaces of non-isotropic Hölder spaces; secondly, we use the theory of singular integral operators to establish stronger a priori regularity for the solutions.

</details>


### [23] [Global smooth solutions in a one-dimensional thermoviscoelastic model with temperature-dependent paramaters](https://arxiv.org/abs/2602.05621)
*Felix Meyer*

Main category: math.AP

TL;DR: The paper establishes existence of global classical solutions for a thermoviscoelastic system modeling Kelvin-Voigt materials with arbitrarily large initial data.


<details>
  <summary>Details</summary>
Motivation: To analyze thermoviscoelastic developments in one-dimensional Kelvin-Voigt materials, which are important in continuum mechanics and materials science for understanding viscoelastic behavior coupled with thermal effects.

Method: The authors study a coupled PDE system describing thermoviscoelasticity, assuming smoothness conditions on the material functions (a, γ, f) with specific bounds and convexity properties. They use analytical techniques from partial differential equations and continuum mechanics.

Result: The main result proves the existence of global classical solutions for sufficiently smooth but arbitrarily large initial data under the given assumptions on the material functions.

Conclusion: The system modeling thermoviscoelastic Kelvin-Voigt materials admits global classical solutions even for large initial data, establishing mathematical well-posedness for this important class of materials.

Abstract: This manuscript is concerned with the system \begin{align*} \left\{ \begin{array}{l} u_{tt} = (γ(Θ) u_{xt})_x + (a(x,t) u_x)_x +(f(Θ))_x, \\[1mm] Θ_t = DΘ_{xx} + γ(Θ) u_{xt}^2 + f(Θ) u_{xt}, \end{array} \right. \end{align*} which is used to describe thermoviscoelastic developments in one-dimensional Kelvin-Voigt materials. \abs It is assumed that $a,γ$ and $f$ are sufficiently smooth functions that satisfy $$c_γ<γ(ζ)<C_γ, \quad γ''(ζ) \le 0,\quad f(0)=0, \quad |f'(ζ)|\le C_f \quad \mbox{ and } |f(ζ)|\le C_f(1+ζ)^α\quad \mbox{ for all }ζ\ge 0 $$ and some positive constants $c_γ,C_γ,C_f>0$ and $α\in (0,5/6)$. Under these conditions, this study then establishes a result on the existence of global classical solutions for sufficiently smooth but arbitrarily large initial data.

</details>


### [24] [Large time existence in a thermoviscoelastic evolution problem with mildly temperature-dependent parameters](https://arxiv.org/abs/2602.05640)
*Felix Meyer*

Main category: math.AP

TL;DR: The paper proves that classical solutions to a thermo-viscoelastic system with sublinear temperature dependencies can have arbitrarily large existence times under smallness conditions on parameter derivatives.


<details>
  <summary>Details</summary>
Motivation: The model generalizes classical thermo-viscoelastic systems for strain and temperature evolution. While local existence of classical solutions is known, the paper aims to show these solutions can exist for arbitrarily long times under appropriate conditions.

Method: The authors analyze a generalized thermo-viscoelastic system with Neumann boundary conditions for displacement and Dirichlet for temperature. They assume sublinear temperature dependencies of parameters and smallness conditions on the derivatives of γ and f. The key is establishing a constant δ_⋆ that ensures solutions exist beyond any given time T_⋆.

Result: For any given T_⋆, initial mass M, and parameter bounds, there exists δ_⋆ > 0 such that if the L^∞ norms of γ' and f' are bounded by δ_⋆, the maximal existence time of classical solutions exceeds T_⋆.

Conclusion: Classical solutions to the thermo-viscoelastic system can be extended to arbitrarily large time intervals when the temperature dependencies of material parameters are sufficiently mild, specifically when their derivatives are small enough.

Abstract: We consider \begin{align*} \label{HS} \left\{ \begin{array}{l} u_{tt} = (γ(Θ) u_{xt})_x + a (γ(Θ) u_x)_x +(f(Θ))_x, \\[1mm] Θ_t = DΘ_{xx} + Γ(Θ) u_{xt}^2 + F(Θ) u_{xt}, \end{array}\right. \qquad \qquad (\star) \end{align*} under Neumann boundary conditions for $u$ and Dirichlet boundary conditions for $Θ$ in a bounded interval $Ω\subset\mathbb{R}$. \abs This model is a generalization of the classical system for the description of strain and temperature evolution in a thermo-viscoelastic material following a Kelvin-Voigt material law, in which $γ\equiv Γ$ and $f\equiv F$. Different variations of this model have already been analyzed in the past and the present study draws upon a known result concerning the existence of classical solutions, which are local in time, for suitably smooth initial data, arbitrary $a>0$, $D>0$ and $γ,f\in C^2([0,\infty))$ as well as $Γ,F\in C^1([0,\infty))$ with $γ>0,Γ\ge0$ and $F(0)=0$. Our work focuses on proving that existence times for classical solutions can be arbitrarily large, assuming sublinear temperature dependencies of $γ$ and $f$, and further $|F(s)|\le C_F(1+s)^α$ for some $C_F>0$ and $α\in(0,1)$. In particular, for any given $T_\star$, initial mass $M$ and $0<\underlineγ<\overlineγ$, there exists a constant $δ_\star(M,T_\star,a,D, Ω, \underlineγ, \overlineγ,C_F,α)>0$, such that if $$\underlineγ\leγ\le \overlineγ\quad\mbox{ and }\quad 0\le Γ\le \overlineγ\quad \mbox{ as well as } \quad\|γ'\|_{L^\infty([0,\infty))}\le δ_\star \quad \mbox{ and }\quad \|f'\|_{L^\infty([0,\infty))}\le δ_\star $$ hold, the maximal existence time of the classical solution to $(\star)$ surpasses $T_\star$.

</details>


### [25] [Fundamental solution for higher order homogeneous hypoelliptic operators structured on Hörmander vector fields](https://arxiv.org/abs/2602.05647)
*Stefano Biagi,Marco Bramanti*

Main category: math.AP

TL;DR: Introduces "generalized Rockland operators" - higher order differential operators built with Hörmander vector fields, homogeneous under dilations but not left-invariant, with hypoelliptic lifted versions.


<details>
  <summary>Details</summary>
Motivation: To study a new class of differential operators that generalize Rockland operators beyond Lie group structures, allowing for operators built with Hörmander vector fields that are homogeneous under dilations but not necessarily left-invariant.

Method: Define generalized Rockland operators using Hörmander vector fields with dilation homogeneity, prove their hypoellipticity, and construct global fundamental solutions with sharp pointwise estimates.

Result: Proves these operators are hypoelliptic and possess global fundamental solutions Γ(x,y) that are jointly homogeneous and satisfy sharp pointwise estimates. Theory also applies to higher order heat-type operators.

Conclusion: Establishes a theory for generalized Rockland operators that extends beyond Lie group settings, providing hypoellipticity results and fundamental solution properties for operators with dilation homogeneity.

Abstract: We introduce and study a new class of higher order differential operators defined on $\mathbb{R}^{n}$, which are built with Hörmander vector fields, homogeneous w.r.t. a family of dilations (but not left invariant w.r.t. any structure of Lie group) and have a structure such that a suitably lifted version of the operator is hypoelliptic. We call these operators ''generalized Rockland operators''. We prove that these operators are themselves hypoelliptic and, under a natural condition on the homogeneity degree, possess a global fundamental solution $Γ\left( x,y\right) $ which is jointly homogeneous in $\left( x,y\right) $ and satisfies sharp pointwise estimates. Our theory can be applied also to some higher order heat-type operators and their fundamental solutions.

</details>


### [26] [Weak and strong averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise](https://arxiv.org/abs/2602.05696)
*Yangyang Shi,Dong Su,Hui Liu*

Main category: math.AP

TL;DR: The paper studies averaging principles for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, establishing well-posedness, ergodicity, and convergence to averaged equations.


<details>
  <summary>Details</summary>
Motivation: To understand the averaging behavior of 2D Boussinesq systems with non-Lipschitz Poisson jump noise, which are important in fluid dynamics and climate modeling but present analytical challenges due to the non-Lipschitz nature of the noise.

Method: First establishes well-posedness, regularity estimates, and tightness for the vorticity variable. Then proves ergodicity of the temperature variable. Next shows convergence of vorticity to averaged equation solutions in probability and 2pth-mean as time scale parameter ε→0. Finally includes case study and numerical simulations.

Result: Successfully proves: 1) Well-posedness and regularity for vorticity with non-Lipschitz Poisson noise, 2) Ergodicity of temperature variable, 3) Convergence of vorticity to averaged equation in probability and 2pth-mean under different conditions as ε→0, 4) Numerical validation through simulations.

Conclusion: The averaging principle holds for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, providing rigorous mathematical foundation for reduced-order modeling of such stochastic fluid systems with applications to climate and geophysical flows.

Abstract: In this paper, we study the averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise. Precisely, we will first explore the well-posedness, regularity estimates and tightness of the vorticity variable. Then, we prove the ergodicity of the temperature variable. Next, we prove that the vorticity variable converge to the solution of the averaged equation in probability and $2p$th-mean, under different conditions, as time scale parameter $\varepsilon$ goes to zero. Finally, we present a specific case study and conduct numerical simulations to substantiate the main conclusions of this paper.

</details>


### [27] [Flow reversal of the Stokes system with localized boundary data in the half space](https://arxiv.org/abs/2602.05858)
*Tongkeun Chang,Kyungkeun Kang,Chanhong Min*

Main category: math.AP

TL;DR: Unsteady Stokes flow in half-space with localized boundary data can exhibit flow reversal where velocity components change sign, with normal component showing more sign changes than tangential components.


<details>
  <summary>Details</summary>
Motivation: To investigate whether boundary-driven unsteady Stokes flow in a half-space can exhibit flow reversal phenomena, where velocity components change direction within the domain, contrary to intuitive expectations about boundary-driven flows.

Method: Analysis of representation formula for Stokes system in half-space using Green tensor with nonzero boundary data, including careful pointwise estimates to construct specific boundary influxes that induce flow reversal.

Result: Existence of boundary influxes that cause flow reversal: tangential velocity components exhibit at least one sign change, normal component exhibits at least two sign changes, with normal component having opposite sign to tangential components near boundary but same sign far from boundary.

Conclusion: Unsteady Stokes flow in half-space with localized boundary data can exhibit complex flow reversal patterns, demonstrating counterintuitive behavior where velocity components change direction within the domain despite localized boundary forcing.

Abstract: We consider the unsteady Stokes system in the half-space with zero initial data and nonzero, space-time localized boundary data. We show that there exist boundary influxes for which the induced flow exhibits flow reversal, in the sense that at least one component of the velocity field changes its sign in the half-space. This phenomenon is demonstrated by a careful analysis of the representation formula for the Stokes system in the half-space, including pointwise estimates, based on the Green tensor with nonzero boundary data. We construct solutions of the Stokes system such that the tangential components of the velocity field exhibit at least one sign change, while the normal component exhibits at least two sign changes. Moreover, the normal component of the constructed velocity field has the opposite sign to the tangential components near the boundary, whereas it has the same sign as the tangential components sufficiently far from the boundary.

</details>


### [28] [Large bulk viscosity limit for compressible MHD equations in critical Besov spaces](https://arxiv.org/abs/2602.05878)
*Gennaro Ciampa,Donatella Donatelli,Giada Pellecchia*

Main category: math.AP

TL;DR: Global well-posedness of compressible MHD equations in large bulk viscosity limit, with convergence to incompressible MHD and application to magnetic reconnection.


<details>
  <summary>Details</summary>
Motivation: Study the singular limit behavior of compressible magnetohydrodynamics (MHD) equations as bulk viscosity becomes arbitrarily large, connecting compressible and incompressible regimes.

Method: Analyze large bulk viscosity limit for compressible MHD equations in 2D and 3D using critical Besov spaces, prove global well-posedness for arbitrarily large initial data, establish convergence with explicit rates to incompressible MHD solutions.

Result: Proved global well-posedness of strong solutions for arbitrarily large initial data in critical Besov spaces, established quantitative convergence rates to incompressible MHD as bulk viscosity → ∞, constructed global smooth solutions with magnetic reconnection extending incompressible scenarios to compressible regime.

Conclusion: The large bulk viscosity limit provides rigorous connection between compressible and incompressible MHD, enabling extension of magnetic reconnection phenomena from incompressible to compressible flows through singular limit analysis.

Abstract: We study the large bulk viscosity limit for the compressible magnetohydrodynamics (MHD) equations in two and three dimensions. For arbitrarily large initial data in critical Besov spaces, we prove the global well-posedness of strong solutions and establish their convergence, with explicit quantitative rates, to solutions of the incompressible MHD system, as the bulk viscosity parameter tends to infinity. As an application of this singular-limit analysis, we construct global smooth solutions to the compressible MHD equations whose magnetic field undergoes reconnection, thereby extending to the compressible regime the reconnection scenarios previously identified for incompressible flows.

</details>


### [29] [Explicit representation of solutions to a linear wave equation with time delay](https://arxiv.org/abs/2602.05906)
*Javad A. Asadzade,Jasarat J. Gasimov,Nazim I. Mahmudov,Ismail T. Huseynov*

Main category: math.AP

TL;DR: Spectral representation for 1D wave equation with constant time delay using stepwise classical solutions and Fourier series reconstruction.


<details>
  <summary>Details</summary>
Motivation: To develop explicit solution representation for wave equations with time delays, which cause loss of global smoothness and require special treatment due to jump discontinuities in higher derivatives.

Method: Combine separation of variables with Sturm-Liouville expansions to reduce delayed PDE to scalar delay differential equations, use delay-dependent fundamental solutions for modal dynamics, and reconstruct PDE solution as Fourier series.

Result: Derived closed-form representation formulas for modal dynamics, established convergence conditions for uniform convergence and termwise differentiation, demonstrated practical computation with numerical example.

Conclusion: Successfully developed spectral representation for delayed wave equations using stepwise classical solutions, enabling explicit solution construction and numerical implementation.

Abstract: This paper develops an explicit spectral representation for solutions of a one-dimensional linear wave equation with a constant time delay. The model is considered on a bounded interval with non-homogeneous Dirichlet boundary data and a prescribed history function. To accommodate the loss of global smoothness in time caused by delay terms, solutions are understood in a \textit{stepwise classical sense}, allowing jump discontinuities in the second time derivative at multiples of the delay while maintaining continuity of the solution and its first time derivative.
  By combining separation of variables with Sturm-Liouville expansions, the delayed PDE is reduced to a family of scalar second-order delay differential equations. Using delay-dependent fundamental solutions, we derive closed-form representation formulas for the modal dynamics and reconstruct the PDE solution as a Fourier series. Convergence conditions guaranteeing uniform convergence and admissibility of termwise differentiation in space are established. A numerical example demonstrates the practical computation of truncated series solutions and their visualization.

</details>


### [30] [Large time stabilization of rough-data solutions in one-dimensional nonlinear thermoelasticity](https://arxiv.org/abs/2602.05962)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper proves stabilization of weak solutions for a one-dimensional thermoelasticity model with minimal regularity assumptions on initial data, showing convergence to equilibrium states.


<details>
  <summary>Details</summary>
Motivation: Previous studies on thermoelasticity models required more regular initial data and relied on compactness properties. This work aims to establish stabilization results under minimal regularity assumptions that only satisfy fundamental physical principles (energy conservation and entropy nondecrease).

Method: The authors consider a one-dimensional thermoelasticity PDE system with Dirichlet boundary conditions for displacement u and Neumann for temperature Θ. They work with weak solutions under minimal regularity assumptions: u₀ ∈ W₀¹²(Ω), u₀ₜ ∈ L²(Ω), and Θ₀ ∈ L¹(Ω) nonnegative and nonzero. Despite lacking favorable compactness properties, they prove stabilization results.

Result: The main result shows that weak solutions stabilize: lim_{t→∞} ‖u(·,t)‖_{L∞(Ω)} = 0 and ess lim_{t→∞} ‖Θ(·,t)-Θ∞‖_{L∞(Ω)} = 0 for some Θ∞ > 0. This demonstrates convergence to equilibrium states despite minimal regularity assumptions.

Conclusion: The paper successfully establishes stabilization of weak solutions for the thermoelasticity model under physically minimal assumptions, overcoming the lack of compactness properties that were essential in previous studies with more regular data.

Abstract: In an open bounded real interval $Ω$, the model for one-dimensional thermoelasticity given by \[
  u_{tt} = u_{xx} - \big(f(Θ)\big)_x,
  \qquad
  Θ_t = Θ_{xx} - f(Θ) u_{xt}, \] is considered along with homogeneous boundary conditions of Dirichlet type for $u$ and of Neumann type for $Θ$, under the assumption that $f\in C^1([0,\infty))$ satisfies $f(0)=0$, $f'\in L^\infty((0,\infty))$ and $f'>0$ on $[0,\infty)$. The focus is on initial data which are merely required to be consistent with the fundamental principles of energy conservation and entropy nondecrease, by satisfying \[
  u_0\in W_0^{1,2}(Ω),
  u_{0t} \in L^2(Ω),
  0 \le Θ_0\in L^1(Ω), Θ_0 \not\equiv 0. \] Despite an apparent lack of favorable compactness properties that have underlain previous related studies on more regular settings, it is shown that corresponding weak solutions stabilize in the sense that \[
  \lim_{t\to\infty} \|u(\cdot,t)\|_{L^\infty(Ω)}=0 \] and \[
  {\rm ess} \lim_{\!\!\!\! t\to\infty} \|Θ(\cdot,t)-Θ_\infty\|_{L^\infty(Ω)}=0 \] with some $Θ_\infty>0$.

</details>


### [31] [A simple model for one-dimensional nonlinear thermoelasticity: Well-posedness in rough-data frameworks](https://arxiv.org/abs/2602.05963)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper proves unconditional global well-posedness for a coupled hyperbolic-parabolic system modeling thermoelasticity with nonlinear coupling function f.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for thermoelastic wave propagation with nonlinear coupling, ensuring global existence, uniqueness, and continuous dependence on initial data under minimal regularity assumptions.

Method: Analysis of a coupled PDE system: hyperbolic wave equation for displacement u coupled with parabolic heat equation for temperature Θ through nonlinear function f. Uses functional analysis, Sobolev spaces, and energy methods to prove well-posedness.

Result: Proves unconditional global existence, uniqueness, and continuous dependence for solutions with minimal initial regularity: u₀∈W₀¹²(Ω), u₀ₜ∈L²(Ω), Θ₀∈L²(Ω) with Θ₀≥0. Solutions satisfy specified regularity classes.

Conclusion: The thermoelastic system with nonlinear coupling is well-posed globally in time under minimal initial conditions, providing rigorous mathematical justification for the model's physical validity.

Abstract: In an open bounded interval $Ω$, the problem \[
  u_{tt} = u_{xx} - \big(f(Θ)\big)_x,
  Θ_t = Θ_{xx} - f(Θ) u_{xt}, \] is considered under the boundary conditions $u|_{\partialΩ}=Θ_x|_{\partialΩ}=0$, and for $f\in C^2([0,\infty))$ satisfying $f(0)=0$, $f'>0$ on $[0,\infty)$ and $f'\in W^{1,\infty}((0,\infty))$.
  In the sense of unconditional global existence, uniqueness and continuous dependence, this problem is shown to be well-posed within ranges of initial data merely satisfying \[
  u_0\in W_0^{1,2}(Ω),
  \quad
  u_{0t} \in L^2(Ω)
  \quad \mbox{and} \quad
  Θ_0 \in L^2(Ω)
  \mbox{ with $Θ\ge 0$ a.e.~in $Ω$,} \] and in classes of solutions fulfilling \[
  u\in C^0([0,\infty);W_0^{1,2}(Ω)),
  \qquad
  u_t \in C^0([0,\infty);L^2(Ω))
  \qquad \mbox{and} \qquad
  Θ\in C^0([0,\infty);L^2(Ω)) \cap L^2_{loc}([0,\infty);W^{1,2}(Ω)). \]

</details>


### [32] [Global solvability and stabilization in multi-dimensional small-strain nonlinear thermoviscoelasticity](https://arxiv.org/abs/2602.05964)
*Michael Winkler*

Main category: math.AP

TL;DR: Global existence of solutions for small-strain thermoviscoelastic evolution in Kelvin-Voigt materials without size restrictions on initial data, with results on large-time behavior and temperature stabilization.


<details>
  <summary>Details</summary>
Motivation: Addresses a long-standing open problem in continuum mechanics: determining global solvability of the thermoviscoelastic evolution model for Kelvin-Voigt materials with inertia in multi-dimensional settings for arbitrary initial data size.

Method: Studies initial value problem in smoothly bounded n-dimensional domains (n≥2) with homogeneous Dirichlet boundary conditions for displacement and Neumann for temperature. Uses generalized solvability concepts and analyzes a more general system allowing heat capacity to depend on temperature. Core analysis relies on evolution properties of logarithmic refinements of classical entropy functionals.

Result: Proves global existence of solutions without size restrictions on data. Derives results on large time behavior showing stabilization of temperature toward spatially homogeneous limit.

Conclusion: Resolves the open problem by establishing global solvability for the thermoviscoelastic evolution model. Introduces novel logarithmic entropy refinements that may be of independent interest beyond this specific application.

Abstract: Despite considerable developments in the literature of the past decades, a standing open problem in the analysis of continuum mechanics appears to consist of determining how far the prototypical model for small-strain thermoviscoelastic evolution in Kelvin-Voigt materials with inertia, as given by \[
  u_{tt} = μΔu_t + (λ+μ)\nabla\nabla\cdot u_t
  + \hatμ Δu + (\hatλ+\hatμ) \nabla\nabla\cdot u
  - B\nablaΘ,
  \qquad \qquad
  κΘ_t = DΔΘ+ μ|\nabla u_t|^2 + (λ+μ) |{\rm div} \, u_t|^2 - BΘ{\rm div} \, u_t,
  \qquad \qquad \qquad (\star) \] is globally solvable in multi-dimensional settings and for initial data of arbitrary size.
  The present manuscript addresses this in the context of an initial value problem in smoothly bounded $n$-dimensional domains with $n\ge 2$, posed under homogeneous boundary conditions of Dirichlet type for the displacement variable $u$, and of Neumann type for the temperature $Θ$. Within suitably generalized concepts of solvability, global existence of solutions is shown without any size restrictions on the data, and for a system actually more general than ($\star$) by, inter alia, allowing the heat capacity $κ$ to depend on $Θ$. Apart from that, results on large time behavior are derived which particularly assert stabilization of $Θ$ toward a spatially homogeneous limit.
  Besides on standard features related to energy conservation and entropy production, in its core parts the analysis relies on an evolution property of certain logarithmic refinements of classical entropy functionals, to the best of our knowledge undiscovered in precedent literature and possibly of independent interest.

</details>


### [33] [Stability of the $L^{p}$-Poincaré inequality for the Lebesgue and Gaussian probability measures with explicit geometric dependency](https://arxiv.org/abs/2602.05968)
*Nurgissa Yessirkegenov,Amir Zhangirbayev*

Main category: math.AP

TL;DR: The paper proves stability results for L^p-Poincaré inequalities for Lebesgue and Gaussian measures using eigenfunction properties and weighted inequalities for log-concave measures.


<details>
  <summary>Details</summary>
Motivation: To establish stability properties for L^p-Poincaré inequalities, which are fundamental in analysis and probability theory, particularly for understanding how these inequalities behave under perturbations or variations in the underlying measure.

Method: The approach uses properties of the first eigenfunction of the (Gaussian) p-Laplacian operator and weighted Poincaré inequalities for log-concave measures on convex domains.

Result: The main results are Theorem 3.3 (stability for Lebesgue measure) and Theorem 3.6 (stability for Gaussian probability measure), establishing stability of L^p-Poincaré inequalities for both types of measures.

Conclusion: The paper successfully obtains stability results for L^p-Poincaré inequalities using analytical techniques involving eigenfunctions and weighted inequalities, contributing to the understanding of stability properties in functional inequalities.

Abstract: In this paper, we obtain stability results for the $L^{p}$-Poincaré inequality for both Lebesgue and Gaussian probability measures (Theorem 3.3 and Theorem 3.6). Our approach relies on properties of the first eigenfunction of the (Gaussian) $p$-Laplacian operator and weighted Poincaré inequalities for log-concave measures on convex domains.

</details>


### [34] [Finite time singularities in the Landau equation with very hard potentials](https://arxiv.org/abs/2602.05981)
*Jacob Bedrossian,Jiajie Chen,Maria Pia Gualdani,Sehyun Ji,Vlad Vicol,Jincheng Yang*

Main category: math.AP

TL;DR: Constructs smooth initial data for inhomogeneous Landau equation that develops finite-time singularity with bounded L∞ norm but blowing up Cα norms, showing first example of collisional kinetic model globally well-posed in homogeneous setting but admitting singularities for inhomogeneous data.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that collisional kinetic models can exhibit fundamentally different behavior in inhomogeneous vs homogeneous settings, providing the first example where a kinetic model is globally well-posed in homogeneous case but develops finite-time singularities for inhomogeneous data.

Method: Construct smooth, strictly positive initial data for the inhomogeneous Landau equation with γ∈(√3,2], analyze solution behavior showing Cα-norms blow up while L∞-norm remains bounded, study solution in self-similar variables showing convergence to local Maxwellian.

Result: Finite-time singularity develops where Cα-norm blows up for every α>0 while L∞-norm remains uniformly bounded; in self-similar variables, solution becomes asymptotically hydrodynamic with distribution function converging to local Maxwellian and hydrodynamic fields developing asymptotically self-similar implosion matching compressible Euler equations profiles.

Conclusion: This provides the first example of a collisional kinetic model that is globally well-posed in homogeneous setting but admits finite time singularities for inhomogeneous data, demonstrating fundamental difference between homogeneous and inhomogeneous behavior in kinetic theory.

Abstract: We consider the inhomogeneous Landau equation with $γ\in (\sqrt{3},2]$ and construct smooth, strictly positive initial data that develop a finite time singularity. The $C^α$-norm of the distribution function blows up for every $α>0$, whereas its $L^{\infty}$-norm remains uniformly bounded. In self-similar variables, the solution becomes asymptotically hydrodynamic - the distribution function converges to a local Maxwellian, while the hydrodynamic fields develop an asymptotically self-similar implosion whose profile coincides with a smooth imploding profile of the compressible Euler equations. To our knowledge, this provides the first example of a collisional kinetic model which is globally well-posed in the homogeneous setting, but admits finite time singularities for inhomogeneous data.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [35] [Path Sampling for Rare Events Boosted by Machine Learning](https://arxiv.org/abs/2602.05167)
*Porhouy Minh,Sapna Sarupria*

Main category: physics.comp-ph

TL;DR: AIMMD is a novel ML-enhanced sampling algorithm that improves transition path sampling efficiency by enabling on-the-fly committor estimation and deriving interpretable reaction coordinates for molecular mechanism discovery.


<details>
  <summary>Details</summary>
Motivation: To address the need for more efficient and interpretable methods for elucidating complex molecular processes, particularly overcoming limitations in traditional transition path sampling approaches.

Method: AIMMD integrates machine learning with transition path sampling to enable on-the-fly estimation of committor probability and simultaneously derive human-interpretable reaction coordinates.

Result: The method provides a robust framework for mechanistic pathway discovery, with recent extensions showing continued development and application potential.

Conclusion: AIMMD represents a significant advancement in molecular simulation methodology with promising impact, though it has limitations that warrant further development and critical assessment.

Abstract: The study by Jung et al. (Jung H, Covino R, Arjun A, et al., Nat Comput Sci. 3:334-345 (2023)) introduced Artificial Intelligence for Molecular Mechanism Discovery (AIMMD), a novel sampling algorithm that integrates machine learning to enhance the efficiency of transition path sampling (TPS). By enabling on-the-fly estimation of the committor probability and simultaneously deriving a human-interpretable reaction coordinate, AIMMD offers a robust framework for elucidating the mechanistic pathways of complex molecular processes. This commentary provides a discussion and critical analysis of the core AIMMD framework, explores its recent extensions, and offers an assessment of the method's potential impact and limitations.

</details>


### [36] [Numerical Evaluation of Angle-Dependent IR-Transparent Radiative Cooling Performance for Asymmetric Periodic Structures](https://arxiv.org/abs/2602.05613)
*Junwoo Gim,Jun Heo,Weng Cho Chew,Dong-Yeop Na*

Main category: physics.comp-ph

TL;DR: Single-angle IR transmission asymmetry is insufficient for predicting practical radiative cooling performance; angularly distributed asymmetric transparency through hemispherical integration is essential for effective non-contact thermal management.


<details>
  <summary>Details</summary>
Motivation: Current infrared-transparent passive radiative cooling (PRC) designs focus on asymmetric transmission at normal incidence, but this single-angle approach doesn't accurately predict real-world cooling performance, leading to potential overestimation of cooling capabilities.

Method: Developed an angle-resolved full-wave electromagnetic model with Bloch periodic boundary conditions and Floquet mode decomposition to compute wavelength- and angle-dependent bidirectional reflection/transmission. Coupled EM response with energy-balance thermal model to predict transient temperature evolution.

Result: Pronounced asymmetric transmission at normal incidence is generally not preserved at oblique angles. Angular integration yields only marginal cooling or net heating, while normal-incidence-only models substantially overestimate cooling performance.

Conclusion: Angularly distributed asymmetric transparency, evaluated through hemispherical integration over emission directions, is a key electromagnetic design principle for effective IR-transparent passive radiative cooling and wide-angle asymmetric metasurfaces.

Abstract: Infrared (IR)-transparent passive radiative cooling (PRC) enables non-contact thermal management by regulating radiative heat exchange without direct attachment to the cooling object. While asymmetric IR transmission at a specific incidence angle -- typically normal incidence -- is often emphasized, we show that such single-angle asymmetry is neither sufficient nor predictive of practical cooling performance. In this work, we demonstrate that effective non-contact PRC requires angularly distributed asymmetric IR transparency evaluated through hemispherical integration over emission directions, rather than asymmetry at a single incidence angle. To quantify this effect, an angle-resolved full-wave electromagnetic (EM) model with Bloch periodic boundary conditions and Floquet mode decomposition is employed to compute wavelength- and angle-dependent bidirectional reflection and transmission of periodic PRC structures. The resulting EM response is coupled to an energy-balance-based thermal model to predict the transient temperature evolution of the cooling object. By comparing models that account for the full angular distribution with normal-incidence-only approximations, we show that pronounced asymmetric transmission at normal incidence is generally not preserved at oblique angles. As a result, angular integration yields only marginal cooling or may even result in net heating, whereas normal-incidence-based models can substantially overestimate cooling performance. These results establish angularly distributed asymmetric transparency as a key EM design principle for IR-transparent PRC and wide-angle asymmetric metasurfaces.

</details>


### [37] [The near-continuum mechanism for extended Boltzmann theory: the non-equilibrium relaxation](https://arxiv.org/abs/2602.05775)
*Sha Liu,Ningchao Ding,Ming Fang,Hao Jin,Rui Zhang,Congshan Zhuo,Chengwen Zhong*

Main category: physics.comp-ph

TL;DR: This paper develops a theoretical framework using the Pullin equation to analyze near-continuum relaxation mechanisms in polyatomic gases, deriving explicit analytical expressions for macroscopic variable relaxation and confirming that thermal conduction coefficients depend on thermal non-equilibrium.


<details>
  <summary>Details</summary>
Motivation: Existing collision models like Borgnakke-Larsen don't guarantee entropic detailed balance and aren't integrable, limiting theoretical analysis of near-continuum relaxation mechanisms in polyatomic gases.

Method: Uses the Pullin equation (which has integrable collision kernel and satisfies detailed balance) with mixed Hermite-Laguerre approximations for distribution functions to compute collision operator moments, enabling direct description of macroscopic non-equilibrium evolution.

Result: First explicit analytical expressions for temporal relaxation of macroscopic variables (stress force, translational/rotational temperatures, heat flux); confirmation that thermal conduction coefficients depend on thermal non-equilibrium; derivation of novel Rykov-type relaxation model that captures translational-rotational heat flux interactions.

Conclusion: The Pullin equation provides rigorous framework for analyzing polyatomic gas relaxation; thermal conduction coefficients indeed depend on thermal non-equilibrium; new Rykov-type model improves accuracy by including translational-rotational heat flux interactions ignored in previous models.

Abstract: The collision phenomenon of polyatomic gases is described by the collision operator of extended Boltzmann equation or the energy-exchange model in particle direct simulations, for example, the Borgnakke-Larsen model. However, as a collision kernel, it dose not guarantee the entrinsic detailed balance and is not integrable. In this work, the Pullin equation, which possesses an integrable collision kernel and satisfies the detailed balance constraint, is adopted as an extended Boltzmann equation for the theoretical analysis of near-continuum relaxation mechanisms. For clarity, only the translational and rotational degrees are considered in this work. Explicit analytical expressions for the temporal relaxation of macroscopic variables, including the stress force, (translational/rotational) temperature and heat flux, are obtained at the first time. This is achieved by approximating the distribution function in mixed Hermite and Laguerre for rotation and computing the collision operator moments, enabling a direct description of macroscopic non-equilibrium evolution. Base on the same elementary moment (integral) of collision operator, the macroscopic transport coefficients is found in Chapman-Enskog framework. The long-standing speculation, that thermal conduction coefficient should be depended on the degrees of thermal non-equilibrium, is rigorously confirmed and evaluated. When thermal equilibrium is enforced, the present thermal conduction coefficients can be degenerated to the famous results of Mason and Monchick. Given the correct relaxation rate, a Rykov-type novel relaxation model for Pullin equation is proposed. It can recover the interaction of transaltional and rotatioanl heat fluxes in relaxation process, which is ignored in the widely used Rykov equation. Finally, the precision of this new Rykov-type equation is examined using a series of benchmark test cases.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [38] [An approximate Kappa generator for particle simulations](https://arxiv.org/abs/2602.05606)
*Seiji Zenitani,Takayuki Umeda*

Main category: physics.plasm-ph

TL;DR: Proposes a fast GPU-compatible random number generator for Kappa velocity distributions using q-exponential approximations and inverse transform methods.


<details>
  <summary>Details</summary>
Motivation: Need efficient random number generation for Kappa velocity distributions in particle simulations, particularly for GPU acceleration where traditional methods may be slow or impractical.

Method: Approximates the cumulative distribution function with q-exponential function and constructs an inverse transform procedure for random number generation.

Result: Method provides practically accurate results, especially for k<4, and runs efficiently on GPUs with good performance.

Conclusion: The proposed GPU-compatible random number generator enables efficient particle simulations with Kappa velocity distributions, particularly benefiting high-performance computing applications.

Abstract: A random number generator for the Kappa velocity distribution in particle simulations is proposed. Approximating the cumulative distribution function with the q-exponential function, an inverse transform procedure is constructed. The proposed method provides practically accurate results, in particular for k<4. It runs fast on graphics processing units (GPUs). The derivation, numerical validation, and relevance to GPU execution models are discussed.

</details>


### [39] [Explosive eruption cycles in a rotating Z-pinch](https://arxiv.org/abs/2602.06012)
*David N. Hosking,Luca Swinnerton,Rahul Kesavan*

Main category: physics.plasm-ph

TL;DR: Transonic shear flow along magnetic field lines can stabilize steep pressure gradients in MHD plasmas, creating a metastable "MHD pedestal" similar to tokamak edge pedestals that collapses and rebuilds in ELM-like cycles.


<details>
  <summary>Details</summary>
Motivation: To understand how transonic shear flows can stabilize pressure gradients in confined MHD plasmas, and to investigate the metastability and collapse mechanisms of such transport barriers, analogous to ELM cycles in fusion experiments.

Method: Using Z-pinch geometry, simulating slow formation of MHD pedestals in heated and sheared Z-pinches, and analyzing collapse via combinatorial optimization of flux-tube interchanges to calculate available energy and ejected plasma amounts.

Result: The MHD pedestal is metastable and collapses when reaching critical height, expelling order-unity fraction of confined thermal energy, then rebuilds in ELM-like cycles. Available energy and optimal ejected plasma amounts can be calculated from first principles.

Conclusion: Transonic shear flows create metastable MHD pedestals in confined plasmas that undergo cyclic collapse and rebuilding similar to tokamak ELM cycles, with energetics calculable via combinatorial optimization of flux-tube interchanges.

Abstract: A transonic shear flow directed along magnetic field lines can linearly stabilize a steep pressure gradient in a confined magnetohydrodynamic (MHD) plasma. In Z-pinch geometry, we show that, like the edge pedestal in tokamak devices, this transport barrier -- which we call the ``MHD pedestal'' -- is metastable, i.e., unstable to finite-amplitude displacements of flux tubes. We simulate the slow formation of an MHD pedestal in a heated and sheared Z-pinch, which collapses on reaching a critical height, expelling an order-unity fraction of the confined thermal energy. The MHD pedestal then rebuilds and the process repeats, in a manner analogous to the ELM cycle seen in fusion experiments. We show that the available energy of the metastable equilibrium, and the most energetically favorable amount of ejected plasma, can be calculated from first principles via combinatorial optimization of flux-tube interchanges.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [40] [A term-by-term variational multiscale method with dynamic subscales for incompressible turbulent aerodynamics](https://arxiv.org/abs/2602.05563)
*Diego Escobar,Douglas Pacheco,Alejando Aguirre,Ernesto Castillo*

Main category: physics.flu-dyn

TL;DR: Dynamic term-by-term VMS method for incompressible flows from laminar to turbulent regimes, validated on large-scale aerodynamics with unstructured meshes up to 40M elements.


<details>
  <summary>Details</summary>
Motivation: To develop a unified stabilized finite element framework that handles under-resolved flow scales without problem-specific turbulence models, working across laminar to turbulent regimes in complex 3D settings.

Method: Dynamic term-by-term VMS stabilized formulation embedded in incremental pressure-correction fractional-step framework with orthogonal projections, minimal stabilization terms, and equal-order velocity-pressure interpolation.

Result: Method validated on large-scale external aerodynamics including Ahmed body at Re=7.68×10⁵ and realistic Formula 1 configuration at Re≈10⁶, capturing separated-flow features and coherent wake organization with robust performance at scale.

Conclusion: The proposed stabilized pressure-segregated formulation provides robust control of convection-dominated dynamics, suitable dissipation for turbulent simulations, and consistent inertial-subrange behavior within a unified framework.

Abstract: Variational multiscale (VMS) methods offer a robust framework for handling under-resolved flow scales without resorting to problem-specific turbulence models. Here, we propose and assess a dynamic, term-by-term VMS stabilized formulation for simulating incompressible flows from laminar to turbulent regimes. The method is embedded in an incremental pressure-correction fractional-step framework and employs a minimal set of stabilization terms, yielding a unified discretization that (i) allows equal-order velocity--pressure interpolation and (ii) provides robust control of convection-dominated dynamics in complex three-dimensional settings. Orthogonal projections are a key ingredient and ensure that the non-residual, term-by-term structure induces dissipation through dynamic subscales suitable for turbulent simulations. The methodology is validated on large-scale external-aerodynamics configurations, including the Ahmed body at Re $ = 7.68\times 10^{5}$ for multiple slant angles, using unstructured tetrahedral meshes ranging from 3 to 40 million elements. Applicability is further demonstrated on a realistic Formula~1 configuration at $U_\infty=56~\mathrm{m/s}$ (201.6~km/h), corresponding to Re $ \approx 10^{6}$. The results show that the proposed stabilized pressure-segregated formulation remains robust at scale and captures key separated-flow features and coherent wake organization. Pointwise velocity and pressure spectra provide an a posteriori consistency indicator, exhibiting finite frequency ranges compatible with inertial-subrange reference slopes in the resolved band and supporting dissipation control in under-resolved regimes within a unified stabilized finite element framework.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [41] [Auroral signatures of ballooning instability and plasmoid formation processes in the near-Earth magnetotail](https://arxiv.org/abs/2602.05108)
*Ping Zhu,Jun Liang,Jiaxing Liu,Sui Wan,Eric Donovan*

Main category: physics.space-ph

TL;DR: This paper validates MHD simulations of ballooning instability and plasmoid formation as substorm onset triggers by comparing simulation results with THEMIS satellite and auroral observations.


<details>
  <summary>Details</summary>
Motivation: To validate the proposed mechanism where ballooning instability and subsequent plasmoid formation trigger substorm onset by comparing MHD simulations with actual observational data from THEMIS satellites and auroral observations.

Method: Selected THEMIS substorm onset events with good auroral conjunction, inferred pre-onset magnetotail conditions from in-situ data, ran MHD simulations, extracted ballooning instability and plasmoid signatures, compared with observed magnetic fields and flow patterns, and mapped field-aligned currents to auroral ionosphere for comparison with auroral patterns.

Result: The study successfully compares simulation signatures (ballooning instability, plasmoid formation, field-aligned currents) with observational data from THEMIS and auroral observations, validating the simulation approach and establishing connections between magnetotail processes and auroral manifestations.

Conclusion: This validation effort represents the first step toward developing a self-consistent coupling model that includes magnetotail-ionosphere interaction in substorm onset processes, bridging the gap between theoretical simulations and observational evidence.

Abstract: The nonlinear development of ballooning instability and the subsequently induced plasmoid formation in the near-Earth magnetotail demonstrated in MHD simulations has been proposed as a potential trigger mechanism for substorm onset over the past decade, and their connections to the in-situ satellite and ground all-sky auroral optical observations have been a subject of continued research. In this work, a set of THEMIS substorm onset events with good conjunction of auroral observations has been selected for comparative simulation study, whose pre-onset magnetotail configuration and conditions are inferred from in-situ data and compared with the onset conditions of ballooning instability obtained in our MHD simulations. The evolution of the near-Earth magnetotail is followed, where the signatures of ballooning instability and the plasmoid formation are extracted from simulations and compared with the magnetic fields and flow patterns within the magnetotail region from observation data. The field-aligned current (FAC) density is evaluated at the Earth side boundary of the magnetotail domain of simulation, which is further mapped along magnetic field lines to the auroral ionosphere and compared with the auroral pattern and evolution there in terms of growth rate, dominant wavenumber, and absolute auroral intensities. Such validation efforts are also the first step towards the development of a self-consistent coupling model that includes the magnetotail-ionosphere interaction in the substorm onset process.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [42] [$L^q$-norm bounds for arithmetic eigenfunctions via microlocal Kakeya-Nikodym estimate](https://arxiv.org/abs/2602.05697)
*Jiaqi Hou,Xiaoqi Huang*

Main category: math.NT

TL;DR: The paper proves power saving for the global L⁶-norm of Hecke-Maass forms on compact arithmetic hyperbolic surfaces, improving over Sogge's local bound.


<details>
  <summary>Details</summary>
Motivation: To obtain better bounds for L⁶-norms of Hecke-Maass forms on arithmetic hyperbolic surfaces, going beyond the standard local bounds from spectral theory.

Method: Uses Iwaniec-Sarnak's L∞-norm bound and harmonic analysis to reduce the problem to a microlocal L⁶ Kakeya-Nikodym estimate, then establishes improved microlocal estimates via arithmetic amplification techniques.

Result: Proves ‖ψ‖_{L⁶(X)} ≲_ε λ^{1/6 - 1/144 + ε}, achieving power saving over the local bound λ^{1/6}.

Conclusion: The paper demonstrates how arithmetic amplification can yield improved microlocal estimates and consequently better global norm bounds for automorphic forms on arithmetic hyperbolic surfaces.

Abstract: Let $X$ be a compact arithmetic hyperbolic surface, and let $ψ$ be an $L^2$-normalized Hecke-Maass form on $X$ with sufficiently large spectral parameter $λ$. We give a new proof to obtain some power saving for the global $L^6$-norm $\|ψ\|_{L^6(X)}\lesssim_ελ^{\frac{1}{6}-\frac{1}{144}+ε}$ over the local bound $\|ψ\|_{L^6(X)}\lesssimλ^{\frac16}$ of Sogge. Using the $L^\infty$-norm bound $\|ψ\|_{L^\infty(X)}\lesssim_ελ^{\frac{5}{12}+ε}$ of Iwaniec and Sarnak and harmonic analysis tools, we reduce the $L^6$-norm problem to a microlocal $L^6$ Kakeya-Nikodym estimate for $ψ$. Finally, we establish an improved microlocal $L^6$ Kakeya-Nikodym estimate via arithmetic amplification developed by Iwaniec and Sarnak.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [43] [lrux: Fast low-rank updates of determinants and Pfaffians in JAX](https://arxiv.org/abs/2602.05255)
*Ao Chen,Christopher Roth*

Main category: cond-mat.str-el

TL;DR: lrux is a JAX-based package for fast low-rank updates of determinants and Pfaffians, reducing computational cost from O(n³) to O(n²k) for quantum Monte Carlo algorithms.


<details>
  <summary>Details</summary>
Motivation: The dominant computational bottleneck in various quantum Monte Carlo algorithms is the repeated evaluation of determinants and Pfaffians, which traditionally scales as O(n³). There's a need for efficient low-rank update methods to accelerate these calculations.

Method: Implements efficient low-rank updates for determinants and Pfaffians using JAX framework. Uses delayed-update strategies to trade floating-point operations for reduced memory traffic. Supports both real and complex data types and integrates with JAX transformations like JIT compilation, vectorization, and automatic differentiation.

Result: Achieves up to 1000× speedup at large matrix sizes on GPUs. Reduces computational cost from O(n³) to O(n²k) when update rank k is smaller than matrix dimension n.

Conclusion: lrux enables scalable, high-performance evaluation of antisymmetric wavefunctions and serves as a drop-in component for a wide range of quantum Monte Carlo workflows, significantly accelerating QMC calculations.

Abstract: We present lrux, a JAX-based software package for fast low-rank updates of determinants and Pfaffians, targeting the dominant computational bottleneck in various quantum Monte Carlo (QMC) algorithms. The package implements efficient low-rank updates that reduce the cost of successive wavefunction evaluations from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2k)$ when the update rank $k$ is smaller than the dimension $n$ of matrices. Both determinant and Pfaffian updates are supported, together with delayed-update strategies that trade floating-point operations for reduced memory traffic on modern accelerators. lrux natively integrates with JAX transformations such as JIT compilation, vectorization, and automatic differentiation, and supports both real and complex data types. Benchmarks on GPUs demonstrate up to $1000\times$ speedup at large matrix sizes. lrux enables scalable, high-performance evaluation of antisymmetric wavefunctions and is designed as a drop-in component for a wide range of QMC workflows. lrux is available at https://github.com/ChenAo-Phys/lrux.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [44] [Towards uncertainty quantification of a model for cancer-on-chip experiments](https://arxiv.org/abs/2602.06018)
*Silvia Bertoluzza,Vittoria Bianchi,Gabriella Bretti,Lorenzo Tamellini,Pietro Zanotti*

Main category: cs.CE

TL;DR: This paper develops a data-informed uncertainty quantification framework for predicting cancer-on-chip dynamics using chemotaxis models, combining sensitivity analysis, Bayesian parameter estimation, and forward uncertainty propagation with surrogate modeling.


<details>
  <summary>Details</summary>
Motivation: To develop predictive models for cancer-on-chip experiments by quantifying and reducing uncertainty in model parameters using experimental data, enabling better prediction and control of cancer-immune cell interactions.

Method: Uses a Keller-Segel-type chemotaxis model for cancer-white blood cell interactions, solved with Hybridized Discontinuous Galerkin method. Applies uncertainty quantification: 1) global sensitivity analysis (Sobol/Morris indices) to identify influential parameters, 2) Bayesian inverse UQ for data-informed parameter distributions, 3) forward UQ to assess residual uncertainty impact. Employs sparse-grid surrogate models for computational efficiency.

Result: Develops a comprehensive uncertainty quantification pipeline for cancer-on-chip models that can: identify influential parameters, estimate parameter distributions from data, and quantify prediction uncertainty. The framework enables data-informed predictions while accounting for residual parameter uncertainty.

Conclusion: The proposed uncertainty quantification framework provides a systematic approach to make cancer-on-chip models more predictive by incorporating experimental data while quantifying remaining uncertainties, representing an important step toward reliable computational tools for cancer research and treatment development.

Abstract: This study is a first step towards using data-informed differential models to predict and control the dynamics of cancer-on-chip experiments. We consider a conceptualized one-dimensional device, containing a cancer and a population of white blood cells. The interaction between the cancer and the population of cells is modeled by a chemotaxis model inspired by Keller-Segel-type equations, which is solved by a Hybridized Discontinuous Galerkin method. Our goal is using (synthetic) data to tune the parameters of the governing equations and to assess the uncertainty on the predictions of the dynamics due to the residual uncertainty on the parameters remaining after the tuning procedure. To this end, we apply techniques from uncertainty quantification for parametric differential models. We first perform a global sensitivity analysis using both Sobol and Morris indices to assess how parameter uncertainty impacts model predictions, and fix the value of parameters with negligible impact. Subsequently, we conduct an inverse uncertainty quantification analysis by Bayesian techniques to compute a data-informed probability distribution of the remaining model parameters. Finally, we carry out a forward uncertainty quantification analysis to compute the impact of the updated (residual) parametric uncertainties on the quantities of interest of the model. The whole procedure is sped up by using surrogate models, based on sparse-grids, to approximate the mapping of the uncertain parameters to the quantities of interest.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics](https://arxiv.org/abs/2602.04975)
*José Afonso,Vasco Guerra,Pedro Viegas*

Main category: cs.LG

TL;DR: A stochastic hierarchical optimization framework using reduced Hessian approximation for efficient calibration of physical models, validated on plasma-surface interactions.


<details>
  <summary>Details</summary>
Motivation: Physical model calibration is computationally expensive, especially for complex systems like plasma-surface interactions where uncertainties in surface reactivity parameters and high computational costs of kinetic simulations limit accurate modeling.

Method: Stochastic hierarchical optimization framework inspired by Sloppy Model theory, using reduced Hessian approximation to identify stiff parameter subspace with minimal simulation queries. Integrates probabilistic formulation to derive principled objective loss function from observed data.

Result: Method consistently outperforms baseline optimization techniques in sample efficiency when applied to plasma-surface interaction problems. Enables efficient navigation of highly anisotropic parameter landscapes.

Conclusion: Provides a general and scalable tool for optimizing models of complex reaction systems, applicable to domains ranging from plasma chemistry to biochemical networks.

Abstract: This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simulation queries. This strategy enables efficient navigation of highly anisotropic landscapes, avoiding the computational burden of exhaustive sampling. To ensure rigorous inference, we integrate this approach with a probabilistic formulation that derives a principled objective loss function directly from observed data. We validate the framework by applying it to the problem of plasma-surface interactions, where accurate modelling is strictly limited by uncertainties in surface reactivity parameters and the computational cost of kinetic simulations. Comparative analysis demonstrates that our method consistently outperforms baseline optimization techniques in sample efficiency. This approach offers a general and scalable tool for optimizing models of complex reaction systems, ranging from plasma chemistry to biochemical networks.

</details>


### [46] [SpectraKAN: Conditioning Spectral Operators](https://arxiv.org/abs/2602.05187)
*Chun-Wun Cheng,Carola-Bibiane Schönlieb,Angelica I. Aviles-Rivero*

Main category: cs.LG

TL;DR: SpectraKAN is a novel neural operator that conditions spectral kernels on input data, enabling adaptive multi-scale PDE solving while maintaining spectral efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing spectral neural operators like FNO use static Fourier kernels applied uniformly across inputs, which limits their ability to capture multi-scale, regime-dependent, and anisotropic dynamics that depend on the global system state.

Method: SpectraKAN extracts a compact global representation from spatio-temporal history and uses it to modulate a multi-scale Fourier trunk via single-query cross-attention, turning static spectral convolution into an input-conditioned integral operator.

Result: SpectraKAN achieves state-of-the-art performance across diverse PDE benchmarks, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.

Conclusion: The proposed input-conditioned spectral operator enables adaptive behavior while retaining spectral mixing efficiency, with theoretical justification showing convergence to resolution-independent continuous operators under mesh refinement.

Abstract: Spectral neural operators, particularly Fourier Neural Operators (FNO), are a powerful framework for learning solution operators of partial differential equations (PDEs) due to their efficient global mixing in the frequency domain. However, existing spectral operators rely on static Fourier kernels applied uniformly across inputs, limiting their ability to capture multi-scale, regime-dependent, and anisotropic dynamics governed by the global state of the system. We introduce SpectraKAN, a neural operator that conditions the spectral operator on the input itself, turning static spectral convolution into an input-conditioned integral operator. This is achieved by extracting a compact global representation from spatio-temporal history and using it to modulate a multi-scale Fourier trunk via single-query cross-attention, enabling the operator to adapt its behaviour while retaining the efficiency of spectral mixing. We provide theoretical justification showing that this modulation converges to a resolution-independent continuous operator under mesh refinement and KAN gives smooth, Lipschitz-controlled global modulation. Across diverse PDE benchmarks, SpectraKAN achieves state-of-the-art performance, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [47] [Radon--Wasserstein Gradient Flows for Interacting-Particle Sampling in High Dimensions](https://arxiv.org/abs/2602.05227)
*Elias Hess-Childs,Dejan Slepčev,Lantian Xu*

Main category: stat.ML

TL;DR: New gradient flows for KL divergence with efficient particle approximations: Radon-Wasserstein and Regularized Radon-Wasserstein geometries enable scalable algorithms with linear cost in particles and dimensions.


<details>
  <summary>Details</summary>
Motivation: Existing gradient flows for KL divergence (like Fokker-Planck and Stein Variational Gradient Descent) need efficient particle approximations in high dimensions with scalable computational costs.

Method: Introduce new transportation-based Riemannian geometries: Radon-Wasserstein and Regularized Radon-Wasserstein geometries using Radon transform, making gradient-flow velocities depend only on 1D projections. This enables efficient FFT-based 1D convolutions for particle approximations.

Result: Algorithms with per-step cost scaling linearly in both number of particles and dimension. Numerical experiments show performance, convergence behavior, and quantization. Theoretical results include well-posedness of flows and long-time convergence guarantees for RRW flow.

Conclusion: New gradient flows provide scalable particle-based methods for sampling from unnormalized target densities with linear computational complexity, bridging theory and practical implementation.

Abstract: Gradient flows of the Kullback--Leibler (KL) divergence, such as the Fokker--Planck equation and Stein Variational Gradient Descent, evolve a distribution toward a target density known only up to a normalizing constant. We introduce new gradient flows of the KL divergence with a remarkable combination of properties: they admit accurate interacting-particle approximations in high dimensions, and the per-step cost scales linearly in both the number of particles and the dimension. These gradient flows are based on new transportation-based Riemannian geometries on the space of probability measures: the Radon--Wasserstein geometry and the related Regularized Radon--Wasserstein (RRW) geometry. We define these geometries using the Radon transform so that the gradient-flow velocities depend only on one-dimensional projections. This yields interacting-particle-based algorithms whose per-step cost follows from efficient Fast Fourier Transform-based evaluation of the required 1D convolutions. We additionally provide numerical experiments that study the performance of the proposed algorithms and compare convergence behavior and quantization. Finally, we prove some theoretical results including well-posedness of the flows and long-time convergence guarantees for the RRW flow.

</details>


### [48] [Wedge Sampling: Efficient Tensor Completion with Nearly-Linear Sample Complexity](https://arxiv.org/abs/2602.05869)
*Hengrui Luo,Anna Ma,Ludovic Stephan,Yizhe Zhu*

Main category: stat.ML

TL;DR: Wedge Sampling enables efficient low-rank tensor completion with nearly linear sample complexity by using structured length-two patterns instead of uniform sampling.


<details>
  <summary>Details</summary>
Motivation: Standard uniform sampling for tensor completion requires high sample complexity (O(n^{k/2})) for efficient algorithms, creating a statistical-to-computational gap. The authors aim to overcome this barrier with alternative non-adaptive sampling designs.

Method: Proposes Wedge Sampling, a non-adaptive scheme that allocates observations to structured length-two patterns (wedges) in a bipartite sampling graph. This strengthens spectral signals for initialization and can be combined with existing refinement procedures using only additional O(n) uniform samples.

Result: Enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in n. The approach substantially improves over the O(n^{k/2}) sample complexity typically required under uniform sampling.

Conclusion: The statistical-to-computational gap in tensor completion is largely a consequence of uniform entry sampling, and alternative non-adaptive designs like Wedge Sampling that guarantee strong initialization can overcome this barrier.

Abstract: We introduce Wedge Sampling, a new non-adaptive sampling scheme for low-rank tensor completion. We study recovery of an order-$k$ low-rank tensor of dimension $n \times \cdots \times n$ from a subset of its entries. Unlike the standard uniform entry model (i.e., i.i.d. samples from $[n]^k$), wedge sampling allocates observations to structured length-two patterns (wedges) in an associated bipartite sampling graph. By directly promoting these length-two connections, the sampling design strengthens the spectral signal that underlies efficient initialization, in regimes where uniform sampling is too sparse to generate enough informative correlations.
  Our main result shows that this change in sampling paradigm enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in $n$. The approach is also plug-and-play: wedge-sampling-based spectral initialization can be combined with existing refinement procedures (e.g., spectral or gradient-based methods) using only an additional $\tilde{O}(n)$ uniformly sampled entries, substantially improving over the $\tilde{O}(n^{k/2})$ sample complexity typically required under uniform entry sampling for efficient methods. Overall, our results suggest that the statistical-to-computational gap highlighted in Barak and Moitra (2022) is, to a large extent, a consequence of the uniform entry sampling model for tensor completion, and that alternative non-adaptive measurement designs that guarantee a strong initialization can overcome this barrier.

</details>


### [49] [Diffusion Model's Generalization Can Be Characterized by Inductive Biases toward a Data-Dependent Ridge Manifold](https://arxiv.org/abs/2602.06021)
*Ye He,Yitong Qiu,Molei Tao*

Main category: stat.ML

TL;DR: The paper analyzes how diffusion models generalize by characterizing the generated distribution through a log-density ridge manifold, revealing an inference process of reach-align-slide around this manifold.


<details>
  <summary>Details</summary>
Motivation: To quantitatively understand how diffusion models generalize when not memorizing training data, which is important for assessing model performance in downstream applications.

Method: Proposes a log-density ridge manifold framework to characterize generated data, analyzing inference dynamics as a reach-align-slide process around this manifold, and examines how different training errors affect normal and tangent motions.

Result: Experiments on synthetic multimodal distributions and MNIST latent diffusion support the predicted directional effects of the reach-align-slide process in both low- and high-dimensional settings.

Conclusion: The reach-align-slide framework provides detailed understanding of diffusion model generalization, showing how inductive biases emerge from architectural bias and training accuracy, with implications for quantifying generation behavior.

Abstract: When a diffusion model is not memorizing the training data set, how does it generalize exactly? A quantitative understanding of the distribution it generates would be beneficial to, for example, an assessment of the model's performance for downstream applications. We thus explicitly characterize what diffusion model generates, by proposing a log-density ridge manifold and quantifying how the generated data relate to this manifold as inference dynamics progresses. More precisely, inference undergoes a reach-align-slide process centered around the ridge manifold: trajectories first reach a neighborhood of the manifold, then align as being pushed toward or away from the manifold in normal directions, and finally slide along the manifold in tangent directions. Within the scope of this general behavior, different training errors will lead to different normal and tangent motions, which can be quantified, and these detailed motions characterize when inter-mode generations emerge. More detailed understanding of training dynamics will lead to more accurate quantification of the generation inductive bias, and an example of random feature model will be considered, for which we can explicitly illustrate how diffusion model's inductive biases originate as a composition of architectural bias and training accuracy, and how they evolve with the inference dynamics. Experiments on synthetic multimodal distributions and MNIST latent diffusion support the predicted directional effects, in both low- and high-dimensions.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [50] [Branch-and-Bound Tensor Networks for Exact Ground-State Characterization](https://arxiv.org/abs/2602.05470)
*Yijia Wang,Xuanzhao Gao,Pan Zhang,Feng Pan,Jinguo Liu*

Main category: cond-mat.stat-mech

TL;DR: BBTN method combines branch-and-bound with tropical tensor networks to solve NP-hard ground-state problems, achieving massive speedups and scaling to previously intractable problem sizes.


<details>
  <summary>Details</summary>
Motivation: Computing exact ground states and counting degeneracies for disordered systems (spin glasses, combinatorial optimization) is NP-hard/#P-hard, posing major challenges. While tensor network methods have shown promise, they suffer from exponential space complexity limitations that restrict scalability.

Method: Branch-and-Bound Tensor Network (BBTN) method integrates adaptive search framework of branch-and-bound with efficient contraction of tropical tensor networks, addressing the space complexity bottleneck of standard tensor network approaches.

Result: BBTN significantly outperforms state-of-the-art solvers, enabling exact ground-state counting for ±J spin glasses up to 64×64 and solving Maximum Independent Set problems on King's subgraphs up to 100×100. It compresses years of runtime into minutes for hard instances and outperforms leading integer-programming solvers by over 30×.

Conclusion: BBTN establishes a versatile and scalable framework that pushes the boundaries of tractability for hard problems in statistical physics and combinatorial optimization, overcoming fundamental limitations of previous tensor network methods.

Abstract: Characterizing the ground-state properties of disordered systems, such as spin glasses and combinatorial optimization problems, is fundamental to science and engineering. However, computing exact ground states and counting their degeneracies are generally NP-hard and #P-hard problems, respectively, posing a formidable challenge for exact algorithms. Recently, Tensor Networks methods, which utilize high-dimensional linear algebra and achieve massive hardware parallelization, have emerged as a rapidly developing paradigm for efficiently solving these tasks. Despite their success, these methods are fundamentally constrained by the exponential growth of space complexity, which severely limits their scalability. To address this bottleneck, we introduce the Branch-and-Bound Tensor Network (BBTN) method, which seamlessly integrates the adaptive search framework of branch-and-bound with the efficient contraction of tropical tensor networks, significantly extending the reach of exact algorithms. We show that BBTN significantly surpasses existing state-of-the-art solvers, setting new benchmarks for exact computation. It pushes the boundaries of tractability to previously unreachable scales, enabling exact ground-state counting for $\pm J$ spin glasses up to $64 \times 64$ and solving Maximum Independent Set problems on King's subgraphs up to $100 \times 100$. For hard instances, BBTN dramatically reduces the computational cost of standard Tropical Tensor Networks, compressing years of runtime into minutes. Furthermore, it outperforms leading integer-programming solvers by over 30$\times$, establishing a versatile and scalable framework for solving hard problems in statistical physics and combinatorial optimization.

</details>


### [51] [Exchange Monte Carlo for continuous-space Path Integral Monte Carlo simulation](https://arxiv.org/abs/2602.05500)
*Xun Zhao,Synge Todo*

Main category: cond-mat.stat-mech

TL;DR: Novel Exchange Monte Carlo method for continuous-space PIMC simulations that addresses autocorrelation issues in bosonic systems by enabling replica transitions between interaction regimes and incorporating Stochastic Potential Switching for efficient long-range potential decomposition.


<details>
  <summary>Details</summary>
Motivation: Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, especially when measuring observables affected by particle permutations like winding number. This computational bottleneck limits efficiency in finite temperature simulations.

Method: Exchange Monte Carlo (EMC) method with exchange update scheme for replica transitions between different interaction regimes, plus Stochastic Potential Switching (SPS) for efficient decomposition of long-range interatomic pair potentials like Lennard-Jones and Aziz potentials.

Result: Significantly accelerates Monte Carlo dynamics, particularly for global observables sensitive to permutation effects, and substantially enhances computational efficiency for long-range potentials.

Conclusion: The proposed EMC method with SPS provides an effective solution to autocorrelation problems in PIMC simulations, improving computational efficiency for bosonic systems at finite temperature.

Abstract: We present a novel Exchange Monte Carlo (EMC) method designed for application in continuous-space Path Integral Monte Carlo (PIMC) simulations at finite temperature. Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, particularly when measuring observables affected by particle permutations, such as the winding number. To address this issue, we introduce an exchange update scheme that facilitates replica transitions between different interaction regimes, significantly accelerating Monte Carlo dynamics-especially for global observables sensitive to permutation effects. Furthermore, we incorporate Stochastic Potential Switching (SPS) to efficiently decompose interactions, substantially enhancing computational efficiency for long-range interatomic pair potentials such as the Lennard-Jones and Aziz potentials.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [52] [Penalized Likelihood Parameter Estimation for Differential Equation Models: A Computational Tutorial](https://arxiv.org/abs/2602.04891)
*Matthew J Simpson,James S Bennett,Alexander Johnston,Ruth E Baker*

Main category: stat.ME

TL;DR: A tutorial article introducing computational exercises for learning generalized profiling (parameter cascading) for parameter estimation in ODE models, with reproducible Jupyter notebooks.


<details>
  <summary>Details</summary>
Motivation: Generalized profiling offers advantages over standard parameter estimation methods like MLE and MCMC by directly linking models and data through penalized likelihood, but is underutilized in practice. The paper aims to address this by providing educational materials.

Method: The paper presents self-directed computational exercises using generalized profiling/parameter cascading approach that penalizes both data fit and model fit to ODEs, implemented in reproducible Jupyter notebooks available on GitHub.

Result: Provides a complete educational framework with computational exercises that enable learners to develop skills in applying generalized profiling to various ODE models, with all code available as open-source notebooks.

Conclusion: The tutorial materials facilitate practical adoption of generalized profiling by providing hands-on learning resources that bridge the gap between theoretical advantages and practical implementation for parameter estimation in differential equation models.

Abstract: Parameter estimation connects mathematical models to real-world data and decision making across many scientific and industrial applications. Standard approaches such as maximum likelihood estimation and Markov chain Monte Carlo estimate parameters by repeatedly solving the model, which often requires numerical solutions of differential equation models. In contrast, generalized profiling (also called parameter cascading) focuses directly on the governing differential equation(s), linking the model and data through a penalized likelihood that explicitly measures both the data fit and model fit. Despite several advantages, generalized profiling is relatively rarely used in practice. This tutorial-style article outlines a set of self-directed computational exercises that facilitate skills development in applying generalized profiling to a range of ordinary differential equation models. All calculations can be repeated using reproducible open-source Jupyter notebooks that are available on GitHub.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [53] [Strong local nondeterminism for stochastic time-fractional slow and fast diffusion equations](https://arxiv.org/abs/2602.05317)
*Le Chen,Cheuk Yin Lee,Panqiu Xia*

Main category: math.PR

TL;DR: Study of stochastic time-fractional equations with Caputo derivative, fractional Laplacian, and Riemann-Liouville integral driven by Gaussian noise, establishing existence conditions and regularity properties.


<details>
  <summary>Details</summary>
Motivation: To analyze stochastic partial differential equations with fractional operators in both time and space, which model complex phenomena with memory effects and anomalous diffusion, and to establish comprehensive regularity theory.

Method: Study equations with Caputo time derivative (order β), fractional Laplacian (order α), and Riemann-Liouville time integral (order γ) driven by fractional-in-time and Riesz-type-in-space Gaussian noise. Derive Dalang-type conditions and analyze fundamental solution kernels.

Result: Obtain sharp necessary and sufficient conditions for random field solution existence across parameter range. Prove sharp variance bounds, strong local nondeterminism in time and space, exact moduli of continuity, Chung-type laws, and small ball probability bounds.

Conclusion: The paper provides comprehensive regularity theory for stochastic time-fractional equations, establishing sharp existence conditions and detailed regularity properties including local nondeterminism and moduli of continuity, with fundamental solution asymptotics of independent interest.

Abstract: We study a class of stochastic time-fractional equations on $\mathbb{R}^d$ driven by a centered Gaussian noise, involving a Caputo time derivative of order $β>0$, a fractional (power) Laplacian of order $α>0$, and a Riemann-Liouville time integral of order $γ\ge0$ acting on the noise. The noise is fractional in time (index $H$) and Riesz-type in space (index $\ell$). We derive sharp Dalang-type necessary and sufficient conditions for the existence of a random field solution across almost full parameter range $(α,β,γ;H,\ell)$. Under the Dalang-type conditions, we prove sharp variance bounds for temporal and spatial increments, as well as strong local nondeterminism in time in several regimes (two-sided version for $β=1$ and for parts of the case $β=2$; one-sided version for $0<β<2$) and strong local nondeterminism in space for the whole range of parameters. As applications, we derive exact uniform and local moduli of continuity, Chung-type laws of the iterated logarithm, and quantitative bounds on small ball probabilities. Along the way, we obtain sharp asymptotics for the fundamental solution kernels at $0$ and $\infty$, which may be of independent interest.

</details>


### [54] [On the Resistance Conjecture](https://arxiv.org/abs/2602.05477)
*Sylvester Eriksson-Bique*

Main category: math.PR

TL;DR: The paper proves the resistance conjecture linking parabolic Harnack inequalities to volume doubling, capacity bounds, and Poincaré inequalities in p-Dirichlet spaces, establishing cutoff Sobolev inequality as the key step.


<details>
  <summary>Details</summary>
Motivation: To resolve the resistance conjecture that characterizes parabolic Harnack inequalities through three fundamental geometric/analytic conditions (volume doubling, upper capacity bounds, and Poincaré inequalities), providing a unified framework for analysis across different settings.

Method: Uses the general framework of p-Dirichlet spaces to show that the three assumptions imply the cutoff Sobolev inequality, which is crucial for studying anomalous diffusions. Extends methods of Jones and Koskela to p-Dirichlet spaces and establishes extension techniques and characterizations of Sobolev functions via Poincaré inequalities.

Result: Affirmative proof of the resistance conjecture, showing that volume doubling, upper capacity bounds, and Poincaré inequalities indeed characterize parabolic Harnack inequalities. Additionally demonstrates that such Dirichlet spaces have finite martingale dimension and admit Cheeger-type differential structures.

Conclusion: The paper provides a unified treatment for proving Harnack inequalities and stability phenomena across diverse settings including metric spaces, fractals, graphs, and manifolds for all p∈(1,∞), resolving a fundamental conjecture in analysis.

Abstract: We give an affirmative answer to the resistance conjecture on characterization of parabolic Harnack inequalities in terms of volume doubling, upper capacity bounds and a Poincaré inequalities. The key step is to show that these three assumptions imply the so called cutoff Sobolev inequality, an important inequality in the study of anomalous diffusions, Dirichlet forms and re-scaled energies in fractals. This implication is shown in the general setting of $p$-Dirichlet Spaces introduced by the author and Murugan, and thus a unified treatment becomes possible to proving Harnack inequalities and stability phenomena in both analysis on metric spaces and fractals and for graphs and manifolds for all exponents $p\in (1,\infty)$. As an application, we also show that a Dirichlet space satisfying volume doubling, Poincaré and upper capacity bounds has finite martingale dimension and admits a type of differential structure similar to the work of Cheeger. In the course of the proof, we establish methods of extension and characterizations of Sobolev functions by Poincaré-inequalities, and extend the methods of Jones and Koskela to the general setting of $p$-Dirichlet spaces.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [55] [The Correlation Length of Turbulence in Magnetic Clouds](https://arxiv.org/abs/2602.05450)
*S. W. Good,J. Lalueza Puértolas,A. -S. M. Jylhä,E. K. J. Kilpua*

Main category: astro-ph.SR

TL;DR: Researchers used force-free flux rope fits to detrend magnetic field data from Parker Solar Probe in two magnetic clouds, revealing significantly smaller turbulence correlation lengths than previously measured, and showing that flux rope contributions steepen large-scale spectra but don't affect inertial range scaling.


<details>
  <summary>Details</summary>
Motivation: To accurately measure turbulence correlation lengths in solar wind magnetic clouds by removing flux rope contamination that causes overestimates, since traditional methods don't separate flux rope trends from turbulent fluctuations.

Method: Applied force-free flux rope fits to detrend magnetic field time series from Parker Solar Probe observations of two magnetic clouds, then calculated turbulence correlation lengths from the detrended data and analyzed spectral scaling.

Result: Detrended correlation lengths were 2.7×10⁴ proton inertial lengths at 0.77 au and 1.6×10⁴ at 0.39 au - significantly smaller than undetrended values. Flux rope contributions produced k⁻³ scaling at large scales but didn't affect the inertial range's k⁻⁵/³ scaling.

Conclusion: Flux rope detrending is essential for accurate turbulence correlation length measurements in magnetic clouds, as flux rope contamination causes significant overestimates. The method reveals true turbulent outer scales and their possible relation to mesoscale cloud structure.

Abstract: The large-scale limit or outer scale of turbulence in the solar wind is associated with the correlation length of the magnetic field. Determining correlation lengths from magnetic field time series in magnetic clouds is complicated by the presence of the global flux rope: without removal of the flux rope trend, correlation length measurements will be sensitive to the flux rope as well as the turbulence, and give overestimates of the outer scale when turbulence amplitudes at the outer scale are small relative to the flux rope amplitude. We have used force-free flux rope fits to detrend magnetic field time series measured by Parker Solar Probe in two magnetic clouds and calculated the turbulence correlation length in the clouds using the detrended data. The detrended correlation length in terms of the proton inertial length, $d_p$, was $2.7\times10^{4} d_p$ in one cloud (observed at 0.77 au) and $1.6\times10^{4}d_p$ in the other (observed at 0.39 au), significantly smaller than the values obtained without detrending. Increments in the flux rope fits scaled equivalently to a $k^{-3}$ wavenumber power spectrum; this contribution from the flux rope considerably steepened the total spectrum at the largest scales but had a negligible effect in the inertial range, where scaling in both clouds equivalent to $\sim$$k^{-5/3}$ was observed. Finally, we discuss the possible relation of turbulence correlation lengths to mesoscale structure in magnetic clouds.

</details>
