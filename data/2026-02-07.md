<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [math.AP](#math.AP) [Total: 22]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [math.PR](#math.PR) [Total: 2]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [math.NT](#math.NT) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [stat.ML](#stat.ML) [Total: 3]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A uniformly accurate multiscale time integrator for the nonlinear Klein-Gordon equation in the nonrelativistic regime via simplified transmission conditions](https://arxiv.org/abs/2602.04988)
*Weizhu Bao,Caoyi Liu*

Main category: math.NA

TL;DR: A new multiscale time integrator Fourier pseudospectral method for nonlinear Klein-Gordon equation achieves uniform first-order accuracy in time in the nonrelativistic regime, with super-resolution properties allowing time steps much larger than the oscillation wavelength.


<details>
  <summary>Details</summary>
Motivation: The nonlinear Klein-Gordon equation in the nonrelativistic regime (0 < ε << 1) has highly oscillatory solutions with O(ε²)-wavelength, making it difficult to design uniformly accurate numerical methods that work efficiently across different ε values.

Method: MTI-FP method combines: (1) multiscale decomposition by frequency with simplified transmission conditions in each time interval, (2) exponential wave integrator for temporal discretization, and (3) Fourier pseudospectral method for spatial discretization. Uses linear interpolation of micro variables for uniform accuracy.

Result: Achieves uniform first-order accuracy in time with error bounds O(h^{m0}+τ²/ε²) and O(h^{m0}+τ+ε²), leading to uniformly accurate bound O(h^{m0}+τ) with respect to ε. Demonstrates super-resolution in time - accurate solutions even when time step >> O(ε²)-wavelength.

Conclusion: The MTI-FP method provides an efficient, uniformly accurate numerical approach for the nonlinear Klein-Gordon equation in nonrelativistic regimes, with super-resolution properties that overcome the limitations of highly oscillatory solutions, enabling study of convergence to limiting models.

Abstract: We propose a new and simplified multiscale time integrator Fourier pseudospectral (MTI-FP) method for the nonlinear Klein-Gordon equation (NKGE) with a dimensionless parameter epsilon in (0,1] inversely proportional to the speed of light, and establish its uniform first-order accuracy in time in the nonrelativistic regime, i.e. 0 < epsilon << 1. In this regime, the solution of the NKGE is highly oscillatory in time with O(epsilon^2)-wavelength, which brings significant difficulties in designing uniformly accurate numerical methods. The MTI-FP is based on (i) a multiscale decomposition by frequency of the NKGE in each time interval with simplified transmission conditions, and (ii) an exponential wave integrator for temporal discretization and a Fourier pseudospectral method for spatial discretization. By adapting the energy method and the mathematical induction, we obtain two error bounds in H1-norm at O(h^{m0}+tau^2/epsilon^2) and O(h^{m0}+tau+epsilon^2) with mesh size h, time step tau and m0 an integer dependent on the regularity of the solution, which immediately implies a uniformly accurate error bound O(h^{m0}+tau) with respect to epsilon in (0,1]. In addition, by adopting a linear interpolation of the micro variables with the multiscale decomposition in each time interval, we obtain a uniformly accurate numerical solution for any time t larger than zero. Thus the proposed MTI-FP method has a super resolution property in time in terms of the Shannon sampling theory, i.e. accurate numerical solutions can be obtained even when the time step is much bigger than the O(epsilon^2)-wavelength. Extensive numerical results are reported to confirm our error bounds and demonstrate their super resolution in time. Finally the proposed MTI-FP method is applied to study numerically convergence rates of the NKGE to its different limiting models in the nonrelativistic regime.

</details>


### [2] [Acoustic scattering by fractal inhomogeneities via geometry-conforming Galerkin methods for the Lippmann-Schwinger equation](https://arxiv.org/abs/2602.05005)
*Joshua Bannister,David P. Hewett,Andrew Gibbs*

Main category: math.NA

TL;DR: Numerical method for acoustic scattering by fractal-boundary inhomogeneities using Galerkin discretization of Lippmann-Schwinger equation with geometry-conforming fractal meshes.


<details>
  <summary>Details</summary>
Motivation: To develop accurate numerical methods for time-harmonic acoustic scattering problems involving inhomogeneities with fractal boundaries, which are challenging for traditional approaches that approximate fractals with smoother prefractals.

Method: Galerkin discretization of Lippmann-Schwinger volume integral equation using discontinuous piecewise-polynomial approximation on geometry-conforming meshes with fractal-boundary elements. Includes h- and p-versions, with special treatment for n-attractor fractals using self-similarity to generate meshes, and singular quadrature rules for practical implementation.

Result: Proves well-posedness and error analysis for arbitrary inhomogeneities, provides convergence estimates for integral equation solutions and superconvergence for linear functionals. Shows method is significantly more accurate than approaches using prefractal approximations, with numerical validation in 2D examples.

Conclusion: The proposed method successfully handles acoustic scattering by fractal-boundary inhomogeneities using geometry-conforming fractal meshes, providing superior accuracy compared to prefractal approximations, with rigorous theoretical analysis and practical implementation capabilities.

Abstract: We propose and analyse a numerical method for time-harmonic acoustic scattering in $\mathbb{R}^n$, $n=2,3$, by a class of inhomogeneities (penetrable scatterers) with fractal boundary. Our method is based on a Galerkin discretisation of the Lippmann-Schwinger volume integral equation, using a discontinuous piecewise-polynomial approximation space on a geometry-conforming mesh comprising elements which themselves have fractal boundary. We first provide a semi-discrete well-posedness and error analysis for both the $h$- and $p$-versions of our method for completely arbitrary inhomogeneities (without any regularity assumption on the boundary of the inhomogeneity or of the mesh elements). We prove convergence estimates for the integral equation solution and superconvergence estimates for linear functionals such as scattered field and far-field pattern evaluations, and elucidate how the regularity of the inhomogeneity boundary and the regularity of the refractive index affect the rates of convergence predicted. We then specialise to the case where the inhomogeneity is an ``$n$-attractor'', i.e.\ the fractal attractor of an iterated function system satisfying the open set condition with non-empty interior, showing how in this case the self-similarity of the inhomogeneity can be used to generate geometry-conforming meshes. For the $h$-version with piecewise constant approximation we also present singular quadrature rules, supported by a fully discrete error analysis, permitting practical implementation of our method. We present numerical results for two-dimensional examples, which validate our theoretical results and show that our method is significantly more accurate than a comparable method involving replacement of the fractal inhomogeneity by a smoother prefractal approximation.

</details>


### [3] [Scalable Fixed-Point Framework for High-Dimensional Hamilton-Jacobi Equations](https://arxiv.org/abs/2602.05124)
*Yesom Park,Stanley Osher*

Main category: math.NA

TL;DR: A mesh-free, gradient-free fixed-point method for solving high-dimensional Hamilton-Jacobi equations using Hopf-Lax formula and Picard iteration, achieving dimension-independent computational times.


<details>
  <summary>Details</summary>
Motivation: Existing methods for solving high-dimensional Hamilton-Jacobi equations face challenges with grids, characteristics, or differentiation, limiting scalability to high dimensions. There's a need for efficient, dimension-independent approaches.

Method: Proposes a novel fixed-point approach that leverages the Hopf-Lax formula to transform the HJ equation into a variational problem, then solves it via Picard iteration without requiring grids, characteristics, or differentiation.

Result: The method demonstrates high accuracy and efficiency in numerical experiments up to 100 dimensions, including control problems and non-smooth solutions. Computational times are largely independent of dimensionality.

Conclusion: The proposed mesh-free, gradient-free fixed-point scheme is highly suitable for high-dimensional Hamilton-Jacobi problems, offering scalability and dimension-independent computational performance.

Abstract: We propose a novel, mesh-free, and gradient-free fixed-point approach for computing viscosity solutions of high-dimensional Hamilton-Jacobi (HJ) equations. By leveraging the Hopf-Lax formula, our approach iteratively solves the associated variational problem via a Picard iteration, enabling efficient evaluation of both the solution and its corresponding control without relying on grids, characteristics, or differentiation. We demonstrate the practical efficacy and scalability of the approach through numerical experiments in up to 100 dimensions, including control problems and non-smooth solutions. Our results show that the proposed scheme achieves high accuracy, is highly efficient, and exhibits computational times that are largely independent of dimensionality, highlighting its suitability for high-dimensional problems.

</details>


### [4] [Numerically Informed Convolutional Operator Network with Subproblem Decomposition for Poisson Equations](https://arxiv.org/abs/2602.05341)
*Kyoungjin Jung,Jae Yong Lee,Dongwook Shin*

Main category: math.NA

TL;DR: NICON: A numerically informed convolutional operator network that couples classical numerical methods (finite difference and finite element) with neural operator learning through residual-based training loss functions to achieve provable convergence under grid refinement.


<details>
  <summary>Details</summary>
Motivation: Neural operators show strong performance for PDE approximation but lack theoretical understanding of convergence behavior under grid refinement from a numerical analysis perspective. The authors aim to bridge this gap by developing operator networks with provable convergence properties.

Method: Propose NICON with two variants: FD-CON (finite difference-based) and FE-CON (finite element-based). These networks use residual-based loss functions derived from classical numerical methods. The approach explicitly couples traditional numerical analysis techniques with operator learning.

Result: Derived error estimates for both FD-CON and FE-CON using finite difference and finite element analysis. Established a direct relationship between training loss decay rate and convergence behavior. Developed training strategies that guarantee optimal convergence rates under grid refinement.

Conclusion: The proposed NICON framework successfully bridges neural operator learning with classical numerical analysis, providing theoretically grounded convergence guarantees under grid refinement while maintaining strong empirical performance on fine grids.

Abstract: Neural operators have shown remarkable performance in approximating solutions of partial differential equations. However, their convergence behavior under grid refinement is still not well understood from the viewpoint of numerical analysis. In this work, we propose a numerically informed convolutional operator network, called NICON, that explicitly couples classical finite difference and finite element methods with operator learning through residual-based training loss functions. We introduce two types of networks, FD-CON and FE-CON, which use residual-based loss functions derived from the corresponding numerical methods. We derive error estimates for FD-CON and FE-CON using finite difference and finite element analysis. These estimates show a direct relation between the convergence behavior and the decay rate of the training loss. From these analyses, we establish training strategies that guarantee optimal convergence rates under grid refinement. Several numerical experiments are presented to validate the theoretical results and show performance on fine grids.

</details>


### [5] [Linear Systems and Eigenvalue Problems: Open Questions from a Simons Workshop](https://arxiv.org/abs/2602.05394)
*Noah Amsel,Yves Baumann,Paul Beckman,Peter Bürgisser,Chris Camaño,Tyler Chen,Edmond Chow,Anil Damle,Michal Derezinski,Mark Embree,Ethan N. Epperly,Robert Falgout,Mark Fornace,Anne Greenbaum,Chen Greif,Diana Halikias,Zhen Huang,Elias Jarlebring,Yiannis Koutis,Daniel Kressner,Rasmus Kyng,Jörg Liesen,Jackie Lok,Raphael A. Meyer,Yuji Nakatsukasa,Kate Pearce,Richard Peng,David Persson,Eliza Rebrova,Ryan Schneider,Rikhav Shah,Edgar Solomonik,Nikhil Srivastava,Alex Townsend,Robert J. Webber,Jess Williams*

Main category: math.NA

TL;DR: This paper presents open questions in matrix computations from a workshop bridging theoretical computer science and numerical analysis, organized into five categories: iterative solvers, eigenvalue computation, low-rank approximation, randomized sketching, and other areas.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between theoretical computer science and numerical analysis by identifying important open questions in matrix computations through collaborative discussions between researchers from both fields.

Method: The paper is based on working group discussions at the "Linear Systems and Eigenvalue Problems" workshop during the Simons Institute's "Complexity and Linear Algebra" program in Fall 2025, where researchers from both theoretical computer science and numerical analysis collaborated to formulate open problems.

Result: A collection of open questions organized into five main categories: 1) iterative solvers for linear systems, 2) eigenvalue computation, 3) low-rank approximation, 4) randomized sketching, and 5) other areas including tensors, quantum systems, and matrix functions.

Conclusion: The paper provides a structured set of open problems in matrix computations that emerged from interdisciplinary collaboration, highlighting important research directions at the intersection of theoretical computer science and numerical analysis.

Abstract: This document presents a series of open questions arising in matrix computations, i.e., the numerical solution of linear algebra problems. It is a result of working groups at the workshop \emph{Linear Systems and Eigenvalue Problems}, which was organized at the Simons Institute for the Theory of Computing program on \emph{Complexity and Linear Algebra} in Fall 2025. The complexity and numerical solution of linear algebra problems %in matrix computations and related fields is a crosscutting area between theoretical computer science and numerical analysis. The value of the particular problem formulations here is that they were produced via discussions between researchers from both groups.
  The open questions are organized in five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas including tensors, quantum systems, and matrix functions.

</details>


### [6] [Taylor-Accelerated Neural Network Interpolation Operators on Irregular Grids with Higher Order Approximation](https://arxiv.org/abs/2602.05589)
*Sachin Saini*

Main category: math.NA

TL;DR: New Taylor-accelerated neural network interpolation operators on irregular grids that incorporate Taylor polynomials at sampling nodes to exploit function smoothness, achieving higher-order convergence and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To improve neural network interpolation on quasi-uniform irregular grids by leveraging the higher smoothness of target functions, overcoming limitations of existing neural network interpolation operators that don't fully exploit smoothness properties.

Method: Introduces Taylor-accelerated neural network interpolation operators that incorporate Taylor polynomials at sampling nodes. The operators are constructed on quasi-uniform irregular grids, maintain exact interpolation at grid points, and ensure polynomial reproduction up to a prescribed degree.

Result: The proposed operators are well-defined, uniformly bounded, and satisfy exact interpolation. They achieve polynomial reproduction and provide direct approximation estimates using higher-order moduli of smoothness. Numerical experiments show significant accuracy improvement, higher-order convergence on irregular grids, and outperformance of existing neural network interpolation operators including Lagrange-based schemes.

Conclusion: Taylor-accelerated neural network interpolation operators effectively exploit function smoothness to achieve enhanced convergence rates on irregular grids, offering superior performance compared to existing interpolation methods while maintaining theoretical guarantees.

Abstract: In this paper, a new class of \emph{Taylor-accelerated neural network interpolation operators} is introduced on quasi-uniform irregular grids. These operators improve existing neural network interpolation operators by incorporating Taylor polynomials at the sampling nodes, thereby exploiting the higher smoothness of the target function. The proposed operators are shown to be well defined, uniformly bounded, and to satisfy an exact interpolation property at the grid points. In addition, polynomial reproduction up to a prescribed degree is established. Direct approximation estimates are derived in terms of higher-order moduli of smoothness, yielding enhanced convergence rates for sufficiently smooth functions. Numerical experiments are presented to support the theoretical analysis and to demonstrate the significant accuracy improvement achieved through the Taylor-accelerated construction. In particular, higher-order convergence on irregular grids is obtained, and the proposed approach outperforms existing neural network interpolation operators on irregular partitions, including Lagrange-based schemes.

</details>


### [7] [Numerical stationary states for nonlocal Fokker-Planck equations via fixed points of consistency maps](https://arxiv.org/abs/2602.05632)
*José A. Carrillo,Yurij Salmaniw,Antonio León Villares*

Main category: math.NA

TL;DR: A fixed-point numerical framework for computing stationary states of nonlocal Fokker-Planck equations using matrix-free Newton-Krylov methods, capable of detecting both stable and unstable states without time evolution.


<details>
  <summary>Details</summary>
Motivation: Need efficient methods to compute stationary states of nonlocal Fokker-Planck equations that can detect both stable and unstable states, independent of dynamical stability considerations.

Method: Reformulate stationary problem as nonlinear fixed-point map from PDE and nonlocal interactions, solve with matrix-free Newton-Krylov method using either analytic Frechet derivative or central-difference approximation.

Result: Method accurately reproduces known bifurcation diagrams and discovers new bifurcation behavior not previously observed in such problems, with accuracy determined by convolution/quadrature treatment rather than differentiation.

Conclusion: The fixed-point approach provides an effective framework for computing stationary states of nonlocal Fokker-Planck equations, enabling discovery of both stable and unstable states and new bifurcation phenomena.

Abstract: We propose a fixed-point-based numerical framework for computing stationary states of nonlocal Fokker-Planck-type equations. Instead of discretising the differential operators directly, we reformulate the stationary problem as a nonlinear fixed-point map built from the original PDE and its nonlocal interaction terms, and solve the resulting finite-dimensional problem with a matrix-free Newton-Krylov method. We compare implementations using the analytic Frechet derivative of this map with a simple central-difference approximation. Because the method does not rely on time evolution, it is agnostic to dynamical stability and can detect both stable and unstable stationary states. Its accuracy is determined mainly by the numerical treatment of convolutions and quadrature, rather than by differentiation stencils. We apply the approach to three model problems with linear diffusion, use existing analytical results to verify the outputs, and reproduce known bifurcation diagrams, as well as new bifurcation behaviour not previously observed in this kind of problem.

</details>


### [8] [A penalized φ-FEM scheme for the Poisson Dirichlet problem](https://arxiv.org/abs/2602.05698)
*Raphaël Bulle,Michel Duprez,Vanessa Lleras,Killian Vuillemot*

Main category: math.NA

TL;DR: A penalized φ-FEM scheme for Poisson equation with Dirichlet BCs using level-set geometry, requiring level-set only near boundary, stabilized with ghost penalty, achieving optimal H1 and quasi-optimal L2 convergence.


<details>
  <summary>Details</summary>
Motivation: To develop an unfitted finite element method for Poisson equation with Dirichlet boundary conditions that avoids boundary-fitted meshes while reducing the computational burden of requiring the level-set function everywhere in the domain.

Method: Penalized φ-FEM scheme using level-set description of geometry, enforcing boundary conditions through penalization term, requiring level-set function only on cells adjacent to boundary, stabilized with ghost penalty technique.

Result: Derived a priori error estimates showing optimal convergence in H1 semi-norm and quasi-optimal convergence in L2 norm under suitable regularity assumptions. Numerical experiments validate theoretical results and compare with original φ-FEM and standard fitted FEM.

Conclusion: The penalized φ-FEM scheme successfully reduces computational requirements by needing level-set only near boundaries while maintaining optimal convergence properties, making it a practical alternative to both original φ-FEM and boundary-fitted methods.

Abstract: In this work, we analyze a penalized variant of the φ-FEM scheme for the Poisson equation with Dirichlet boundary conditions. The φ-FEM is a recently introduced unfitted finite element method based on a level-set description of the geometry, which avoids the need for boundary-fitted meshes. Unlike the original φ-FEM formulation, the method proposed here enforces boundary conditions through a penalization term. This approach has the advantage that the level-set function is required only on the cells adjacent to the boundary in the variational formulation. The scheme is stabilized using a ghost penalty technique. We derive a priori error estimates, showing optimal convergence in the H1 semi-norm and quasi-optimal convergence in the L2 norm under suitable regularity assumptions. Numerical experiments are presented to validate the theoretical results and to compare the proposed method with both the original φ-FEM and the standard fitted finite element method.

</details>


### [9] [Finite element approximation for a reformulation of a 3D fluid-2D plate interaction system](https://arxiv.org/abs/2602.05701)
*Lander Besabe,Hyesuk Lee*

Main category: math.NA

TL;DR: A finite element method for 3D fluid-2D plate interaction using second-order reformulation and Lagrange multipliers for coupling.


<details>
  <summary>Details</summary>
Motivation: To develop a practical numerical method for fluid-structure interaction problems that avoids complex H²-conforming or nonconforming plate elements, making implementation easier while maintaining accuracy.

Method: Reformulates fourth-order plate equation into coupled second-order equations using auxiliary variable, enforces coupling via Lagrange multiplier (trace of mean-zero fluid pressure), uses partitioned domain decomposition with fixed-point iteration.

Result: Establishes well-posedness and stability for time-discrete and fully-discrete problems, derives a priori error estimates, verifies theoretical convergence rates numerically, demonstrates applicability to physical problems.

Conclusion: The proposed method provides a practical alternative to complex plate elements for fluid-structure interaction problems, with proven mathematical properties and demonstrated numerical performance.

Abstract: We study a finite element approximation of a coupled fluid-structure interaction consisting of a three-dimensional incompressible viscous fluid governed by the unsteady Stokes equations and a two-dimensional elastic plate. To avoid the use of $H^2-$conforming or nonconforming $\mathbb{P}_2$-Morley plate elements, the fourth-order plate equation is reformulated into a system of coupled second-order equations using an auxiliary variable. The coupling condition is enforced using a Lagrange multiplier representing the trace of the mean-zero fluid pressure on the interface.
  We establish well-posedness and stability results for the time-discrete and fully-discrete problems, and derive a priori error estimates. A partitioned domain decomposition algorithm based on a fixed-point iteration is employed for the numerical solution. Numerical experiments verify the theoretical rates of convergence in space and time using manufactured solutions, and demonstrate the applicability of the method to a physical problem.

</details>


### [10] [Optimal boundary closures for diagonal-norm upwind SBP operators](https://arxiv.org/abs/2602.05727)
*Ken Mattsson,David Niemelä,Andrew R. Winters*

Main category: math.NA

TL;DR: Developed high-order boundary-optimized upwind finite-difference operators (up to 9th order) using non-equispaced grid points near boundaries within SBP framework for improved accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: To improve accuracy and computational efficiency of numerical discretizations for hyperbolic problems by optimizing boundary treatments, addressing limitations of equidistant grid SBP operators.

Method: Developed boundary-optimized upwind finite-difference operators using non-equispaced grid points near boundaries within diagonal-norm SBP framework, with boundary conditions enforced via SAT (weak) or projection method (strong).

Result: Significantly improved accuracy and computational efficiency compared to equidistant-grid SBP operators, producing fully explicit ODE systems with demonstrated stability for linear hyperbolic problems and compressible Euler equations.

Conclusion: Boundary-optimized SBP operators with non-equispaced boundary grids provide superior accuracy and efficiency for hyperbolic PDE discretizations while maintaining stability properties.

Abstract: By employing non-equispaced grid points near boundaries, boundary-optimized upwind finite-difference operators of orders up to nine are developed. The boundary closures are constructed within a diagonal-norm summation-by-parts (SBP) framework, ensuring linear stability on piecewise curvilinear multiblock grids. Boundary and interface conditions are imposed using either weak enforcement through simultaneous approximation terms (SAT) or strong enforcement via the projection method.
  The proposed operators yield significantly improved accuracy and computational efficiency compared with SBP operators constructed on equidistant grids. The resulting SBP--SAT and SBP--projection discretizations produce fully explicit systems of ordinary differential equations. The accuracy and stability properties of the proposed operators are demonstrated through numerical experiments for linear hyperbolic problems in one spatial dimension and for the compressible Euler equations in two spatial dimensions.

</details>


### [11] [A Perturbation-Correction Method Based on Local Randomized Neural Networks for Quasi-Linear Interface Problems](https://arxiv.org/abs/2602.05800)
*Siyuan Lang,Zhiyue Zhang*

Main category: math.NA

TL;DR: Proposes perturbation-correction framework using Local Randomized Neural Networks to overcome optimization stagnation in quasi-linear interface problems with discontinuous diffusion coefficients.


<details>
  <summary>Details</summary>
Motivation: Randomized neural networks often stagnate at moderate accuracy when solving quasi-linear interface problems with discontinuous diffusion coefficients due to nonconvex objective functionals.

Method: Two-step framework: 1) Initialization step minimizes original nonconvex residual to get base approximation, 2) Correction step solves convex subproblem via perturbation expansion around base approximation to determine correction term.

Result: Method overcomes optimization plateau, achieves 4-6 order magnitude improvement in L² accuracy, works for nonlinear diffusion problems with irregular moving interfaces, gradient-dependent diffusivities, and high-contrast media.

Conclusion: Perturbation-correction framework with LRaNNs effectively addresses optimization stagnation in challenging interface problems, providing rapid convergence through convex reformulation and rigorous error control.

Abstract: For quasi-linear interface problems with discontinuous diffusion coefficients, the nonconvex objective functional often leads to optimization stagnation in randomized neural network approximations. This paper Proposes a perturbation-correction framework based on Loacal Randomized Neural Networks(LRaNNs) to overcome this limitation. In the initialization step, a satisisfactory based approximation is obtained by minimizing the original nonconvex residual, typically stagnating at a moderate accuracy level. Subsequently, in the correction step, a correction term is determined by solving a subproblem governed by a perturbation expansion around the base approximation. This reformulation yields a convex optimization problem for the output coefficients, which guarantees rapic convergence. We rigorously derive an a posteriori error estitmate, demonstrating that the total generalization error is governed by the discrete residual norm, quadrature error, and a controllable truncation error. Numerical experiments on nonlinear diffusion problems with irregular moving interfaces, gradient-dependent diffusivities, and high-contrast media demonstrate that the proposed method effectively overcomes the optimization plateau. The correction step yields a significant improvement of 4-6 order of magnitude in L^2 accuracy.

</details>


### [12] [Spectral Analysis of Block Diagonally Preconditioned Multiple Saddle-Point Matrices with Inexact Schur Complements](https://arxiv.org/abs/2602.05952)
*Marco Pilotto,Luca Bergamaschi,Angeles Martinez*

Main category: math.NA

TL;DR: Eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices, with analysis for arbitrary blocks and approximated Schur complements.


<details>
  <summary>Details</summary>
Motivation: To analyze and bound eigenvalues of symmetric block-tridiagonal multiple saddle-point systems when preconditioned with block-diagonal Schur complement matrices, extending previous work to more general cases.

Method: Derivation of eigenvalue bounds through mathematical analysis of symmetric block-tridiagonal multiple saddle-point systems, considering arbitrary number of blocks and allowing for approximated Schur complements.

Result: Proposed eigenvalue bounds are validated through numerical experiments, generalizing previous findings from Bergamaschi et al. (2026).

Conclusion: The analysis provides eigenvalue bounds for a broader class of preconditioned saddle-point systems, including cases with approximated Schur complements and arbitrary block structure.

Abstract: We derive eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices. This analysis applies to an arbitrary number of blocks and accounts for the case where the Schur complements are approximated, generalizing the findings in [Bergamaschi et al., Linear Algebra and its Applications, 2026]. Numerical experiments are carried out to validate the proposed estimates.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [13] [$\bf{S^1}$-index theory for the Lorentz force equation](https://arxiv.org/abs/2602.05015)
*Cristian Bereanu,Alexandru Pîrvuceanu*

Main category: math.AP

TL;DR: Proves existence of multiple periodic solutions to Lorentz force equation using S^1-invariance and Lusternik-Schnirelman method with S^1-index.


<details>
  <summary>Details</summary>
Motivation: To establish existence of multiple critical points (periodic solutions) for the Poincaré action functional associated with the Lorentz force equation by leveraging its S^1-invariance property.

Method: Develops abstract multiplicity result using Lusternik-Schnirelman method with S^1-index, extending previous work by Ekeland and Lasry that used Fadell-Rabinowitz index. The approach handles nonsmooth functionals with weak compactness conditions suitable for the Poincaré functional.

Result: Proves existence of multiple critical points which are periodic solutions with fixed period for the Lorentz force equation, achieved through the abstract multiplicity theorem applied to the S^1-invariant Poincaré action functional.

Conclusion: The S^1-invariance of the Poincaré functional enables application of Lusternik-Schnirelman theory with S^1-index to obtain multiple periodic solutions, providing a framework that accommodates nonsmooth functionals with weak compactness conditions.

Abstract: In this paper we prove that the $S^1$-invariance of the Poincaré action functional associated to the Lorentz force equation gives the existence of multiple critical points which are periodic solutions with a fixed period. To do this, we prove an abstract multiplicity result which is based upon the Lusternik-Schnirelman method with the $S^1$-index. The corresponding result in the context of the Fadell-Rabinowitz index is proved in Ekeland and Lasry (Ann. Math., 112 (1980)). The main feature of our abstract result is that it allows us to consider nonsmooth functionals satisfying only a weak compactness condition well adapted to the Poincaré functional.

</details>


### [14] [Painlevé Universality classes for the maximal amplitude solution of the Focusing Nonlinear Schrödinger Equation with randomness](https://arxiv.org/abs/2602.05101)
*Aikaterini Gkogkou,Guido Mazzuca,Kenneth D. T-R McLaughlin*

Main category: math.AP

TL;DR: Universality of extremal NLS solutions: random eigenvalue distributions yield two Painlevé-type rogue wave classes (III and V) as deterministic limits.


<details>
  <summary>Details</summary>
Motivation: To understand universal patterns in extreme rogue wave formation from focusing nonlinear Schrödinger equation with random soliton parameters, showing robustness to randomness.

Method: Study extremal N-soliton solutions with eigenvalues drawn from sub-exponential distributions, analyze two spectral structures: Painlevé-III regime (λ_j = v_j + iμ_j) and Painlevé-V regime (λ_j = -ζj + v_j + iμ_j).

Result: Identified two universality classes: rescaled solutions converge locally to deterministic Painlevé-III profiles in first regime, Painlevé-V profiles in second regime, independent of eigenvalue distribution specifics.

Conclusion: Painlevé-type rogue wave formation is universal phenomenon robust to randomness in eigenvalue distributions, with macroscopic spectral structure determining the specific Painlevé equation governing the limit.

Abstract: We establish universality for extremal solutions of the focusing nonlinear Schrödinger equation. Extremal solutions are $N$-soliton solutions that achieve the theoretical maximal amplitude and diverge as $N \to \infty$. We consider extremal solutions with the discrete eigenvalues randomly drawn from sub-exponential distributions, and identify two distinct universality classes, determined by the macroscopic structure of the spectrum: the Painlevé--III rogue-wave solution, where the eigenvalues take the form $λ_j = v_j + i μ_j$, and the Painlevé--V rogue wave solution, where $λ_j = -ζ\, j + v_j + i μ_j$, with $0 < ζ< 1$. (In both cases, $μ_{j}$ and $v_{j}$ are subexponential random variables.) Universality can then be summarized as follows: independently of the specific distribution of the eigenvalues, the rescaled solutions converge locally to a deterministic profile governed by the Painlevé-III equation in the first regime, and the Painlevé-V equation in the second. These results demonstrate that the formation of Painlevé-type rogue waves is a universal phenomenon robust to randomness.

</details>


### [15] [Existence and symmetry of extremals for the high order Hardy-Sobolev-Maz'ya inequalities](https://arxiv.org/abs/2602.05203)
*Guozhen Lu,Chunxia Tao*

Main category: math.AP

TL;DR: Existence of extremal functions for k-th order critical Hardy-Sobolev-Maz'ya inequalities on upper half space via hyperbolic space approach and applications to Brezis-Nirenberg equations.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenging problem of establishing existence of extremal functions for higher-order critical Hardy-Sobolev-Maz'ya inequalities on the upper half space. The difficulties include: presence of higher-order derivatives, lack of translation invariance, inapplicability of rearrangement techniques on upper half-space, and Hardy singularity along the boundary.

Method: Instead of directly working on the upper half space, the authors establish existence of extremals for an equivalent Poincaré-Sobolev inequality on hyperbolic space. They develop novel tools including: duality theory of minimizing sequences, concentration-compactness principle for radial functions in hyperbolic setting, combined with Helgason-Fourier analysis and Riesz rearrangement inequality on hyperbolic space to resolve compactness issues.

Result: The paper proves existence of extremal functions for k-th order critical Hardy-Sobolev-Maz'ya inequalities when k≥2 and n≥2k+2. As an application, it obtains existence of positive symmetric solutions for high-order Brezis-Nirenberg equations on entire hyperbolic space associated with GJMS operators P_k at critical situations.

Conclusion: The hyperbolic space approach successfully overcomes the technical difficulties of the original problem on upper half space. The developed methods provide a framework for analyzing higher-order critical inequalities with Hardy singularities and have applications to nonlinear elliptic equations on hyperbolic spaces.

Abstract: In this article, we establish the existence of an extremal function for the k-th order critical Hardy-Sobolev-Maz'ya (HSM) inequalities on the upper half space $\mathbb{R}^{n+1}_{+}$ when $k\ge 2$ and $n\geq 2k+2$:
  $$\int_{\mathbb{R}^{n}_{+}}|\nabla^{k}u|^2dx-\prod_{i=1}^{k}\frac{\left(2i-1\right)^2}{4}\int_{\mathbb{R}^{n}_{+}}\frac{u^2}{x_1^{2k}}dx\geq C_{n,k,\frac{2n}{n-2k}} \left(\int_{\mathbb{R}^{n}_{+}}|u|^{\frac{2n}{n-2k}}dx\right)^{\frac{n-2k}{n}}. $$
  The analysis of this extremal problem is challenging due to the presence of the higher order derivatives, the lack of translation invariance, the inapplicability of rearrangement techniques on the upper half-space, and the presence of a Hardy singularity along the boundary. To overcome these difficulties, instead of directly considering the HSM inequality on the upper half space, we establish the existence of an extremal for its equivalent version: Poincaré-Sobolev inequality on the hyperbolic space. We develop a novel duality theory of the minimizing sequences, the concentration-compactness principle for radial functions in the hyperbolic setting, which combines with the Helgason-Fourier analysis and the Riesz rearrangement inequality on the hyperbolic space, to resolve the lack of compactness issue. As an application, we also obtain the existence of positive symmetric solutions for the high order Brezis-Nirenberg equation on the entire hyperbolic space associated with the GJMS operators $P_k$ (i.e., when $k\ge 2$): $$ P_{k}\left(f\right)-αf=|f|^{p-2}f $$ at the critical situation $α=\prod\limits_{i=1}^{k}\frac{\left(2i-1\right)^2}{4}$ when either $2k+2\leq n$ and $p=\frac{2n}{n-2k}$ or $2k<n$ and $2<p<\frac{2n}{n-2k}$.

</details>


### [16] [Strong solutions to the initial-boundary-value problem of compressible MHD equations with degenerate viscosities and far field vacuum in 3D exterior domains](https://arxiv.org/abs/2602.05264)
*Jiaxu Li,Boqiang Lü,Bing Yuan*

Main category: math.AP

TL;DR: Local existence and uniqueness of strong solutions to compressible MHD equations in 3D exterior domains with vacuum far-field, density-dependent viscosities, and Navier-slip/perfect conducting boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To establish a local well-posedness theory for compressible MHD equations in exterior domains with vacuum far-field conditions and density-dependent viscosities, addressing challenges from singularities that arise when density approaches zero.

Method: Study the initial-boundary-value problem of compressible MHD equations in 3D exterior domains with Navier-slip boundary conditions for velocity and perfect conducting conditions for magnetic field. Consider density-dependent viscosities as power functions of density (ρ^δ with 0 < δ < 1).

Result: Proved local existence and uniqueness of strong solutions for regular large initial data. Showed that magnetic field maintains faster decay rate than density throughout time evolution, unlike compressible Navier-Stokes case.

Conclusion: The magnetic field plays a crucial role in handling singularities arising from density-dependent viscosities by maintaining better decay properties than density, enabling local well-posedness even with vacuum far-field conditions.

Abstract: This paper concerns the initial-boundary-value problem (IBVP) of the compressible Magnetohydrodynamic (MHD) equations in 3D exterior domains with Navier-slip boundary conditions for the velocity and perfect conducting conditions for the magnetic field. For the case that the density approaches far-field vacuum initially and the viscosities are power functions of the density (ρ}δ with 0 < δ < 1), the local existence and uniqueness of strong solutions to the IBVP is established for regular large initial data. In particular, in contrast to the local theory of compressible Navier-Stokes equation Li-Lü-Yuan [24], we show that the magnetic field maintains the initial quality of decaying faster rate than density throughout the time evolution, which reveals the role of the magnetic field in handling singularities arising from density-dependent viscosities.

</details>


### [17] [Infinitely many new solutions for a nonlinear coupled Schrödinger system](https://arxiv.org/abs/2602.05283)
*Qingfang Wang,Mingxue Zhai*

Main category: math.AP

TL;DR: The paper studies a nonlinear Schrödinger system with two components, proving existence of new synchronized and segregated solutions that concentrate both in bounded domains and near infinity, and establishing non-degeneracy of these solutions.


<details>
  <summary>Details</summary>
Motivation: To investigate novel solution structures for coupled nonlinear Schrödinger systems, addressing difficulties arising from interspecies interactions that don't appear in single equations, and to establish non-degeneracy properties which are independently interesting.

Method: Uses finite dimensional reduction method to construct solutions, applies local Pohozaev identities and point-wise error estimates to prove non-degeneracy, and first verifies non-degeneracy of previously established solutions.

Result: Proves existence of new synchronized and segregated solutions with special structure that concentrate both in bounded domains and near infinity, and establishes that these synchronized solutions are non-degenerate.

Conclusion: The paper successfully constructs novel solution types for coupled Schrödinger systems and proves their non-degeneracy, overcoming challenges from interspecies interactions and contributing to understanding of solution structures in such systems.

Abstract: We revisit the following nonlinear Schrödinger system \begin{align*}\begin{cases} -ε^{2}Δu +P(x) u= μ_1 u^3 +βuv^2, &~\text{in}\;\mathbb {R}^3,\\ -ε^{2}Δv+Q(x) v= μ_2 v^3 +βu^2v, &~\text{in}\;\mathbb{ R}^3, \end{cases} \end{align*} where $ε$ is a positive parameter, $P(x),\,Q(x)$ are the potential functions, $μ_1>0$, $μ_2>0$ and $β\in\mathbb R$ is a coupling constant. Employing the finite dimensional reduction method, we prove that there are new kind of synchronized and segregated solutions, which concentrate both in a bounded domain and near infinity, and present a special structure. Moreover, by applying the local Pohozaev identities and some point-wise estimates of the errors, we prove that the new kind of synchronized solutions are non-degenerate, which is of great interest independently. One of the main difficulties of Schrödinger system come from the interspecies interaction between the components, which never appear in the study of single equation. Secondly, prior to the construction of new solutions, we shall verify the non-degeneracy of the solutions established in [Peng-Pi, Discrete Contin. Dyn. Syst., 2016] for the Schrödinger systems.

</details>


### [18] [Precise propagation profile for some monostable free boundary problems in time-periodic media](https://arxiv.org/abs/2602.05328)
*Yihong Du,Zhuo Ma,Zhi-Cheng Wang*

Main category: math.AP

TL;DR: This paper proves sharp convergence results for solutions of a time-periodic monostable reaction-diffusion equation with free boundaries to semi-wave solutions, without requiring the KPP condition that was needed in previous works.


<details>
  <summary>Details</summary>
Motivation: Previous results for free boundary models either required autonomous nonlinearities or strong KPP conditions for time-periodic cases. There was a need to establish sharp convergence results for general monostable free boundary problems in heterogeneous environments without special KPP conditions.

Method: The authors study reaction-diffusion equations with free boundaries subject to "preferred population density" conditions at habitat edges. They prove existence and uniqueness of semi-wave solutions (analogous to traveling waves in Cauchy problems) and establish precise convergence of solutions to these semi-waves as time goes to infinity.

Result: The paper proves existence and uniqueness of semi-wave solutions for general monostable free boundary problems and obtains precise description of solution convergence to semi-waves as time goes to infinity, without requiring the KPP condition that was essential in previous works.

Conclusion: This is the first work to prove sharp convergence results for general monostable free boundary problems in heterogeneous environments. The methods developed should be applicable to related free boundary problems with nonlinearities more general than KPP type.

Abstract: We consider reaction-diffusion equations of the form \begin{equation*} u_t - d u_{xx} = f(t,u), \quad t>0,\ \ x \in [g(t), h(t)], \end{equation*} where $f(t,u)$ is periodic in $t$ and monostable in $u$, and the interval $[g(t), h(t)]$ represents the one dimensional population range of a species with density $u(t,x)$ at time $t$ and spatial location $x$. The free boundaries $x=g(t)$ and $x=h(t)$ evolve subject to a ``preferred population density" condition at the habitat edges. Analogous to the traveling wave solutions in the corresponding Cauchy problem, semi-wave solutions play a fundamental role in understanding the propagation phenomena governed by the free boundary problem here. But in contrast to the Cauchy problem, where the KPP condition plays a subtle role in the precise approximation of its solution (with compactly supported initial function) by the traveling wave solution with minimal speed, here we prove the existence and uniqueness of a semi-wave in a general monostable setting, and obtain a precise description of the convergence of the solution toward the semi-wave as time goes to infinity, where the KPP condition plays no special role. Previously, such a sharp result was proved for a free boundary model only when $f$ is autonomous ($f=f(u)$, see \cite{D} or \cite{DL15} for a related free boundary model), or a less precise result was obtained in the time-periodic case under an extra strong KPP condition on $f$ (see \cite{MDW}, or \cite{DGP} for a related free boundary model). This work appears to be the first to prove the sharp convergence result for a general monostable free boundary problem in a heterogeneous environment, and we believe the methods developed here should have applications to related free boundary problems in heterogeneous media with nonlinearities more general than those of KPP type.

</details>


### [19] [Dynamics of a nonlocal epidemic model with a new free boundary condition, part 1: Spreading-vanishing dichotomy](https://arxiv.org/abs/2602.05331)
*Yao Chen,Yihong Du,Wan-Tong Li,Rong Wang*

Main category: math.AP

TL;DR: This paper proposes a new free boundary condition for a nonlocal epidemic model, proves well-posedness, and establishes a spreading-vanishing dichotomy with sharp thresholds based on initial data and diffusion rates.


<details>
  <summary>Details</summary>
Motivation: To develop a more realistic epidemic model that incorporates both pathogen flux through boundaries and infected population density in determining the expansion rate of epidemic regions, improving upon existing free boundary conditions.

Method: Proposes a new free boundary condition combining outward pathogen flux and weighted total infected population. Uses mathematical analysis including well-posedness proofs, eigenvalue problems, and asymptotic analysis to characterize long-time dynamics.

Result: The system is well-posed and exhibits spreading-vanishing dichotomy. Sharp thresholds are established for this dichotomy based on initial data and diffusion rates, complementing existing results.

Conclusion: The new free boundary condition yields mathematically tractable epidemic dynamics with clear spreading-vanishing behavior, providing a foundation for studying spreading speeds in Part 2.

Abstract: This paper investigates the long-time dynamics of a nonlocal epidemic model with free boundaries, where a pathogen with density $u(t,x)$ and the infected humans with density $v(t,x)$ evolve according to a reaction-diffusion system with nonlocal diffusion over a one dimensional interval $[g(t), h(t)]$, which represents the epidemic region expanding through its boundaries $x=g(t)$ and $x=h(t)$, known as free boundaries. Such a model with free boundary conditions based on those of Cao et al. \cite{fb27} was considered by several works. Inspired by recent works of Feng et al. \cite{fb20} and Long et al. \cite{fb5}, we propose a new free boundary condition, where the expansion rate of the epidemic region, determined by $h'(t)$ and $g'(t)$, is proportional to a linear combination of the outward flux of the pathogen \(u\) through the range boundary (as in \cite{fb27}) and the weighted total population of infected individuals \(v\) within the region (as in \cite{fb5}). We prove that the system under this new free boundary condition is well-posed, and its long-time dynamical behavior is characterized by a spreading-vanishing dichotomy. Moreover, we obtain sharp criteria for this dichotomy, including a sharp threshold in terms of the initial data $(u_0,v_0)$; and by studying a related eigenvalue problem, we also find a sharp threshold in terms of the diffusion rate, which complements related results in Nguyen and Vo \cite{fb7}. This is Part $1$ of a two part series. In Part $2$, we will determine the spreading speed of the model when spreading occurs, and for some typical classes of kernel functions, we will obtain the precise rates of accelerated spreading.

</details>


### [20] [Lipschitz regularity of harmonic quasiconformal maps between Lyapunov domains in $\mathbb{R}^n$](https://arxiv.org/abs/2602.05436)
*Anton Gjokaj,David Kalaj*

Main category: math.AP

TL;DR: Harmonic K-quasiconformal homeomorphisms between C^{1,α} domains in ℝⁿ are globally Lipschitz up to the boundary.


<details>
  <summary>Details</summary>
Motivation: To establish global Lipschitz regularity for sense-preserving harmonic quasiconformal homeomorphisms between smooth domains, extending known interior regularity results to the boundary.

Method: Boundary iteration scheme: start with Hölder boundary trace from quasiconformality, improve via C^{1,α} graph representation to get better normal component regularity, convert to near-boundary gradient bounds using harmonic-measure techniques, propagate control via quasiconformality, and iterate to bound |Df| up to the boundary.

Result: Every sense-preserving harmonic K-quasiconformal homeomorphism between Lyapunov domains (bounded C^{1,α} domains) in ℝⁿ is globally Lipschitz on the closure of the domain.

Conclusion: The combination of harmonicity and quasiconformality, together with smooth boundary geometry, yields strong global Lipschitz regularity up to the boundary, demonstrating how boundary smoothness interacts with these mapping properties.

Abstract: We prove that every sense-preserving harmonic $K$--quasiconformal homeomorphism $f\colon D\toΩ$ between Lyapunov domains (equivalently, bounded $C^{1,α}$ domains) in $\mathbb{R}^n$, $α\in(0,1]$, is globally Lipschitz on $\overline D$. The argument is based on a boundary iteration scheme: an initial Hölder modulus for the boundary trace (coming from quasiconformality) is improved via the $C^{1,α}$ graph representation of $\partialΩ$, yielding higher Hölder regularity for the normal component. This boundary gain is converted into a near-boundary gradient bound for harmonic functions through a basepoint boundary Hölder-to-gradient estimate obtained by flattening the boundary and using local harmonic-measure bounds. Quasiconformality then propagates the resulting control from one component to the full differential, and iteration gives boundedness of $|Df|$ up to the boundary. Along the way we briefly survey several standard tools from the theory of quasiconformal harmonic mappings (QCH), including boundary Hölder continuity, distortion of derivatives, and boundary-to-interior propagation principles that enter the iteration.

</details>


### [21] [Convergence of the PML method for thermoelastic wave scattering problems](https://arxiv.org/abs/2602.05497)
*Qianyuan Yin,Changkun Wei,Bo Zhang*

Main category: math.AP

TL;DR: First analysis of PML method for 3D thermoelastic obstacle scattering, proving well-posedness and exponential convergence for the uniaxial PML approach.


<details>
  <summary>Details</summary>
Motivation: To develop and analyze a perfectly matched layer (PML) method for truncating unbounded thermoelastic scattering problems in three dimensions, addressing the lack of convergence results for PML methods in time-harmonic thermoelastic scattering.

Method: Introduces a uniaxial PML method to truncate the unbounded scattering domain, analyzes the truncated PML problem using analytic Fredholm theory to prove well-posedness (except for discrete frequencies), and establishes exponential convergence using PML extension techniques and analysis of modified fundamental solution decay properties.

Result: Proves well-posedness of the truncated PML problem under certain parameter constraints (except possibly for discrete frequencies) and establishes exponential convergence of the uniaxial PML method with respect to PML layer thickness and absorbing parameters.

Conclusion: This work provides the first convergence analysis of PML methods for time-harmonic thermoelastic scattering problems, demonstrating both theoretical well-posedness and practical exponential convergence for the uniaxial PML approach in 3D thermoelastic obstacle scattering.

Abstract: This paper is concerned with the thermoelastic obstacle scattering problem in three dimensions. A uniaxial perfectly matched layer (PML) method is firstly introduced to truncate the unbounded scattering problem, leading to a truncated PML problem in a bounded domain. Under certain constraints on model parameters, the well-posedness for the truncated PML problem is then proved except possibly for a discrete set of frequencies, based on the analytic Fredholm theory. Moreover, the exponential convergence of the uniaxial PML method is established in terms of the thickness and absorbing parameters of PML layer. The proof is based on the PML extension technique and the exponential decay properties of the modified fundamental solution. As far as we know, this is the first convergence result of the PML method for the time-harmonic thermoelastic scattering problem.

</details>


### [22] [Regularity results for linear parabolic equations on Carnot tori via mollifier kernel construction](https://arxiv.org/abs/2602.05498)
*Yiming Jiang,Yawei Wei,Yiyun Yang*

Main category: math.AP

TL;DR: Proves existence, uniqueness, and regularity for linear backward parabolic equations on Carnot tori, then applies results to Fokker-Planck-Kolmogorov equations.


<details>
  <summary>Details</summary>
Motivation: Study parabolic equations on non-commutative Carnot groups (sub-Riemannian manifolds) where standard Euclidean analysis doesn't apply, extending regularity theory to these geometric settings.

Method: 1) Construct specialized mollifiers adapted to Hörmander vector fields, Carnot tori, and dual spaces of non-isotropic Hölder spaces. 2) Use singular integral operator theory to establish stronger a priori regularity estimates.

Result: Proves existence, uniqueness, and regularity for solutions to linear backward parabolic equations on Carnot tori, and extends these results to weak solutions of the dual Fokker-Planck-Kolmogorov equation.

Conclusion: Develops analytical tools for studying parabolic equations on Carnot groups, establishing foundational regularity results that bridge sub-Riemannian geometry with PDE theory.

Abstract: This paper first proves the existence, uniqueness and regularity of the solution to a class of linear backward parabolic equations on Carnot tori, namely the periodic linear parabolic equation on Carnot groups. Such groups are non-commutative and typical examples of sub-Riemannian manifolds. Moreover, we apply the results for this equation to its dual equation (i.e., the Fokker-Planck-Kolmogorov equation in the general form), and derive the existence, uniqueness and regularity of its weak solution. To obtain the regularity results for solutions to the linear parabolic equation and its dual equation, firstly, we construct several families of mollifiers adapted respectively to the Hörmander vector fields generating Carnot groups, Carnot tori and dual spaces of non-isotropic Hölder spaces; secondly, we use the theory of singular integral operators to establish stronger a priori regularity for the solutions.

</details>


### [23] [Global smooth solutions in a one-dimensional thermoviscoelastic model with temperature-dependent paramaters](https://arxiv.org/abs/2602.05621)
*Felix Meyer*

Main category: math.AP

TL;DR: The paper establishes existence of global classical solutions for a thermoviscoelastic system modeling Kelvin-Voigt materials with arbitrarily large initial data.


<details>
  <summary>Details</summary>
Motivation: To analyze the mathematical properties of thermoviscoelastic systems describing one-dimensional Kelvin-Voigt materials, which are important in material science and continuum mechanics.

Method: Studies a coupled PDE system for displacement (u) and temperature (Θ) with nonlinear terms involving γ(Θ) and f(Θ). Uses assumptions about smoothness and growth conditions on the functions a, γ, and f to prove existence results.

Result: Establishes existence of global classical solutions for sufficiently smooth but arbitrarily large initial data under the given conditions on the nonlinear functions.

Conclusion: The thermoviscoelastic system for Kelvin-Voigt materials admits global classical solutions even for large initial data, which has important implications for the mathematical analysis of such materials.

Abstract: This manuscript is concerned with the system \begin{align*} \left\{ \begin{array}{l} u_{tt} = (γ(Θ) u_{xt})_x + (a(x,t) u_x)_x +(f(Θ))_x, \\[1mm] Θ_t = DΘ_{xx} + γ(Θ) u_{xt}^2 + f(Θ) u_{xt}, \end{array} \right. \end{align*} which is used to describe thermoviscoelastic developments in one-dimensional Kelvin-Voigt materials. \abs It is assumed that $a,γ$ and $f$ are sufficiently smooth functions that satisfy $$c_γ<γ(ζ)<C_γ, \quad γ''(ζ) \le 0,\quad f(0)=0, \quad |f'(ζ)|\le C_f \quad \mbox{ and } |f(ζ)|\le C_f(1+ζ)^α\quad \mbox{ for all }ζ\ge 0 $$ and some positive constants $c_γ,C_γ,C_f>0$ and $α\in (0,5/6)$. Under these conditions, this study then establishes a result on the existence of global classical solutions for sufficiently smooth but arbitrarily large initial data.

</details>


### [24] [Large time existence in a thermoviscoelastic evolution problem with mildly temperature-dependent parameters](https://arxiv.org/abs/2602.05640)
*Felix Meyer*

Main category: math.AP

TL;DR: The paper proves that classical solutions to a thermo-viscoelastic system can exist for arbitrarily long times under certain sublinear growth conditions on temperature-dependent coefficients.


<details>
  <summary>Details</summary>
Motivation: The model generalizes classical thermo-viscoelastic systems following Kelvin-Voigt material laws. While local existence of classical solutions is known, the paper aims to extend existence times to be arbitrarily large, addressing long-time behavior of thermo-viscoelastic materials.

Method: The authors assume sublinear temperature dependencies: γ and f have bounded derivatives, and F satisfies |F(s)| ≤ C_F(1+s)^α with α∈(0,1). They prove that for any given time T_★, there exists a constant δ_★ such that if the derivatives of γ and f are bounded by δ_★, the maximal existence time surpasses T_★.

Result: For any T_★, initial mass M, and bounds on coefficients, there exists δ_★ > 0 such that if ‖γ'‖_∞ ≤ δ_★ and ‖f'‖_∞ ≤ δ_★, the classical solution exists beyond T_★. This establishes arbitrarily long existence times under smallness conditions on coefficient derivatives.

Conclusion: Classical solutions to the thermo-viscoelastic system can be extended to arbitrarily long time intervals when the temperature-dependent coefficients have sufficiently small derivatives, providing important insights into long-time behavior of thermo-viscoelastic materials.

Abstract: We consider \begin{align*} \label{HS} \left\{ \begin{array}{l} u_{tt} = (γ(Θ) u_{xt})_x + a (γ(Θ) u_x)_x +(f(Θ))_x, \\[1mm] Θ_t = DΘ_{xx} + Γ(Θ) u_{xt}^2 + F(Θ) u_{xt}, \end{array}\right. \qquad \qquad (\star) \end{align*} under Neumann boundary conditions for $u$ and Dirichlet boundary conditions for $Θ$ in a bounded interval $Ω\subset\mathbb{R}$. \abs This model is a generalization of the classical system for the description of strain and temperature evolution in a thermo-viscoelastic material following a Kelvin-Voigt material law, in which $γ\equiv Γ$ and $f\equiv F$. Different variations of this model have already been analyzed in the past and the present study draws upon a known result concerning the existence of classical solutions, which are local in time, for suitably smooth initial data, arbitrary $a>0$, $D>0$ and $γ,f\in C^2([0,\infty))$ as well as $Γ,F\in C^1([0,\infty))$ with $γ>0,Γ\ge0$ and $F(0)=0$. Our work focuses on proving that existence times for classical solutions can be arbitrarily large, assuming sublinear temperature dependencies of $γ$ and $f$, and further $|F(s)|\le C_F(1+s)^α$ for some $C_F>0$ and $α\in(0,1)$. In particular, for any given $T_\star$, initial mass $M$ and $0<\underlineγ<\overlineγ$, there exists a constant $δ_\star(M,T_\star,a,D, Ω, \underlineγ, \overlineγ,C_F,α)>0$, such that if $$\underlineγ\leγ\le \overlineγ\quad\mbox{ and }\quad 0\le Γ\le \overlineγ\quad \mbox{ as well as } \quad\|γ'\|_{L^\infty([0,\infty))}\le δ_\star \quad \mbox{ and }\quad \|f'\|_{L^\infty([0,\infty))}\le δ_\star $$ hold, the maximal existence time of the classical solution to $(\star)$ surpasses $T_\star$.

</details>


### [25] [Fundamental solution for higher order homogeneous hypoelliptic operators structured on Hörmander vector fields](https://arxiv.org/abs/2602.05647)
*Stefano Biagi,Marco Bramanti*

Main category: math.AP

TL;DR: Introduces "generalized Rockland operators" - higher order differential operators built with Hörmander vector fields that are homogeneous but not left invariant, with hypoelliptic lifted versions and sharp fundamental solution estimates.


<details>
  <summary>Details</summary>
Motivation: To study a new class of higher order differential operators that extend classical Rockland operators to more general settings where operators are homogeneous with respect to dilations but not necessarily left invariant under any Lie group structure.

Method: Define generalized Rockland operators using Hörmander vector fields with dilation homogeneity, prove their hypoellipticity, and construct global fundamental solutions with joint homogeneity and sharp pointwise estimates.

Result: Proves these operators are hypoelliptic and, under natural conditions on homogeneity degree, possess global fundamental solutions with joint homogeneity and sharp pointwise estimates. Theory applies to higher order heat-type operators.

Conclusion: Establishes a new class of generalized Rockland operators with strong analytic properties including hypoellipticity and existence of well-behaved fundamental solutions, extending classical theory to non-group-invariant settings.

Abstract: We introduce and study a new class of higher order differential operators defined on $\mathbb{R}^{n}$, which are built with Hörmander vector fields, homogeneous w.r.t. a family of dilations (but not left invariant w.r.t. any structure of Lie group) and have a structure such that a suitably lifted version of the operator is hypoelliptic. We call these operators ''generalized Rockland operators''. We prove that these operators are themselves hypoelliptic and, under a natural condition on the homogeneity degree, possess a global fundamental solution $Γ\left( x,y\right) $ which is jointly homogeneous in $\left( x,y\right) $ and satisfies sharp pointwise estimates. Our theory can be applied also to some higher order heat-type operators and their fundamental solutions.

</details>


### [26] [Weak and strong averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise](https://arxiv.org/abs/2602.05696)
*Yangyang Shi,Dong Su,Hui Liu*

Main category: math.AP

TL;DR: The paper studies averaging principles for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, establishing well-posedness, ergodicity, and convergence to averaged equations.


<details>
  <summary>Details</summary>
Motivation: To analyze the averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, which extends existing theory to more complex stochastic systems with jump processes.

Method: First establishes well-posedness, regularity estimates, and tightness of vorticity variable; then proves ergodicity of temperature variable; next shows convergence of vorticity to averaged equation in probability and 2p-th mean; finally includes case study and numerical simulations.

Result: Proves rigorous mathematical results including well-posedness, ergodicity, and convergence to averaged equations under different conditions as time scale parameter ε→0, supported by numerical simulations.

Conclusion: The averaging principle holds for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, with vorticity converging to averaged equation and temperature exhibiting ergodic behavior, validated by theoretical analysis and numerical evidence.

Abstract: In this paper, we study the averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise. Precisely, we will first explore the well-posedness, regularity estimates and tightness of the vorticity variable. Then, we prove the ergodicity of the temperature variable. Next, we prove that the vorticity variable converge to the solution of the averaged equation in probability and $2p$th-mean, under different conditions, as time scale parameter $\varepsilon$ goes to zero. Finally, we present a specific case study and conduct numerical simulations to substantiate the main conclusions of this paper.

</details>


### [27] [Flow reversal of the Stokes system with localized boundary data in the half space](https://arxiv.org/abs/2602.05858)
*Tongkeun Chang,Kyungkeun Kang,Chanhong Min*

Main category: math.AP

TL;DR: The paper demonstrates flow reversal phenomena in unsteady Stokes flow in a half-space with localized boundary data, showing velocity components can change sign in space.


<details>
  <summary>Details</summary>
Motivation: To investigate whether boundary-driven unsteady Stokes flow in a half-space can exhibit flow reversal, where velocity components change sign within the domain, despite zero initial conditions.

Method: Careful analysis of the representation formula for the Stokes system using the Green tensor with nonzero boundary data, including pointwise estimates. Construction of specific boundary influxes that induce flow reversal.

Result: Existence of boundary influxes that cause flow reversal: tangential velocity components exhibit at least one sign change, normal component exhibits at least two sign changes. Near boundary, normal component has opposite sign to tangential components; far from boundary, they have the same sign.

Conclusion: Flow reversal is possible in unsteady Stokes flow with localized boundary data, demonstrating complex flow patterns can emerge even from simple boundary conditions in half-space geometry.

Abstract: We consider the unsteady Stokes system in the half-space with zero initial data and nonzero, space-time localized boundary data. We show that there exist boundary influxes for which the induced flow exhibits flow reversal, in the sense that at least one component of the velocity field changes its sign in the half-space. This phenomenon is demonstrated by a careful analysis of the representation formula for the Stokes system in the half-space, including pointwise estimates, based on the Green tensor with nonzero boundary data. We construct solutions of the Stokes system such that the tangential components of the velocity field exhibit at least one sign change, while the normal component exhibits at least two sign changes. Moreover, the normal component of the constructed velocity field has the opposite sign to the tangential components near the boundary, whereas it has the same sign as the tangential components sufficiently far from the boundary.

</details>


### [28] [Large bulk viscosity limit for compressible MHD equations in critical Besov spaces](https://arxiv.org/abs/2602.05878)
*Gennaro Ciampa,Donatella Donatelli,Giada Pellecchia*

Main category: math.AP

TL;DR: Global well-posedness of compressible MHD equations in large bulk viscosity limit, with convergence to incompressible MHD and application to magnetic reconnection.


<details>
  <summary>Details</summary>
Motivation: Study the singular limit behavior of compressible magnetohydrodynamics (MHD) equations as bulk viscosity becomes arbitrarily large, connecting compressible and incompressible regimes.

Method: Analyze compressible MHD equations in 2D and 3D with large bulk viscosity, using critical Besov spaces for initial data, proving global well-posedness and establishing convergence rates to incompressible MHD as viscosity parameter tends to infinity.

Result: Proved global well-posedness for arbitrarily large initial data in critical Besov spaces, established explicit quantitative convergence rates to incompressible MHD solutions, and constructed global smooth solutions with magnetic field reconnection extending incompressible scenarios to compressible regime.

Conclusion: The large bulk viscosity limit provides a rigorous connection between compressible and incompressible MHD, enabling extension of magnetic reconnection phenomena from incompressible to compressible flows through singular limit analysis.

Abstract: We study the large bulk viscosity limit for the compressible magnetohydrodynamics (MHD) equations in two and three dimensions. For arbitrarily large initial data in critical Besov spaces, we prove the global well-posedness of strong solutions and establish their convergence, with explicit quantitative rates, to solutions of the incompressible MHD system, as the bulk viscosity parameter tends to infinity. As an application of this singular-limit analysis, we construct global smooth solutions to the compressible MHD equations whose magnetic field undergoes reconnection, thereby extending to the compressible regime the reconnection scenarios previously identified for incompressible flows.

</details>


### [29] [Explicit representation of solutions to a linear wave equation with time delay](https://arxiv.org/abs/2602.05906)
*Javad A. Asadzade,Jasarat J. Gasimov,Nazim I. Mahmudov,Ismail T. Huseynov*

Main category: math.AP

TL;DR: Explicit spectral representation for 1D wave equation with constant time delay using stepwise classical solutions and Fourier series reconstruction.


<details>
  <summary>Details</summary>
Motivation: To develop analytical solution methods for wave equations with time delays, which cause loss of global smoothness and require special treatment of discontinuities at delay multiples.

Method: Combines separation of variables with Sturm-Liouville expansions to reduce delayed PDE to scalar delay differential equations, uses delay-dependent fundamental solutions for modal dynamics, and reconstructs PDE solution as Fourier series with convergence analysis.

Result: Derived closed-form representation formulas for modal dynamics, established convergence conditions for uniform convergence and termwise differentiation, and demonstrated practical computation with numerical example.

Conclusion: Successfully developed explicit spectral representation for delayed wave equations using stepwise classical solutions, providing analytical framework and computational approach for such systems.

Abstract: This paper develops an explicit spectral representation for solutions of a one-dimensional linear wave equation with a constant time delay. The model is considered on a bounded interval with non-homogeneous Dirichlet boundary data and a prescribed history function. To accommodate the loss of global smoothness in time caused by delay terms, solutions are understood in a \textit{stepwise classical sense}, allowing jump discontinuities in the second time derivative at multiples of the delay while maintaining continuity of the solution and its first time derivative.
  By combining separation of variables with Sturm-Liouville expansions, the delayed PDE is reduced to a family of scalar second-order delay differential equations. Using delay-dependent fundamental solutions, we derive closed-form representation formulas for the modal dynamics and reconstruct the PDE solution as a Fourier series. Convergence conditions guaranteeing uniform convergence and admissibility of termwise differentiation in space are established. A numerical example demonstrates the practical computation of truncated series solutions and their visualization.

</details>


### [30] [Large time stabilization of rough-data solutions in one-dimensional nonlinear thermoelasticity](https://arxiv.org/abs/2602.05962)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper proves stabilization of weak solutions for a 1D thermoelasticity model with minimal regularity assumptions on initial data, showing convergence to equilibrium states.


<details>
  <summary>Details</summary>
Motivation: Previous studies on thermoelasticity models required more regular initial data and relied on compactness properties. This work aims to establish stabilization results for weak solutions with minimal regularity assumptions that only satisfy basic physical principles (energy conservation and entropy nondecrease).

Method: The authors consider a one-dimensional thermoelasticity model with nonlinear coupling through function f(Θ). They work with weak solutions under homogeneous boundary conditions (Dirichlet for displacement u, Neumann for temperature Θ). The analysis handles the lack of favorable compactness properties by using only fundamental physical principles as constraints on initial data.

Result: Despite minimal regularity assumptions on initial data, the paper proves that corresponding weak solutions stabilize: displacement u converges to 0 in L∞ norm, and temperature Θ converges to a positive constant Θ∞ in L∞ norm as time goes to infinity.

Conclusion: The thermoelasticity model exhibits stabilization to equilibrium even for weak solutions with minimal regularity, demonstrating that the physical principles of energy conservation and entropy nondecrease are sufficient to guarantee long-time behavior without requiring additional compactness properties.

Abstract: In an open bounded real interval $Ω$, the model for one-dimensional thermoelasticity given by \[
  u_{tt} = u_{xx} - \big(f(Θ)\big)_x,
  \qquad
  Θ_t = Θ_{xx} - f(Θ) u_{xt}, \] is considered along with homogeneous boundary conditions of Dirichlet type for $u$ and of Neumann type for $Θ$, under the assumption that $f\in C^1([0,\infty))$ satisfies $f(0)=0$, $f'\in L^\infty((0,\infty))$ and $f'>0$ on $[0,\infty)$. The focus is on initial data which are merely required to be consistent with the fundamental principles of energy conservation and entropy nondecrease, by satisfying \[
  u_0\in W_0^{1,2}(Ω),
  u_{0t} \in L^2(Ω),
  0 \le Θ_0\in L^1(Ω), Θ_0 \not\equiv 0. \] Despite an apparent lack of favorable compactness properties that have underlain previous related studies on more regular settings, it is shown that corresponding weak solutions stabilize in the sense that \[
  \lim_{t\to\infty} \|u(\cdot,t)\|_{L^\infty(Ω)}=0 \] and \[
  {\rm ess} \lim_{\!\!\!\! t\to\infty} \|Θ(\cdot,t)-Θ_\infty\|_{L^\infty(Ω)}=0 \] with some $Θ_\infty>0$.

</details>


### [31] [A simple model for one-dimensional nonlinear thermoelasticity: Well-posedness in rough-data frameworks](https://arxiv.org/abs/2602.05963)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper establishes well-posedness (global existence, uniqueness, continuous dependence) for a coupled hyperbolic-parabolic system modeling thermoelasticity with nonlinear coupling function f.


<details>
  <summary>Details</summary>
Motivation: To analyze the mathematical properties of a thermoelastic system with nonlinear coupling, establishing rigorous well-posedness results under minimal regularity assumptions on initial data.

Method: Considers a coupled PDE system (wave equation coupled with heat equation via nonlinear function f) on bounded interval with Dirichlet boundary conditions for u and Neumann for Θ. Uses functional analysis and PDE theory to prove unconditional global existence, uniqueness, and continuous dependence.

Result: Proves the problem is well-posed for initial data with minimal regularity: u₀∈W₀¹²(Ω), u₀ₜ∈L²(Ω), Θ₀∈L²(Ω) with Θ≥0 a.e., yielding solutions in specified function spaces.

Conclusion: The thermoelastic system with nonlinear coupling function f satisfying mild regularity conditions admits global well-posed solutions under minimal initial data assumptions, establishing strong mathematical foundation for such models.

Abstract: In an open bounded interval $Ω$, the problem \[
  u_{tt} = u_{xx} - \big(f(Θ)\big)_x,
  Θ_t = Θ_{xx} - f(Θ) u_{xt}, \] is considered under the boundary conditions $u|_{\partialΩ}=Θ_x|_{\partialΩ}=0$, and for $f\in C^2([0,\infty))$ satisfying $f(0)=0$, $f'>0$ on $[0,\infty)$ and $f'\in W^{1,\infty}((0,\infty))$.
  In the sense of unconditional global existence, uniqueness and continuous dependence, this problem is shown to be well-posed within ranges of initial data merely satisfying \[
  u_0\in W_0^{1,2}(Ω),
  \quad
  u_{0t} \in L^2(Ω)
  \quad \mbox{and} \quad
  Θ_0 \in L^2(Ω)
  \mbox{ with $Θ\ge 0$ a.e.~in $Ω$,} \] and in classes of solutions fulfilling \[
  u\in C^0([0,\infty);W_0^{1,2}(Ω)),
  \qquad
  u_t \in C^0([0,\infty);L^2(Ω))
  \qquad \mbox{and} \qquad
  Θ\in C^0([0,\infty);L^2(Ω)) \cap L^2_{loc}([0,\infty);W^{1,2}(Ω)). \]

</details>


### [32] [Global solvability and stabilization in multi-dimensional small-strain nonlinear thermoviscoelasticity](https://arxiv.org/abs/2602.05964)
*Michael Winkler*

Main category: math.AP

TL;DR: Global existence of solutions for small-strain thermoviscoelastic evolution in Kelvin-Voigt materials without size restrictions on initial data, plus large-time behavior results showing temperature stabilization.


<details>
  <summary>Details</summary>
Motivation: Addressing a long-standing open problem in continuum mechanics: determining global solvability of the prototypical model for small-strain thermoviscoelastic evolution in Kelvin-Voigt materials with inertia, particularly in multi-dimensional settings for arbitrary initial data size.

Method: Studies an initial value problem in smoothly bounded n-dimensional domains (n≥2) with homogeneous boundary conditions (Dirichlet for displacement, Neumann for temperature). Uses generalized concepts of solvability and relies on evolution properties of logarithmic refinements of classical entropy functionals, along with energy conservation and entropy production principles.

Result: Proves global existence of solutions without size restrictions on initial data for a system more general than the standard model (allowing temperature-dependent heat capacity). Also derives large-time behavior results showing stabilization of temperature toward a spatially homogeneous limit.

Conclusion: The paper resolves the open problem by establishing global solvability for arbitrary initial data in multi-dimensional settings, introducing novel logarithmic entropy refinements that may be of independent interest, and showing temperature stabilization over time.

Abstract: Despite considerable developments in the literature of the past decades, a standing open problem in the analysis of continuum mechanics appears to consist of determining how far the prototypical model for small-strain thermoviscoelastic evolution in Kelvin-Voigt materials with inertia, as given by \[
  u_{tt} = μΔu_t + (λ+μ)\nabla\nabla\cdot u_t
  + \hatμ Δu + (\hatλ+\hatμ) \nabla\nabla\cdot u
  - B\nablaΘ,
  \qquad \qquad
  κΘ_t = DΔΘ+ μ|\nabla u_t|^2 + (λ+μ) |{\rm div} \, u_t|^2 - BΘ{\rm div} \, u_t,
  \qquad \qquad \qquad (\star) \] is globally solvable in multi-dimensional settings and for initial data of arbitrary size.
  The present manuscript addresses this in the context of an initial value problem in smoothly bounded $n$-dimensional domains with $n\ge 2$, posed under homogeneous boundary conditions of Dirichlet type for the displacement variable $u$, and of Neumann type for the temperature $Θ$. Within suitably generalized concepts of solvability, global existence of solutions is shown without any size restrictions on the data, and for a system actually more general than ($\star$) by, inter alia, allowing the heat capacity $κ$ to depend on $Θ$. Apart from that, results on large time behavior are derived which particularly assert stabilization of $Θ$ toward a spatially homogeneous limit.
  Besides on standard features related to energy conservation and entropy production, in its core parts the analysis relies on an evolution property of certain logarithmic refinements of classical entropy functionals, to the best of our knowledge undiscovered in precedent literature and possibly of independent interest.

</details>


### [33] [Stability of the $L^{p}$-Poincaré inequality for the Lebesgue and Gaussian probability measures with explicit geometric dependency](https://arxiv.org/abs/2602.05968)
*Nurgissa Yessirkegenov,Amir Zhangirbayev*

Main category: math.AP

TL;DR: The paper establishes stability results for L^p-Poincaré inequalities for Lebesgue and Gaussian measures using eigenfunction analysis and weighted inequalities.


<details>
  <summary>Details</summary>
Motivation: To understand the stability properties of L^p-Poincaré inequalities for different probability measures, which are fundamental in analysis and probability theory.

Method: Uses properties of the first eigenfunction of the (Gaussian) p-Laplacian operator and weighted Poincaré inequalities for log-concave measures on convex domains.

Result: Obtains stability results for L^p-Poincaré inequality for both Lebesgue and Gaussian probability measures (Theorem 3.3 and Theorem 3.6).

Conclusion: The approach combining eigenfunction analysis and weighted inequalities provides stability results for Poincaré inequalities across different probability measures.

Abstract: In this paper, we obtain stability results for the $L^{p}$-Poincaré inequality for both Lebesgue and Gaussian probability measures (Theorem 3.3 and Theorem 3.6). Our approach relies on properties of the first eigenfunction of the (Gaussian) $p$-Laplacian operator and weighted Poincaré inequalities for log-concave measures on convex domains.

</details>


### [34] [Finite time singularities in the Landau equation with very hard potentials](https://arxiv.org/abs/2602.05981)
*Jacob Bedrossian,Jiajie Chen,Maria Pia Gualdani,Sehyun Ji,Vlad Vicol,Jincheng Yang*

Main category: math.AP

TL;DR: Constructed smooth positive initial data for inhomogeneous Landau equation (γ∈(√3,2]) that develops finite-time singularity with C^α-norm blowup but bounded L^∞-norm.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that collisional kinetic models can exhibit fundamentally different behavior in inhomogeneous vs homogeneous settings, providing first example of global well-posedness in homogeneous case but finite-time singularities for inhomogeneous data.

Method: Constructed smooth, strictly positive initial data for the inhomogeneous Landau equation with specific parameter range. Analyzed solution behavior in self-similar variables showing convergence to local Maxwellian distribution while hydrodynamic fields develop asymptotically self-similar implosion.

Result: Found finite-time singularity where C^α-norm blows up for all α>0 while L^∞-norm remains bounded. In self-similar variables, distribution function converges to local Maxwellian and hydrodynamic fields develop implosion profile matching smooth imploding profiles of compressible Euler equations.

Conclusion: First example showing collisional kinetic model (Landau equation) is globally well-posed in homogeneous setting but admits finite-time singularities for inhomogeneous data, demonstrating fundamental difference between homogeneous and inhomogeneous behavior.

Abstract: We consider the inhomogeneous Landau equation with $γ\in (\sqrt{3},2]$ and construct smooth, strictly positive initial data that develop a finite time singularity. The $C^α$-norm of the distribution function blows up for every $α>0$, whereas its $L^{\infty}$-norm remains uniformly bounded. In self-similar variables, the solution becomes asymptotically hydrodynamic - the distribution function converges to a local Maxwellian, while the hydrodynamic fields develop an asymptotically self-similar implosion whose profile coincides with a smooth imploding profile of the compressible Euler equations. To our knowledge, this provides the first example of a collisional kinetic model which is globally well-posed in the homogeneous setting, but admits finite time singularities for inhomogeneous data.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [35] [Path Sampling for Rare Events Boosted by Machine Learning](https://arxiv.org/abs/2602.05167)
*Porhouy Minh,Sapna Sarupria*

Main category: physics.comp-ph

TL;DR: AIMMD is a novel sampling algorithm that combines machine learning with transition path sampling to efficiently discover molecular mechanisms by estimating committor probabilities and deriving interpretable reaction coordinates.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency of transition path sampling for complex molecular processes by integrating machine learning approaches that can provide both computational efficiency and human-interpretable mechanistic insights.

Method: AIMMD integrates machine learning into transition path sampling to enable on-the-fly estimation of committor probability while simultaneously deriving human-interpretable reaction coordinates for molecular mechanism discovery.

Result: The method offers a robust framework for elucidating mechanistic pathways of complex molecular processes, with recent extensions demonstrating continued development and application potential.

Conclusion: AIMMD represents a significant advancement in molecular mechanism discovery with potential impact, though it has limitations that warrant critical assessment and further development.

Abstract: The study by Jung et al. (Jung H, Covino R, Arjun A, et al., Nat Comput Sci. 3:334-345 (2023)) introduced Artificial Intelligence for Molecular Mechanism Discovery (AIMMD), a novel sampling algorithm that integrates machine learning to enhance the efficiency of transition path sampling (TPS). By enabling on-the-fly estimation of the committor probability and simultaneously deriving a human-interpretable reaction coordinate, AIMMD offers a robust framework for elucidating the mechanistic pathways of complex molecular processes. This commentary provides a discussion and critical analysis of the core AIMMD framework, explores its recent extensions, and offers an assessment of the method's potential impact and limitations.

</details>


### [36] [Numerical Evaluation of Angle-Dependent IR-Transparent Radiative Cooling Performance for Asymmetric Periodic Structures](https://arxiv.org/abs/2602.05613)
*Junwoo Gim,Jun Heo,Weng Cho Chew,Dong-Yeop Na*

Main category: physics.comp-ph

TL;DR: IR-transparent passive radiative cooling requires angularly distributed asymmetric transparency, not just single-angle asymmetry, for effective non-contact thermal management.


<details>
  <summary>Details</summary>
Motivation: Current IR-transparent passive radiative cooling designs focus on asymmetric IR transmission at normal incidence, but this single-angle approach doesn't accurately predict practical cooling performance.

Method: Used angle-resolved full-wave electromagnetic model with Bloch periodic boundary conditions and Floquet mode decomposition to compute wavelength- and angle-dependent bidirectional reflection/transmission of periodic PRC structures, coupled with energy-balance thermal model.

Result: Asymmetric transmission at normal incidence is not preserved at oblique angles; angular integration yields only marginal cooling or net heating, while normal-incidence models overestimate performance.

Conclusion: Angularly distributed asymmetric transparency is a key design principle for effective IR-transparent passive radiative cooling and wide-angle asymmetric metasurfaces.

Abstract: Infrared (IR)-transparent passive radiative cooling (PRC) enables non-contact thermal management by regulating radiative heat exchange without direct attachment to the cooling object. While asymmetric IR transmission at a specific incidence angle -- typically normal incidence -- is often emphasized, we show that such single-angle asymmetry is neither sufficient nor predictive of practical cooling performance. In this work, we demonstrate that effective non-contact PRC requires angularly distributed asymmetric IR transparency evaluated through hemispherical integration over emission directions, rather than asymmetry at a single incidence angle. To quantify this effect, an angle-resolved full-wave electromagnetic (EM) model with Bloch periodic boundary conditions and Floquet mode decomposition is employed to compute wavelength- and angle-dependent bidirectional reflection and transmission of periodic PRC structures. The resulting EM response is coupled to an energy-balance-based thermal model to predict the transient temperature evolution of the cooling object. By comparing models that account for the full angular distribution with normal-incidence-only approximations, we show that pronounced asymmetric transmission at normal incidence is generally not preserved at oblique angles. As a result, angular integration yields only marginal cooling or may even result in net heating, whereas normal-incidence-based models can substantially overestimate cooling performance. These results establish angularly distributed asymmetric transparency as a key EM design principle for IR-transparent PRC and wide-angle asymmetric metasurfaces.

</details>


### [37] [The near-continuum mechanism for extended Boltzmann theory: the non-equilibrium relaxation](https://arxiv.org/abs/2602.05775)
*Sha Liu,Ningchao Ding,Ming Fang,Hao Jin,Rui Zhang,Congshan Zhuo,Chengwen Zhong*

Main category: physics.comp-ph

TL;DR: This paper analyzes the Pullin equation as an extended Boltzmann equation for polyatomic gases, deriving explicit analytical expressions for macroscopic variable relaxation and transport coefficients, confirming the dependence of thermal conduction on thermal non-equilibrium, and proposing a new Rykov-type relaxation model.


<details>
  <summary>Details</summary>
Motivation: Existing collision models for polyatomic gases (like Borgnakke-Larsen) don't guarantee detailed balance and aren't integrable. The Pullin equation addresses these limitations with an integrable kernel satisfying detailed balance, enabling rigorous analysis of near-continuum relaxation mechanisms.

Method: Uses Pullin equation as extended Boltzmann equation, approximates distribution function with mixed Hermite and Laguerre polynomials for rotation, computes collision operator moments to derive macroscopic relaxation expressions, applies Chapman-Enskog framework for transport coefficients, and proposes a novel Rykov-type relaxation model.

Result: First explicit analytical expressions for temporal relaxation of macroscopic variables (stress force, translational/rotational temperatures, heat fluxes). Confirms thermal conduction coefficients depend on thermal non-equilibrium. New Rykov-type model recovers translational-rotational heat flux interactions ignored in standard Rykov equation.

Conclusion: The Pullin equation provides a rigorous foundation for analyzing polyatomic gas relaxation. The derived expressions and new Rykov-type model offer improved accuracy for near-continuum simulations, with benchmark tests validating the approach's precision.

Abstract: The collision phenomenon of polyatomic gases is described by the collision operator of extended Boltzmann equation or the energy-exchange model in particle direct simulations, for example, the Borgnakke-Larsen model. However, as a collision kernel, it dose not guarantee the entrinsic detailed balance and is not integrable. In this work, the Pullin equation, which possesses an integrable collision kernel and satisfies the detailed balance constraint, is adopted as an extended Boltzmann equation for the theoretical analysis of near-continuum relaxation mechanisms. For clarity, only the translational and rotational degrees are considered in this work. Explicit analytical expressions for the temporal relaxation of macroscopic variables, including the stress force, (translational/rotational) temperature and heat flux, are obtained at the first time. This is achieved by approximating the distribution function in mixed Hermite and Laguerre for rotation and computing the collision operator moments, enabling a direct description of macroscopic non-equilibrium evolution. Base on the same elementary moment (integral) of collision operator, the macroscopic transport coefficients is found in Chapman-Enskog framework. The long-standing speculation, that thermal conduction coefficient should be depended on the degrees of thermal non-equilibrium, is rigorously confirmed and evaluated. When thermal equilibrium is enforced, the present thermal conduction coefficients can be degenerated to the famous results of Mason and Monchick. Given the correct relaxation rate, a Rykov-type novel relaxation model for Pullin equation is proposed. It can recover the interaction of transaltional and rotatioanl heat fluxes in relaxation process, which is ignored in the widely used Rykov equation. Finally, the precision of this new Rykov-type equation is examined using a series of benchmark test cases.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [38] [An approximate Kappa generator for particle simulations](https://arxiv.org/abs/2602.05606)
*Seiji Zenitani,Takayuki Umeda*

Main category: physics.plasm-ph

TL;DR: A fast GPU-compatible random number generator for Kappa velocity distributions using q-exponential approximations and inverse transform sampling.


<details>
  <summary>Details</summary>
Motivation: Need efficient random number generation for Kappa velocity distributions in particle simulations, particularly for GPU acceleration where traditional methods may be slow or complex.

Method: Approximate the cumulative distribution function with q-exponential function and construct an inverse transform procedure for random number generation.

Result: The method provides practically accurate results, especially for k<4, and runs efficiently on GPUs.

Conclusion: The proposed generator enables fast, accurate Kappa-distributed random numbers suitable for GPU-accelerated particle simulations.

Abstract: A random number generator for the Kappa velocity distribution in particle simulations is proposed. Approximating the cumulative distribution function with the q-exponential function, an inverse transform procedure is constructed. The proposed method provides practically accurate results, in particular for k<4. It runs fast on graphics processing units (GPUs). The derivation, numerical validation, and relevance to GPU execution models are discussed.

</details>


### [39] [Explosive eruption cycles in a rotating Z-pinch](https://arxiv.org/abs/2602.06012)
*David N. Hosking,Luca Swinnerton,Rahul Kesavan*

Main category: physics.plasm-ph

TL;DR: A transonic shear flow along magnetic field lines can stabilize steep pressure gradients in MHD plasmas, creating a metastable "MHD pedestal" in Z-pinch geometry that collapses and rebuilds in cycles analogous to tokamak ELMs.


<details>
  <summary>Details</summary>
Motivation: To understand and model the formation and collapse of transport barriers in magnetically confined plasmas, particularly the edge pedestal behavior observed in tokamak fusion experiments that exhibits cyclic instabilities (ELMs).

Method: Simulation of MHD pedestal formation in a heated and sheared Z-pinch geometry, analyzing metastable equilibrium and collapse dynamics using combinatorial optimization of flux-tube interchanges from first principles.

Result: The MHD pedestal forms slowly but collapses when reaching critical height, expelling a significant fraction of thermal energy, then rebuilds in cycles similar to ELM behavior in fusion experiments. The available energy and optimal ejected plasma amount can be calculated from first principles.

Conclusion: Transonic shear flows can create metastable MHD pedestals in Z-pinch geometry that exhibit cyclic collapse and rebuilding analogous to tokamak ELMs, with the energetics calculable from first principles via flux-tube interchange optimization.

Abstract: A transonic shear flow directed along magnetic field lines can linearly stabilize a steep pressure gradient in a confined magnetohydrodynamic (MHD) plasma. In Z-pinch geometry, we show that, like the edge pedestal in tokamak devices, this transport barrier -- which we call the ``MHD pedestal'' -- is metastable, i.e., unstable to finite-amplitude displacements of flux tubes. We simulate the slow formation of an MHD pedestal in a heated and sheared Z-pinch, which collapses on reaching a critical height, expelling an order-unity fraction of the confined thermal energy. The MHD pedestal then rebuilds and the process repeats, in a manner analogous to the ELM cycle seen in fusion experiments. We show that the available energy of the metastable equilibrium, and the most energetically favorable amount of ejected plasma, can be calculated from first principles via combinatorial optimization of flux-tube interchanges.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [40] [Strong local nondeterminism for stochastic time-fractional slow and fast diffusion equations](https://arxiv.org/abs/2602.05317)
*Le Chen,Cheuk Yin Lee,Panqiu Xia*

Main category: math.PR

TL;DR: Study of stochastic time-fractional equations with Caputo derivative, fractional Laplacian, and Riemann-Liouville integral driven by fractional Gaussian noise, establishing existence conditions and regularity properties.


<details>
  <summary>Details</summary>
Motivation: To analyze stochastic partial differential equations with fractional operators in both time and space, which model complex phenomena with memory effects and anomalous diffusion, and to establish rigorous mathematical foundations for their solutions.

Method: Derive Dalang-type necessary and sufficient conditions for existence of random field solutions, prove sharp variance bounds for temporal/spatial increments, establish strong local nondeterminism properties, and analyze fundamental solution kernels.

Result: Obtained sharp existence conditions across almost full parameter range, proved sharp variance bounds, established strong local nondeterminism in time and space, derived exact moduli of continuity, Chung-type laws, and small ball probability bounds.

Conclusion: The paper provides comprehensive analysis of stochastic time-fractional equations, establishing sharp existence criteria and detailed regularity properties of solutions, with fundamental solution kernel asymptotics that may have independent interest.

Abstract: We study a class of stochastic time-fractional equations on $\mathbb{R}^d$ driven by a centered Gaussian noise, involving a Caputo time derivative of order $β>0$, a fractional (power) Laplacian of order $α>0$, and a Riemann-Liouville time integral of order $γ\ge0$ acting on the noise. The noise is fractional in time (index $H$) and Riesz-type in space (index $\ell$). We derive sharp Dalang-type necessary and sufficient conditions for the existence of a random field solution across almost full parameter range $(α,β,γ;H,\ell)$. Under the Dalang-type conditions, we prove sharp variance bounds for temporal and spatial increments, as well as strong local nondeterminism in time in several regimes (two-sided version for $β=1$ and for parts of the case $β=2$; one-sided version for $0<β<2$) and strong local nondeterminism in space for the whole range of parameters. As applications, we derive exact uniform and local moduli of continuity, Chung-type laws of the iterated logarithm, and quantitative bounds on small ball probabilities. Along the way, we obtain sharp asymptotics for the fundamental solution kernels at $0$ and $\infty$, which may be of independent interest.

</details>


### [41] [On the Resistance Conjecture](https://arxiv.org/abs/2602.05477)
*Sylvester Eriksson-Bique*

Main category: math.PR

TL;DR: The paper proves the resistance conjecture linking parabolic Harnack inequalities to volume doubling, capacity bounds, and Poincaré inequalities in p-Dirichlet spaces, establishing cutoff Sobolev inequalities and applications to martingale dimension and differential structure.


<details>
  <summary>Details</summary>
Motivation: To resolve the resistance conjecture about characterizing parabolic Harnack inequalities through three key geometric/analytic conditions (volume doubling, upper capacity bounds, Poincaré inequalities) in a unified framework applicable across different settings.

Method: Uses p-Dirichlet spaces framework to show the three assumptions imply cutoff Sobolev inequalities, then proves Harnack inequalities. Extends methods of Jones and Koskela to p-Dirichlet spaces, establishes extension techniques and characterizations of Sobolev functions via Poincaré inequalities.

Result: Affirmative proof of resistance conjecture; unified treatment of Harnack inequalities and stability phenomena across metric spaces, fractals, graphs, and manifolds for all p∈(1,∞). Additional results: finite martingale dimension and Cheeger-type differential structure under the three conditions.

Conclusion: The paper successfully resolves the resistance conjecture, providing a comprehensive framework connecting geometric/analytic conditions to parabolic Harnack inequalities with broad applications in analysis on metric spaces, fractals, graphs, and manifolds.

Abstract: We give an affirmative answer to the resistance conjecture on characterization of parabolic Harnack inequalities in terms of volume doubling, upper capacity bounds and a Poincaré inequalities. The key step is to show that these three assumptions imply the so called cutoff Sobolev inequality, an important inequality in the study of anomalous diffusions, Dirichlet forms and re-scaled energies in fractals. This implication is shown in the general setting of $p$-Dirichlet Spaces introduced by the author and Murugan, and thus a unified treatment becomes possible to proving Harnack inequalities and stability phenomena in both analysis on metric spaces and fractals and for graphs and manifolds for all exponents $p\in (1,\infty)$. As an application, we also show that a Dirichlet space satisfying volume doubling, Poincaré and upper capacity bounds has finite martingale dimension and admits a type of differential structure similar to the work of Cheeger. In the course of the proof, we establish methods of extension and characterizations of Sobolev functions by Poincaré-inequalities, and extend the methods of Jones and Koskela to the general setting of $p$-Dirichlet spaces.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [42] [Auroral signatures of ballooning instability and plasmoid formation processes in the near-Earth magnetotail](https://arxiv.org/abs/2602.05108)
*Ping Zhu,Jun Liang,Jiaxing Liu,Sui Wan,Eric Donovan*

Main category: physics.space-ph

TL;DR: This paper validates MHD simulations of ballooning instability and plasmoid formation as substorm onset triggers by comparing simulation results with THEMIS satellite and auroral observations.


<details>
  <summary>Details</summary>
Motivation: To validate the proposed mechanism where ballooning instability and subsequent plasmoid formation trigger substorm onset by comparing MHD simulations with actual observational data from THEMIS satellites and auroral observations.

Method: Selected THEMIS substorm onset events with good auroral conjunction, inferred pre-onset magnetotail conditions from in-situ data, ran MHD simulations, extracted ballooning instability and plasmoid signatures, compared with observational magnetic fields and flow patterns, and mapped field-aligned currents to auroral ionosphere for comparison.

Result: The study compares simulation signatures of ballooning instability and plasmoid formation with observational data, evaluates field-aligned current density mapping to auroral ionosphere, and compares with auroral patterns in terms of growth rate, dominant wavenumber, and absolute intensities.

Conclusion: This validation effort represents the first step toward developing a self-consistent coupling model that includes magnetotail-ionosphere interaction in the substorm onset process, bridging simulation predictions with observational evidence.

Abstract: The nonlinear development of ballooning instability and the subsequently induced plasmoid formation in the near-Earth magnetotail demonstrated in MHD simulations has been proposed as a potential trigger mechanism for substorm onset over the past decade, and their connections to the in-situ satellite and ground all-sky auroral optical observations have been a subject of continued research. In this work, a set of THEMIS substorm onset events with good conjunction of auroral observations has been selected for comparative simulation study, whose pre-onset magnetotail configuration and conditions are inferred from in-situ data and compared with the onset conditions of ballooning instability obtained in our MHD simulations. The evolution of the near-Earth magnetotail is followed, where the signatures of ballooning instability and the plasmoid formation are extracted from simulations and compared with the magnetic fields and flow patterns within the magnetotail region from observation data. The field-aligned current (FAC) density is evaluated at the Earth side boundary of the magnetotail domain of simulation, which is further mapped along magnetic field lines to the auroral ionosphere and compared with the auroral pattern and evolution there in terms of growth rate, dominant wavenumber, and absolute auroral intensities. Such validation efforts are also the first step towards the development of a self-consistent coupling model that includes the magnetotail-ionosphere interaction in the substorm onset process.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [43] [Penalized Likelihood Parameter Estimation for Differential Equation Models: A Computational Tutorial](https://arxiv.org/abs/2602.04891)
*Matthew J Simpson,James S Bennett,Alexander Johnston,Ruth E Baker*

Main category: stat.ME

TL;DR: This paper presents a tutorial on generalized profiling (parameter cascading) for parameter estimation in differential equation models, providing computational exercises and Jupyter notebooks to help practitioners learn and apply this underutilized method.


<details>
  <summary>Details</summary>
Motivation: Generalized profiling offers advantages over standard parameter estimation methods like MLE and MCMC by directly linking models and data through penalized likelihood, but it remains underutilized in practice despite its benefits.

Method: The paper provides self-directed computational exercises and reproducible Jupyter notebooks that guide users through applying generalized profiling to various ordinary differential equation models, facilitating hands-on learning.

Result: The tutorial materials enable practitioners to develop skills in generalized profiling through practical implementation, with all calculations reproducible using open-source notebooks available on GitHub.

Conclusion: This tutorial aims to increase adoption of generalized profiling by providing accessible, hands-on learning resources that bridge the gap between theoretical advantages and practical implementation for parameter estimation in differential equation models.

Abstract: Parameter estimation connects mathematical models to real-world data and decision making across many scientific and industrial applications. Standard approaches such as maximum likelihood estimation and Markov chain Monte Carlo estimate parameters by repeatedly solving the model, which often requires numerical solutions of differential equation models. In contrast, generalized profiling (also called parameter cascading) focuses directly on the governing differential equation(s), linking the model and data through a penalized likelihood that explicitly measures both the data fit and model fit. Despite several advantages, generalized profiling is relatively rarely used in practice. This tutorial-style article outlines a set of self-directed computational exercises that facilitate skills development in applying generalized profiling to a range of ordinary differential equation models. All calculations can be repeated using reproducible open-source Jupyter notebooks that are available on GitHub.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [44] [The Correlation Length of Turbulence in Magnetic Clouds](https://arxiv.org/abs/2602.05450)
*S. W. Good,J. Lalueza Puértolas,A. -S. M. Jylhä,E. K. J. Kilpua*

Main category: astro-ph.SR

TL;DR: Researchers detrend magnetic field data from solar wind magnetic clouds using force-free flux rope fits to accurately measure turbulence correlation lengths, finding significantly smaller values than without detrending, and analyze spectral scaling effects.


<details>
  <summary>Details</summary>
Motivation: Measuring turbulence correlation lengths in solar wind magnetic clouds is complicated by the presence of global flux rope structures, which can lead to overestimates when not properly removed from magnetic field time series.

Method: Used force-free flux rope fits to detrend magnetic field time series from Parker Solar Probe measurements in two magnetic clouds, then calculated turbulence correlation lengths from the detrended data.

Result: Detrended correlation lengths were 2.7×10⁴ proton inertial lengths at 0.77 au and 1.6×10⁴ at 0.39 au, significantly smaller than undetrended values. Flux rope increments showed k⁻³ scaling at large scales but didn't affect the inertial range's k⁻⁵/³ scaling.

Conclusion: Proper detrending of flux rope structures is essential for accurate turbulence correlation length measurements in magnetic clouds, and these lengths may relate to mesoscale cloud structure.

Abstract: The large-scale limit or outer scale of turbulence in the solar wind is associated with the correlation length of the magnetic field. Determining correlation lengths from magnetic field time series in magnetic clouds is complicated by the presence of the global flux rope: without removal of the flux rope trend, correlation length measurements will be sensitive to the flux rope as well as the turbulence, and give overestimates of the outer scale when turbulence amplitudes at the outer scale are small relative to the flux rope amplitude. We have used force-free flux rope fits to detrend magnetic field time series measured by Parker Solar Probe in two magnetic clouds and calculated the turbulence correlation length in the clouds using the detrended data. The detrended correlation length in terms of the proton inertial length, $d_p$, was $2.7\times10^{4} d_p$ in one cloud (observed at 0.77 au) and $1.6\times10^{4}d_p$ in the other (observed at 0.39 au), significantly smaller than the values obtained without detrending. Increments in the flux rope fits scaled equivalently to a $k^{-3}$ wavenumber power spectrum; this contribution from the flux rope considerably steepened the total spectrum at the largest scales but had a negligible effect in the inertial range, where scaling in both clouds equivalent to $\sim$$k^{-5/3}$ was observed. Finally, we discuss the possible relation of turbulence correlation lengths to mesoscale structure in magnetic clouds.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [45] [Towards uncertainty quantification of a model for cancer-on-chip experiments](https://arxiv.org/abs/2602.06018)
*Silvia Bertoluzza,Vittoria Bianchi,Gabriella Bretti,Lorenzo Tamellini,Pietro Zanotti*

Main category: cs.CE

TL;DR: This paper develops a data-informed uncertainty quantification framework for predicting cancer-on-chip dynamics using chemotaxis models, combining sensitivity analysis, Bayesian parameter estimation, and forward uncertainty propagation with surrogate modeling.


<details>
  <summary>Details</summary>
Motivation: To develop predictive models for cancer-on-chip experiments that can account for parameter uncertainty and use experimental data to improve predictions of cancer-immune cell interactions.

Method: Uses a Keller-Segel-type chemotaxis model solved with Hybridized Discontinuous Galerkin method, then applies uncertainty quantification techniques: global sensitivity analysis (Sobol/Morris indices), Bayesian inverse UQ for parameter estimation, and forward UQ with sparse-grid surrogate models.

Result: Develops a comprehensive UQ pipeline that identifies influential parameters, estimates data-informed parameter distributions, and quantifies residual uncertainty in model predictions, all accelerated by surrogate modeling.

Conclusion: The proposed framework enables data-informed prediction of cancer-on-chip dynamics while quantifying uncertainty, providing a foundation for experimental control and optimization in cancer research.

Abstract: This study is a first step towards using data-informed differential models to predict and control the dynamics of cancer-on-chip experiments. We consider a conceptualized one-dimensional device, containing a cancer and a population of white blood cells. The interaction between the cancer and the population of cells is modeled by a chemotaxis model inspired by Keller-Segel-type equations, which is solved by a Hybridized Discontinuous Galerkin method. Our goal is using (synthetic) data to tune the parameters of the governing equations and to assess the uncertainty on the predictions of the dynamics due to the residual uncertainty on the parameters remaining after the tuning procedure. To this end, we apply techniques from uncertainty quantification for parametric differential models. We first perform a global sensitivity analysis using both Sobol and Morris indices to assess how parameter uncertainty impacts model predictions, and fix the value of parameters with negligible impact. Subsequently, we conduct an inverse uncertainty quantification analysis by Bayesian techniques to compute a data-informed probability distribution of the remaining model parameters. Finally, we carry out a forward uncertainty quantification analysis to compute the impact of the updated (residual) parametric uncertainties on the quantities of interest of the model. The whole procedure is sped up by using surrogate models, based on sparse-grids, to approximate the mapping of the uncertain parameters to the quantities of interest.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [46] [$L^q$-norm bounds for arithmetic eigenfunctions via microlocal Kakeya-Nikodym estimate](https://arxiv.org/abs/2602.05697)
*Jiaqi Hou,Xiaoqi Huang*

Main category: math.NT

TL;DR: The paper proves a power saving improvement for the global L⁶-norm of Hecke-Maass forms on compact arithmetic hyperbolic surfaces, beating Sogge's local bound via arithmetic amplification techniques.


<details>
  <summary>Details</summary>
Motivation: To improve upon Sogge's local bound for L⁶-norms of eigenfunctions on Riemannian manifolds in the arithmetic setting, leveraging the special arithmetic structure of Hecke-Maass forms to obtain better estimates.

Method: 1. Uses Iwaniec-Sarnak's L∞-norm bound as input. 2. Reduces L⁶-norm problem to microlocal L⁶ Kakeya-Nikodym estimate via harmonic analysis. 3. Establishes improved microlocal estimate using arithmetic amplification techniques developed by Iwaniec and Sarnak.

Result: Proves ‖ψ‖_{L⁶(X)} ≲_ε λ^{1/6 - 1/144 + ε}, achieving power saving of 1/144 over Sogge's local bound λ^{1/6} for Hecke-Maass forms with large spectral parameter λ.

Conclusion: Arithmetic structure of Hecke-Maass forms enables breaking the universal local bounds for eigenfunction norms, demonstrating the power of arithmetic methods in spectral geometry problems.

Abstract: Let $X$ be a compact arithmetic hyperbolic surface, and let $ψ$ be an $L^2$-normalized Hecke-Maass form on $X$ with sufficiently large spectral parameter $λ$. We give a new proof to obtain some power saving for the global $L^6$-norm $\|ψ\|_{L^6(X)}\lesssim_ελ^{\frac{1}{6}-\frac{1}{144}+ε}$ over the local bound $\|ψ\|_{L^6(X)}\lesssimλ^{\frac16}$ of Sogge. Using the $L^\infty$-norm bound $\|ψ\|_{L^\infty(X)}\lesssim_ελ^{\frac{5}{12}+ε}$ of Iwaniec and Sarnak and harmonic analysis tools, we reduce the $L^6$-norm problem to a microlocal $L^6$ Kakeya-Nikodym estimate for $ψ$. Finally, we establish an improved microlocal $L^6$ Kakeya-Nikodym estimate via arithmetic amplification developed by Iwaniec and Sarnak.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics](https://arxiv.org/abs/2602.04975)
*José Afonso,Vasco Guerra,Pedro Viegas*

Main category: cs.LG

TL;DR: A stochastic hierarchical optimization framework using reduced Hessian approximation for efficient calibration of physical models, validated on plasma-surface interaction problems.


<details>
  <summary>Details</summary>
Motivation: Physical model calibration is computationally expensive, especially for complex systems like plasma-surface interactions where uncertainties in surface reactivity parameters and high computational costs of kinetic simulations limit accurate modeling.

Method: Stochastic hierarchical optimization framework inspired by Sloppy Model theory, using reduced Hessian approximation to identify and target stiff parameter subspace with minimal simulation queries, integrated with probabilistic formulation for principled objective loss function.

Result: Method consistently outperforms baseline optimization techniques in sample efficiency when applied to plasma-surface interaction problems.

Conclusion: The approach offers a general and scalable tool for optimizing models of complex reaction systems, applicable to diverse domains from plasma chemistry to biochemical networks.

Abstract: This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simulation queries. This strategy enables efficient navigation of highly anisotropic landscapes, avoiding the computational burden of exhaustive sampling. To ensure rigorous inference, we integrate this approach with a probabilistic formulation that derives a principled objective loss function directly from observed data. We validate the framework by applying it to the problem of plasma-surface interactions, where accurate modelling is strictly limited by uncertainties in surface reactivity parameters and the computational cost of kinetic simulations. Comparative analysis demonstrates that our method consistently outperforms baseline optimization techniques in sample efficiency. This approach offers a general and scalable tool for optimizing models of complex reaction systems, ranging from plasma chemistry to biochemical networks.

</details>


### [48] [SpectraKAN: Conditioning Spectral Operators](https://arxiv.org/abs/2602.05187)
*Chun-Wun Cheng,Carola-Bibiane Schönlieb,Angelica I. Aviles-Rivero*

Main category: cs.LG

TL;DR: SpectraKAN is a novel neural operator that conditions spectral convolution on input data, enabling adaptive multi-scale PDE solving with state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: Existing spectral neural operators like FNO use static Fourier kernels applied uniformly across inputs, which limits their ability to capture multi-scale, regime-dependent, and anisotropic dynamics that depend on the global system state.

Method: SpectraKAN extracts a compact global representation from spatio-temporal history and uses single-query cross-attention to modulate a multi-scale Fourier trunk, turning static spectral convolution into an input-conditioned integral operator.

Result: SpectraKAN achieves state-of-the-art performance across diverse PDE benchmarks, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.

Conclusion: The proposed input-conditioned spectral operator enables adaptive behavior while retaining spectral mixing efficiency, with theoretical justification showing convergence to resolution-independent continuous operators under mesh refinement.

Abstract: Spectral neural operators, particularly Fourier Neural Operators (FNO), are a powerful framework for learning solution operators of partial differential equations (PDEs) due to their efficient global mixing in the frequency domain. However, existing spectral operators rely on static Fourier kernels applied uniformly across inputs, limiting their ability to capture multi-scale, regime-dependent, and anisotropic dynamics governed by the global state of the system. We introduce SpectraKAN, a neural operator that conditions the spectral operator on the input itself, turning static spectral convolution into an input-conditioned integral operator. This is achieved by extracting a compact global representation from spatio-temporal history and using it to modulate a multi-scale Fourier trunk via single-query cross-attention, enabling the operator to adapt its behaviour while retaining the efficiency of spectral mixing. We provide theoretical justification showing that this modulation converges to a resolution-independent continuous operator under mesh refinement and KAN gives smooth, Lipschitz-controlled global modulation. Across diverse PDE benchmarks, SpectraKAN achieves state-of-the-art performance, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [49] [A term-by-term variational multiscale method with dynamic subscales for incompressible turbulent aerodynamics](https://arxiv.org/abs/2602.05563)
*Diego Escobar,Douglas Pacheco,Alejando Aguirre,Ernesto Castillo*

Main category: physics.flu-dyn

TL;DR: A dynamic term-by-term VMS stabilized formulation for incompressible flows from laminar to turbulent regimes, embedded in pressure-correction framework, validated on large-scale aerodynamics with unstructured meshes up to 40M elements.


<details>
  <summary>Details</summary>
Motivation: To develop a unified VMS framework that handles under-resolved flow scales without problem-specific turbulence models, providing robust control of convection-dominated dynamics in complex 3D settings while allowing equal-order velocity-pressure interpolation.

Method: Dynamic term-by-term VMS stabilized formulation embedded in incremental pressure-correction fractional-step framework with minimal stabilization terms, using orthogonal projections to ensure dissipation through dynamic subscales suitable for turbulent simulations.

Result: Method validated on large-scale external aerodynamics (Ahmed body at Re=7.68×10^5, multiple slant angles) using unstructured tetrahedral meshes (3-40M elements), and demonstrated on realistic Formula 1 configuration at Re≈10^6. Captures separated-flow features and coherent wake organization with consistent velocity/pressure spectra.

Conclusion: The proposed stabilized pressure-segregated formulation remains robust at scale, provides dissipation control in under-resolved regimes within a unified stabilized finite element framework, and exhibits finite frequency ranges compatible with inertial-subrange reference slopes.

Abstract: Variational multiscale (VMS) methods offer a robust framework for handling under-resolved flow scales without resorting to problem-specific turbulence models. Here, we propose and assess a dynamic, term-by-term VMS stabilized formulation for simulating incompressible flows from laminar to turbulent regimes. The method is embedded in an incremental pressure-correction fractional-step framework and employs a minimal set of stabilization terms, yielding a unified discretization that (i) allows equal-order velocity--pressure interpolation and (ii) provides robust control of convection-dominated dynamics in complex three-dimensional settings. Orthogonal projections are a key ingredient and ensure that the non-residual, term-by-term structure induces dissipation through dynamic subscales suitable for turbulent simulations. The methodology is validated on large-scale external-aerodynamics configurations, including the Ahmed body at Re $ = 7.68\times 10^{5}$ for multiple slant angles, using unstructured tetrahedral meshes ranging from 3 to 40 million elements. Applicability is further demonstrated on a realistic Formula~1 configuration at $U_\infty=56~\mathrm{m/s}$ (201.6~km/h), corresponding to Re $ \approx 10^{6}$. The results show that the proposed stabilized pressure-segregated formulation remains robust at scale and captures key separated-flow features and coherent wake organization. Pointwise velocity and pressure spectra provide an a posteriori consistency indicator, exhibiting finite frequency ranges compatible with inertial-subrange reference slopes in the resolved band and supporting dissipation control in under-resolved regimes within a unified stabilized finite element framework.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [50] [Branch-and-Bound Tensor Networks for Exact Ground-State Characterization](https://arxiv.org/abs/2602.05470)
*Yijia Wang,Xuanzhao Gao,Pan Zhang,Feng Pan,Jinguo Liu*

Main category: cond-mat.stat-mech

TL;DR: BBTN method combines branch-and-bound with tropical tensor networks to solve NP-hard ground-state problems, achieving massive speedups over existing methods and enabling exact solutions at unprecedented scales.


<details>
  <summary>Details</summary>
Motivation: Characterizing ground-state properties of disordered systems (spin glasses, combinatorial optimization) is fundamental but computationally challenging due to NP-hard and #P-hard complexity. Tensor Network methods have shown promise but suffer from exponential space complexity limitations that restrict scalability.

Method: Introduces Branch-and-Bound Tensor Network (BBTN) method that integrates adaptive search framework of branch-and-bound with efficient contraction of tropical tensor networks. This hybrid approach combines the systematic search strategy of branch-and-bound with the computational efficiency of tensor network contractions.

Result: BBTN significantly outperforms state-of-the-art solvers: enables exact ground-state counting for ±J spin glasses up to 64×64, solves Maximum Independent Set problems on King's subgraphs up to 100×100. Dramatically reduces computational cost - compresses years of runtime into minutes for hard instances. Outperforms leading integer-programming solvers by over 30×.

Conclusion: BBTN establishes a versatile and scalable framework that pushes the boundaries of tractability for hard problems in statistical physics and combinatorial optimization, overcoming fundamental limitations of previous tensor network methods through innovative integration of branch-and-bound search strategies.

Abstract: Characterizing the ground-state properties of disordered systems, such as spin glasses and combinatorial optimization problems, is fundamental to science and engineering. However, computing exact ground states and counting their degeneracies are generally NP-hard and #P-hard problems, respectively, posing a formidable challenge for exact algorithms. Recently, Tensor Networks methods, which utilize high-dimensional linear algebra and achieve massive hardware parallelization, have emerged as a rapidly developing paradigm for efficiently solving these tasks. Despite their success, these methods are fundamentally constrained by the exponential growth of space complexity, which severely limits their scalability. To address this bottleneck, we introduce the Branch-and-Bound Tensor Network (BBTN) method, which seamlessly integrates the adaptive search framework of branch-and-bound with the efficient contraction of tropical tensor networks, significantly extending the reach of exact algorithms. We show that BBTN significantly surpasses existing state-of-the-art solvers, setting new benchmarks for exact computation. It pushes the boundaries of tractability to previously unreachable scales, enabling exact ground-state counting for $\pm J$ spin glasses up to $64 \times 64$ and solving Maximum Independent Set problems on King's subgraphs up to $100 \times 100$. For hard instances, BBTN dramatically reduces the computational cost of standard Tropical Tensor Networks, compressing years of runtime into minutes. Furthermore, it outperforms leading integer-programming solvers by over 30$\times$, establishing a versatile and scalable framework for solving hard problems in statistical physics and combinatorial optimization.

</details>


### [51] [Exchange Monte Carlo for continuous-space Path Integral Monte Carlo simulation](https://arxiv.org/abs/2602.05500)
*Xun Zhao,Synge Todo*

Main category: cond-mat.stat-mech

TL;DR: Novel Exchange Monte Carlo method for continuous-space Path Integral Monte Carlo that addresses autocorrelation issues in bosonic systems and improves efficiency for long-range potentials.


<details>
  <summary>Details</summary>
Motivation: Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, especially when measuring observables affected by particle permutations like winding number. There's a need to accelerate Monte Carlo dynamics for global observables sensitive to permutation effects.

Method: 1) Exchange Monte Carlo method with exchange update scheme facilitating replica transitions between different interaction regimes. 2) Incorporation of Stochastic Potential Switching to efficiently decompose interactions for long-range pair potentials like Lennard-Jones and Aziz potentials.

Result: The method significantly accelerates Monte Carlo dynamics, particularly for global observables sensitive to permutation effects, and substantially enhances computational efficiency for long-range interatomic pair potentials.

Conclusion: The novel Exchange Monte Carlo method combined with Stochastic Potential Switching provides an effective solution to autocorrelation problems in PIMC simulations of bosonic systems, improving both sampling efficiency and computational performance for long-range potentials.

Abstract: We present a novel Exchange Monte Carlo (EMC) method designed for application in continuous-space Path Integral Monte Carlo (PIMC) simulations at finite temperature. Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, particularly when measuring observables affected by particle permutations, such as the winding number. To address this issue, we introduce an exchange update scheme that facilitates replica transitions between different interaction regimes, significantly accelerating Monte Carlo dynamics-especially for global observables sensitive to permutation effects. Furthermore, we incorporate Stochastic Potential Switching (SPS) to efficiently decompose interactions, substantially enhancing computational efficiency for long-range interatomic pair potentials such as the Lennard-Jones and Aziz potentials.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [52] [lrux: Fast low-rank updates of determinants and Pfaffians in JAX](https://arxiv.org/abs/2602.05255)
*Ao Chen,Christopher Roth*

Main category: cond-mat.str-el

TL;DR: lrux is a JAX-based package for fast low-rank updates of determinants and Pfaffians, reducing computational cost from O(n³) to O(n²k) for quantum Monte Carlo algorithms.


<details>
  <summary>Details</summary>
Motivation: The dominant computational bottleneck in various quantum Monte Carlo algorithms is the repeated evaluation of determinants and Pfaffians, which traditionally scales as O(n³). There's a need for efficient low-rank update methods to accelerate these calculations, especially on modern accelerators like GPUs.

Method: The package implements efficient low-rank update algorithms for both determinants and Pfaffians, with delayed-update strategies that trade floating-point operations for reduced memory traffic. It natively integrates with JAX transformations including JIT compilation, vectorization, and automatic differentiation, supporting both real and complex data types.

Result: Benchmarks on GPUs demonstrate up to 1000× speedup at large matrix sizes. The package provides scalable, high-performance evaluation of antisymmetric wavefunctions and serves as a drop-in component for quantum Monte Carlo workflows.

Conclusion: lrux enables efficient low-rank updates for determinants and Pfaffians, significantly accelerating quantum Monte Carlo calculations while maintaining compatibility with modern JAX-based workflows and GPU acceleration.

Abstract: We present lrux, a JAX-based software package for fast low-rank updates of determinants and Pfaffians, targeting the dominant computational bottleneck in various quantum Monte Carlo (QMC) algorithms. The package implements efficient low-rank updates that reduce the cost of successive wavefunction evaluations from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2k)$ when the update rank $k$ is smaller than the dimension $n$ of matrices. Both determinant and Pfaffian updates are supported, together with delayed-update strategies that trade floating-point operations for reduced memory traffic on modern accelerators. lrux natively integrates with JAX transformations such as JIT compilation, vectorization, and automatic differentiation, and supports both real and complex data types. Benchmarks on GPUs demonstrate up to $1000\times$ speedup at large matrix sizes. lrux enables scalable, high-performance evaluation of antisymmetric wavefunctions and is designed as a drop-in component for a wide range of QMC workflows. lrux is available at https://github.com/ChenAo-Phys/lrux.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [53] [Radon--Wasserstein Gradient Flows for Interacting-Particle Sampling in High Dimensions](https://arxiv.org/abs/2602.05227)
*Elias Hess-Childs,Dejan Slepčev,Lantian Xu*

Main category: stat.ML

TL;DR: New gradient flows for KL divergence with efficient particle approximations: Radon-Wasserstein and Regularized Radon-Wasserstein geometries enable high-dimensional optimization with linear scaling in particles and dimensions.


<details>
  <summary>Details</summary>
Motivation: Existing gradient flows for KL divergence (like Fokker-Planck and Stein Variational Gradient Descent) need efficient particle approximations in high dimensions. Current methods have computational limitations, so new geometries are needed that allow accurate approximations with linear scaling in both particles and dimensions.

Method: Introduce new transportation-based Riemannian geometries: Radon-Wasserstein (RW) and Regularized Radon-Wasserstein (RRW) geometries. These use the Radon transform so gradient-flow velocities depend only on 1D projections. This enables efficient Fast Fourier Transform-based evaluation of 1D convolutions for particle approximations.

Result: Algorithms with per-step cost scaling linearly in both number of particles and dimension. Numerical experiments show performance, convergence behavior, and quantization. Theoretical results include well-posedness of flows and long-time convergence guarantees for RRW flow.

Conclusion: The proposed Radon-Wasserstein geometries provide a novel framework for gradient flows of KL divergence that combines theoretical guarantees with practical computational efficiency, enabling high-dimensional optimization with linear scaling.

Abstract: Gradient flows of the Kullback--Leibler (KL) divergence, such as the Fokker--Planck equation and Stein Variational Gradient Descent, evolve a distribution toward a target density known only up to a normalizing constant. We introduce new gradient flows of the KL divergence with a remarkable combination of properties: they admit accurate interacting-particle approximations in high dimensions, and the per-step cost scales linearly in both the number of particles and the dimension. These gradient flows are based on new transportation-based Riemannian geometries on the space of probability measures: the Radon--Wasserstein geometry and the related Regularized Radon--Wasserstein (RRW) geometry. We define these geometries using the Radon transform so that the gradient-flow velocities depend only on one-dimensional projections. This yields interacting-particle-based algorithms whose per-step cost follows from efficient Fast Fourier Transform-based evaluation of the required 1D convolutions. We additionally provide numerical experiments that study the performance of the proposed algorithms and compare convergence behavior and quantization. Finally, we prove some theoretical results including well-posedness of the flows and long-time convergence guarantees for the RRW flow.

</details>


### [54] [Wedge Sampling: Efficient Tensor Completion with Nearly-Linear Sample Complexity](https://arxiv.org/abs/2602.05869)
*Hengrui Luo,Anna Ma,Ludovic Stephan,Yizhe Zhu*

Main category: stat.ML

TL;DR: Wedge Sampling enables polynomial-time low-rank tensor completion with nearly linear sample complexity by using structured length-two patterns instead of uniform sampling.


<details>
  <summary>Details</summary>
Motivation: Standard uniform sampling for tensor completion requires ~O(n^{k/2}) samples for efficient algorithms, creating a statistical-to-computational gap. The authors aim to overcome this barrier with alternative non-adaptive sampling designs.

Method: Wedge sampling allocates observations to structured length-two patterns (wedges) in an associated bipartite graph, promoting informative correlations. This strengthens spectral signals for initialization, then combines with refinement procedures using only additional ~O(n) uniform samples.

Result: Enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in n. The approach substantially improves over the ~O(n^{k/2}) sample complexity typically required under uniform sampling.

Conclusion: The statistical-to-computational gap in tensor completion is largely a consequence of uniform entry sampling, and alternative non-adaptive measurement designs like wedge sampling can overcome this barrier by guaranteeing strong initialization.

Abstract: We introduce Wedge Sampling, a new non-adaptive sampling scheme for low-rank tensor completion. We study recovery of an order-$k$ low-rank tensor of dimension $n \times \cdots \times n$ from a subset of its entries. Unlike the standard uniform entry model (i.e., i.i.d. samples from $[n]^k$), wedge sampling allocates observations to structured length-two patterns (wedges) in an associated bipartite sampling graph. By directly promoting these length-two connections, the sampling design strengthens the spectral signal that underlies efficient initialization, in regimes where uniform sampling is too sparse to generate enough informative correlations.
  Our main result shows that this change in sampling paradigm enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in $n$. The approach is also plug-and-play: wedge-sampling-based spectral initialization can be combined with existing refinement procedures (e.g., spectral or gradient-based methods) using only an additional $\tilde{O}(n)$ uniformly sampled entries, substantially improving over the $\tilde{O}(n^{k/2})$ sample complexity typically required under uniform entry sampling for efficient methods. Overall, our results suggest that the statistical-to-computational gap highlighted in Barak and Moitra (2022) is, to a large extent, a consequence of the uniform entry sampling model for tensor completion, and that alternative non-adaptive measurement designs that guarantee a strong initialization can overcome this barrier.

</details>


### [55] [Diffusion Model's Generalization Can Be Characterized by Inductive Biases toward a Data-Dependent Ridge Manifold](https://arxiv.org/abs/2602.06021)
*Ye He,Yitong Qiu,Molei Tao*

Main category: stat.ML

TL;DR: The paper analyzes how diffusion models generalize by characterizing the generated distribution through a log-density ridge manifold, revealing an inference process of reach-align-slide around this manifold.


<details>
  <summary>Details</summary>
Motivation: To quantitatively understand how diffusion models generalize when not memorizing training data, which is important for assessing model performance in downstream applications.

Method: Proposes a log-density ridge manifold framework to characterize generated data, analyzing inference dynamics as a reach-align-slide process around the manifold, and using random feature models to illustrate inductive biases.

Result: Inference undergoes reach-align-slide process: trajectories reach manifold neighborhood, align in normal directions, then slide along manifold in tangent directions. Different training errors lead to quantifiable normal/tangent motions that characterize inter-mode generations.

Conclusion: The framework provides detailed understanding of diffusion model generalization, showing how inductive biases originate from architectural bias and training accuracy, with experimental support from synthetic multimodal distributions and MNIST latent diffusion.

Abstract: When a diffusion model is not memorizing the training data set, how does it generalize exactly? A quantitative understanding of the distribution it generates would be beneficial to, for example, an assessment of the model's performance for downstream applications. We thus explicitly characterize what diffusion model generates, by proposing a log-density ridge manifold and quantifying how the generated data relate to this manifold as inference dynamics progresses. More precisely, inference undergoes a reach-align-slide process centered around the ridge manifold: trajectories first reach a neighborhood of the manifold, then align as being pushed toward or away from the manifold in normal directions, and finally slide along the manifold in tangent directions. Within the scope of this general behavior, different training errors will lead to different normal and tangent motions, which can be quantified, and these detailed motions characterize when inter-mode generations emerge. More detailed understanding of training dynamics will lead to more accurate quantification of the generation inductive bias, and an example of random feature model will be considered, for which we can explicitly illustrate how diffusion model's inductive biases originate as a composition of architectural bias and training accuracy, and how they evolve with the inference dynamics. Experiments on synthetic multimodal distributions and MNIST latent diffusion support the predicted directional effects, in both low- and high-dimensions.

</details>
