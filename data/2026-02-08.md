<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [math.AP](#math.AP) [Total: 22]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [math.PR](#math.PR) [Total: 2]
- [stat.ME](#stat.ME) [Total: 1]
- [stat.ML](#stat.ML) [Total: 3]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 1]
- [math.NT](#math.NT) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A uniformly accurate multiscale time integrator for the nonlinear Klein-Gordon equation in the nonrelativistic regime via simplified transmission conditions](https://arxiv.org/abs/2602.04988)
*Weizhu Bao,Caoyi Liu*

Main category: math.NA

TL;DR: A new multiscale time integrator Fourier pseudospectral (MTI-FP) method for nonlinear Klein-Gordon equation achieves uniform first-order accuracy in time for small epsilon (nonrelativistic regime) with super-resolution properties.


<details>
  <summary>Details</summary>
Motivation: The nonlinear Klein-Gordon equation with small epsilon (inversely proportional to speed of light) has highly oscillatory solutions with O(epsilon^2)-wavelength, making it difficult to design uniformly accurate numerical methods that work across all epsilon values.

Method: MTI-FP combines: (i) multiscale decomposition by frequency with simplified transmission conditions in each time interval, (ii) exponential wave integrator for temporal discretization, and (iii) Fourier pseudospectral method for spatial discretization. Uses linear interpolation of micro variables for uniform accuracy.

Result: Achieves uniform first-order accuracy in time with error bounds O(h^{m0}+tau) independent of epsilon. Demonstrates super-resolution: accurate solutions even when time step >> O(epsilon^2)-wavelength. Applied to study convergence rates of NKGE to limiting models.

Conclusion: The MTI-FP method successfully addresses the challenge of highly oscillatory solutions in the nonrelativistic regime, providing uniformly accurate numerical solutions with super-resolution properties that outperform traditional methods constrained by the small wavelength.

Abstract: We propose a new and simplified multiscale time integrator Fourier pseudospectral (MTI-FP) method for the nonlinear Klein-Gordon equation (NKGE) with a dimensionless parameter epsilon in (0,1] inversely proportional to the speed of light, and establish its uniform first-order accuracy in time in the nonrelativistic regime, i.e. 0 < epsilon << 1. In this regime, the solution of the NKGE is highly oscillatory in time with O(epsilon^2)-wavelength, which brings significant difficulties in designing uniformly accurate numerical methods. The MTI-FP is based on (i) a multiscale decomposition by frequency of the NKGE in each time interval with simplified transmission conditions, and (ii) an exponential wave integrator for temporal discretization and a Fourier pseudospectral method for spatial discretization. By adapting the energy method and the mathematical induction, we obtain two error bounds in H1-norm at O(h^{m0}+tau^2/epsilon^2) and O(h^{m0}+tau+epsilon^2) with mesh size h, time step tau and m0 an integer dependent on the regularity of the solution, which immediately implies a uniformly accurate error bound O(h^{m0}+tau) with respect to epsilon in (0,1]. In addition, by adopting a linear interpolation of the micro variables with the multiscale decomposition in each time interval, we obtain a uniformly accurate numerical solution for any time t larger than zero. Thus the proposed MTI-FP method has a super resolution property in time in terms of the Shannon sampling theory, i.e. accurate numerical solutions can be obtained even when the time step is much bigger than the O(epsilon^2)-wavelength. Extensive numerical results are reported to confirm our error bounds and demonstrate their super resolution in time. Finally the proposed MTI-FP method is applied to study numerically convergence rates of the NKGE to its different limiting models in the nonrelativistic regime.

</details>


### [2] [Acoustic scattering by fractal inhomogeneities via geometry-conforming Galerkin methods for the Lippmann-Schwinger equation](https://arxiv.org/abs/2602.05005)
*Joshua Bannister,David P. Hewett,Andrew Gibbs*

Main category: math.NA

TL;DR: A numerical method for acoustic scattering by fractal-boundary inhomogeneities using Galerkin discretization of Lippmann-Schwinger equation with geometry-conforming fractal meshes.


<details>
  <summary>Details</summary>
Motivation: To develop accurate numerical methods for time-harmonic acoustic scattering problems involving inhomogeneities with fractal boundaries, which are challenging for conventional methods that typically require smooth boundaries.

Method: Galerkin discretization of Lippmann-Schwinger volume integral equation using discontinuous piecewise-polynomial approximation on geometry-conforming meshes with fractal elements. Includes h- and p-versions, with special treatment for n-attractor fractals using self-similarity for mesh generation, and singular quadrature rules for practical implementation.

Result: Provides well-posedness and error analysis for arbitrary inhomogeneities, proves convergence estimates for integral equation solutions and superconvergence for linear functionals. Shows how boundary regularity and refractive index affect convergence rates. Numerical results demonstrate significantly higher accuracy compared to methods using smoother prefractal approximations.

Conclusion: The proposed method effectively handles acoustic scattering by fractal-boundary inhomogeneities, offering superior accuracy over conventional prefractal approximation approaches, with theoretical guarantees and practical implementation capabilities.

Abstract: We propose and analyse a numerical method for time-harmonic acoustic scattering in $\mathbb{R}^n$, $n=2,3$, by a class of inhomogeneities (penetrable scatterers) with fractal boundary. Our method is based on a Galerkin discretisation of the Lippmann-Schwinger volume integral equation, using a discontinuous piecewise-polynomial approximation space on a geometry-conforming mesh comprising elements which themselves have fractal boundary. We first provide a semi-discrete well-posedness and error analysis for both the $h$- and $p$-versions of our method for completely arbitrary inhomogeneities (without any regularity assumption on the boundary of the inhomogeneity or of the mesh elements). We prove convergence estimates for the integral equation solution and superconvergence estimates for linear functionals such as scattered field and far-field pattern evaluations, and elucidate how the regularity of the inhomogeneity boundary and the regularity of the refractive index affect the rates of convergence predicted. We then specialise to the case where the inhomogeneity is an ``$n$-attractor'', i.e.\ the fractal attractor of an iterated function system satisfying the open set condition with non-empty interior, showing how in this case the self-similarity of the inhomogeneity can be used to generate geometry-conforming meshes. For the $h$-version with piecewise constant approximation we also present singular quadrature rules, supported by a fully discrete error analysis, permitting practical implementation of our method. We present numerical results for two-dimensional examples, which validate our theoretical results and show that our method is significantly more accurate than a comparable method involving replacement of the fractal inhomogeneity by a smoother prefractal approximation.

</details>


### [3] [Scalable Fixed-Point Framework for High-Dimensional Hamilton-Jacobi Equations](https://arxiv.org/abs/2602.05124)
*Yesom Park,Stanley Osher*

Main category: math.NA

TL;DR: Novel mesh-free, gradient-free fixed-point method for solving high-dimensional Hamilton-Jacobi equations using Hopf-Lax formula and Picard iteration.


<details>
  <summary>Details</summary>
Motivation: Existing methods for solving high-dimensional Hamilton-Jacobi equations face challenges with grids, characteristics, or differentiation, limiting scalability to high dimensions.

Method: Leverages Hopf-Lax formula to transform HJ equations into variational problems, then uses Picard iteration to solve them without grids, characteristics, or differentiation.

Result: Method achieves high accuracy and efficiency in up to 100 dimensions, with computational times largely independent of dimensionality, suitable for control problems and non-smooth solutions.

Conclusion: Proposed fixed-point approach provides scalable, efficient solution for high-dimensional HJ equations, overcoming limitations of traditional methods.

Abstract: We propose a novel, mesh-free, and gradient-free fixed-point approach for computing viscosity solutions of high-dimensional Hamilton-Jacobi (HJ) equations. By leveraging the Hopf-Lax formula, our approach iteratively solves the associated variational problem via a Picard iteration, enabling efficient evaluation of both the solution and its corresponding control without relying on grids, characteristics, or differentiation. We demonstrate the practical efficacy and scalability of the approach through numerical experiments in up to 100 dimensions, including control problems and non-smooth solutions. Our results show that the proposed scheme achieves high accuracy, is highly efficient, and exhibits computational times that are largely independent of dimensionality, highlighting its suitability for high-dimensional problems.

</details>


### [4] [Numerically Informed Convolutional Operator Network with Subproblem Decomposition for Poisson Equations](https://arxiv.org/abs/2602.05341)
*Kyoungjin Jung,Jae Yong Lee,Dongwook Shin*

Main category: math.NA

TL;DR: NICON: A neural operator framework that couples classical numerical methods (finite difference and finite element) with operator learning through residual-based training losses, providing theoretical convergence guarantees under grid refinement.


<details>
  <summary>Details</summary>
Motivation: Neural operators show strong performance for PDE approximation but lack theoretical understanding of convergence behavior under grid refinement from a numerical analysis perspective.

Method: Proposes NICON with two variants: FD-CON (finite difference convolutional operator network) and FE-CON (finite element convolutional operator network) that use residual-based loss functions derived from corresponding numerical methods, enabling theoretical error analysis.

Result: Derived error estimates showing direct relationship between convergence behavior and training loss decay rate, established training strategies guaranteeing optimal convergence rates under grid refinement, validated with numerical experiments.

Conclusion: NICON bridges classical numerical methods with operator learning, providing theoretically grounded neural operators with provable convergence guarantees under grid refinement.

Abstract: Neural operators have shown remarkable performance in approximating solutions of partial differential equations. However, their convergence behavior under grid refinement is still not well understood from the viewpoint of numerical analysis. In this work, we propose a numerically informed convolutional operator network, called NICON, that explicitly couples classical finite difference and finite element methods with operator learning through residual-based training loss functions. We introduce two types of networks, FD-CON and FE-CON, which use residual-based loss functions derived from the corresponding numerical methods. We derive error estimates for FD-CON and FE-CON using finite difference and finite element analysis. These estimates show a direct relation between the convergence behavior and the decay rate of the training loss. From these analyses, we establish training strategies that guarantee optimal convergence rates under grid refinement. Several numerical experiments are presented to validate the theoretical results and show performance on fine grids.

</details>


### [5] [Linear Systems and Eigenvalue Problems: Open Questions from a Simons Workshop](https://arxiv.org/abs/2602.05394)
*Noah Amsel,Yves Baumann,Paul Beckman,Peter Bürgisser,Chris Camaño,Tyler Chen,Edmond Chow,Anil Damle,Michal Derezinski,Mark Embree,Ethan N. Epperly,Robert Falgout,Mark Fornace,Anne Greenbaum,Chen Greif,Diana Halikias,Zhen Huang,Elias Jarlebring,Yiannis Koutis,Daniel Kressner,Rasmus Kyng,Jörg Liesen,Jackie Lok,Raphael A. Meyer,Yuji Nakatsukasa,Kate Pearce,Richard Peng,David Persson,Eliza Rebrova,Ryan Schneider,Rikhav Shah,Edgar Solomonik,Nikhil Srivastava,Alex Townsend,Robert J. Webber,Jess Williams*

Main category: math.NA

TL;DR: This paper presents open questions in matrix computations that emerged from discussions between theoretical computer science and numerical analysis researchers at a 2025 Simons Institute workshop.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between theoretical computer science and numerical analysis by identifying important open problems in matrix computations through interdisciplinary collaboration.

Method: Organized working groups at the "Linear Systems and Eigenvalue Problems" workshop during the Simons Institute's "Complexity and Linear Algebra" program in Fall 2025 to facilitate discussions between researchers from both fields.

Result: Produced a collection of open questions organized into five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas (tensors, quantum systems, matrix functions).

Conclusion: The interdisciplinary approach generated valuable problem formulations that could advance both theoretical understanding and practical numerical solutions in linear algebra.

Abstract: This document presents a series of open questions arising in matrix computations, i.e., the numerical solution of linear algebra problems. It is a result of working groups at the workshop \emph{Linear Systems and Eigenvalue Problems}, which was organized at the Simons Institute for the Theory of Computing program on \emph{Complexity and Linear Algebra} in Fall 2025. The complexity and numerical solution of linear algebra problems %in matrix computations and related fields is a crosscutting area between theoretical computer science and numerical analysis. The value of the particular problem formulations here is that they were produced via discussions between researchers from both groups.
  The open questions are organized in five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas including tensors, quantum systems, and matrix functions.

</details>


### [6] [Taylor-Accelerated Neural Network Interpolation Operators on Irregular Grids with Higher Order Approximation](https://arxiv.org/abs/2602.05589)
*Sachin Saini*

Main category: math.NA

TL;DR: Taylor-accelerated neural network interpolation operators improve existing methods by incorporating Taylor polynomials at sampling nodes to exploit function smoothness, achieving higher-order convergence on irregular grids.


<details>
  <summary>Details</summary>
Motivation: Existing neural network interpolation operators on irregular grids don't fully exploit the smoothness of target functions, limiting convergence rates. The authors aim to develop operators that can achieve higher-order convergence by incorporating local polynomial information.

Method: Introduces Taylor-accelerated neural network interpolation operators that combine neural networks with Taylor polynomials at sampling nodes on quasi-uniform irregular grids. The operators maintain exact interpolation at grid points while incorporating higher-order local approximations.

Result: The operators are proven to be well-defined, uniformly bounded, and satisfy exact interpolation. They achieve polynomial reproduction up to prescribed degree and provide direct approximation estimates using higher-order moduli of smoothness. Numerical experiments show significant accuracy improvement and higher-order convergence on irregular grids, outperforming existing methods including Lagrange-based schemes.

Conclusion: Taylor-accelerated neural network interpolation operators successfully combine neural networks with local polynomial approximations to achieve enhanced convergence rates for smooth functions on irregular grids, representing a significant improvement over existing interpolation methods.

Abstract: In this paper, a new class of \emph{Taylor-accelerated neural network interpolation operators} is introduced on quasi-uniform irregular grids. These operators improve existing neural network interpolation operators by incorporating Taylor polynomials at the sampling nodes, thereby exploiting the higher smoothness of the target function. The proposed operators are shown to be well defined, uniformly bounded, and to satisfy an exact interpolation property at the grid points. In addition, polynomial reproduction up to a prescribed degree is established. Direct approximation estimates are derived in terms of higher-order moduli of smoothness, yielding enhanced convergence rates for sufficiently smooth functions. Numerical experiments are presented to support the theoretical analysis and to demonstrate the significant accuracy improvement achieved through the Taylor-accelerated construction. In particular, higher-order convergence on irregular grids is obtained, and the proposed approach outperforms existing neural network interpolation operators on irregular partitions, including Lagrange-based schemes.

</details>


### [7] [Numerical stationary states for nonlocal Fokker-Planck equations via fixed points of consistency maps](https://arxiv.org/abs/2602.05632)
*José A. Carrillo,Yurij Salmaniw,Antonio León Villares*

Main category: math.NA

TL;DR: A fixed-point numerical framework for computing stationary states of nonlocal Fokker-Planck equations using matrix-free Newton-Krylov methods, capable of detecting both stable and unstable states without time evolution.


<details>
  <summary>Details</summary>
Motivation: To develop a numerical method for computing stationary states of nonlocal Fokker-Planck equations that doesn't rely on time evolution, can detect both stable and unstable states, and is agnostic to dynamical stability.

Method: Reformulate stationary problem as nonlinear fixed-point map from PDE and nonlocal interaction terms, solve with matrix-free Newton-Krylov method, compare analytic Frechet derivative with central-difference approximation.

Result: Method accurately computes stationary states, reproduces known bifurcation diagrams, and reveals new bifurcation behavior not previously observed in such problems.

Conclusion: The fixed-point framework provides an effective approach for stationary state computation in nonlocal Fokker-Planck equations, with accuracy determined by convolution/quadrature treatment rather than differentiation stencils.

Abstract: We propose a fixed-point-based numerical framework for computing stationary states of nonlocal Fokker-Planck-type equations. Instead of discretising the differential operators directly, we reformulate the stationary problem as a nonlinear fixed-point map built from the original PDE and its nonlocal interaction terms, and solve the resulting finite-dimensional problem with a matrix-free Newton-Krylov method. We compare implementations using the analytic Frechet derivative of this map with a simple central-difference approximation. Because the method does not rely on time evolution, it is agnostic to dynamical stability and can detect both stable and unstable stationary states. Its accuracy is determined mainly by the numerical treatment of convolutions and quadrature, rather than by differentiation stencils. We apply the approach to three model problems with linear diffusion, use existing analytical results to verify the outputs, and reproduce known bifurcation diagrams, as well as new bifurcation behaviour not previously observed in this kind of problem.

</details>


### [8] [A penalized φ-FEM scheme for the Poisson Dirichlet problem](https://arxiv.org/abs/2602.05698)
*Raphaël Bulle,Michel Duprez,Vanessa Lleras,Killian Vuillemot*

Main category: math.NA

TL;DR: Penalized φ-FEM scheme for Poisson equation with Dirichlet BCs using level-set geometry description, enforcing BCs via penalization instead of original formulation, requiring level-set only near boundary cells.


<details>
  <summary>Details</summary>
Motivation: To develop an unfitted finite element method that avoids boundary-fitted meshes while simplifying the original φ-FEM formulation by using penalization for boundary conditions, reducing the need for level-set function evaluation throughout the domain.

Method: Penalized φ-FEM scheme using level-set geometry description with boundary conditions enforced through penalization term, requiring level-set function only on cells adjacent to boundary, stabilized with ghost penalty technique.

Result: Derived a priori error estimates showing optimal convergence in H1 semi-norm and quasi-optimal convergence in L2 norm under suitable regularity assumptions. Numerical experiments validate theoretical results and compare with original φ-FEM and standard fitted FEM.

Conclusion: The penalized φ-FEM scheme provides an effective alternative to the original φ-FEM with simplified implementation (level-set needed only near boundary) while maintaining optimal convergence properties comparable to standard fitted FEM methods.

Abstract: In this work, we analyze a penalized variant of the φ-FEM scheme for the Poisson equation with Dirichlet boundary conditions. The φ-FEM is a recently introduced unfitted finite element method based on a level-set description of the geometry, which avoids the need for boundary-fitted meshes. Unlike the original φ-FEM formulation, the method proposed here enforces boundary conditions through a penalization term. This approach has the advantage that the level-set function is required only on the cells adjacent to the boundary in the variational formulation. The scheme is stabilized using a ghost penalty technique. We derive a priori error estimates, showing optimal convergence in the H1 semi-norm and quasi-optimal convergence in the L2 norm under suitable regularity assumptions. Numerical experiments are presented to validate the theoretical results and to compare the proposed method with both the original φ-FEM and the standard fitted finite element method.

</details>


### [9] [Finite element approximation for a reformulation of a 3D fluid-2D plate interaction system](https://arxiv.org/abs/2602.05701)
*Lander Besabe,Hyesuk Lee*

Main category: math.NA

TL;DR: A finite element method for 3D fluid-2D plate interaction using second-order reformulation and Lagrange multiplier coupling.


<details>
  <summary>Details</summary>
Motivation: To develop a practical numerical method for fluid-structure interaction problems that avoids complex H²-conforming or nonconforming plate elements, making the implementation more accessible while maintaining accuracy.

Method: Reformulates fourth-order plate equation into coupled second-order equations using auxiliary variable; enforces coupling via Lagrange multiplier representing fluid pressure trace; uses partitioned domain decomposition with fixed-point iteration.

Result: Establishes well-posedness and stability for time-discrete and fully-discrete problems; derives a priori error estimates; numerical experiments confirm theoretical convergence rates and demonstrate physical applicability.

Conclusion: The proposed method successfully avoids complex plate elements while maintaining theoretical rigor and practical applicability for fluid-structure interaction problems.

Abstract: We study a finite element approximation of a coupled fluid-structure interaction consisting of a three-dimensional incompressible viscous fluid governed by the unsteady Stokes equations and a two-dimensional elastic plate. To avoid the use of $H^2-$conforming or nonconforming $\mathbb{P}_2$-Morley plate elements, the fourth-order plate equation is reformulated into a system of coupled second-order equations using an auxiliary variable. The coupling condition is enforced using a Lagrange multiplier representing the trace of the mean-zero fluid pressure on the interface.
  We establish well-posedness and stability results for the time-discrete and fully-discrete problems, and derive a priori error estimates. A partitioned domain decomposition algorithm based on a fixed-point iteration is employed for the numerical solution. Numerical experiments verify the theoretical rates of convergence in space and time using manufactured solutions, and demonstrate the applicability of the method to a physical problem.

</details>


### [10] [Optimal boundary closures for diagonal-norm upwind SBP operators](https://arxiv.org/abs/2602.05727)
*Ken Mattsson,David Niemelä,Andrew R. Winters*

Main category: math.NA

TL;DR: Boundary-optimized upwind finite-difference operators (up to 9th order) using non-equispaced grid points near boundaries, developed within SBP framework for stability on curvilinear multiblock grids.


<details>
  <summary>Details</summary>
Motivation: To improve accuracy and computational efficiency compared to SBP operators on equidistant grids, while maintaining linear stability on piecewise curvilinear multiblock grids.

Method: Develop boundary-optimized upwind finite-difference operators using non-equispaced grid points near boundaries within diagonal-norm SBP framework. Use SAT for weak boundary/interface enforcement or projection method for strong enforcement.

Result: Significantly improved accuracy and computational efficiency compared to equidistant-grid SBP operators. Produces fully explicit ODE systems. Demonstrated accuracy and stability for linear hyperbolic problems in 1D and compressible Euler equations in 2D.

Conclusion: The proposed boundary-optimized SBP operators with non-equispaced boundary points provide superior accuracy and efficiency while maintaining stability on complex curvilinear grids.

Abstract: By employing non-equispaced grid points near boundaries, boundary-optimized upwind finite-difference operators of orders up to nine are developed. The boundary closures are constructed within a diagonal-norm summation-by-parts (SBP) framework, ensuring linear stability on piecewise curvilinear multiblock grids. Boundary and interface conditions are imposed using either weak enforcement through simultaneous approximation terms (SAT) or strong enforcement via the projection method.
  The proposed operators yield significantly improved accuracy and computational efficiency compared with SBP operators constructed on equidistant grids. The resulting SBP--SAT and SBP--projection discretizations produce fully explicit systems of ordinary differential equations. The accuracy and stability properties of the proposed operators are demonstrated through numerical experiments for linear hyperbolic problems in one spatial dimension and for the compressible Euler equations in two spatial dimensions.

</details>


### [11] [A Perturbation-Correction Method Based on Local Randomized Neural Networks for Quasi-Linear Interface Problems](https://arxiv.org/abs/2602.05800)
*Siyuan Lang,Zhiyue Zhang*

Main category: math.NA

TL;DR: A perturbation-correction framework using Local Randomized Neural Networks overcomes optimization stagnation in quasi-linear interface problems with discontinuous coefficients by converting nonconvex optimization to convex subproblems.


<details>
  <summary>Details</summary>
Motivation: Randomized neural networks struggle with quasi-linear interface problems having discontinuous diffusion coefficients due to nonconvex objective functionals causing optimization stagnation at moderate accuracy levels.

Method: Two-step perturbation-correction framework: 1) Initialization obtains base approximation via nonconvex residual minimization, 2) Correction solves convex subproblem from perturbation expansion around base approximation to determine correction term.

Result: Method overcomes optimization plateau with 4-6 order magnitude improvement in L² accuracy for nonlinear diffusion problems with irregular moving interfaces, gradient-dependent diffusivities, and high-contrast media.

Conclusion: The perturbation-correction framework with LRaNNs effectively addresses optimization stagnation in challenging interface problems, providing rigorous error control and significant accuracy improvements through convex reformulation.

Abstract: For quasi-linear interface problems with discontinuous diffusion coefficients, the nonconvex objective functional often leads to optimization stagnation in randomized neural network approximations. This paper Proposes a perturbation-correction framework based on Loacal Randomized Neural Networks(LRaNNs) to overcome this limitation. In the initialization step, a satisisfactory based approximation is obtained by minimizing the original nonconvex residual, typically stagnating at a moderate accuracy level. Subsequently, in the correction step, a correction term is determined by solving a subproblem governed by a perturbation expansion around the base approximation. This reformulation yields a convex optimization problem for the output coefficients, which guarantees rapic convergence. We rigorously derive an a posteriori error estitmate, demonstrating that the total generalization error is governed by the discrete residual norm, quadrature error, and a controllable truncation error. Numerical experiments on nonlinear diffusion problems with irregular moving interfaces, gradient-dependent diffusivities, and high-contrast media demonstrate that the proposed method effectively overcomes the optimization plateau. The correction step yields a significant improvement of 4-6 order of magnitude in L^2 accuracy.

</details>


### [12] [Spectral Analysis of Block Diagonally Preconditioned Multiple Saddle-Point Matrices with Inexact Schur Complements](https://arxiv.org/abs/2602.05952)
*Marco Pilotto,Luca Bergamaschi,Angeles Martinez*

Main category: math.NA

TL;DR: This paper derives eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices, generalizing previous work to arbitrary block numbers and approximate Schur complements.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend eigenvalue analysis for preconditioned saddle-point systems to more general cases with multiple blocks and approximate Schur complements, building on previous work by Bergamaschi et al.

Method: The authors derive mathematical eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems that are preconditioned with block-diagonal Schur complement matrices. The analysis handles arbitrary numbers of blocks and accounts for cases where Schur complements are approximated rather than exact.

Result: The paper presents generalized eigenvalue bounds that extend previous findings. Numerical experiments are conducted to validate the proposed eigenvalue estimates, confirming their accuracy and applicability.

Conclusion: The analysis successfully generalizes eigenvalue bounds for preconditioned saddle-point systems to arbitrary block configurations and approximate Schur complements, with numerical validation supporting the theoretical results.

Abstract: We derive eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices. This analysis applies to an arbitrary number of blocks and accounts for the case where the Schur complements are approximated, generalizing the findings in [Bergamaschi et al., Linear Algebra and its Applications, 2026]. Numerical experiments are carried out to validate the proposed estimates.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [13] [$\bf{S^1}$-index theory for the Lorentz force equation](https://arxiv.org/abs/2602.05015)
*Cristian Bereanu,Alexandru Pîrvuceanu*

Main category: math.AP

TL;DR: The paper proves existence of multiple periodic solutions to the Lorentz force equation using S¹-invariance and Lusternik-Schnirelman theory with S¹-index.


<details>
  <summary>Details</summary>
Motivation: To establish multiple periodic solutions for the Lorentz force equation by leveraging the S¹-invariance of the Poincaré action functional, extending previous work by Ekeland and Lasry using Fadell-Rabinowitz index.

Method: Develops an abstract multiplicity result using Lusternik-Schnirelman method with S¹-index, applied to nonsmooth functionals with weak compactness conditions suitable for the Poincaré functional.

Result: Proves existence of multiple critical points (periodic solutions) with fixed period for the Lorentz force equation through the S¹-invariance property.

Conclusion: The S¹-invariance of the Poincaré action functional enables application of Lusternik-Schnirelman theory with S¹-index to obtain multiple periodic solutions, generalizing previous Fadell-Rabinowitz index results to nonsmooth functionals.

Abstract: In this paper we prove that the $S^1$-invariance of the Poincaré action functional associated to the Lorentz force equation gives the existence of multiple critical points which are periodic solutions with a fixed period. To do this, we prove an abstract multiplicity result which is based upon the Lusternik-Schnirelman method with the $S^1$-index. The corresponding result in the context of the Fadell-Rabinowitz index is proved in Ekeland and Lasry (Ann. Math., 112 (1980)). The main feature of our abstract result is that it allows us to consider nonsmooth functionals satisfying only a weak compactness condition well adapted to the Poincaré functional.

</details>


### [14] [Painlevé Universality classes for the maximal amplitude solution of the Focusing Nonlinear Schrödinger Equation with randomness](https://arxiv.org/abs/2602.05101)
*Aikaterini Gkogkou,Guido Mazzuca,Kenneth D. T-R McLaughlin*

Main category: math.AP

TL;DR: Extremal N-soliton solutions of focusing nonlinear Schrödinger equation with random eigenvalues exhibit universal convergence to deterministic Painlevé-type rogue wave profiles, forming two distinct universality classes.


<details>
  <summary>Details</summary>
Motivation: To understand the universality of extremal solutions (maximal amplitude N-solitons) in the focusing nonlinear Schrödinger equation when eigenvalues are randomly drawn, and to determine if Painlevé-type rogue wave formation is robust to randomness.

Method: Study extremal N-soliton solutions with discrete eigenvalues randomly drawn from sub-exponential distributions. Analyze two spectral regimes: eigenvalues of form λ_j = v_j + iμ_j (Painlevé-III class) and λ_j = -ζj + v_j + iμ_j with 0<ζ<1 (Painlevé-V class), where μ_j and v_j are subexponential random variables.

Result: Identified two distinct universality classes: 1) Solutions converge locally to deterministic Painlevé-III rogue-wave profile, 2) Solutions converge locally to deterministic Painlevé-V rogue wave profile. Universality holds independently of specific eigenvalue distributions.

Conclusion: Painlevé-type rogue wave formation is a universal phenomenon robust to randomness in extremal solutions of focusing nonlinear Schrödinger equation, with two distinct universality classes determined by macroscopic spectral structure.

Abstract: We establish universality for extremal solutions of the focusing nonlinear Schrödinger equation. Extremal solutions are $N$-soliton solutions that achieve the theoretical maximal amplitude and diverge as $N \to \infty$. We consider extremal solutions with the discrete eigenvalues randomly drawn from sub-exponential distributions, and identify two distinct universality classes, determined by the macroscopic structure of the spectrum: the Painlevé--III rogue-wave solution, where the eigenvalues take the form $λ_j = v_j + i μ_j$, and the Painlevé--V rogue wave solution, where $λ_j = -ζ\, j + v_j + i μ_j$, with $0 < ζ< 1$. (In both cases, $μ_{j}$ and $v_{j}$ are subexponential random variables.) Universality can then be summarized as follows: independently of the specific distribution of the eigenvalues, the rescaled solutions converge locally to a deterministic profile governed by the Painlevé-III equation in the first regime, and the Painlevé-V equation in the second. These results demonstrate that the formation of Painlevé-type rogue waves is a universal phenomenon robust to randomness.

</details>


### [15] [Existence and symmetry of extremals for the high order Hardy-Sobolev-Maz'ya inequalities](https://arxiv.org/abs/2602.05203)
*Guozhen Lu,Chunxia Tao*

Main category: math.AP

TL;DR: Existence of extremal functions for k-th order critical Hardy-Sobolev-Maz'ya inequalities on upper half space via hyperbolic space approach and applications to Brezis-Nirenberg equations.


<details>
  <summary>Details</summary>
Motivation: The paper aims to establish existence of extremal functions for higher-order critical Hardy-Sobolev-Maz'ya inequalities on the upper half space, which is challenging due to higher-order derivatives, lack of translation invariance, inapplicability of rearrangement techniques, and Hardy singularity along the boundary.

Method: Instead of directly working on the upper half space, the authors establish existence of extremals for an equivalent Poincaré-Sobolev inequality on hyperbolic space. They develop novel duality theory for minimizing sequences, concentration-compactness principle for radial functions in hyperbolic setting, combined with Helgason-Fourier analysis and Riesz rearrangement inequality on hyperbolic space to resolve compactness issues.

Result: Proves existence of extremal functions for k-th order critical Hardy-Sobolev-Maz'ya inequalities on upper half space when k≥2 and n≥2k+2. Also obtains existence of positive symmetric solutions for high-order Brezis-Nirenberg equation on entire hyperbolic space associated with GJMS operators at critical parameter values.

Conclusion: The hyperbolic space approach successfully overcomes the analytical challenges of the upper half space problem. The developed techniques provide a framework for handling higher-order inequalities with singularities and have applications to nonlinear PDEs on hyperbolic spaces.

Abstract: In this article, we establish the existence of an extremal function for the k-th order critical Hardy-Sobolev-Maz'ya (HSM) inequalities on the upper half space $\mathbb{R}^{n+1}_{+}$ when $k\ge 2$ and $n\geq 2k+2$:
  $$\int_{\mathbb{R}^{n}_{+}}|\nabla^{k}u|^2dx-\prod_{i=1}^{k}\frac{\left(2i-1\right)^2}{4}\int_{\mathbb{R}^{n}_{+}}\frac{u^2}{x_1^{2k}}dx\geq C_{n,k,\frac{2n}{n-2k}} \left(\int_{\mathbb{R}^{n}_{+}}|u|^{\frac{2n}{n-2k}}dx\right)^{\frac{n-2k}{n}}. $$
  The analysis of this extremal problem is challenging due to the presence of the higher order derivatives, the lack of translation invariance, the inapplicability of rearrangement techniques on the upper half-space, and the presence of a Hardy singularity along the boundary. To overcome these difficulties, instead of directly considering the HSM inequality on the upper half space, we establish the existence of an extremal for its equivalent version: Poincaré-Sobolev inequality on the hyperbolic space. We develop a novel duality theory of the minimizing sequences, the concentration-compactness principle for radial functions in the hyperbolic setting, which combines with the Helgason-Fourier analysis and the Riesz rearrangement inequality on the hyperbolic space, to resolve the lack of compactness issue. As an application, we also obtain the existence of positive symmetric solutions for the high order Brezis-Nirenberg equation on the entire hyperbolic space associated with the GJMS operators $P_k$ (i.e., when $k\ge 2$): $$ P_{k}\left(f\right)-αf=|f|^{p-2}f $$ at the critical situation $α=\prod\limits_{i=1}^{k}\frac{\left(2i-1\right)^2}{4}$ when either $2k+2\leq n$ and $p=\frac{2n}{n-2k}$ or $2k<n$ and $2<p<\frac{2n}{n-2k}$.

</details>


### [16] [Strong solutions to the initial-boundary-value problem of compressible MHD equations with degenerate viscosities and far field vacuum in 3D exterior domains](https://arxiv.org/abs/2602.05264)
*Jiaxu Li,Boqiang Lü,Bing Yuan*

Main category: math.AP

TL;DR: Local existence and uniqueness of strong solutions for compressible MHD equations in 3D exterior domains with Navier-slip and perfect conducting boundary conditions, where density approaches vacuum initially and viscosities are power functions of density.


<details>
  <summary>Details</summary>
Motivation: To study the initial-boundary-value problem for compressible MHD equations in exterior domains with physical boundary conditions, particularly when dealing with density-dependent viscosities and initial vacuum states, which present mathematical challenges due to potential singularities.

Method: Analysis of the IBVP for compressible MHD equations with Navier-slip boundary conditions for velocity and perfect conducting conditions for magnetic field. The viscosities are modeled as power functions of density (ρ^δ with 0 < δ < 1), and the density approaches far-field vacuum initially.

Result: Established local existence and uniqueness of strong solutions for regular large initial data. Showed that the magnetic field maintains faster decay rate than density throughout time evolution, unlike in compressible Navier-Stokes equations, revealing the magnetic field's role in handling singularities from density-dependent viscosities.

Conclusion: The magnetic field plays a crucial stabilizing role in compressible MHD systems with density-dependent viscosities and initial vacuum states, preventing certain singularities that occur in the Navier-Stokes case and enabling local well-posedness for large initial data.

Abstract: This paper concerns the initial-boundary-value problem (IBVP) of the compressible Magnetohydrodynamic (MHD) equations in 3D exterior domains with Navier-slip boundary conditions for the velocity and perfect conducting conditions for the magnetic field. For the case that the density approaches far-field vacuum initially and the viscosities are power functions of the density (ρ}δ with 0 < δ < 1), the local existence and uniqueness of strong solutions to the IBVP is established for regular large initial data. In particular, in contrast to the local theory of compressible Navier-Stokes equation Li-Lü-Yuan [24], we show that the magnetic field maintains the initial quality of decaying faster rate than density throughout the time evolution, which reveals the role of the magnetic field in handling singularities arising from density-dependent viscosities.

</details>


### [17] [Infinitely many new solutions for a nonlinear coupled Schrödinger system](https://arxiv.org/abs/2602.05283)
*Qingfang Wang,Mingxue Zhai*

Main category: math.AP

TL;DR: The paper studies a nonlinear Schrödinger system with two components, proving existence of new synchronized and segregated solutions that concentrate both in bounded domains and near infinity, and establishing non-degeneracy of these solutions.


<details>
  <summary>Details</summary>
Motivation: To investigate new types of solutions for coupled nonlinear Schrödinger systems that exhibit concentration phenomena in multiple regions (bounded domain and near infinity), addressing challenges from interspecies interactions not present in single equations.

Method: Uses finite dimensional reduction method to construct solutions, applies local Pohozaev identities and point-wise error estimates to prove non-degeneracy, and first verifies non-degeneracy of existing solutions from previous work.

Result: Proves existence of new synchronized and segregated solutions with special structure that concentrate in both bounded domains and near infinity, and establishes that these synchronized solutions are non-degenerate.

Conclusion: The paper successfully constructs novel solutions for coupled Schrödinger systems and proves their non-degeneracy, addressing the unique challenges posed by interspecies interactions in multi-component systems.

Abstract: We revisit the following nonlinear Schrödinger system \begin{align*}\begin{cases} -ε^{2}Δu +P(x) u= μ_1 u^3 +βuv^2, &~\text{in}\;\mathbb {R}^3,\\ -ε^{2}Δv+Q(x) v= μ_2 v^3 +βu^2v, &~\text{in}\;\mathbb{ R}^3, \end{cases} \end{align*} where $ε$ is a positive parameter, $P(x),\,Q(x)$ are the potential functions, $μ_1>0$, $μ_2>0$ and $β\in\mathbb R$ is a coupling constant. Employing the finite dimensional reduction method, we prove that there are new kind of synchronized and segregated solutions, which concentrate both in a bounded domain and near infinity, and present a special structure. Moreover, by applying the local Pohozaev identities and some point-wise estimates of the errors, we prove that the new kind of synchronized solutions are non-degenerate, which is of great interest independently. One of the main difficulties of Schrödinger system come from the interspecies interaction between the components, which never appear in the study of single equation. Secondly, prior to the construction of new solutions, we shall verify the non-degeneracy of the solutions established in [Peng-Pi, Discrete Contin. Dyn. Syst., 2016] for the Schrödinger systems.

</details>


### [18] [Precise propagation profile for some monostable free boundary problems in time-periodic media](https://arxiv.org/abs/2602.05328)
*Yihong Du,Zhuo Ma,Zhi-Cheng Wang*

Main category: math.AP

TL;DR: The paper proves existence, uniqueness, and sharp convergence results for semi-wave solutions in a general monostable free boundary problem with time-periodic reaction-diffusion equations, without requiring the KPP condition.


<details>
  <summary>Details</summary>
Motivation: To understand propagation phenomena in free boundary problems for reaction-diffusion equations with time-periodic monostable nonlinearities, where previous results were limited to autonomous cases or required strong KPP conditions.

Method: Analysis of reaction-diffusion equations with free boundaries subject to preferred population density conditions, developing new methods to handle general monostable settings without KPP conditions.

Result: Proved existence and uniqueness of semi-wave solutions, and obtained precise description of convergence toward semi-wave as time goes to infinity for general monostable free boundary problems in heterogeneous environments.

Conclusion: This is the first sharp convergence result for general monostable free boundary problems in heterogeneous environments, with methods applicable to related problems beyond KPP-type nonlinearities.

Abstract: We consider reaction-diffusion equations of the form \begin{equation*} u_t - d u_{xx} = f(t,u), \quad t>0,\ \ x \in [g(t), h(t)], \end{equation*} where $f(t,u)$ is periodic in $t$ and monostable in $u$, and the interval $[g(t), h(t)]$ represents the one dimensional population range of a species with density $u(t,x)$ at time $t$ and spatial location $x$. The free boundaries $x=g(t)$ and $x=h(t)$ evolve subject to a ``preferred population density" condition at the habitat edges. Analogous to the traveling wave solutions in the corresponding Cauchy problem, semi-wave solutions play a fundamental role in understanding the propagation phenomena governed by the free boundary problem here. But in contrast to the Cauchy problem, where the KPP condition plays a subtle role in the precise approximation of its solution (with compactly supported initial function) by the traveling wave solution with minimal speed, here we prove the existence and uniqueness of a semi-wave in a general monostable setting, and obtain a precise description of the convergence of the solution toward the semi-wave as time goes to infinity, where the KPP condition plays no special role. Previously, such a sharp result was proved for a free boundary model only when $f$ is autonomous ($f=f(u)$, see \cite{D} or \cite{DL15} for a related free boundary model), or a less precise result was obtained in the time-periodic case under an extra strong KPP condition on $f$ (see \cite{MDW}, or \cite{DGP} for a related free boundary model). This work appears to be the first to prove the sharp convergence result for a general monostable free boundary problem in a heterogeneous environment, and we believe the methods developed here should have applications to related free boundary problems in heterogeneous media with nonlinearities more general than those of KPP type.

</details>


### [19] [Dynamics of a nonlocal epidemic model with a new free boundary condition, part 1: Spreading-vanishing dichotomy](https://arxiv.org/abs/2602.05331)
*Yao Chen,Yihong Du,Wan-Tong Li,Rong Wang*

Main category: math.AP

TL;DR: The paper proposes a new free boundary condition for a nonlocal epidemic model and establishes a spreading-vanishing dichotomy with sharp criteria.


<details>
  <summary>Details</summary>
Motivation: To develop a more realistic epidemic model that incorporates both pathogen flux and infected population effects on boundary expansion, improving upon existing free boundary conditions in the literature.

Method: Proposes a new free boundary condition combining outward pathogen flux and weighted infected population. Uses analytical methods to prove well-posedness and study long-time dynamics through eigenvalue problems and spreading-vanishing dichotomy analysis.

Result: The system is well-posed under the new boundary condition. Long-time behavior follows a spreading-vanishing dichotomy with sharp thresholds based on initial data and diffusion rates. This is Part 1 of a two-part series.

Conclusion: The new free boundary condition successfully captures epidemic dynamics with both pathogen and population effects, establishing rigorous mathematical foundations for spreading-vanishing behavior with precise threshold criteria.

Abstract: This paper investigates the long-time dynamics of a nonlocal epidemic model with free boundaries, where a pathogen with density $u(t,x)$ and the infected humans with density $v(t,x)$ evolve according to a reaction-diffusion system with nonlocal diffusion over a one dimensional interval $[g(t), h(t)]$, which represents the epidemic region expanding through its boundaries $x=g(t)$ and $x=h(t)$, known as free boundaries. Such a model with free boundary conditions based on those of Cao et al. \cite{fb27} was considered by several works. Inspired by recent works of Feng et al. \cite{fb20} and Long et al. \cite{fb5}, we propose a new free boundary condition, where the expansion rate of the epidemic region, determined by $h'(t)$ and $g'(t)$, is proportional to a linear combination of the outward flux of the pathogen \(u\) through the range boundary (as in \cite{fb27}) and the weighted total population of infected individuals \(v\) within the region (as in \cite{fb5}). We prove that the system under this new free boundary condition is well-posed, and its long-time dynamical behavior is characterized by a spreading-vanishing dichotomy. Moreover, we obtain sharp criteria for this dichotomy, including a sharp threshold in terms of the initial data $(u_0,v_0)$; and by studying a related eigenvalue problem, we also find a sharp threshold in terms of the diffusion rate, which complements related results in Nguyen and Vo \cite{fb7}. This is Part $1$ of a two part series. In Part $2$, we will determine the spreading speed of the model when spreading occurs, and for some typical classes of kernel functions, we will obtain the precise rates of accelerated spreading.

</details>


### [20] [Lipschitz regularity of harmonic quasiconformal maps between Lyapunov domains in $\mathbb{R}^n$](https://arxiv.org/abs/2602.05436)
*Anton Gjokaj,David Kalaj*

Main category: math.AP

TL;DR: Harmonic K-quasiconformal homeomorphisms between smooth domains in ℝⁿ are globally Lipschitz up to the boundary.


<details>
  <summary>Details</summary>
Motivation: To establish global Lipschitz regularity for sense-preserving harmonic quasiconformal homeomorphisms between smooth domains, extending boundary regularity results to the entire closure of the domain.

Method: Boundary iteration scheme: start with Hölder regularity from quasiconformality, improve it using C¹,α boundary representation, convert to gradient bounds via flattening and harmonic measure, propagate control via quasiconformality, and iterate to bound |Df| up to the boundary.

Result: Every sense-preserving harmonic K-quasiconformal homeomorphism between Lyapunov domains (bounded C¹,α domains) in ℝⁿ is globally Lipschitz on the closure of the domain.

Conclusion: The paper establishes global Lipschitz regularity for harmonic quasiconformal mappings between smooth domains, providing a complete boundary regularity theory using an iterative approach that combines quasiconformal and harmonic analysis techniques.

Abstract: We prove that every sense-preserving harmonic $K$--quasiconformal homeomorphism $f\colon D\toΩ$ between Lyapunov domains (equivalently, bounded $C^{1,α}$ domains) in $\mathbb{R}^n$, $α\in(0,1]$, is globally Lipschitz on $\overline D$. The argument is based on a boundary iteration scheme: an initial Hölder modulus for the boundary trace (coming from quasiconformality) is improved via the $C^{1,α}$ graph representation of $\partialΩ$, yielding higher Hölder regularity for the normal component. This boundary gain is converted into a near-boundary gradient bound for harmonic functions through a basepoint boundary Hölder-to-gradient estimate obtained by flattening the boundary and using local harmonic-measure bounds. Quasiconformality then propagates the resulting control from one component to the full differential, and iteration gives boundedness of $|Df|$ up to the boundary. Along the way we briefly survey several standard tools from the theory of quasiconformal harmonic mappings (QCH), including boundary Hölder continuity, distortion of derivatives, and boundary-to-interior propagation principles that enter the iteration.

</details>


### [21] [Convergence of the PML method for thermoelastic wave scattering problems](https://arxiv.org/abs/2602.05497)
*Qianyuan Yin,Changkun Wei,Bo Zhang*

Main category: math.AP

TL;DR: First convergence analysis of PML method for 3D thermoelastic obstacle scattering, proving exponential convergence with respect to PML parameters.


<details>
  <summary>Details</summary>
Motivation: To develop and analyze a perfectly matched layer (PML) method for truncating unbounded thermoelastic scattering problems in 3D, addressing the lack of convergence results for PML methods in thermoelastic scattering.

Method: Introduces uniaxial PML method to truncate unbounded domain, uses analytic Fredholm theory to prove well-posedness (except discrete frequencies), and employs PML extension technique with exponential decay properties of modified fundamental solution to establish convergence.

Result: Proves well-posedness of truncated PML problem and establishes exponential convergence of the uniaxial PML method in terms of PML layer thickness and absorbing parameters.

Conclusion: Provides first convergence result for PML method in time-harmonic thermoelastic scattering, demonstrating effective domain truncation with exponential convergence.

Abstract: This paper is concerned with the thermoelastic obstacle scattering problem in three dimensions. A uniaxial perfectly matched layer (PML) method is firstly introduced to truncate the unbounded scattering problem, leading to a truncated PML problem in a bounded domain. Under certain constraints on model parameters, the well-posedness for the truncated PML problem is then proved except possibly for a discrete set of frequencies, based on the analytic Fredholm theory. Moreover, the exponential convergence of the uniaxial PML method is established in terms of the thickness and absorbing parameters of PML layer. The proof is based on the PML extension technique and the exponential decay properties of the modified fundamental solution. As far as we know, this is the first convergence result of the PML method for the time-harmonic thermoelastic scattering problem.

</details>


### [22] [Regularity results for linear parabolic equations on Carnot tori via mollifier kernel construction](https://arxiv.org/abs/2602.05498)
*Yiming Jiang,Yawei Wei,Yiyun Yang*

Main category: math.AP

TL;DR: Proves existence, uniqueness, and regularity for linear backward parabolic equations on Carnot tori, then applies results to dual Fokker-Planck-Kolmogorov equations.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for parabolic equations on non-commutative Carnot groups, which are important examples of sub-Riemannian manifolds with applications in probability theory and physics.

Method: 1) Construct specialized mollifiers adapted to Hörmander vector fields, Carnot tori, and dual spaces of non-isotropic Hölder spaces. 2) Use singular integral operator theory to establish stronger a priori regularity estimates.

Result: Proves existence, uniqueness, and regularity for solutions to linear backward parabolic equations on Carnot tori, and extends these results to weak solutions of the dual Fokker-Planck-Kolmogorov equation.

Conclusion: Successfully establishes comprehensive solution theory for parabolic equations on Carnot groups, providing mathematical tools for studying evolution equations in sub-Riemannian geometry and related probability problems.

Abstract: This paper first proves the existence, uniqueness and regularity of the solution to a class of linear backward parabolic equations on Carnot tori, namely the periodic linear parabolic equation on Carnot groups. Such groups are non-commutative and typical examples of sub-Riemannian manifolds. Moreover, we apply the results for this equation to its dual equation (i.e., the Fokker-Planck-Kolmogorov equation in the general form), and derive the existence, uniqueness and regularity of its weak solution. To obtain the regularity results for solutions to the linear parabolic equation and its dual equation, firstly, we construct several families of mollifiers adapted respectively to the Hörmander vector fields generating Carnot groups, Carnot tori and dual spaces of non-isotropic Hölder spaces; secondly, we use the theory of singular integral operators to establish stronger a priori regularity for the solutions.

</details>


### [23] [Global smooth solutions in a one-dimensional thermoviscoelastic model with temperature-dependent paramaters](https://arxiv.org/abs/2602.05621)
*Felix Meyer*

Main category: math.AP

TL;DR: The paper establishes existence of global classical solutions for a thermoviscoelastic system modeling Kelvin-Voigt materials with arbitrarily large initial data.


<details>
  <summary>Details</summary>
Motivation: To analyze thermoviscoelastic developments in one-dimensional Kelvin-Voigt materials, which are important for understanding viscoelastic behavior with thermal effects in materials science and continuum mechanics.

Method: Studies a coupled PDE system describing thermoviscoelasticity with assumptions on smoothness and boundedness of material functions (a, γ, f). Uses analytical techniques to prove global existence results under specified conditions.

Result: Establishes existence of global classical solutions for sufficiently smooth but arbitrarily large initial data under the given assumptions on material functions and parameters.

Conclusion: The thermoviscoelastic system for Kelvin-Voigt materials admits global classical solutions even for large initial data, providing important mathematical foundation for studying such materials.

Abstract: This manuscript is concerned with the system \begin{align*} \left\{ \begin{array}{l} u_{tt} = (γ(Θ) u_{xt})_x + (a(x,t) u_x)_x +(f(Θ))_x, \\[1mm] Θ_t = DΘ_{xx} + γ(Θ) u_{xt}^2 + f(Θ) u_{xt}, \end{array} \right. \end{align*} which is used to describe thermoviscoelastic developments in one-dimensional Kelvin-Voigt materials. \abs It is assumed that $a,γ$ and $f$ are sufficiently smooth functions that satisfy $$c_γ<γ(ζ)<C_γ, \quad γ''(ζ) \le 0,\quad f(0)=0, \quad |f'(ζ)|\le C_f \quad \mbox{ and } |f(ζ)|\le C_f(1+ζ)^α\quad \mbox{ for all }ζ\ge 0 $$ and some positive constants $c_γ,C_γ,C_f>0$ and $α\in (0,5/6)$. Under these conditions, this study then establishes a result on the existence of global classical solutions for sufficiently smooth but arbitrarily large initial data.

</details>


### [24] [Large time existence in a thermoviscoelastic evolution problem with mildly temperature-dependent parameters](https://arxiv.org/abs/2602.05640)
*Felix Meyer*

Main category: math.AP

TL;DR: The paper proves that classical solutions to a thermo-viscoelastic system with sublinear temperature dependencies can exist for arbitrarily long times under smallness conditions on coefficient derivatives.


<details>
  <summary>Details</summary>
Motivation: The model generalizes classical thermo-viscoelastic systems for strain and temperature evolution. While local existence of classical solutions is known, the paper aims to extend these solutions to arbitrarily long time horizons by imposing specific structural conditions on the temperature-dependent coefficients.

Method: The authors establish that for any given time horizon T*, there exists a constant δ* (depending on various parameters) such that if the derivatives of γ and f are bounded by δ*, then the maximal existence time of classical solutions exceeds T*. This requires sublinear temperature dependencies of γ and f, and specific growth conditions on F.

Result: The main result shows that classical solutions to the thermo-viscoelastic system can be extended to arbitrarily large time intervals under smallness conditions on the derivatives of temperature-dependent coefficients γ and f, assuming sublinear growth of these coefficients.

Conclusion: The paper demonstrates that by controlling the derivatives of temperature-dependent material coefficients (γ and f) and imposing sublinear growth conditions, classical solutions to thermo-viscoelastic systems can persist for arbitrarily long times, extending beyond known local existence results.

Abstract: We consider \begin{align*} \label{HS} \left\{ \begin{array}{l} u_{tt} = (γ(Θ) u_{xt})_x + a (γ(Θ) u_x)_x +(f(Θ))_x, \\[1mm] Θ_t = DΘ_{xx} + Γ(Θ) u_{xt}^2 + F(Θ) u_{xt}, \end{array}\right. \qquad \qquad (\star) \end{align*} under Neumann boundary conditions for $u$ and Dirichlet boundary conditions for $Θ$ in a bounded interval $Ω\subset\mathbb{R}$. \abs This model is a generalization of the classical system for the description of strain and temperature evolution in a thermo-viscoelastic material following a Kelvin-Voigt material law, in which $γ\equiv Γ$ and $f\equiv F$. Different variations of this model have already been analyzed in the past and the present study draws upon a known result concerning the existence of classical solutions, which are local in time, for suitably smooth initial data, arbitrary $a>0$, $D>0$ and $γ,f\in C^2([0,\infty))$ as well as $Γ,F\in C^1([0,\infty))$ with $γ>0,Γ\ge0$ and $F(0)=0$. Our work focuses on proving that existence times for classical solutions can be arbitrarily large, assuming sublinear temperature dependencies of $γ$ and $f$, and further $|F(s)|\le C_F(1+s)^α$ for some $C_F>0$ and $α\in(0,1)$. In particular, for any given $T_\star$, initial mass $M$ and $0<\underlineγ<\overlineγ$, there exists a constant $δ_\star(M,T_\star,a,D, Ω, \underlineγ, \overlineγ,C_F,α)>0$, such that if $$\underlineγ\leγ\le \overlineγ\quad\mbox{ and }\quad 0\le Γ\le \overlineγ\quad \mbox{ as well as } \quad\|γ'\|_{L^\infty([0,\infty))}\le δ_\star \quad \mbox{ and }\quad \|f'\|_{L^\infty([0,\infty))}\le δ_\star $$ hold, the maximal existence time of the classical solution to $(\star)$ surpasses $T_\star$.

</details>


### [25] [Fundamental solution for higher order homogeneous hypoelliptic operators structured on Hörmander vector fields](https://arxiv.org/abs/2602.05647)
*Stefano Biagi,Marco Bramanti*

Main category: math.AP

TL;DR: Introduces "generalized Rockland operators" - higher order differential operators on ℝⁿ built with Hörmander vector fields, homogeneous w.r.t. dilations but not left invariant, with hypoelliptic lifted versions.


<details>
  <summary>Details</summary>
Motivation: To study a new class of higher order differential operators that generalize Rockland operators beyond Lie group settings, allowing for operators built with Hörmander vector fields and homogeneous w.r.t. dilations without requiring left invariance.

Method: Introduce generalized Rockland operators defined on ℝⁿ using Hörmander vector fields, homogeneous w.r.t. family of dilations. Prove these operators are hypoelliptic and, under natural conditions on homogeneity degree, construct global fundamental solutions with joint homogeneity and sharp pointwise estimates.

Result: Proved hypoellipticity of generalized Rockland operators and established existence of global fundamental solutions Γ(x,y) that are jointly homogeneous in (x,y) with sharp pointwise estimates. Theory also applies to higher order heat-type operators.

Conclusion: Successfully developed theory for generalized Rockland operators extending classical Rockland theory to operators not requiring Lie group structure, with applications to heat-type operators and their fundamental solutions.

Abstract: We introduce and study a new class of higher order differential operators defined on $\mathbb{R}^{n}$, which are built with Hörmander vector fields, homogeneous w.r.t. a family of dilations (but not left invariant w.r.t. any structure of Lie group) and have a structure such that a suitably lifted version of the operator is hypoelliptic. We call these operators ''generalized Rockland operators''. We prove that these operators are themselves hypoelliptic and, under a natural condition on the homogeneity degree, possess a global fundamental solution $Γ\left( x,y\right) $ which is jointly homogeneous in $\left( x,y\right) $ and satisfies sharp pointwise estimates. Our theory can be applied also to some higher order heat-type operators and their fundamental solutions.

</details>


### [26] [Weak and strong averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise](https://arxiv.org/abs/2602.05696)
*Yangyang Shi,Dong Su,Hui Liu*

Main category: math.AP

TL;DR: The paper studies averaging principles for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, establishing well-posedness, regularity, ergodicity, and convergence results with numerical validation.


<details>
  <summary>Details</summary>
Motivation: To understand the averaging behavior of 2D Boussinesq equations with non-Lipschitz Poisson jump noise, which is important for modeling turbulent flows with random forcing in geophysical and engineering applications.

Method: First establishes well-posedness, regularity estimates, and tightness of the vorticity variable. Then proves ergodicity of the temperature variable. Next shows convergence of vorticity to averaged equation solutions in probability and 2pth-mean as time scale parameter ε→0. Finally includes case study and numerical simulations.

Result: The paper proves: 1) Well-posedness and regularity for the system, 2) Ergodicity of temperature variable, 3) Convergence of vorticity to averaged equation in probability and 2pth-mean under different conditions as ε→0, 4) Numerical validation of theoretical results.

Conclusion: The averaging principle holds for 2D Boussinesq equations with non-Lipschitz Poisson jump noise, with rigorous mathematical proofs and numerical confirmation, providing theoretical foundation for reduced-order modeling of such stochastic systems.

Abstract: In this paper, we study the averaging principle for 2D Boussinesq equations with non-Lipschitz Poisson jump noise. Precisely, we will first explore the well-posedness, regularity estimates and tightness of the vorticity variable. Then, we prove the ergodicity of the temperature variable. Next, we prove that the vorticity variable converge to the solution of the averaged equation in probability and $2p$th-mean, under different conditions, as time scale parameter $\varepsilon$ goes to zero. Finally, we present a specific case study and conduct numerical simulations to substantiate the main conclusions of this paper.

</details>


### [27] [Flow reversal of the Stokes system with localized boundary data in the half space](https://arxiv.org/abs/2602.05858)
*Tongkeun Chang,Kyungkeun Kang,Chanhong Min*

Main category: math.AP

TL;DR: The paper demonstrates that in unsteady Stokes flow in a half-space, certain boundary influxes can cause flow reversal where velocity components change sign in the domain.


<details>
  <summary>Details</summary>
Motivation: To investigate whether flow reversal phenomena can occur in unsteady Stokes systems with localized boundary data, challenging the intuitive expectation that flow direction remains consistent.

Method: Careful analysis of the representation formula for the Stokes system in half-space using Green tensor with nonzero boundary data, including pointwise estimates. Construction of specific boundary influx solutions.

Result: Existence of boundary influxes that induce flow reversal: tangential velocity components exhibit at least one sign change, normal component exhibits at least two sign changes. Near boundary, normal component has opposite sign to tangential components; far from boundary, they share the same sign.

Conclusion: Flow reversal is possible in unsteady Stokes systems with localized boundary data, demonstrating complex flow patterns where velocity components change sign within the domain, contrary to simple intuitive expectations.

Abstract: We consider the unsteady Stokes system in the half-space with zero initial data and nonzero, space-time localized boundary data. We show that there exist boundary influxes for which the induced flow exhibits flow reversal, in the sense that at least one component of the velocity field changes its sign in the half-space. This phenomenon is demonstrated by a careful analysis of the representation formula for the Stokes system in the half-space, including pointwise estimates, based on the Green tensor with nonzero boundary data. We construct solutions of the Stokes system such that the tangential components of the velocity field exhibit at least one sign change, while the normal component exhibits at least two sign changes. Moreover, the normal component of the constructed velocity field has the opposite sign to the tangential components near the boundary, whereas it has the same sign as the tangential components sufficiently far from the boundary.

</details>


### [28] [Large bulk viscosity limit for compressible MHD equations in critical Besov spaces](https://arxiv.org/abs/2602.05878)
*Gennaro Ciampa,Donatella Donatelli,Giada Pellecchia*

Main category: math.AP

TL;DR: Global well-posedness of compressible MHD equations in large bulk viscosity limit, with convergence to incompressible MHD and application to magnetic reconnection.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of compressible magnetohydrodynamics equations in the limit of large bulk viscosity, connecting compressible and incompressible regimes, and to study magnetic field reconnection phenomena in compressible flows.

Method: Analysis of compressible MHD equations in two and three dimensions with arbitrarily large initial data in critical Besov spaces. Using singular limit analysis as bulk viscosity parameter tends to infinity, establishing global well-posedness and convergence rates to incompressible MHD.

Result: Proved global well-posedness of strong solutions for arbitrarily large initial data, established explicit quantitative convergence rates to incompressible MHD system as bulk viscosity → ∞. Applied results to construct global smooth solutions with magnetic field reconnection in compressible regime.

Conclusion: The large bulk viscosity limit provides a rigorous connection between compressible and incompressible MHD, enabling extension of magnetic reconnection phenomena from incompressible to compressible flows with global smooth solutions.

Abstract: We study the large bulk viscosity limit for the compressible magnetohydrodynamics (MHD) equations in two and three dimensions. For arbitrarily large initial data in critical Besov spaces, we prove the global well-posedness of strong solutions and establish their convergence, with explicit quantitative rates, to solutions of the incompressible MHD system, as the bulk viscosity parameter tends to infinity. As an application of this singular-limit analysis, we construct global smooth solutions to the compressible MHD equations whose magnetic field undergoes reconnection, thereby extending to the compressible regime the reconnection scenarios previously identified for incompressible flows.

</details>


### [29] [Explicit representation of solutions to a linear wave equation with time delay](https://arxiv.org/abs/2602.05906)
*Javad A. Asadzade,Jasarat J. Gasimov,Nazim I. Mahmudov,Ismail T. Huseynov*

Main category: math.AP

TL;DR: Spectral representation for 1D wave equation with constant time delay using stepwise classical solutions and Fourier series reconstruction.


<details>
  <summary>Details</summary>
Motivation: To develop explicit solution representation for wave equations with time delays, which cause loss of global smoothness and require special treatment of discontinuities.

Method: Separation of variables with Sturm-Liouville expansions reduces delayed PDE to scalar delay differential equations, using delay-dependent fundamental solutions and Fourier series reconstruction.

Result: Derived closed-form representation formulas for modal dynamics, established convergence conditions for uniform convergence and termwise differentiation, demonstrated practical computation with numerical example.

Conclusion: Successfully developed spectral representation for delayed wave equation using stepwise classical solutions, providing computable Fourier series solutions with rigorous convergence guarantees.

Abstract: This paper develops an explicit spectral representation for solutions of a one-dimensional linear wave equation with a constant time delay. The model is considered on a bounded interval with non-homogeneous Dirichlet boundary data and a prescribed history function. To accommodate the loss of global smoothness in time caused by delay terms, solutions are understood in a \textit{stepwise classical sense}, allowing jump discontinuities in the second time derivative at multiples of the delay while maintaining continuity of the solution and its first time derivative.
  By combining separation of variables with Sturm-Liouville expansions, the delayed PDE is reduced to a family of scalar second-order delay differential equations. Using delay-dependent fundamental solutions, we derive closed-form representation formulas for the modal dynamics and reconstruct the PDE solution as a Fourier series. Convergence conditions guaranteeing uniform convergence and admissibility of termwise differentiation in space are established. A numerical example demonstrates the practical computation of truncated series solutions and their visualization.

</details>


### [30] [Large time stabilization of rough-data solutions in one-dimensional nonlinear thermoelasticity](https://arxiv.org/abs/2602.05962)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper proves stabilization of weak solutions for a 1D thermoelasticity model with minimal regularity assumptions on initial data, showing convergence to equilibrium states.


<details>
  <summary>Details</summary>
Motivation: To establish existence and long-time behavior of weak solutions for thermoelastic systems under minimal regularity assumptions, going beyond previous studies that required more regular initial data and relied on compactness properties.

Method: Considers a 1D thermoelasticity model with nonlinear coupling via function f(Θ). Uses weak solution framework with initial data only required to satisfy energy conservation and entropy principles. Develops analytical techniques to handle lack of compactness in low-regularity setting.

Result: Proves that weak solutions stabilize: displacement u converges to 0 in L∞ norm, and temperature Θ converges to a positive constant Θ∞ in L∞ norm as time goes to infinity.

Conclusion: The thermoelastic system exhibits stabilization to equilibrium even under minimal regularity assumptions on initial data, demonstrating robustness of the model's long-time behavior.

Abstract: In an open bounded real interval $Ω$, the model for one-dimensional thermoelasticity given by \[
  u_{tt} = u_{xx} - \big(f(Θ)\big)_x,
  \qquad
  Θ_t = Θ_{xx} - f(Θ) u_{xt}, \] is considered along with homogeneous boundary conditions of Dirichlet type for $u$ and of Neumann type for $Θ$, under the assumption that $f\in C^1([0,\infty))$ satisfies $f(0)=0$, $f'\in L^\infty((0,\infty))$ and $f'>0$ on $[0,\infty)$. The focus is on initial data which are merely required to be consistent with the fundamental principles of energy conservation and entropy nondecrease, by satisfying \[
  u_0\in W_0^{1,2}(Ω),
  u_{0t} \in L^2(Ω),
  0 \le Θ_0\in L^1(Ω), Θ_0 \not\equiv 0. \] Despite an apparent lack of favorable compactness properties that have underlain previous related studies on more regular settings, it is shown that corresponding weak solutions stabilize in the sense that \[
  \lim_{t\to\infty} \|u(\cdot,t)\|_{L^\infty(Ω)}=0 \] and \[
  {\rm ess} \lim_{\!\!\!\! t\to\infty} \|Θ(\cdot,t)-Θ_\infty\|_{L^\infty(Ω)}=0 \] with some $Θ_\infty>0$.

</details>


### [31] [A simple model for one-dimensional nonlinear thermoelasticity: Well-posedness in rough-data frameworks](https://arxiv.org/abs/2602.05963)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper proves unconditional global well-posedness for a coupled hyperbolic-parabolic system modeling thermoelasticity with nonlinear coupling function f.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for thermoelastic wave propagation with nonlinear coupling, ensuring global existence, uniqueness, and continuous dependence on initial data under minimal regularity assumptions.

Method: Analysis of coupled PDE system using functional analytic techniques, energy estimates, and fixed-point arguments in appropriate Sobolev spaces with boundary conditions u|∂Ω=0 and Θ_x|∂Ω=0.

Result: Proves unconditional global well-posedness (existence, uniqueness, continuous dependence) for initial data in minimal regularity classes: u₀∈W₀¹²(Ω), u₀ₜ∈L²(Ω), Θ₀∈L²(Ω) with Θ₀≥0.

Conclusion: The thermoelastic system is well-posed globally in time without additional smallness or growth restrictions on initial data, establishing robust mathematical framework for nonlinear thermoelastic wave models.

Abstract: In an open bounded interval $Ω$, the problem \[
  u_{tt} = u_{xx} - \big(f(Θ)\big)_x,
  Θ_t = Θ_{xx} - f(Θ) u_{xt}, \] is considered under the boundary conditions $u|_{\partialΩ}=Θ_x|_{\partialΩ}=0$, and for $f\in C^2([0,\infty))$ satisfying $f(0)=0$, $f'>0$ on $[0,\infty)$ and $f'\in W^{1,\infty}((0,\infty))$.
  In the sense of unconditional global existence, uniqueness and continuous dependence, this problem is shown to be well-posed within ranges of initial data merely satisfying \[
  u_0\in W_0^{1,2}(Ω),
  \quad
  u_{0t} \in L^2(Ω)
  \quad \mbox{and} \quad
  Θ_0 \in L^2(Ω)
  \mbox{ with $Θ\ge 0$ a.e.~in $Ω$,} \] and in classes of solutions fulfilling \[
  u\in C^0([0,\infty);W_0^{1,2}(Ω)),
  \qquad
  u_t \in C^0([0,\infty);L^2(Ω))
  \qquad \mbox{and} \qquad
  Θ\in C^0([0,\infty);L^2(Ω)) \cap L^2_{loc}([0,\infty);W^{1,2}(Ω)). \]

</details>


### [32] [Global solvability and stabilization in multi-dimensional small-strain nonlinear thermoviscoelasticity](https://arxiv.org/abs/2602.05964)
*Michael Winkler*

Main category: math.AP

TL;DR: The paper proves global existence of solutions for a thermoviscoelastic Kelvin-Voigt model with inertia in multi-dimensional domains without size restrictions on initial data, and establishes large-time stabilization results.


<details>
  <summary>Details</summary>
Motivation: Addresses a longstanding open problem in continuum mechanics: determining global solvability of the small-strain thermoviscoelastic evolution model for Kelvin-Voigt materials with inertia in multi-dimensional settings for arbitrary initial data size.

Method: Uses generalized concepts of solvability, energy conservation principles, entropy production analysis, and introduces novel logarithmic refinements of classical entropy functionals with previously undiscovered evolution properties.

Result: Proves global existence of solutions without size restrictions on data for a generalized system (allowing temperature-dependent heat capacity) in smoothly bounded n-dimensional domains (n≥2) with homogeneous Dirichlet boundary conditions for displacement and Neumann conditions for temperature.

Conclusion: The paper resolves the open problem by establishing global solvability and large-time behavior results, including temperature stabilization toward spatially homogeneous limits, using innovative entropy functional techniques that may have independent mathematical interest.

Abstract: Despite considerable developments in the literature of the past decades, a standing open problem in the analysis of continuum mechanics appears to consist of determining how far the prototypical model for small-strain thermoviscoelastic evolution in Kelvin-Voigt materials with inertia, as given by \[
  u_{tt} = μΔu_t + (λ+μ)\nabla\nabla\cdot u_t
  + \hatμ Δu + (\hatλ+\hatμ) \nabla\nabla\cdot u
  - B\nablaΘ,
  \qquad \qquad
  κΘ_t = DΔΘ+ μ|\nabla u_t|^2 + (λ+μ) |{\rm div} \, u_t|^2 - BΘ{\rm div} \, u_t,
  \qquad \qquad \qquad (\star) \] is globally solvable in multi-dimensional settings and for initial data of arbitrary size.
  The present manuscript addresses this in the context of an initial value problem in smoothly bounded $n$-dimensional domains with $n\ge 2$, posed under homogeneous boundary conditions of Dirichlet type for the displacement variable $u$, and of Neumann type for the temperature $Θ$. Within suitably generalized concepts of solvability, global existence of solutions is shown without any size restrictions on the data, and for a system actually more general than ($\star$) by, inter alia, allowing the heat capacity $κ$ to depend on $Θ$. Apart from that, results on large time behavior are derived which particularly assert stabilization of $Θ$ toward a spatially homogeneous limit.
  Besides on standard features related to energy conservation and entropy production, in its core parts the analysis relies on an evolution property of certain logarithmic refinements of classical entropy functionals, to the best of our knowledge undiscovered in precedent literature and possibly of independent interest.

</details>


### [33] [Stability of the $L^{p}$-Poincaré inequality for the Lebesgue and Gaussian probability measures with explicit geometric dependency](https://arxiv.org/abs/2602.05968)
*Nurgissa Yessirkegenov,Amir Zhangirbayev*

Main category: math.AP

TL;DR: The paper proves stability results for L^p-Poincaré inequalities for Lebesgue and Gaussian measures using eigenfunction analysis and weighted inequalities for log-concave measures.


<details>
  <summary>Details</summary>
Motivation: To establish stability properties for L^p-Poincaré inequalities, which are fundamental functional inequalities in analysis, particularly for both Lebesgue and Gaussian probability measures.

Method: Uses properties of the first eigenfunction of the (Gaussian) p-Laplacian operator and weighted Poincaré inequalities for log-concave measures on convex domains.

Result: Obtains stability results for L^p-Poincaré inequality for both Lebesgue measures (Theorem 3.3) and Gaussian probability measures (Theorem 3.6).

Conclusion: The approach combining eigenfunction analysis of p-Laplacian operators with weighted Poincaré inequalities for log-concave measures provides effective tools for establishing stability of L^p-Poincaré inequalities.

Abstract: In this paper, we obtain stability results for the $L^{p}$-Poincaré inequality for both Lebesgue and Gaussian probability measures (Theorem 3.3 and Theorem 3.6). Our approach relies on properties of the first eigenfunction of the (Gaussian) $p$-Laplacian operator and weighted Poincaré inequalities for log-concave measures on convex domains.

</details>


### [34] [Finite time singularities in the Landau equation with very hard potentials](https://arxiv.org/abs/2602.05981)
*Jacob Bedrossian,Jiajie Chen,Maria Pia Gualdani,Sehyun Ji,Vlad Vicol,Jincheng Yang*

Main category: math.AP

TL;DR: Constructs smooth positive initial data for inhomogeneous Landau equation that develops finite-time singularity with bounded L∞ norm but blowing up Cα norms, showing first collisional kinetic model globally well-posed in homogeneous setting but admitting singularities for inhomogeneous data.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that the Landau equation, which is globally well-posed in the homogeneous setting, can develop finite-time singularities in the inhomogeneous case, providing the first example of such behavior in collisional kinetic models.

Method: Construct smooth, strictly positive initial data for the inhomogeneous Landau equation with γ ∈ (√3,2] that leads to finite-time singularity formation. Analyze solution in self-similar variables showing convergence to local Maxwellian distribution while hydrodynamic fields develop asymptotically self-similar implosion matching compressible Euler equations profiles.

Result: The Cα-norm of the distribution function blows up for every α > 0 while its L∞-norm remains uniformly bounded. In self-similar variables, the solution becomes asymptotically hydrodynamic - distribution function converges to local Maxwellian, and hydrodynamic fields develop asymptotically self-similar implosion matching smooth imploding profiles of compressible Euler equations.

Conclusion: This provides the first example of a collisional kinetic model that is globally well-posed in homogeneous setting but admits finite time singularities for inhomogeneous data, demonstrating fundamental differences between homogeneous and inhomogeneous behavior in kinetic equations.

Abstract: We consider the inhomogeneous Landau equation with $γ\in (\sqrt{3},2]$ and construct smooth, strictly positive initial data that develop a finite time singularity. The $C^α$-norm of the distribution function blows up for every $α>0$, whereas its $L^{\infty}$-norm remains uniformly bounded. In self-similar variables, the solution becomes asymptotically hydrodynamic - the distribution function converges to a local Maxwellian, while the hydrodynamic fields develop an asymptotically self-similar implosion whose profile coincides with a smooth imploding profile of the compressible Euler equations. To our knowledge, this provides the first example of a collisional kinetic model which is globally well-posed in the homogeneous setting, but admits finite time singularities for inhomogeneous data.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [35] [Path Sampling for Rare Events Boosted by Machine Learning](https://arxiv.org/abs/2602.05167)
*Porhouy Minh,Sapna Sarupria*

Main category: physics.comp-ph

TL;DR: AIMMD is a novel ML-enhanced sampling algorithm that improves transition path sampling efficiency by enabling real-time committor estimation and deriving interpretable reaction coordinates for molecular mechanism discovery.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenges in elucidating mechanistic pathways of complex molecular processes by enhancing the efficiency of transition path sampling through machine learning integration.

Method: AIMMD integrates machine learning with transition path sampling to enable on-the-fly estimation of committor probability and simultaneously derive human-interpretable reaction coordinates.

Result: Provides a robust framework for molecular mechanism discovery that improves sampling efficiency while maintaining interpretability through derived reaction coordinates.

Conclusion: AIMMD represents a significant advancement in molecular simulation methodology with promising potential, though the commentary suggests critical analysis of its extensions, impact, and limitations is warranted.

Abstract: The study by Jung et al. (Jung H, Covino R, Arjun A, et al., Nat Comput Sci. 3:334-345 (2023)) introduced Artificial Intelligence for Molecular Mechanism Discovery (AIMMD), a novel sampling algorithm that integrates machine learning to enhance the efficiency of transition path sampling (TPS). By enabling on-the-fly estimation of the committor probability and simultaneously deriving a human-interpretable reaction coordinate, AIMMD offers a robust framework for elucidating the mechanistic pathways of complex molecular processes. This commentary provides a discussion and critical analysis of the core AIMMD framework, explores its recent extensions, and offers an assessment of the method's potential impact and limitations.

</details>


### [36] [Numerical Evaluation of Angle-Dependent IR-Transparent Radiative Cooling Performance for Asymmetric Periodic Structures](https://arxiv.org/abs/2602.05613)
*Junwoo Gim,Jun Heo,Weng Cho Chew,Dong-Yeop Na*

Main category: physics.comp-ph

TL;DR: IR-transparent passive radiative cooling requires angularly distributed asymmetric transparency, not just single-angle asymmetry, for effective non-contact thermal management.


<details>
  <summary>Details</summary>
Motivation: Current IR-transparent passive radiative cooling designs focus on asymmetric IR transmission at normal incidence, but this single-angle approach doesn't accurately predict practical cooling performance.

Method: Used angle-resolved full-wave electromagnetic model with Bloch periodic boundary conditions and Floquet mode decomposition to compute wavelength- and angle-dependent bidirectional reflection/transmission, coupled with energy-balance thermal model for transient temperature prediction.

Result: Pronounced asymmetric transmission at normal incidence is not preserved at oblique angles; angular integration yields only marginal cooling or net heating, while normal-incidence models substantially overestimate cooling performance.

Conclusion: Angularly distributed asymmetric transparency is a key design principle for effective IR-transparent passive radiative cooling and wide-angle asymmetric metasurfaces.

Abstract: Infrared (IR)-transparent passive radiative cooling (PRC) enables non-contact thermal management by regulating radiative heat exchange without direct attachment to the cooling object. While asymmetric IR transmission at a specific incidence angle -- typically normal incidence -- is often emphasized, we show that such single-angle asymmetry is neither sufficient nor predictive of practical cooling performance. In this work, we demonstrate that effective non-contact PRC requires angularly distributed asymmetric IR transparency evaluated through hemispherical integration over emission directions, rather than asymmetry at a single incidence angle. To quantify this effect, an angle-resolved full-wave electromagnetic (EM) model with Bloch periodic boundary conditions and Floquet mode decomposition is employed to compute wavelength- and angle-dependent bidirectional reflection and transmission of periodic PRC structures. The resulting EM response is coupled to an energy-balance-based thermal model to predict the transient temperature evolution of the cooling object. By comparing models that account for the full angular distribution with normal-incidence-only approximations, we show that pronounced asymmetric transmission at normal incidence is generally not preserved at oblique angles. As a result, angular integration yields only marginal cooling or may even result in net heating, whereas normal-incidence-based models can substantially overestimate cooling performance. These results establish angularly distributed asymmetric transparency as a key EM design principle for IR-transparent PRC and wide-angle asymmetric metasurfaces.

</details>


### [37] [The near-continuum mechanism for extended Boltzmann theory: the non-equilibrium relaxation](https://arxiv.org/abs/2602.05775)
*Sha Liu,Ningchao Ding,Ming Fang,Hao Jin,Rui Zhang,Congshan Zhuo,Chengwen Zhong*

Main category: physics.comp-ph

TL;DR: The paper develops a theoretical framework using the Pullin equation to analyze near-continuum relaxation mechanisms in polyatomic gases, obtaining explicit analytical expressions for macroscopic variable relaxation and confirming that thermal conduction coefficients depend on thermal non-equilibrium.


<details>
  <summary>Details</summary>
Motivation: Existing collision models like Borgnakke-Larsen don't guarantee detailed balance and aren't integrable. The Pullin equation provides an integrable collision kernel that satisfies detailed balance, enabling rigorous analysis of relaxation mechanisms in polyatomic gases.

Method: Use Pullin equation as extended Boltzmann equation; approximate distribution function using mixed Hermite and Laguerre polynomials for rotation; compute collision operator moments; derive macroscopic transport coefficients in Chapman-Enskog framework; propose novel Rykov-type relaxation model.

Result: First explicit analytical expressions for temporal relaxation of macroscopic variables (stress force, translational/rotational temperature, heat flux); confirmation that thermal conduction coefficients depend on thermal non-equilibrium; new Rykov-type relaxation model that captures translational-rotational heat flux interactions; validation through benchmark tests.

Conclusion: The Pullin equation provides a rigorous foundation for analyzing polyatomic gas relaxation. The new Rykov-type model improves upon existing equations by properly accounting for translational-rotational heat flux interactions, with validated precision in benchmark tests.

Abstract: The collision phenomenon of polyatomic gases is described by the collision operator of extended Boltzmann equation or the energy-exchange model in particle direct simulations, for example, the Borgnakke-Larsen model. However, as a collision kernel, it dose not guarantee the entrinsic detailed balance and is not integrable. In this work, the Pullin equation, which possesses an integrable collision kernel and satisfies the detailed balance constraint, is adopted as an extended Boltzmann equation for the theoretical analysis of near-continuum relaxation mechanisms. For clarity, only the translational and rotational degrees are considered in this work. Explicit analytical expressions for the temporal relaxation of macroscopic variables, including the stress force, (translational/rotational) temperature and heat flux, are obtained at the first time. This is achieved by approximating the distribution function in mixed Hermite and Laguerre for rotation and computing the collision operator moments, enabling a direct description of macroscopic non-equilibrium evolution. Base on the same elementary moment (integral) of collision operator, the macroscopic transport coefficients is found in Chapman-Enskog framework. The long-standing speculation, that thermal conduction coefficient should be depended on the degrees of thermal non-equilibrium, is rigorously confirmed and evaluated. When thermal equilibrium is enforced, the present thermal conduction coefficients can be degenerated to the famous results of Mason and Monchick. Given the correct relaxation rate, a Rykov-type novel relaxation model for Pullin equation is proposed. It can recover the interaction of transaltional and rotatioanl heat fluxes in relaxation process, which is ignored in the widely used Rykov equation. Finally, the precision of this new Rykov-type equation is examined using a series of benchmark test cases.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [38] [An approximate Kappa generator for particle simulations](https://arxiv.org/abs/2602.05606)
*Seiji Zenitani,Takayuki Umeda*

Main category: physics.plasm-ph

TL;DR: A fast GPU-optimized random number generator for Kappa velocity distributions using q-exponential approximations and inverse transform sampling.


<details>
  <summary>Details</summary>
Motivation: Need efficient random number generation for Kappa velocity distributions in particle simulations, especially for GPU-based computations where speed is critical.

Method: Approximate the cumulative distribution function with q-exponential function and construct inverse transform sampling procedure optimized for GPU execution.

Result: Method provides practically accurate results (especially for k<4) and runs fast on GPUs, validated through numerical tests.

Conclusion: Proposed generator enables efficient particle simulations with Kappa distributions on GPUs, balancing accuracy and computational speed.

Abstract: A random number generator for the Kappa velocity distribution in particle simulations is proposed. Approximating the cumulative distribution function with the q-exponential function, an inverse transform procedure is constructed. The proposed method provides practically accurate results, in particular for k<4. It runs fast on graphics processing units (GPUs). The derivation, numerical validation, and relevance to GPU execution models are discussed.

</details>


### [39] [Explosive eruption cycles in a rotating Z-pinch](https://arxiv.org/abs/2602.06012)
*David N. Hosking,Luca Swinnerton,Rahul Kesavan*

Main category: physics.plasm-ph

TL;DR: Transonic shear flow along magnetic field lines can stabilize steep pressure gradients in MHD plasmas, creating a metastable "MHD pedestal" that collapses and rebuilds in ELM-like cycles, with available energy calculable via combinatorial optimization.


<details>
  <summary>Details</summary>
Motivation: To understand and model transport barriers in magnetically confined plasmas, particularly the metastable edge pedestal phenomenon observed in tokamaks, using Z-pinch geometry as a simplified analog system.

Method: Simulation of MHD pedestal formation in a heated and sheared Z-pinch, analysis of metastable equilibrium, and calculation of available energy and ejected plasma amounts using combinatorial optimization of flux-tube interchanges.

Result: The MHD pedestal forms slowly but collapses at critical height, expelling significant thermal energy, then rebuilds in ELM-like cycles. Available energy and optimal ejection amounts can be calculated from first principles.

Conclusion: Transonic shear flow creates metastable MHD pedestals analogous to tokamak edge pedestals, with predictable collapse-rebuild cycles and calculable energy release, providing insights for fusion plasma confinement.

Abstract: A transonic shear flow directed along magnetic field lines can linearly stabilize a steep pressure gradient in a confined magnetohydrodynamic (MHD) plasma. In Z-pinch geometry, we show that, like the edge pedestal in tokamak devices, this transport barrier -- which we call the ``MHD pedestal'' -- is metastable, i.e., unstable to finite-amplitude displacements of flux tubes. We simulate the slow formation of an MHD pedestal in a heated and sheared Z-pinch, which collapses on reaching a critical height, expelling an order-unity fraction of the confined thermal energy. The MHD pedestal then rebuilds and the process repeats, in a manner analogous to the ELM cycle seen in fusion experiments. We show that the available energy of the metastable equilibrium, and the most energetically favorable amount of ejected plasma, can be calculated from first principles via combinatorial optimization of flux-tube interchanges.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [40] [Auroral signatures of ballooning instability and plasmoid formation processes in the near-Earth magnetotail](https://arxiv.org/abs/2602.05108)
*Ping Zhu,Jun Liang,Jiaxing Liu,Sui Wan,Eric Donovan*

Main category: physics.space-ph

TL;DR: This paper validates MHD simulations of ballooning instability and plasmoid formation as substorm onset triggers by comparing simulation results with THEMIS satellite and auroral observations.


<details>
  <summary>Details</summary>
Motivation: To validate the proposed mechanism that ballooning instability and subsequent plasmoid formation in the near-Earth magnetotail trigger substorm onset, by comparing MHD simulation results with actual observational data from THEMIS satellites and auroral observations.

Method: Selected THEMIS substorm onset events with good auroral conjunction, inferred pre-onset magnetotail conditions from in-situ data, compared with MHD simulation onset conditions, extracted ballooning instability and plasmoid signatures from simulations, and compared with observational magnetic fields and flow patterns. Also mapped field-aligned currents to auroral ionosphere for comparison with auroral patterns.

Result: The study provides comparative validation between MHD simulation predictions of ballooning instability/plasmoid formation and actual observational data from THEMIS and auroral measurements, examining growth rates, wavenumbers, and auroral intensities.

Conclusion: This validation effort represents a crucial first step toward developing a self-consistent coupling model that includes magnetotail-ionosphere interaction in the substorm onset process, bridging simulation predictions with observational evidence.

Abstract: The nonlinear development of ballooning instability and the subsequently induced plasmoid formation in the near-Earth magnetotail demonstrated in MHD simulations has been proposed as a potential trigger mechanism for substorm onset over the past decade, and their connections to the in-situ satellite and ground all-sky auroral optical observations have been a subject of continued research. In this work, a set of THEMIS substorm onset events with good conjunction of auroral observations has been selected for comparative simulation study, whose pre-onset magnetotail configuration and conditions are inferred from in-situ data and compared with the onset conditions of ballooning instability obtained in our MHD simulations. The evolution of the near-Earth magnetotail is followed, where the signatures of ballooning instability and the plasmoid formation are extracted from simulations and compared with the magnetic fields and flow patterns within the magnetotail region from observation data. The field-aligned current (FAC) density is evaluated at the Earth side boundary of the magnetotail domain of simulation, which is further mapped along magnetic field lines to the auroral ionosphere and compared with the auroral pattern and evolution there in terms of growth rate, dominant wavenumber, and absolute auroral intensities. Such validation efforts are also the first step towards the development of a self-consistent coupling model that includes the magnetotail-ionosphere interaction in the substorm onset process.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [41] [Towards uncertainty quantification of a model for cancer-on-chip experiments](https://arxiv.org/abs/2602.06018)
*Silvia Bertoluzza,Vittoria Bianchi,Gabriella Bretti,Lorenzo Tamellini,Pietro Zanotti*

Main category: cs.CE

TL;DR: This paper develops a data-informed differential modeling framework for cancer-on-chip experiments using uncertainty quantification techniques to tune parameters and assess prediction uncertainties.


<details>
  <summary>Details</summary>
Motivation: To create predictive models for cancer-on-chip experiments that can account for parameter uncertainties and use synthetic data to improve model reliability for predicting and controlling cancer dynamics.

Method: Uses Keller-Segel-type chemotaxis models solved by Hybridized Discontinuous Galerkin method, combined with uncertainty quantification techniques: global sensitivity analysis (Sobol/Morris indices), Bayesian inverse uncertainty quantification for parameter tuning, and forward uncertainty quantification with sparse-grid surrogate models.

Result: Develops a comprehensive framework that can identify influential parameters, tune model parameters using data, and quantify residual uncertainties in predictions, with computational efficiency achieved through surrogate modeling.

Conclusion: The proposed uncertainty quantification pipeline provides a systematic approach for data-informed modeling of cancer-on-chip systems, enabling more reliable predictions while accounting for parameter uncertainties.

Abstract: This study is a first step towards using data-informed differential models to predict and control the dynamics of cancer-on-chip experiments. We consider a conceptualized one-dimensional device, containing a cancer and a population of white blood cells. The interaction between the cancer and the population of cells is modeled by a chemotaxis model inspired by Keller-Segel-type equations, which is solved by a Hybridized Discontinuous Galerkin method. Our goal is using (synthetic) data to tune the parameters of the governing equations and to assess the uncertainty on the predictions of the dynamics due to the residual uncertainty on the parameters remaining after the tuning procedure. To this end, we apply techniques from uncertainty quantification for parametric differential models. We first perform a global sensitivity analysis using both Sobol and Morris indices to assess how parameter uncertainty impacts model predictions, and fix the value of parameters with negligible impact. Subsequently, we conduct an inverse uncertainty quantification analysis by Bayesian techniques to compute a data-informed probability distribution of the remaining model parameters. Finally, we carry out a forward uncertainty quantification analysis to compute the impact of the updated (residual) parametric uncertainties on the quantities of interest of the model. The whole procedure is sped up by using surrogate models, based on sparse-grids, to approximate the mapping of the uncertain parameters to the quantities of interest.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [42] [A term-by-term variational multiscale method with dynamic subscales for incompressible turbulent aerodynamics](https://arxiv.org/abs/2602.05563)
*Diego Escobar,Douglas Pacheco,Alejando Aguirre,Ernesto Castillo*

Main category: physics.flu-dyn

TL;DR: A dynamic term-by-term VMS stabilized formulation for incompressible flows from laminar to turbulent regimes, validated on large-scale aerodynamics using unstructured meshes up to 40M elements.


<details>
  <summary>Details</summary>
Motivation: To develop a unified stabilized finite element framework that handles under-resolved flow scales without problem-specific turbulence models, working across laminar to turbulent regimes in complex 3D settings.

Method: Dynamic term-by-term VMS formulation embedded in incremental pressure-correction fractional-step framework with orthogonal projections, minimal stabilization terms, allowing equal-order velocity-pressure interpolation.

Result: Method validated on Ahmed body at Re=7.68×10⁵ with multiple slant angles using 3-40M element meshes, and on Formula 1 configuration at Re≈10⁶, showing robust performance at scale and capturing separated-flow features.

Conclusion: The proposed stabilized pressure-segregated formulation provides robust control of convection-dominated dynamics, captures key flow features, and offers consistent dissipation control in under-resolved regimes within a unified framework.

Abstract: Variational multiscale (VMS) methods offer a robust framework for handling under-resolved flow scales without resorting to problem-specific turbulence models. Here, we propose and assess a dynamic, term-by-term VMS stabilized formulation for simulating incompressible flows from laminar to turbulent regimes. The method is embedded in an incremental pressure-correction fractional-step framework and employs a minimal set of stabilization terms, yielding a unified discretization that (i) allows equal-order velocity--pressure interpolation and (ii) provides robust control of convection-dominated dynamics in complex three-dimensional settings. Orthogonal projections are a key ingredient and ensure that the non-residual, term-by-term structure induces dissipation through dynamic subscales suitable for turbulent simulations. The methodology is validated on large-scale external-aerodynamics configurations, including the Ahmed body at Re $ = 7.68\times 10^{5}$ for multiple slant angles, using unstructured tetrahedral meshes ranging from 3 to 40 million elements. Applicability is further demonstrated on a realistic Formula~1 configuration at $U_\infty=56~\mathrm{m/s}$ (201.6~km/h), corresponding to Re $ \approx 10^{6}$. The results show that the proposed stabilized pressure-segregated formulation remains robust at scale and captures key separated-flow features and coherent wake organization. Pointwise velocity and pressure spectra provide an a posteriori consistency indicator, exhibiting finite frequency ranges compatible with inertial-subrange reference slopes in the resolved band and supporting dissipation control in under-resolved regimes within a unified stabilized finite element framework.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [43] [Strong local nondeterminism for stochastic time-fractional slow and fast diffusion equations](https://arxiv.org/abs/2602.05317)
*Le Chen,Cheuk Yin Lee,Panqiu Xia*

Main category: math.PR

TL;DR: The paper studies stochastic time-fractional equations with Caputo derivatives, fractional Laplacians, and Riemann-Liouville integrals, deriving sharp conditions for solution existence and establishing regularity properties like local nondeterminism and moduli of continuity.


<details>
  <summary>Details</summary>
Motivation: To analyze stochastic time-fractional partial differential equations driven by Gaussian noise, which generalize classical stochastic PDEs and have applications in modeling anomalous diffusion and memory effects in various physical and biological systems.

Method: The authors study equations involving Caputo time derivatives, fractional Laplacians, and Riemann-Liouville time integrals acting on fractional-in-time and Riesz-type-in-space Gaussian noise. They use analytical techniques to derive fundamental solution kernels and apply probabilistic methods to establish solution properties.

Result: Derived sharp Dalang-type necessary and sufficient conditions for random field solution existence across almost full parameter range. Proved sharp variance bounds, strong local nondeterminism in time and space, exact moduli of continuity, Chung-type laws, and small ball probability bounds.

Conclusion: The paper provides a comprehensive analysis of stochastic time-fractional equations, establishing sharp existence conditions and detailed regularity properties. The fundamental solution kernel asymptotics and derived probabilistic results offer tools for studying such equations and may have independent mathematical interest.

Abstract: We study a class of stochastic time-fractional equations on $\mathbb{R}^d$ driven by a centered Gaussian noise, involving a Caputo time derivative of order $β>0$, a fractional (power) Laplacian of order $α>0$, and a Riemann-Liouville time integral of order $γ\ge0$ acting on the noise. The noise is fractional in time (index $H$) and Riesz-type in space (index $\ell$). We derive sharp Dalang-type necessary and sufficient conditions for the existence of a random field solution across almost full parameter range $(α,β,γ;H,\ell)$. Under the Dalang-type conditions, we prove sharp variance bounds for temporal and spatial increments, as well as strong local nondeterminism in time in several regimes (two-sided version for $β=1$ and for parts of the case $β=2$; one-sided version for $0<β<2$) and strong local nondeterminism in space for the whole range of parameters. As applications, we derive exact uniform and local moduli of continuity, Chung-type laws of the iterated logarithm, and quantitative bounds on small ball probabilities. Along the way, we obtain sharp asymptotics for the fundamental solution kernels at $0$ and $\infty$, which may be of independent interest.

</details>


### [44] [On the Resistance Conjecture](https://arxiv.org/abs/2602.05477)
*Sylvester Eriksson-Bique*

Main category: math.PR

TL;DR: The paper proves the resistance conjecture linking parabolic Harnack inequalities to volume doubling, capacity bounds, and Poincaré inequalities in p-Dirichlet spaces.


<details>
  <summary>Details</summary>
Motivation: To resolve the resistance conjecture that characterizes parabolic Harnack inequalities through three geometric/analytic conditions, providing a unified framework for analysis on diverse spaces including metric spaces, fractals, graphs, and manifolds.

Method: Uses p-Dirichlet spaces framework to show that volume doubling, upper capacity bounds, and Poincaré inequalities imply cutoff Sobolev inequality, then establishes extension methods and characterization of Sobolev functions via Poincaré inequalities, extending techniques from Jones and Koskela.

Result: Affirmative proof of the resistance conjecture, enabling unified treatment of Harnack inequalities and stability phenomena across various settings for all p∈(1,∞), with applications showing finite martingale dimension and Cheeger-type differential structure.

Conclusion: The paper successfully resolves the resistance conjecture, providing a comprehensive framework that bridges analysis on metric spaces, fractals, graphs, and manifolds through the p-Dirichlet spaces approach.

Abstract: We give an affirmative answer to the resistance conjecture on characterization of parabolic Harnack inequalities in terms of volume doubling, upper capacity bounds and a Poincaré inequalities. The key step is to show that these three assumptions imply the so called cutoff Sobolev inequality, an important inequality in the study of anomalous diffusions, Dirichlet forms and re-scaled energies in fractals. This implication is shown in the general setting of $p$-Dirichlet Spaces introduced by the author and Murugan, and thus a unified treatment becomes possible to proving Harnack inequalities and stability phenomena in both analysis on metric spaces and fractals and for graphs and manifolds for all exponents $p\in (1,\infty)$. As an application, we also show that a Dirichlet space satisfying volume doubling, Poincaré and upper capacity bounds has finite martingale dimension and admits a type of differential structure similar to the work of Cheeger. In the course of the proof, we establish methods of extension and characterizations of Sobolev functions by Poincaré-inequalities, and extend the methods of Jones and Koskela to the general setting of $p$-Dirichlet spaces.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [45] [Penalized Likelihood Parameter Estimation for Differential Equation Models: A Computational Tutorial](https://arxiv.org/abs/2602.04891)
*Matthew J Simpson,James S Bennett,Alexander Johnston,Ruth E Baker*

Main category: stat.ME

TL;DR: A tutorial article providing computational exercises for learning generalized profiling (parameter cascading) for parameter estimation in ODE models, with reproducible Jupyter notebooks.


<details>
  <summary>Details</summary>
Motivation: Generalized profiling offers advantages over standard parameter estimation methods like MLE and MCMC by directly linking models and data through penalized likelihood, but is underutilized in practice. The paper aims to address this gap through educational resources.

Method: The article provides self-directed computational exercises using reproducible open-source Jupyter notebooks available on GitHub, focusing on applying generalized profiling to ordinary differential equation models.

Result: A set of educational resources including computational exercises and Jupyter notebooks that enable readers to develop skills in applying generalized profiling to ODE parameter estimation problems.

Conclusion: The tutorial-style article successfully creates accessible learning materials to promote wider adoption of generalized profiling for parameter estimation in differential equation models, bridging the gap between theoretical advantages and practical implementation.

Abstract: Parameter estimation connects mathematical models to real-world data and decision making across many scientific and industrial applications. Standard approaches such as maximum likelihood estimation and Markov chain Monte Carlo estimate parameters by repeatedly solving the model, which often requires numerical solutions of differential equation models. In contrast, generalized profiling (also called parameter cascading) focuses directly on the governing differential equation(s), linking the model and data through a penalized likelihood that explicitly measures both the data fit and model fit. Despite several advantages, generalized profiling is relatively rarely used in practice. This tutorial-style article outlines a set of self-directed computational exercises that facilitate skills development in applying generalized profiling to a range of ordinary differential equation models. All calculations can be repeated using reproducible open-source Jupyter notebooks that are available on GitHub.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [46] [Radon--Wasserstein Gradient Flows for Interacting-Particle Sampling in High Dimensions](https://arxiv.org/abs/2602.05227)
*Elias Hess-Childs,Dejan Slepčev,Lantian Xu*

Main category: stat.ML

TL;DR: New gradient flows for KL divergence with efficient interacting-particle approximations in high dimensions, using Radon-Wasserstein geometries based on Radon transform.


<details>
  <summary>Details</summary>
Motivation: Existing gradient flows of KL divergence (like Fokker-Planck and Stein Variational Gradient Descent) need efficient approximations in high dimensions with linear scaling in both particle count and dimension.

Method: Introduce new transportation-based Riemannian geometries: Radon-Wasserstein and Regularized Radon-Wasserstein (RRW) geometries using Radon transform, making gradient-flow velocities depend only on 1D projections, enabling efficient FFT-based 1D convolutions.

Result: Algorithms with per-step cost scaling linearly in both number of particles and dimension, with numerical experiments comparing convergence and quantization, plus theoretical results on well-posedness and long-time convergence guarantees for RRW flow.

Conclusion: New gradient flows provide efficient high-dimensional KL divergence optimization with linear scaling, combining theoretical guarantees with practical computational efficiency through Radon transform-based geometries.

Abstract: Gradient flows of the Kullback--Leibler (KL) divergence, such as the Fokker--Planck equation and Stein Variational Gradient Descent, evolve a distribution toward a target density known only up to a normalizing constant. We introduce new gradient flows of the KL divergence with a remarkable combination of properties: they admit accurate interacting-particle approximations in high dimensions, and the per-step cost scales linearly in both the number of particles and the dimension. These gradient flows are based on new transportation-based Riemannian geometries on the space of probability measures: the Radon--Wasserstein geometry and the related Regularized Radon--Wasserstein (RRW) geometry. We define these geometries using the Radon transform so that the gradient-flow velocities depend only on one-dimensional projections. This yields interacting-particle-based algorithms whose per-step cost follows from efficient Fast Fourier Transform-based evaluation of the required 1D convolutions. We additionally provide numerical experiments that study the performance of the proposed algorithms and compare convergence behavior and quantization. Finally, we prove some theoretical results including well-posedness of the flows and long-time convergence guarantees for the RRW flow.

</details>


### [47] [Wedge Sampling: Efficient Tensor Completion with Nearly-Linear Sample Complexity](https://arxiv.org/abs/2602.05869)
*Hengrui Luo,Anna Ma,Ludovic Stephan,Yizhe Zhu*

Main category: stat.ML

TL;DR: Wedge Sampling enables efficient low-rank tensor completion with nearly linear sample complexity by using structured length-two patterns instead of uniform random sampling.


<details>
  <summary>Details</summary>
Motivation: Standard uniform sampling for tensor completion requires high sample complexity (typically O(n^{k/2})) for efficient algorithms, creating a statistical-to-computational gap. The paper aims to overcome this barrier by designing a non-adaptive sampling scheme that enables efficient polynomial-time algorithms.

Method: Proposes Wedge Sampling, a non-adaptive scheme that allocates observations to structured length-two patterns (wedges) in an associated bipartite sampling graph. This strengthens spectral signals for initialization. The method is plug-and-play: wedge sampling provides spectral initialization, then existing refinement procedures (spectral or gradient-based) use only additional O(n) uniform samples.

Result: Enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in n. Substantially improves over the O(n^{k/2}) sample complexity typically required under uniform sampling. Shows that the statistical-to-computational gap is largely a consequence of uniform sampling model.

Conclusion: Alternative non-adaptive measurement designs like Wedge Sampling that guarantee strong initialization can overcome the statistical-to-computational barrier in tensor completion. The approach demonstrates that sampling paradigm changes enable efficient algorithms with near-optimal sample complexity.

Abstract: We introduce Wedge Sampling, a new non-adaptive sampling scheme for low-rank tensor completion. We study recovery of an order-$k$ low-rank tensor of dimension $n \times \cdots \times n$ from a subset of its entries. Unlike the standard uniform entry model (i.e., i.i.d. samples from $[n]^k$), wedge sampling allocates observations to structured length-two patterns (wedges) in an associated bipartite sampling graph. By directly promoting these length-two connections, the sampling design strengthens the spectral signal that underlies efficient initialization, in regimes where uniform sampling is too sparse to generate enough informative correlations.
  Our main result shows that this change in sampling paradigm enables polynomial-time algorithms to achieve both weak and exact recovery with nearly linear sample complexity in $n$. The approach is also plug-and-play: wedge-sampling-based spectral initialization can be combined with existing refinement procedures (e.g., spectral or gradient-based methods) using only an additional $\tilde{O}(n)$ uniformly sampled entries, substantially improving over the $\tilde{O}(n^{k/2})$ sample complexity typically required under uniform entry sampling for efficient methods. Overall, our results suggest that the statistical-to-computational gap highlighted in Barak and Moitra (2022) is, to a large extent, a consequence of the uniform entry sampling model for tensor completion, and that alternative non-adaptive measurement designs that guarantee a strong initialization can overcome this barrier.

</details>


### [48] [Diffusion Model's Generalization Can Be Characterized by Inductive Biases toward a Data-Dependent Ridge Manifold](https://arxiv.org/abs/2602.06021)
*Ye He,Yitong Qiu,Molei Tao*

Main category: stat.ML

TL;DR: The paper analyzes how diffusion models generalize by characterizing the generated distribution through a log-density ridge manifold, revealing an inference process of reach-align-slide around this manifold.


<details>
  <summary>Details</summary>
Motivation: To understand how diffusion models generalize when not memorizing training data, which is important for assessing model performance in downstream applications.

Method: Proposes a log-density ridge manifold framework to quantify generated data relationships with inference dynamics, analyzing the reach-align-slide process around the manifold and how training errors affect normal/tangent motions.

Result: Inference undergoes reach-align-slide process: trajectories reach manifold neighborhood, align via normal direction pushes, then slide along manifold in tangent directions. Different training errors lead to quantifiable normal/tangent motions that characterize inter-mode generations.

Conclusion: Understanding training dynamics enables accurate quantification of generation inductive bias, with random feature model example showing how architectural bias and training accuracy compose to create inductive biases that evolve with inference dynamics.

Abstract: When a diffusion model is not memorizing the training data set, how does it generalize exactly? A quantitative understanding of the distribution it generates would be beneficial to, for example, an assessment of the model's performance for downstream applications. We thus explicitly characterize what diffusion model generates, by proposing a log-density ridge manifold and quantifying how the generated data relate to this manifold as inference dynamics progresses. More precisely, inference undergoes a reach-align-slide process centered around the ridge manifold: trajectories first reach a neighborhood of the manifold, then align as being pushed toward or away from the manifold in normal directions, and finally slide along the manifold in tangent directions. Within the scope of this general behavior, different training errors will lead to different normal and tangent motions, which can be quantified, and these detailed motions characterize when inter-mode generations emerge. More detailed understanding of training dynamics will lead to more accurate quantification of the generation inductive bias, and an example of random feature model will be considered, for which we can explicitly illustrate how diffusion model's inductive biases originate as a composition of architectural bias and training accuracy, and how they evolve with the inference dynamics. Experiments on synthetic multimodal distributions and MNIST latent diffusion support the predicted directional effects, in both low- and high-dimensions.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [49] [Branch-and-Bound Tensor Networks for Exact Ground-State Characterization](https://arxiv.org/abs/2602.05470)
*Yijia Wang,Xuanzhao Gao,Pan Zhang,Feng Pan,Jinguo Liu*

Main category: cond-mat.stat-mech

TL;DR: BBTN method combines branch-and-bound with tropical tensor networks to solve NP-hard ground-state problems, achieving massive speedups and scaling to previously intractable problem sizes.


<details>
  <summary>Details</summary>
Motivation: Characterizing ground-state properties of disordered systems (spin glasses, combinatorial optimization) is fundamental but computationally challenging - exact ground state computation is NP-hard and degeneracy counting is #P-hard. Tensor Networks methods have emerged but face exponential space complexity limitations.

Method: Branch-and-Bound Tensor Network (BBTN) method integrates adaptive branch-and-bound search framework with efficient contraction of tropical tensor networks, addressing the space complexity bottleneck of standard tensor network methods.

Result: BBTN significantly surpasses state-of-the-art solvers, enabling exact ground-state counting for ±J spin glasses up to 64×64 and solving Maximum Independent Set problems on King's subgraphs up to 100×100. It compresses years of runtime into minutes for hard instances and outperforms leading integer-programming solvers by over 30×.

Conclusion: BBTN establishes a versatile and scalable framework for solving hard problems in statistical physics and combinatorial optimization, pushing the boundaries of tractability to previously unreachable scales.

Abstract: Characterizing the ground-state properties of disordered systems, such as spin glasses and combinatorial optimization problems, is fundamental to science and engineering. However, computing exact ground states and counting their degeneracies are generally NP-hard and #P-hard problems, respectively, posing a formidable challenge for exact algorithms. Recently, Tensor Networks methods, which utilize high-dimensional linear algebra and achieve massive hardware parallelization, have emerged as a rapidly developing paradigm for efficiently solving these tasks. Despite their success, these methods are fundamentally constrained by the exponential growth of space complexity, which severely limits their scalability. To address this bottleneck, we introduce the Branch-and-Bound Tensor Network (BBTN) method, which seamlessly integrates the adaptive search framework of branch-and-bound with the efficient contraction of tropical tensor networks, significantly extending the reach of exact algorithms. We show that BBTN significantly surpasses existing state-of-the-art solvers, setting new benchmarks for exact computation. It pushes the boundaries of tractability to previously unreachable scales, enabling exact ground-state counting for $\pm J$ spin glasses up to $64 \times 64$ and solving Maximum Independent Set problems on King's subgraphs up to $100 \times 100$. For hard instances, BBTN dramatically reduces the computational cost of standard Tropical Tensor Networks, compressing years of runtime into minutes. Furthermore, it outperforms leading integer-programming solvers by over 30$\times$, establishing a versatile and scalable framework for solving hard problems in statistical physics and combinatorial optimization.

</details>


### [50] [Exchange Monte Carlo for continuous-space Path Integral Monte Carlo simulation](https://arxiv.org/abs/2602.05500)
*Xun Zhao,Synge Todo*

Main category: cond-mat.stat-mech

TL;DR: Novel Exchange Monte Carlo method for continuous-space PIMC simulations that reduces autocorrelation times for bosonic systems by enabling replica transitions between interaction regimes.


<details>
  <summary>Details</summary>
Motivation: Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, especially when measuring observables affected by particle permutations like winding number, which limits computational efficiency.

Method: Introduces Exchange Monte Carlo (EMC) with exchange update scheme for replica transitions between different interaction regimes, plus Stochastic Potential Switching (SPS) to efficiently decompose long-range interatomic pair potentials.

Result: Significantly accelerates Monte Carlo dynamics, particularly for global observables sensitive to permutation effects, and substantially enhances computational efficiency for long-range potentials like Lennard-Jones and Aziz potentials.

Conclusion: The proposed EMC method with SPS provides an effective solution to autocorrelation problems in bosonic PIMC simulations, enabling more efficient computation of permutation-sensitive observables and handling of long-range interactions.

Abstract: We present a novel Exchange Monte Carlo (EMC) method designed for application in continuous-space Path Integral Monte Carlo (PIMC) simulations at finite temperature. Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, particularly when measuring observables affected by particle permutations, such as the winding number. To address this issue, we introduce an exchange update scheme that facilitates replica transitions between different interaction regimes, significantly accelerating Monte Carlo dynamics-especially for global observables sensitive to permutation effects. Furthermore, we incorporate Stochastic Potential Switching (SPS) to efficiently decompose interactions, substantially enhancing computational efficiency for long-range interatomic pair potentials such as the Lennard-Jones and Aziz potentials.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [51] [lrux: Fast low-rank updates of determinants and Pfaffians in JAX](https://arxiv.org/abs/2602.05255)
*Ao Chen,Christopher Roth*

Main category: cond-mat.str-el

TL;DR: lrux is a JAX-based package for fast low-rank updates of determinants and Pfaffians, achieving up to 1000× speedup for quantum Monte Carlo algorithms by reducing computational complexity from O(n³) to O(n²k).


<details>
  <summary>Details</summary>
Motivation: The dominant computational bottleneck in various quantum Monte Carlo algorithms is the repeated evaluation of determinants and Pfaffians, which scales cubically with matrix size (O(n³)). This limits the scalability of QMC simulations.

Method: Implements efficient low-rank updates that reduce successive wavefunction evaluation cost from O(n³) to O(n²k) when update rank k < matrix dimension n. Supports both determinant and Pfaffian updates with delayed-update strategies that trade FLOPs for reduced memory traffic. Natively integrates with JAX transformations (JIT compilation, vectorization, automatic differentiation) and supports real/complex data types.

Result: Benchmarks on GPUs demonstrate up to 1000× speedup at large matrix sizes. The package enables scalable, high-performance evaluation of antisymmetric wavefunctions and serves as a drop-in component for QMC workflows.

Conclusion: lrux provides a high-performance solution for fast low-rank updates of determinants and Pfaffians, significantly accelerating quantum Monte Carlo algorithms while maintaining integration with modern JAX-based computational workflows.

Abstract: We present lrux, a JAX-based software package for fast low-rank updates of determinants and Pfaffians, targeting the dominant computational bottleneck in various quantum Monte Carlo (QMC) algorithms. The package implements efficient low-rank updates that reduce the cost of successive wavefunction evaluations from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2k)$ when the update rank $k$ is smaller than the dimension $n$ of matrices. Both determinant and Pfaffian updates are supported, together with delayed-update strategies that trade floating-point operations for reduced memory traffic on modern accelerators. lrux natively integrates with JAX transformations such as JIT compilation, vectorization, and automatic differentiation, and supports both real and complex data types. Benchmarks on GPUs demonstrate up to $1000\times$ speedup at large matrix sizes. lrux enables scalable, high-performance evaluation of antisymmetric wavefunctions and is designed as a drop-in component for a wide range of QMC workflows. lrux is available at https://github.com/ChenAo-Phys/lrux.

</details>


<div id='math.NT'></div>

# math.NT [[Back]](#toc)

### [52] [$L^q$-norm bounds for arithmetic eigenfunctions via microlocal Kakeya-Nikodym estimate](https://arxiv.org/abs/2602.05697)
*Jiaqi Hou,Xiaoqi Huang*

Main category: math.NT

TL;DR: The paper proves a power saving improvement for the global L⁶-norm of Hecke-Maass forms on compact arithmetic hyperbolic surfaces, beating the local bound of Sogge.


<details>
  <summary>Details</summary>
Motivation: To improve upon the local bound for L⁶-norms of Hecke-Maass forms established by Sogge, which gives ∥ψ∥_{L⁶(X)} ≲ λ^{1/6}. The authors aim to obtain power saving beyond this standard bound using arithmetic methods.

Method: 1. Use Iwaniec-Sarnak's L∞-norm bound ∥ψ∥_{L∞(X)} ≲_ε λ^{5/12+ε}. 2. Apply harmonic analysis tools to reduce the L⁶-norm problem to a microlocal L⁶ Kakeya-Nikodym estimate. 3. Establish an improved microlocal L⁶ Kakeya-Nikodym estimate using arithmetic amplification techniques developed by Iwaniec and Sarnak.

Result: Proves ∥ψ∥_{L⁶(X)} ≲_ε λ^{1/6 - 1/144 + ε}, achieving power saving of 1/144 over Sogge's local bound λ^{1/6}.

Conclusion: The paper demonstrates that arithmetic methods, specifically Iwaniec-Sarnak's amplification technique, can yield quantitative improvements in L⁷-norm bounds for automorphic forms beyond what purely analytic methods provide.

Abstract: Let $X$ be a compact arithmetic hyperbolic surface, and let $ψ$ be an $L^2$-normalized Hecke-Maass form on $X$ with sufficiently large spectral parameter $λ$. We give a new proof to obtain some power saving for the global $L^6$-norm $\|ψ\|_{L^6(X)}\lesssim_ελ^{\frac{1}{6}-\frac{1}{144}+ε}$ over the local bound $\|ψ\|_{L^6(X)}\lesssimλ^{\frac16}$ of Sogge. Using the $L^\infty$-norm bound $\|ψ\|_{L^\infty(X)}\lesssim_ελ^{\frac{5}{12}+ε}$ of Iwaniec and Sarnak and harmonic analysis tools, we reduce the $L^6$-norm problem to a microlocal $L^6$ Kakeya-Nikodym estimate for $ψ$. Finally, we establish an improved microlocal $L^6$ Kakeya-Nikodym estimate via arithmetic amplification developed by Iwaniec and Sarnak.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [53] [The Correlation Length of Turbulence in Magnetic Clouds](https://arxiv.org/abs/2602.05450)
*S. W. Good,J. Lalueza Puértolas,A. -S. M. Jylhä,E. K. J. Kilpua*

Main category: astro-ph.SR

TL;DR: Researchers used force-free flux rope fits to detrend magnetic field data from Parker Solar Probe in two magnetic clouds, finding significantly smaller turbulence correlation lengths after detrending, and observed k⁻⁵/³ scaling in the inertial range despite flux rope effects at larger scales.


<details>
  <summary>Details</summary>
Motivation: To accurately measure turbulence correlation lengths in solar wind magnetic clouds by removing the global flux rope trend, which otherwise contaminates measurements and leads to overestimates when turbulence amplitudes are small relative to flux rope amplitude.

Method: Used force-free flux rope fits to detrend magnetic field time series from Parker Solar Probe measurements in two magnetic clouds, then calculated turbulence correlation lengths from the detrended data and analyzed spectral scaling.

Result: Detrended correlation lengths were 2.7×10⁴ dₚ (at 0.77 au) and 1.6×10⁴ dₚ (at 0.39 au), significantly smaller than undetrended values. Flux rope contributed k⁻³ scaling at large scales but had negligible effect in inertial range where k⁻⁵/³ scaling was observed.

Conclusion: Proper detrending of flux rope structures is essential for accurate turbulence correlation length measurements in magnetic clouds, and the inertial range turbulence follows Kolmogorov-like scaling despite flux rope effects at larger scales.

Abstract: The large-scale limit or outer scale of turbulence in the solar wind is associated with the correlation length of the magnetic field. Determining correlation lengths from magnetic field time series in magnetic clouds is complicated by the presence of the global flux rope: without removal of the flux rope trend, correlation length measurements will be sensitive to the flux rope as well as the turbulence, and give overestimates of the outer scale when turbulence amplitudes at the outer scale are small relative to the flux rope amplitude. We have used force-free flux rope fits to detrend magnetic field time series measured by Parker Solar Probe in two magnetic clouds and calculated the turbulence correlation length in the clouds using the detrended data. The detrended correlation length in terms of the proton inertial length, $d_p$, was $2.7\times10^{4} d_p$ in one cloud (observed at 0.77 au) and $1.6\times10^{4}d_p$ in the other (observed at 0.39 au), significantly smaller than the values obtained without detrending. Increments in the flux rope fits scaled equivalently to a $k^{-3}$ wavenumber power spectrum; this contribution from the flux rope considerably steepened the total spectrum at the largest scales but had a negligible effect in the inertial range, where scaling in both clouds equivalent to $\sim$$k^{-5/3}$ was observed. Finally, we discuss the possible relation of turbulence correlation lengths to mesoscale structure in magnetic clouds.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [54] [Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics](https://arxiv.org/abs/2602.04975)
*José Afonso,Vasco Guerra,Pedro Viegas*

Main category: cs.LG

TL;DR: A stochastic hierarchical optimization framework using reduced Hessian approximation for efficient calibration of physical models, validated on plasma-surface interactions.


<details>
  <summary>Details</summary>
Motivation: Physical model calibration is computationally expensive due to high-dimensional parameter spaces and anisotropic landscapes. Traditional methods require exhaustive sampling, which is prohibitive for complex systems like plasma-surface interactions where surface reactivity parameters are uncertain and kinetic simulations are costly.

Method: Uses a stochastic hierarchical optimization framework inspired by Sloppy Model theory. Employs reduced Hessian approximation to identify and target stiff parameter subspace with minimal simulation queries. Integrates with probabilistic formulation to derive principled objective loss function directly from observed data.

Result: Method consistently outperforms baseline optimization techniques in sample efficiency. Validated on plasma-surface interactions problem, demonstrating efficient navigation of highly anisotropic landscapes while avoiding computational burden of exhaustive sampling.

Conclusion: Provides a general and scalable tool for optimizing models of complex reaction systems, applicable to diverse domains from plasma chemistry to biochemical networks.

Abstract: This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simulation queries. This strategy enables efficient navigation of highly anisotropic landscapes, avoiding the computational burden of exhaustive sampling. To ensure rigorous inference, we integrate this approach with a probabilistic formulation that derives a principled objective loss function directly from observed data. We validate the framework by applying it to the problem of plasma-surface interactions, where accurate modelling is strictly limited by uncertainties in surface reactivity parameters and the computational cost of kinetic simulations. Comparative analysis demonstrates that our method consistently outperforms baseline optimization techniques in sample efficiency. This approach offers a general and scalable tool for optimizing models of complex reaction systems, ranging from plasma chemistry to biochemical networks.

</details>


### [55] [SpectraKAN: Conditioning Spectral Operators](https://arxiv.org/abs/2602.05187)
*Chun-Wun Cheng,Carola-Bibiane Schönlieb,Angelica I. Aviles-Rivero*

Main category: cs.LG

TL;DR: SpectraKAN introduces an input-conditioned spectral neural operator that adapts Fourier kernels based on the global system state, achieving SOTA performance on PDE benchmarks with up to 49% RMSE reduction.


<details>
  <summary>Details</summary>
Motivation: Existing spectral neural operators like FNO use static Fourier kernels applied uniformly across inputs, which limits their ability to capture multi-scale, regime-dependent, and anisotropic dynamics that depend on the global state of the system.

Method: SpectraKAN conditions the spectral operator on the input itself by extracting a compact global representation from spatio-temporal history and using it to modulate a multi-scale Fourier trunk via single-query cross-attention, turning static spectral convolution into an input-conditioned integral operator.

Result: SpectraKAN achieves state-of-the-art performance across diverse PDE benchmarks, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.

Conclusion: The proposed input-conditioned spectral operator enables adaptive behavior while retaining the efficiency of spectral mixing, with theoretical justification showing convergence to a resolution-independent continuous operator under mesh refinement and Lipschitz-controlled global modulation.

Abstract: Spectral neural operators, particularly Fourier Neural Operators (FNO), are a powerful framework for learning solution operators of partial differential equations (PDEs) due to their efficient global mixing in the frequency domain. However, existing spectral operators rely on static Fourier kernels applied uniformly across inputs, limiting their ability to capture multi-scale, regime-dependent, and anisotropic dynamics governed by the global state of the system. We introduce SpectraKAN, a neural operator that conditions the spectral operator on the input itself, turning static spectral convolution into an input-conditioned integral operator. This is achieved by extracting a compact global representation from spatio-temporal history and using it to modulate a multi-scale Fourier trunk via single-query cross-attention, enabling the operator to adapt its behaviour while retaining the efficiency of spectral mixing. We provide theoretical justification showing that this modulation converges to a resolution-independent continuous operator under mesh refinement and KAN gives smooth, Lipschitz-controlled global modulation. Across diverse PDE benchmarks, SpectraKAN achieves state-of-the-art performance, reducing RMSE by up to 49% over strong baselines, with particularly large gains on challenging spatio-temporal prediction tasks.

</details>
