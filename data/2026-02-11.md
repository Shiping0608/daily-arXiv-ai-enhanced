<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 10]
- [math.AP](#math.AP) [Total: 23]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 5]
- [math.ST](#math.ST) [Total: 1]
- [cs.LG](#cs.LG) [Total: 7]
- [physics.optics](#physics.optics) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [hep-ph](#hep-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 2]
- [math-ph](#math-ph) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 3]
- [cs.CV](#cs.CV) [Total: 2]
- [gr-qc](#gr-qc) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [An adaptive perfectly matched layer finite element method for acoustic-elastic interaction in periodic structures](https://arxiv.org/abs/2602.09055)
*Sijia Li,Lei Lin,Junliang Lv*

Main category: math.NA

TL;DR: This paper develops an adaptive finite element method with PML for acoustic-elastic wave scattering by periodic surfaces, establishing well-posedness and exponential convergence.


<details>
  <summary>Details</summary>
Motivation: To solve the challenging problem of acoustic wave scattering by elastic bodies with unbounded periodic surfaces, which requires handling infinite domains and non-smooth boundaries.

Method: Uses PML to truncate unbounded domain, constructs transparent boundary conditions for both acoustic and elastic waves, applies FEM, and develops adaptive algorithm with residual-type a posteriori error estimates.

Result: Established well-posedness and exponential convergence of the PML solution, developed adaptive FEM algorithm, and demonstrated effectiveness through numerical examples.

Conclusion: The proposed adaptive PML-FEM approach effectively solves acoustic-elastic interaction problems with periodic surfaces, handling both domain truncation and boundary singularity issues.

Abstract: This paper considers the scattering of a time-harmonic acoustic plane wave by an elastic body with an unbounded periodic surface. The original problem can be confined to the analysis of the fields in one periodic cell. With the help of the perfectly matched layer (PML) technique, we can truncate the unbounded physical domain into a bounded computational domain. By respectively constructing the equivalent transparent boundary conditions of acoustic and elastic waves simultaneously, the well-posedness and exponential convergence of the solution to the associated truncated PML problem are established. The finite element method is applied to solve the PML problem of acoustic-elastic interaction. To address the singularity caused by the non-smooth surface of the elastic body, we establish a residual-type a posteriori error estimate and develop an adaptive PML finite element algorithm. Several numerical examples are presented to demonstrate the effectiveness of the proposed adaptive algorithm.

</details>


### [2] [SVD-Preconditioned Gradient Descent Method for Solving Nonlinear Least Squares Problems](https://arxiv.org/abs/2602.09057)
*Zhipeng Chang,Wenrui Hao,Nian Liu*

Main category: math.NA

TL;DR: SVD-preconditioned Adam optimizer for nonlinear least-squares problems with proven convergence guarantees and superior performance over standard Adam.


<details>
  <summary>Details</summary>
Motivation: To develop a more effective optimization algorithm for nonlinear least-squares problems by combining gradient preconditioning with adaptive learning rate mechanisms.

Method: Precondition gradient descent direction using SVD of Jacobian, then integrate with Adam's first- and second-moment adaptive learning rate mechanism.

Result: Proven local linear convergence under standard assumptions and global convergence for modified version. Experimental results show consistent outperformance over standard Adam with faster convergence and lower error in function approximation, PDE solving, and CIFAR-10 classification.

Conclusion: The SVD-preconditioned Adam algorithm is an effective optimization method for nonlinear least-squares problems with theoretical convergence guarantees and practical performance advantages.

Abstract: This paper introduces a novel optimization algorithm designed for nonlinear least-squares problems. The method is derived by preconditioning the gradient descent direction using the Singular Value Decomposition (SVD) of the Jacobian. This SVD-based preconditioner is then integrated with the first- and second-moment adaptive learning rate mechanism of the Adam optimizer. We establish the local linear convergence of the proposed method under standard regularity assumptions and prove global convergence for a modified version of the algorithm under suitable conditions. The effectiveness of the approach is demonstrated experimentally across a range of tasks, including function approximation, partial differential equation (PDE) solving, and image classification on the CIFAR-10 dataset. Results show that the proposed method consistently outperforms standard Adam, achieving faster convergence and lower error in both regression and classification settings.

</details>


### [3] [Stability analysis of Arbitrary-Lagrangian-Eulerian ADER-DG methods on classical and degenerate spacetime geometries](https://arxiv.org/abs/2602.09198)
*Mauro Bonafini,Davide Torlo,Elena Gaburro*

Main category: math.NA

TL;DR: Von Neumann stability analysis of explicit/implicit ALE ADER-DG methods on classical and degenerate spacetime geometries for hyperbolic equations, showing CFL constraints remain unchanged even with degenerate elements.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous stability analysis for ALE ADER-DG methods, particularly understanding CFL conditions for both classical and degenerate spacetime geometries that arise in direct ALE methods with topology changes.

Method: Conducted thorough von Neumann stability analysis of explicit and implicit ALE ADER-DG methods. Studied CFL conditions for explicit methods, analyzed mesh velocity constraints for ALE stability, and extended analysis to degenerate spacetime elements with zero size at time step boundaries but non-zero spacetime volume. Used 1D simulations with fictitious degenerate elements between cells to mimic topology change behavior.

Result: Confirmed existing CFL stability conditions for explicit ADER-DG while specifying limitations. Identified mesh velocity conditions for ALE method stability. Most importantly, showed that for degenerate spacetime geometries (used in direct ALE methods with topology changes), both explicit and implicit ADER-DG maintain the same CFL stability constraints as classical geometries.

Conclusion: The theoretical foundations are established for using ALE ADER-DG methods with degenerate spacetime elements, demonstrating that stability constraints remain unchanged even with these geometrically challenging elements that arise in topology-changing simulations.

Abstract: In this paper, we present a thorough von Neumann stability analysis of explicit and implicit Arbitrary-Lagrangian-Eulerian (ALE) ADER discontinuous Galerkin (DG) methods on classical and degenerate spacetime geometries for hyperbolic equations. First, we rigorously study the CFL stability conditions for the explicit ADER-DG method, confirming results widely used in the literature while specifying their limitations. Moreover, we highlight under which conditions on the mesh velocity the ALE methods, constrained to a given CFL, are actually stable. Next, we extend the stability study to ADER-DG in the presence of degenerate spacetime elements, with zero size at the beginning and the end of the time step, but with a non zero spacetime volume. This kind of elements has been introduced in a series of articles on direct ALE methods by Gaburro et al. to connect via spacetime control volumes regenerated Voronoi tessellations after a topology change. Here, we imitate this behavior in 1d by fictitiously inserting degenerate elements in between two cells. Then, we show that over this degenerate spacetime geometry, both for the explicit and implicit ADER-DG, the CFL stability constraints remain the same as those for classical geometries, laying the theoretical foundations for their use in the context of ALE methods.

</details>


### [4] [Boundary elements for clamped Kirchhoff--Love plates](https://arxiv.org/abs/2602.09265)
*Thomas Führer,Gregor Gantner,Norbert Heuer*

Main category: math.NA

TL;DR: A Galerkin boundary element method for clamped Kirchhoff-Love plates with piecewise smooth boundaries, using direct method based on representation formula with single-layer operator inversion and double-layer operator application.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for solving clamped Kirchhoff-Love plate problems with piecewise smooth boundaries, which are common in engineering applications but challenging to solve with traditional methods.

Method: Direct boundary element method based on representation formula, requiring inversion of single-layer operator and application of double-layer operator to Dirichlet data. Uses trace approximation spaces of arbitrary order for both Dirichlet data and unknown Neumann trace.

Result: The method is quasi-optimal with respect to natural trace norm and achieves optimal convergence order under minimal regularity assumptions. Numerical experiments for smooth and non-smooth domains confirm predicted convergence rates.

Conclusion: The developed boundary element method provides an effective numerical approach for clamped Kirchhoff-Love plate problems with piecewise smooth boundaries, achieving theoretical optimality and practical convergence as demonstrated through numerical experiments.

Abstract: We present a Galerkin boundary element method for clamped Kirchhoff--Love plates with piecewise smooth boundary. It is a direct method based on the representation formula and requires the inversion of the single-layer operator and an application of the double-layer operator to the Dirichlet data. We present trace approximation spaces of arbitrary order, required for both the Dirichlet data and the unknown Neumann trace. Our boundary element method is quasi-optimal with respect to the natural trace norm
  and achieves optimal convergence order under minimal regularity assumptions. We provide explicit representations of both boundary integral operators and discuss the implementation of the appearing integrals. Numerical experiments for smooth and non-smooth domains confirm predicted convergence rates.

</details>


### [5] [Interpolating between Tikhonov regularization and spectral cutoff](https://arxiv.org/abs/2602.09505)
*Martin Sæbye Carøe,Mirza Karamehmedović,Pierre Maréchal*

Main category: math.NA

TL;DR: The paper introduces a new regularization method that interpolates between Tikhonov regularization and spectral cutoff, creating a one-parameter family of regularizations to address limitations of both approaches.


<details>
  <summary>Details</summary>
Motivation: Both Tikhonov regularization and spectral cutoff methods have limitations when solving linear ill-posed operator equations. The authors aim to develop a more flexible regularization approach that can overcome the drawbacks of these established methods.

Method: The authors propose an interpolating formula that defines a one-parameter family of regularizations. This formula bridges Tikhonov regularization and spectral cutoff as limiting cases. The interpolating parameter can be adjusted based on the specific operator equation being solved.

Result: The proposed interpolation-based regularization method is demonstrated through numerical simulations in signal and image processing applications. The approach shows potential for mitigating limitations associated with both Tikhonov and spectral cutoff regularizations.

Conclusion: The paper presents a novel regularization framework that interpolates between two classical methods, offering a flexible approach to solving linear ill-posed operator equations that can be tailored to specific problems in signal and image processing.

Abstract: Regularizing a linear ill-posed operator equation can be achieved by manipulating the spectrum of the operator's pseudo-inverse. Tikhonov regularization and spectral cutoff are well-known techniques within this category. This paper introduces an interpolating formula that defines a one-parameter family of regularizations, where Tikhonov and spectral cutoff methods are represented as limiting cases. By adjusting the interpolating parameter taking into account the specific operator equation under consideration, it is possible to mitigate the limitations associated with both Tikhonov and spectral cutoff regularizations. The proposed approach is demonstrated through numerical simulations in the fields of signal and image processing.

</details>


### [6] [Tensor CUR Decomposition under the Linear-Map-Based Tensor-Tensor Multiplication](https://arxiv.org/abs/2602.09539)
*Susana Lopez-Moreno,June-Ho Lee,Taehyeong Kim*

Main category: math.NA

TL;DR: Tensor CUR decomposition for 3D data using linear-map-based tensor multiplication, with applications to video foreground-background separation and theoretical analysis.


<details>
  <summary>Details</summary>
Motivation: Factorization of 3D data is important for representing and compressing large-scale datasets. The paper aims to extend CUR decomposition from matrices to tensors using linear-map-based tensor multiplication.

Method: Introduces tensor CUR decomposition based on linear-map-based tensor-tensor multiplication (generalization of T-product). Compares it with robust matrix CUR decomposition, other tensor approximations, and slice-based SVD (SS-SVD).

Result: Demonstrates performance in video foreground-background separation for different linear maps. Provides theoretical analysis extending classical matrix results to establish exactness conditions and perturbation bounds.

Conclusion: Tensor CUR decomposition is a viable approach for 3D data factorization with practical applications in video processing and solid theoretical foundations extending matrix decomposition results.

Abstract: The factorization of three-dimensional data continues to gain attention due to its relevance in representing and compressing large-scale datasets. The linear-map-based tensor-tensor multiplication is a matrix-mimetic operation that extends the notion of matrix multiplication to higher order tensors, and which is a generalization of the T-product. Under this framework, we introduce the tensor CUR decomposition, show its performance in video foreground-background separation for different linear maps and compare it to a robust matrix CUR decomposition, another tensor approximation and the slice-based singular value decomposition (SS-SVD). We also provide a theoretical analysis of our tensor CUR decomposition, extending classical matrix results to establish exactness conditions and perturbation bounds.

</details>


### [7] [A Reynolds- and Hartmann-semirobust hybrid method for magnetohydrodynamics](https://arxiv.org/abs/2602.09626)
*Daniele A. Di Pietro,Jerome Droniou,Vito Patierno*

Main category: math.NA

TL;DR: New hybrid method for unsteady incompressible magnetohydrodynamics on convex domains with convection-semirobust properties and improved features.


<details>
  <summary>Details</summary>
Motivation: To develop a method for magnetohydrodynamics that avoids dependence on inverse diffusion coefficients while providing additional computational advantages.

Method: Hybrid approximations for both vector-valued and scalar fields, convection-semirobust design, small stencil without inter-element penalty terms, with static condensation capability.

Result: Method achieves a priori estimates independent of inverse diffusion coefficients, improved convergence for diffusion-dominated regime, and confirmed by numerical experiments.

Conclusion: The proposed hybrid method successfully combines convection-semirobustness with practical computational advantages for magnetohydrodynamics problems.

Abstract: We propose and analyze a new method for the unsteady incompressible magnetohydrodynamics equations on convex domains with hybrid approximations of both vector-valued and scalar-valued fields. The proposed method is convection-semirobust, meaning that, for sufficiently smooth solutions, one can derive a priori estimates for the velocity and the magnetic field that do not depend on the inverse of the diffusion coefficients. This is achieved while at the same time providing relevant additional features, namely an improved order of convergence for the (asymptotic) diffusion-dominated regime, a small stencil (owing to the absence of inter-element penalty terms), and the possibility to significantly reduce the size of the algebraic problems through static condensation. The theoretical results are confirmed by a complete panel of numerical experiments.

</details>


### [8] [LDG method for solving spatial and temporal fractional nonlinear convection-diffusion equations](https://arxiv.org/abs/2602.09650)
*Majid Rajabzadeh,Moein Khalighi*

Main category: math.NA

TL;DR: Local discontinuous Galerkin methods with Legendre basis functions are developed for nonlinear convection-diffusion equations with space-time fractional Laplacian operators, achieving optimal convergence order O(h^{k+1}+(Δt)^{1+p/2}+p²).


<details>
  <summary>Details</summary>
Motivation: To develop efficient numerical methods for solving nonlinear convection-diffusion equations with fractional Laplacian operators in both space (1<β<2) and time (0<α≤1), which are challenging due to their non-local nature and complex mathematical properties.

Method: Local discontinuous Galerkin methods using Legendre basis functions that transform the fractional equation into a system of first-order equations. The method selects appropriate basis functions to approximate the solution while maintaining stability and accuracy.

Result: The proposed scheme demonstrates efficient and accurate performance across various conditions, achieving the theoretically proven optimal convergence order O(h^{k+1}+(Δt)^{1+p/2}+p²), with basis functions significantly improving both accuracy and stability.

Conclusion: The local discontinuous Galerkin method with Legendre basis functions provides an effective numerical solution for space-time fractional convection-diffusion equations, with proven stability and optimal convergence rates validated by numerical experiments.

Abstract: This paper focuses on a nonlinear convection-diffusion equation with space and time-fractional Laplacian operators of orders $1<β<2$ and $0<α\leq1$, respectively. We develop local discontinuous Galerkin methods, including Legendre basis functions, for a solution to this class of fractional diffusion problem, and prove stability and optimal order of convergence $O(h^{k+1}+(Δt)^{1+\frac{p}{2}}+p^2)$. This technique turns the equation into a system of first-order equations and approximates the solution by selecting the appropriate basis functions. Regarding accuracy and stability, the basis functions greatly improve the method. According to the numerical results, the proposed scheme performs efficiently and accurately in various conditions and meets the optimal order of convergence.

</details>


### [9] [Beyond Free-Stream Preservation: Transport Polynomial Exactness for Moving-Mesh Methods under Arbitrary Mesh Motion](https://arxiv.org/abs/2602.09729)
*Chaoyi Cai,Qiqin Cheng,Di Wu,Jianxian Qiu*

Main category: math.NA

TL;DR: Third-order moving-mesh scheme achieves exact quadratic polynomial transport for arbitrary mesh motion by introducing evolved geometric moments, breaking efficiency bottleneck of conventional remapping.


<details>
  <summary>Details</summary>
Motivation: High-order moving-mesh methods suffer from accuracy degradation when mesh motion becomes nonsmooth due to solution-driven adaptation in hyperbolic conservation laws. The dependency on mesh velocity regularity creates a fundamental conflict between adaptation and formal accuracy.

Method: Introduces Transport Polynomial Exactness (TPE(k)) criterion generalizing free-stream preservation. Proposes evolved geometric moments (EGMs) obtained by solving auxiliary transport equations. Uses third-order SSPRK3 method for EGM evolution, which exhibits superconvergence to Simpson's rule. Constructs third-order conservative finite-volume rezoning moving-mesh scheme satisfying TPE(2) property.

Result: Proves second-degree EGMs evolved via SSPRK3 coincide with exact geometric moments. Scheme achieves exact quadratic transport for arbitrary mesh motion and any pseudo-time step size, reducing required pseudo-time levels from O(h⁻¹) to O(1) under discontinuous mesh velocity. Numerical experiments verify exact quadratic transport and stable third-order convergence under extreme mesh deformation.

Conclusion: The proposed method breaks the efficiency bottleneck in conventional advection-based remapping by eliminating dependency on mesh velocity regularity, enabling high-order accuracy even with spatiotemporally discontinuous mesh motion while maintaining computational efficiency.

Abstract: High-order moving-mesh methods can effectively reduce numerical diffusion, but their formal accuracy typically relies on the regularity of the mesh velocity. This dependency creates a fundamental conflict in the numerical solution of hyperbolic conservation laws, where solution-driven adaptation may induce nonsmooth mesh motion, thereby degrading convergence order. We introduce \emph{transport polynomial exactness} (TPE($k$)), a mesh-motion-independent criterion that generalizes classical free-stream preservation (TPE(0)) to the exact advection of degree-$k$ polynomials. We show that the classical geometric conservation law (GCL) is insufficient to ensure TPE($k$) for $k \ge 1$ due to mismatches in higher-order geometric moments. To resolve this, we propose \emph{evolved geometric moments} (EGMs), obtained by solving auxiliary transport equations discretized compatibly with the physical variables. We rigorously prove that second-degree EGMs evolved via the third-order strong stability preserving Runge--Kutta (SSPRK3) method coincide with the exact geometric moments. This exactness arises from a \emph{superconvergence} mechanism wherein SSPRK3 reduces to Simpson's rule for EGM evolution. Leveraging this result, we construct a third-order conservative finite-volume rezoning moving-mesh scheme. The scheme satisfies the TPE(2) property for \emph{arbitrary mesh motion} and \emph{any pseudo-time step size}, thereby naturally accommodating spatiotemporally discontinuous mesh velocity. Crucially, this \emph{breaks the efficiency bottleneck} in the conventional advection-based remapping step and reduces the required pseudo-time levels from $\mathcal{O}(h^{-1})$ to $\mathcal{O}(1)$ under bounded but discontinuous mesh velocity. Numerical experiments verify exact quadratic transport and stable third-order convergence under extreme mesh deformation, demonstrating substantial efficiency gains.

</details>


### [10] [Asymptotic error distribution for tamed Euler method with coupled monotonicity condition](https://arxiv.org/abs/2602.09854)
*Xinjie Dai,Diancong Jin,Jiaoyang Xu*

Main category: math.NA

TL;DR: The paper establishes asymptotic error distribution for tamed Euler methods for SDEs with monotonicity conditions, showing how parameter α affects convergence rates and long-term error behavior.


<details>
  <summary>Details</summary>
Motivation: To analyze the asymptotic error distribution of tamed Euler methods for SDEs with coupled monotonicity conditions, particularly for equations with super-linearly growing coefficients where standard results don't apply.

Method: Proposes a tamed Euler method parameterized by α ∈ (0,1], establishes strong convergence rate of α∧½, derives asymptotic error distribution, and analyzes long-term mean-square error behavior for different α values.

Result: Strong convergence rate is α∧½; among methods with order ½, α=½ yields largest long-term mean-square error, while α>½ share unified asymptotic error distribution; results extended to additive noise cases.

Conclusion: The tamed Euler method's asymptotic error distribution is characterized, revealing how parameter α affects both convergence rate and long-term error behavior, with novel analysis for super-linearly growing coefficients.

Abstract: This paper establishes the asymptotic error distribution of the tamed Euler method for stochastic differential equations (SDEs) with a coupled monotonicity condition, that is, the limit distribution of the corresponding normalized error process. Specifically, for SDEs driven by multiplicative noise, we first propose a tamed Euler method parameterized by $α\in (0, 1]$ and establish that its strong convergence rate is $α\wedge\frac{1}{2}$. Notably, $α$ can take arbitrary positive values by adjusting the regularization coefficient without altering the strong convergence rate. We then derive the asymptotic error distribution for this tamed Euler method. Further, we infer from the limit equation that among the tamed Euler method of strong order $\frac{1}{2}$, the one with $α= \frac{1}{2}$ yields the largest mean-square error after a long time, while those of $α>\frac{1}{2}$ share a unified asymptotic error distribution. In addition, our analysis is also extended to SDEs with additive noise and similar conclusions are obtained. Additional treatments are required to accommodate super-linearly growing coefficients, a feature that distinguishes our analysis on the asymptotic error distribution from established results.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [11] [Ions-electrons-states for the two-component Vlasov-Poisson equation](https://arxiv.org/abs/2602.09293)
*Emeric Roulley*

Main category: math.AP

TL;DR: The paper establishes local and global bifurcation results for traveling periodic solutions in the 1D two-species Vlasov-Poisson equation, extending previous work on the purely electronic case.


<details>
  <summary>Details</summary>
Motivation: To analyze traveling periodic solutions in the two-species Vlasov-Poisson system where both ions and electrons evolve dynamically, extending previous work that treated ions as an immobile background. The more intricate dynamics require higher-dimensional analysis.

Method: Uses bifurcation theory to establish both local and global results for traveling periodic solutions. Analyzes the geometry of equilibrium layers and Fourier modes to determine solution branches. Employs an affine change of variables to connect with the Euler-Poisson system.

Result: Shows that bifurcation diagrams exhibit either two or four solution branches depending on equilibrium geometry and Fourier mode, all of pitchfork type. In symmetric configurations, local structure has hyperbolic geometry. Globally extends locally constructed branches. Also constructs traveling periodic waves for the Euler-Poisson system.

Conclusion: Successfully extends bifurcation analysis from the purely electronic Vlasov-Poisson case to the full two-species system, revealing richer structure and connecting with the Euler-Poisson model to construct both small and large amplitude traveling waves.

Abstract: We establish both local and global bifurcation results for traveling periodic solutions of the one-dimensional two-species Vlasov-Poisson equation. These solutions consist of strip-like regions of ions and electrons in phase space that propagate coherently and emerge from spatially homogeneous, velocity-dependent equilibrium layers. Depending on the geometry of the underlying equilibrium and on the selected Fourier mode, the bifurcation diagram exhibits either two or four solution branches. In all cases, the bifurcation is of pitchfork type; in symmetric configurations, the local structure near the equilibrium has a hyperbolic geometry. We further show that these locally constructed branches extend globally. This work extends the previous study by the same author of the purely electronic case, where the ions were modeled as an immobile neutralizing background. Allowing both species to evolve dynamically leads to a more intricate, higher-dimensional analysis. Finally, by means of an affine change of variables, we reveal a connection with the one-dimensional two-component Euler-Poisson system, which in turn enables the construction of traveling periodic waves of both small and large amplitude for that model as well.

</details>


### [12] [A strong unique continuation result for the Baouendi operator](https://arxiv.org/abs/2602.09322)
*Agnid Banerjee,Nicola Garofalo*

Main category: math.AP

TL;DR: Strong unique continuation property for subelliptic Baouendi operators with zero-order perturbations satisfying Hardy-type growth conditions, including L^∞ and singular potentials.


<details>
  <summary>Details</summary>
Motivation: To establish unique continuation properties for degenerate elliptic operators (Baouendi operators) with singular potentials, extending classical results to more general perturbation classes.

Method: Uses L^2 Carleman estimates combined with classical Hardy inequality to prove that solutions vanishing to infinite order at degeneracy points must be identically zero.

Result: Proves strong unique continuation property for subelliptic Baouendi operators with zero-order perturbations satisfying almost Hardy-type growth conditions, including both L^∞ and singular potentials.

Conclusion: The result extends to variable-coefficient operators with intrinsic Lipschitz regularity, providing a robust unique continuation theorem for degenerate elliptic operators with singular potentials.

Abstract: We establish a strong unique continuation property for the subelliptic Baouendi operator under the presence of zero-order perturbations satisfying an almost Hardy-type growth condition. In particular, the admissible class includes both $L^\infty_{\mathrm{loc}}$ and singular potentials. We prove that any solution vanishing to infinite order at a point of the degeneracy manifold of the operator must be identically zero. The result holds extends to variable-coefficient operators with intrinsic Lipschitz regularity. A notable feature of the proof is that it relies exclusively on $L^2$ Carleman estimates combined with the classical Hardy inequality.

</details>


### [13] [Electrostatic effects on critical regularity and long-time behavior of viscous compressible fluids](https://arxiv.org/abs/2602.09332)
*Ling-yun Shou,Zihao Song*

Main category: math.AP

TL;DR: The paper establishes global well-posedness for compressible Navier-Stokes-Poisson equations in critical Besov spaces without hyperbolic symmetrization, and proves optimal convergence rates to equilibrium using a time-weighted energy method.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of electrostatic coupling on long-time dynamics of compressible flows, and to establish improved well-posedness results in critical Besov spaces without the extra L² assumptions required in previous Poisson-free studies.

Method: Uses critical Besov space framework without hyperbolic symmetrization; develops a time-weighted energy method to capture maximal decay estimates; analyzes distinct low-frequency behaviors of density and velocity due to Poisson coupling.

Result: 1) Global well-posedness in full-frequency L^p-type critical Besov spaces with p in sharp range 1≤p<2d, removing extra L² assumptions. 2) Optimal convergence rates to equilibrium under general L^p-type low-frequency assumptions, yielding faster decay than classical L¹ framework.

Conclusion: Electrostatic coupling significantly impacts long-time dynamics through Klein-Gordon structure; the approach enables handling highly oscillatory velocity fields across all frequencies and provides optimal decay estimates without additional smallness conditions.

Abstract: We consider the compressible Navier-Stokes-Poisson equations in $\mathbb{R}^d$ ($d\geq2$), a classical model for barotropic compressible flows coupled with a self-consistent electrostatic potential. We show that the electrostatic coupling has a significant impact on the long-time dynamics of solutions due to its underlying Klein-Gordon structure. As a first result, we prove the global well-posedness of the Cauchy problem with initial data near equilibrium in the full-frequency $L^{p}$-type critical Besov space \emph{without relying on hyperbolic symmetrization}. Compared with the Poisson-free case studied in several milestone works [Charve and Danchin, Arch. Rational Mech. Anal., 198 (2010), 233-271; Chen, Miao and Zhang, Commun. Pure Appl. Math., 63 (2010), 1173-1224; Haspot, Arch. Rational Mech. Anal., 202 (2011), 427-460], we remove the extra $L^{2}$ assumption in low frequencies and extend the admissible choice of $p$ to the sharp range $1\leq p<2d$. This is, to the best of our knowledge, the first result in compressible fluids that allows the initial velocity field to be highly oscillatory across all frequencies.
  Furthermore, stemming from the Poisson coupling, the density and velocity exhibit distinct low-frequency behaviors. Motivated by this feature, we propose a general $L^p$-type low-frequency assumption and establish the optimal convergence rates of global solutions toward equilibrium. For a broad class of indices, this assumption yields faster decay than those obtained under the classical $L^1$ framework. To this end, we develop a time-weighted energy method, which is of interest and enables us to capture maximal decay estimates without additional smallness of initial data.

</details>


### [14] [Principal spectral theory and asymptotic analysis for time-periodic cooperative systems with temporally nonlocal dispersal](https://arxiv.org/abs/2602.09436)
*Hao Wu,Wan-Tong Li,Jian-Wen Sun,Hoang-Hung Vo*

Main category: math.AP

TL;DR: This paper develops spectral theory for time-periodic cooperative systems with nonlocal dispersal, establishing existence criteria for principal eigenvalues and analyzing asymptotic behavior of principal spectrum points with respect to dispersal parameters.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a comprehensive spectral theory for time-periodic cooperative systems with nonlocal dispersal operators, which are important in modeling biological phenomena like disease spread and stem cell dynamics. These systems often lack principal eigenvalues, so understanding principal spectrum points is crucial for characterizing global dynamics.

Method: The authors use resolvent positive operator theory and perturbation methods to establish principal eigenvalue existence criteria. They construct sequences of smooth upper and lower approximating matrix-valued functions whose corresponding operators satisfy eigenvalue existence conditions. This approximation framework allows principal spectrum points to substitute for principal eigenvalues in analyzing nonlinear system dynamics.

Result: The paper establishes existence criteria for principal eigenvalues in time-periodic cooperative systems with nonlocal dispersal. It develops an approximation framework that enables principal spectrum points to characterize global dynamics. The asymptotic behavior of principal spectrum points is analyzed with respect to dispersal rate, dispersal range, and frequency parameters. Theoretical results are applied to Zika virus and stem cell models.

Conclusion: The developed spectral theory provides a robust framework for analyzing time-periodic cooperative systems with nonlocal dispersal. The approximation method allows principal spectrum points to effectively characterize system dynamics even when principal eigenvalues don't exist. The asymptotic analysis offers insights into how dispersal parameters affect system behavior, with applications to biological models demonstrating practical utility.

Abstract: This paper investigates the principal spectral theory and the asymptotic behavior of the principal spectrum point for a class of time-periodic cooperative systems with nonlocal dispersal operators, incorporating both coupled and uncoupled nonlocal terms. By applying the theory of resolvent positive operators and their perturbations, we first establish criteria for the existence of the principal eigenvalue. We then construct sequences of smooth upper and lower approximating matrix-valued functions, each of whose corresponding operators satisfies the principal eigenvalue existence condition. This approximation framework allows the principal spectrum point to effectively substitute for the principal eigenvalue in characterizing the global dynamics of the nonlinear system. Moreover, it facilitates the study of the asymptotic behavior of the principal spectrum point with respect to parameters under fairly general assumptions. Subsequently, for systems with both coupled and uncoupled nonlocal terms, we analyze the asymptotic behavior of the principal spectrum point in terms of the dispersal rate, dispersal range, and frequency. Finally, we illustrate the applicability of our theoretical results through a Zika virus model and a stem cell model.

</details>


### [15] [Homogenization of nonlocal equations in randomly evolving media. Diffusion approximation](https://arxiv.org/abs/2602.09584)
*Marina Kleptsyna,Andrey Piatnitski,Alexandre Popier*

Main category: math.AP

TL;DR: The paper studies homogenization and higher-order approximations for nonlocal evolution equations with periodic spatial coefficients and random stationary temporal coefficients, showing normalized differences converge to stochastic PDE solutions.


<details>
  <summary>Details</summary>
Motivation: To understand the limit behavior of solutions to nonlocal evolution equations with heterogeneous coefficients (periodic in space, random stationary in time) and develop higher-order approximations beyond standard homogenization.

Method: Analyzes normalized difference between original and homogenized solutions using convolution kernels with finite moments (up to order three) under proper mixing assumptions, employing homogenization techniques for nonlocal equations.

Result: The normalized difference converges to the solution of a linear stochastic partial differential equation, providing higher-order approximation results for the original nonlocal evolution equations.

Conclusion: The paper establishes rigorous convergence results for higher-order approximations in nonlocal homogenization problems with random temporal coefficients, extending homogenization theory to capture finer statistical fluctuations.

Abstract: The paper deals with homogenization and higher order approximations of solutions to nonlocal evolution equations of convolution type whose coefficients are periodic in the spatial variables and random stationary in time. We assume that the convolution kernel has finite moments up to order three. Under proper mixing assumptions, we study the limit behavior of the normalized difference between solutions of the original and the homogenized problems and show that this difference converges to the solution of a linear stochastic partial differential equation.

</details>


### [16] [Differential Complexes in Time-Periodic Gelfand-Shilov Spaces](https://arxiv.org/abs/2602.09646)
*Fernando de Ávila Silva,Marco Cappiello,Alexandre Kirilov,Pedro Meyer Tokoro*

Main category: math.AP

TL;DR: The paper studies global solvability of differential complexes on product manifolds with evolution operators having time-dependent real Gevrey coefficients, providing complete characterization via Diophantine conditions.


<details>
  <summary>Details</summary>
Motivation: To extend previous results on scalar operators and constant coefficient systems to differential complexes with time-dependent real coefficients, particularly for evolution operators on product manifolds.

Method: Introduce natural differential complex generated by evolution operators L_r = ∂_t_r + ia_r(t)P(x,D_x) within time-periodic Gelfand-Shilov spaces framework, analyze solvability in functional and ultradistributional settings.

Result: Complete characterization of global solvability in terms of Diophantine condition involving constant part of associated 1-form and spectrum of P; also analyze global hypoellipticity of the complex.

Conclusion: The results successfully extend previous works to differential complexes with time-dependent real coefficients, providing comprehensive understanding of solvability conditions for such systems.

Abstract: We study the global solvability of a class of differential complexes on the product manifold $\mathbb{T}^m \times \mathbb{R}^n$ associated with systems of evolution operators of the form $L_r = \partial_{t_r} + ia_r(t)P(x,D_x), r=1,\ldots,m,$ where the coefficients $a_r$ are real-valued Gevrey functions on the torus and $P(x,D_x)$ is a globally elliptic normal differential operator on $\mathbb{R}^n$. Within the framework of time-periodic Gelfand--Shilov spaces, we introduce a natural differential complex generated by these operators and investigate its solvability in both functional and ultradistributional settings. We provide a complete characterization of global solvability in terms of a Diophantine condition involving the constant part of the associated $1$-form and the spectrum of $P$. We also analyze global hypoellipticity of the complex. These results extend previous works on scalar operators and constant coefficient systems to the setting of differential complexes with time-dependent real coefficients.

</details>


### [17] [A Lions' type formula for some reproducing kernel Hilbert spaces of fractional harmonic functions](https://arxiv.org/abs/2602.09669)
*Sidy M. Djitte,Franck Sueur*

Main category: math.AP

TL;DR: The paper extends Lions' RKHS kernel formula to fractional Laplace operators, showing that despite the fractional order, the resulting formula resembles the Hadamard variational formula, unlike the original Lions' result which only resembled Hadamard for order 2 operators.


<details>
  <summary>Details</summary>
Motivation: To extend Lions' reproducing kernel Hilbert space (RKHS) formula for harmonic functions to fractional Laplace operators (a-harmonic functions), and investigate the relationship between Lions' type formulas and Hadamard variational formulas for operators of different orders.

Method: Uses a-transmission Sobolev spaces developed by Hörmander and Grubb to address the local nonhomogeneous Dirichlet problem for fractional order pseudo-differential operators. Derives a fractional Poisson formula and applies it to obtain a Lions' type formula for RKHS of a-harmonic functions.

Result: Obtained a Lions' type formula for fractional Laplace operators that resembles the Hadamard variational formula, despite the operator order not being 2. Also observed that for the steady Stokes system (second order), the Lions' type formula for RKHS kernels does not resemble the corresponding Hadamard variation formula.

Conclusion: The resemblance between Lions' type formulas and Hadamard variational formulas is not strictly dependent on the operator being of order 2, as demonstrated by the fractional case. The relationship between these formulas is more nuanced than previously thought.

Abstract: In \cite{Lions}, J. L. Lions considered a reproducing kernel Hilbert space (RKHS) of harmonic functions on a regular domain with Sobolev traces and obtained a formula that expresses the kernel of this space as an integral on the boundary of some derivatives of the Green function associated with the Laplace operator and the homogeneous Dirichlet boundary condition. This result was simplified and extended later by Englis, Lukkassen, Peetre, and Persson in \cite{ELPL} to more general elliptic systems of even orders. In particular, they emphasized that the resemblance between Lions' type formula and the Hadamard variational formula only appears when the operator is of order $2$. In this paper, we investigate some RKHS of $a$-harmonic functions, where $a$ in $(0,1)$ refers to a fractional exponent of the Laplace operator. For such fractional order pseudo-differential operators, the local nonhomogeneous Dirichlet problem can be addressed by means of some $a$-transmission Sobolev spaces, which were introduced by Hörmander in the sixties and recently developed by Grubb in a series of papers. We deduce from these works a fractional Poisson formula, which is applied to obtain a Lions' type formula. We observe, in particular, that despite the order of the operator not being $2$, this formula resembles the Hadamard variational formula that we prove in the companion paper \cite{sidy-franck_1}. As a complementary remark, we observe that for a family of RKHS associated with the steady Stokes system, a second order system, there is also a Lions' type formula for their two-point kernels, which turn out not to be similar to the corresponding Hadamard variation formula.

</details>


### [18] [Sharp Sobolev and Moser-Trudinger inequalities on noncompact Riemannian manifolds with Ricci curvature bounded below](https://arxiv.org/abs/2602.09677)
*Carlo Morpurgo,Liuyu Qin*

Main category: math.AP

TL;DR: The paper establishes optimal Sobolev and Moser-Trudinger inequalities on noncompact Riemannian manifolds with Ricci curvature lower bounds and positive injectivity radius.


<details>
  <summary>Details</summary>
Motivation: To extend classical Sobolev and Moser-Trudinger inequalities from Euclidean spaces to noncompact Riemannian manifolds with geometric constraints, obtaining sharp constants that match the Euclidean case.

Method: The authors likely use geometric analysis techniques, combining curvature bounds (Ricci curvature bounded below) with topological conditions (positive injectivity radius) to establish functional inequalities on noncompact manifolds.

Result: Proves that Sobolev and Moser-Trudinger inequalities hold with best possible constants on such manifolds, generalizing Euclidean results to this geometric setting.

Conclusion: Noncompact Riemannian manifolds with Ricci curvature bounded below and positive injectivity radius support optimal functional inequalities, extending classical analysis results to broader geometric contexts.

Abstract: We establish Sobolev and Moser-Trudinger inequalities with best constants on noncompact Riemannan manifolds with Ricci curvature bounded below, and positive injectivity radius.

</details>


### [19] [Static class-guided selection of elementary solutions in non-monotone vanishing discount problems](https://arxiv.org/abs/2602.09697)
*Panrui Ni,Jun Yan,Maxime Zavidovique*

Main category: math.AP

TL;DR: The paper studies vanishing discount problems for Hamilton-Jacobi equations without monotonicity assumptions, showing that multiple viscosity solutions can be selected via static class-guided discount coefficients.


<details>
  <summary>Details</summary>
Motivation: Previous vanishing discount problems under standard monotonicity assumptions could only select a single viscosity solution. The authors aim to overcome this limitation and enable selection of multiple solutions by removing monotonicity requirements.

Method: The authors consider a generalized vanishing discount problem with a modified equation λa(x)u(x)+H(x,Du(x))-Aλ=c₀, where A>0 is suitably chosen. They change signs of function a(x) on different static classes associated with H, allowing controlled selection of solutions.

Result: The maximal viscosity solution converges uniformly as λ→0⁺, and all elementary solutions of the stationary equation H(x,Du(x))=c₀ can be selected as limits. This provides the first result for selecting multiple viscosity solutions in vanishing discount problems beyond usual monotonicity assumptions.

Conclusion: Static classes play a crucial role in controlling the asymptotic behavior of viscosity solutions. The approach allows controlled selection of multiple solutions via static class-guided discount coefficients, overcoming previous limitations where only a single solution could be selected.

Abstract: We study a generalized vanishing discount problem for Hamilton--Jacobi equations, removing the standard monotonicity assumption, either in a global sense or when integrated against all Mather measures. Specifically, we consider \[ λa(x)u(x)+H(x,Du(x))-Aλ=c_0, \] with a suitably chosen constant $A>0$. By appropriately changing the signs of the function $a(x)$ on different static classes associated with $H$, we show that the maximal viscosity solution converges uniformly as $λ\to 0^+$ and that all elementary solutions of the stationary equation \[ H(x,Du(x))=c_0 \] can be selected as limits. This provides the first result for selecting multiple viscosity solutions in vanishing discount problems beyond the usual monotonicity and integral assumptions, as long as $a(x)$ is positive on one static class. Our results highlight the crucial role of static classes in controlling the asymptotic behavior of viscosity solutions. Previously, under usual monotonicity assumptions, only a single solution could be selected (as discussed in \cite{GL}), whereas our approach allows controlled selection of multiple solutions via static class-guided discount coefficients.

</details>


### [20] [One-Sided and Parabolic BLO Spaces with Time Lag and Their Applications to Muckenhoupt $A_1$ Weights and Doubly Nonlinear Parabolic Equations](https://arxiv.org/abs/2602.09741)
*Weiyi Kong,Dachun Yang,Wen Yuan*

Main category: math.AP

TL;DR: The paper introduces one-sided BLO space and its parabolic analogue, establishes characterizations via Muckenhoupt class and John-Nirenberg inequality, proves decomposition theorems, and connects to parabolic equations.


<details>
  <summary>Details</summary>
Motivation: To study one-sided bounded lower oscillation (BLO) spaces and their parabolic generalizations, establishing fundamental properties, characterizations, and connections to PDEs.

Method: Introduces one-sided BLO space BLO⁺(ℝ), characterizes it via one-sided Muckenhoupt class A₁⁺(ℝ) and John-Nirenberg inequality, establishes Coifman-Rochberg type decomposition, proves independence from interval distance, connects to BMO⁺(ℝ), and extends to parabolic BLO space PBLOγ⁻(ℝⁿ⁺¹) with time lag.

Result: Characterizations of BLO⁺(ℝ) via A₁⁺(ℝ) and John-Nirenberg inequality; decomposition theorems; BMO⁺(ℝ) functions split into sum of two BLO⁺(ℝ) functions; explicit distance from BLO⁺(ℝ) to L∞(ℝ); extension to parabolic setting with applications to doubly nonlinear parabolic equations and weak porosity conditions.

Conclusion: The paper establishes comprehensive theory for one-sided BLO spaces, provides fundamental characterizations and decomposition results, extends to parabolic setting, and connects to PDE applications, offering new tools for analysis of function spaces and parabolic equations.

Abstract: In this article, we first introduce the one-sided BLO space $\mathrm{BLO}^+(\mathbb{R})$ and characterize it, respectively, in terms of the one-sided Muckenhoupt class $A_1^+(\mathbb{R})$ and the one-sided John--Nirenberg inequality. Using these, we establish the Coifman--Rochberg type decomposition of $\mathrm{BLO}^+(\mathbb{R})$ functions and show that $\mathrm{BLO}^+(\mathbb{R})$ is independent of the distance between the two intervals, which further induces the characterization of this space in terms of the one-sided BMO space $\mathrm{BMO}^+(\mathbb{R})$ (the Bennett type lemma). As applications, we prove that any $\mathrm{BMO}^+(\mathbb{R})$ function can split into the sum of two $\mathrm{BLO}^+(\mathbb{R})$ functions and we provide an explicit description of the distance from $\mathrm{BLO}^+(\mathbb{R})$ functions to $L^\infty(\mathbb{R})$. Finally, as a higher-dimensional analogue we introduce the parabolic BLO space $\mathrm{PBLO}_γ^-(\mathbb{R}^{n+1})$ with time lag, and we extend all the above one-dimensional results to $\mathrm{PBLO}_γ^-(\mathbb{R}^{n+1})$; furthermore, as applications, we not only establish the relationships between $\mathrm{PBLO}_γ^-(\mathbb{R}^{n+1})$ and the solutions of doubly nonlinear parabolic equations, but also provide a necessary condition for the negative logarithm of the parabolic distance function to belong to $\mathrm{PBLO}_γ^-(\mathbb{R}^{n+1})$ in terms of the weak porosity of the set.

</details>


### [21] [Phase Transition With Rapini-Papoular Surface Anchoring](https://arxiv.org/abs/2602.09778)
*Shun Li,Yong Yu*

Main category: math.AP

TL;DR: The paper analyzes stability of nematic liquid crystals under magnetic fields and surface potentials, finding a thickness threshold for P-HAN transition where solutions converge to either nontrivial or trivial equilibrium states.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze the dynamical stability of nematic liquid crystals in external magnetic fields with Rapini-Papoular surface potential, and to mathematically justify the P-HAN (Planar to Homeotropic Alignment Nematic) transition discussed in physics literature.

Method: Using a simplified 3D Ericksen-Leslie system to investigate the P-HAN transition, analyzing thickness thresholds and studying global-in-time suitable weak solutions with exponential convergence properties.

Result: Found a thickness threshold for P-HAN transition: when nematic layer thickness exceeds threshold, solutions converge exponentially to nontrivial equilibrium; when thickness ≤ threshold, solutions converge to trivial equilibrium. Results rigorously justify physics literature discussions.

Conclusion: The paper provides rigorous mathematical justification for the P-HAN transition in nematic liquid crystals under magnetic fields and surface potentials, establishing precise thickness conditions for different asymptotic behaviors of the system.

Abstract: We analyze the dynamical (in)stability of nematic liquid crystals in the presence of external magnetic fields and Rapini-Papoular surface potential. The P-HAN transition is investigated using a simplified 3D Ericksen-Leslie system. We find the thickness threshold of the P-HAN transition. If the thickness of the nematic layer exceeds this threshold, there is a global-in-time suitable weak solution converging exponentially to a nontrivial equilibrium state as time tends to infinity. If the thickness is no more than the threshold, the global-in-time suitable weak solution has a trivial long-time asymptotic limit. Our results rigorously justify the P-HAN transition discussed in the physics literature.

</details>


### [22] [The $N$-dimensional gravity driven Muskat problem](https://arxiv.org/abs/2602.09786)
*Bogdan-Vasile Matioc,Georg Prokert*

Main category: math.AP

TL;DR: The paper analyzes the Muskat problem for two immiscible fluids in porous media, establishing it as a parabolic evolution problem with well-posedness in subcritical Sobolev spaces and C^∞ smoothing.


<details>
  <summary>Details</summary>
Motivation: To understand the mathematical properties of the Muskat problem, which models the interface evolution between two immiscible fluids in porous media driven by gravity, and to establish its well-posedness and regularity properties.

Method: Reformulate the interface problem as a nonlinear, nonlocal evolution equation involving singular integrals. Use harmonic analysis to show the evolution is parabolic in the Rayleigh-Taylor stable region. Apply abstract theory of parabolic evolution equations to establish well-posedness.

Result: The Muskat problem defines a semiflow on the Rayleigh-Taylor stable set in all subcritical Sobolev spaces H^s(R^N) for s > s_c = 1 + N/2. Additionally obtains parabolic smoothing up to C^∞ regularity.

Conclusion: The Muskat problem exhibits parabolic behavior in the Rayleigh-Taylor stable regime, leading to well-posedness in appropriate function spaces and infinite regularity through parabolic smoothing effects.

Abstract: We study the Muskat problem, which describes the motion of two immiscible, incompressible fluids in a homogeneous porous medium occupying the full space ${\mathbb{R}^{N+1}}$, $N \geq 2$, driven by gravity. The interface between the fluids is given as graph of a function over $\mathbb{R}^N$. The problem is reformulated as a nonlinear, nonlocal evolution problem for this function, involving singular integrals arising from potential representations of the velocity and pressure fields. Using results from harmonic analysis, we demonstrate that the evolution is of parabolic type in the open set identified by the Rayleigh-Taylor condition. We use the abstract theory of such problems to establish that the Muskat problem defines a semiflow on this set in all subcritical Sobolev spaces $H^s(\mathbb{R}^N)$, $s>s_c$, where ${s_c=1+N/2}$ is the critical exponent. We additionally obtain parabolic smoothing up to ${\rm C}^\infty$.

</details>


### [23] [Large time decay of the Oseen flow in exterior domains subject to the Navier slip-with-friction boundary condition](https://arxiv.org/abs/2602.09804)
*Toshiaki Hishida*

Main category: math.AP

TL;DR: Analysis of Oseen system resolvent and semigroup decay estimates for viscous incompressible fluid in 3D exterior domain with Navier slip-with-friction boundary conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the resolvent properties and decay behavior of the Oseen semigroup for viscous incompressible fluids in exterior domains with slip-with-friction boundary conditions, which is important for stability analysis and long-time behavior of fluid flows.

Method: Study the resolvent set of the Oseen system linearization, analyze regularity near the origin in complex plane, and develop L^q-L^r decay estimates for the Oseen semigroup under geometric and boundary condition constraints.

Result: Established resolvent properties under specific relationships between domain geometry, friction coefficient α(x), and outflow u_∞. Derived L^q-L^r decay estimates for the Oseen semigroup when α(x)+u_∞·ν(x)/2 ≥ 0 on the boundary.

Conclusion: The paper provides important analytical tools for studying stability and decay properties of viscous incompressible flows in exterior domains with slip boundary conditions, establishing conditions under which the Oseen semigroup exhibits desirable decay behavior.

Abstract: Consider the motion of a viscous incompressible fluid filling a 3D exterior domain $Ω$ subject to the Navier slip-with-friction boundary condition as well as outflow at infinity. For the Oseen system as the linearization, we discuss the resolvent set under a certain relationship among the geometry of the boundary $\partialΩ$, friction coefficient $α(x)$ and the outflow $u_\infty$. We then study the regularity of the resolvent near the origin in the complex plane to develop $L^q$-$L^r$ decay estimates of the Oseen semigroup provided that $α(x)+u_\infty\cdotν(x)/2\geq 0$ for every $x\in\partialΩ$, where $ν(x)$ stands for the outward unit normal to the boundary $\partialΩ$.

</details>


### [24] [Convergence to pushed fronts and the behavior of level sets in monostable reaction-diffusion equations](https://arxiv.org/abs/2602.09806)
*Ryo Kiyono*

Main category: math.AP

TL;DR: The paper studies a monostable reaction-diffusion equation in higher dimensions and shows that solutions approach a pushed front profile that evolves according to mean curvature flow with drift.


<details>
  <summary>Details</summary>
Motivation: To understand the long-time behavior of solutions to monostable reaction-diffusion equations in higher dimensions, particularly how front propagation occurs and what geometric evolution governs the front interface.

Method: Analyze solutions of the monostable reaction-diffusion equation u_t = Δ_x u + u_yy + f(u) in ℝ^(n-1)×ℝ×ℝ^+, assuming the corresponding 1D equation has a pushed front solution. Study the asymptotic behavior as t→∞ using front profile approximation and geometric evolution analysis.

Result: The solution u(x,y,t) approaches Φ_{c^*}(y-γ(x,t)) as t→∞, where Φ_{c^*} is the pushed front profile and γ(x,t) evolves approximately according to mean curvature flow with a drift term. This holds under initial conditions with fast decay as y→∞ and positive lower bound near y→-∞.

Conclusion: For monostable reaction-diffusion equations in higher dimensions, solutions converge to pushed front profiles whose interfaces follow mean curvature flow with drift, providing a geometric description of front propagation in multidimensional settings.

Abstract: We study the behavior of solutions of a monostable reaction-diffusion equation $u_t=Δ_x u +u_{yy} +f(u)$ ($x \in \mathbb{R}^{n-1}$, $y \in \mathbb{R}$, $t>0$), with the unstable equilibrium point $0$ and the stable equilibrium point $1$. Under the condition that the corresponding one-dimensional equation has a pushed front $Φ_{c^*}(z)$ with $Φ_{c^*}(-\infty)=1$, $Φ_{c^*}(\infty)=0$, we show that the solution $u(x,y,t)$ approaches $Φ_{c^*}(y-γ(x,t))$ for some $γ(x,t)$ as $t \to \infty$, if initially $u(x,y,0)$ decays sufficiently fast as $y \to \infty$ and is bounded below by some positive constant near $y=-\infty$. It is also shown that $γ(x,t)$ is approximated by the mean curvature flow with a drift term.

</details>


### [25] [A direct method for doubly nonlinear equations via convexification in spaces of measures and duality](https://arxiv.org/abs/2602.09808)
*Alessandro Pinzi,Filippo Riva,Giuseppe Savaré*

Main category: math.AP

TL;DR: A global-in-time variational approach for solving doubly nonlinear equations in reflexive Banach spaces without time-discretization, using measure relaxation and Hamilton-Jacobi duality.


<details>
  <summary>Details</summary>
Motivation: To establish existence of solutions to doubly nonlinear equations in reflexive Banach spaces using a direct variational method that avoids time-discretization and iterative constructions like minimizing movements schemes.

Method: A global-in-time variational approach inspired by De Giorgi's principle, characterizing flows as null-minimizers of an energy-dissipation functional. The method uses relaxation in spaces of measures constrained by the continuity equation, with no gap introduced due to Ambrosio's superposition principle. The approach involves: 1) Using Von Neumann minimax theorem to identify the dual problem as a supremum over smooth bounded cylinder functions solving Hamilton-Jacobi-type inequalities, and 2) Establishing "backward boundedness" properties to bound the dual problem and ensure minimum value is zero.

Result: Existence of solutions to doubly nonlinear equations in reflexive Banach spaces is established through this direct variational method that works without time-discretization.

Conclusion: The proposed strategy provides a direct variational approach for solving doubly nonlinear equations that naturally extends to non-autonomous equations with time- and space-dependent dissipation potentials and time-dependent potential energies.

Abstract: Existence of solutions to doubly nonlinear equations in reflexive Banach spaces is established by resorting to a global-in-time variational approach inspired by De Giorgi's principle, which characterizes the associated flows as null-minimizers of a suitable energy-dissipation functional defined on trajectories. In contrast to the celebrated minimizing movements scheme, the proposed strategy does not rely on any time-discretization or iterative constructions. Instead, it provides a direct method based on the relaxation of the problem in spaces of measures, constrained by the continuity equation: in this procedure, no gap is introduced due to the Ambrosio's superposition principle.
  Within this weak convex framework, the validity of the null-minimization property is recovered through two further steps. First, a careful application of the Von Neumann minimax theorem yields an identification of the dual problem as a supremum over the set of smooth and bounded cylinder functions, solving an Hamilton-Jacobi-type inequality. Secondly, a suitable "backward boundedness" property of solutions to such Hamilton-Jacobi system gives a proper bound of the dual problem, ensuring that the minimum value of the original functional is actually zero.
  The proposed strategy naturally extends to non-autonomous equations, encompassing time- and space-dependent dissipation potentials and time-dependent potential energies.

</details>


### [26] [Multi-species kinetic models: GENERIC formulation and Fisher information](https://arxiv.org/abs/2602.09875)
*Manh Hong Duong,Zihui He*

Main category: math.AP

TL;DR: The paper analyzes GENERIC structures for multi-species Boltzmann and Landau equations with quantum statistics, and proves Fisher information monotonicity for homogeneous Boltzmann equations.


<details>
  <summary>Details</summary>
Motivation: To understand the mathematical structure and thermodynamic properties of multi-species kinetic equations with quantum statistics (Bose-Einstein, Maxwell-Boltzmann, Fermi-Dirac), which are important for modeling complex particle systems.

Method: Studying GENERIC (General Equation for Non-Equilibrium Reversible-Irreversible Coupling) structures for spatially inhomogeneous multi-species Boltzmann and Landau equations, and analyzing Fisher information evolution under suitable collision kernel assumptions.

Result: Established GENERIC structures for multi-species Boltzmann and Landau equations with quantum statistics, and proved that Fisher information for multi-species spatially homogeneous Boltzmann equation is non-increasing in time.

Conclusion: The work provides rigorous mathematical foundations for thermodynamic consistency of multi-species kinetic equations with quantum statistics, showing their compatibility with GENERIC formalism and information-theoretic properties.

Abstract: In this paper, we study the GENERIC structures of multi-species spatially inhomogeneous Boltzmann and Landau equations with Bose-Einstein, Maxwell-Boltzmann, and Fermi-Dirac statistics. In addition, under suitable assumptions on the collision kernels, we show that the Fisher information for the multi-species spatially homogeneous Boltzmann equation is non-increasing in time.

</details>


### [27] [Regularity for Doubly Nonlinear Equations in the Mixed Regime](https://arxiv.org/abs/2602.09906)
*Simone Ciani,Eurica Henriques,Mariia Savchenko,Igor I. Skrypnik,Yevgeniia Yevgenieva*

Main category: math.AP

TL;DR: New technique establishes local Hölder continuity for nonnegative solutions to doubly nonlinear equations, covering both singular and degenerate cases up to specific Barenblatt numbers.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the regularity theory for doubly nonlinear equations, which can exhibit both singular and degenerate behavior depending on parameters. Understanding the local Hölder continuity of solutions is fundamental for analyzing these equations, but existing techniques may not fully cover the range of singular and degenerate cases up to specific Barenblatt numbers.

Method: The authors introduce a novel technique that can handle both singular and degenerate cases. The core of their approach is a new integral $L^1$-$L^1$ Harnack estimate, which is of independent mathematical interest beyond the specific application to regularity theory.

Result: The paper proves local Hölder continuity for nonnegative solutions to doubly nonlinear equations, extending the regularity theory to cover cases where the equation is both singular and degenerate, up to specific Barenblatt numbers.

Conclusion: The new technique and the $L^1$-$L^1$ Harnack estimate provide a unified approach to establishing regularity for doubly nonlinear equations, bridging the gap between singular and degenerate cases and advancing the understanding of these important PDEs.

Abstract: We study the local Hölder continuity of nonnegative solutions to doubly nonlinear equations by introducing a new technique that allows us to treat the cases where the equation is both singular and degenerate, up to specific Barenblatt numbers. Our argument relies on a new integral $L^1$-$L^1$ Harnack estimate, of independent interest.

</details>


### [28] [A Viscosity Framework for Dynamic Programming Principles and Applications](https://arxiv.org/abs/2602.09946)
*Félix del Teso,Julio D. Rossi,Jorge Ruiz-Cases*

Main category: math.AP

TL;DR: The paper introduces a viscosity-based solution concept for approximation schemes like dynamic programming principles, bypassing measurability requirements and establishing comparison principles for stability and convergence to PDE solutions.


<details>
  <summary>Details</summary>
Motivation: To develop a viscosity solution framework for general approximation schemes that avoids difficult-to-verify measurability requirements on DPP solutions, which can fail in relevant examples, and to provide a unified approach for various PDE types.

Method: Introduces viscosity-based notion of solution for approximation schemes; establishes comparison principle between classical strict supersolutions and viscosity subsolutions; proves stability results under minimal hypotheses; shows convergence to PDE solutions; demonstrates asymptotic expansions encoded by approximation operators.

Result: Existence of viscosity solutions for DPPs and their convergence to viscosity solutions of consistent PDEs; asymptotic expansions for limiting PDE solutions; framework applicable to local, nonlocal, and nonlinear PDEs, recovering known examples and completing gaps in literature.

Conclusion: The viscosity-based framework provides a robust solution concept for approximation schemes that bypasses measurability issues, establishes strong stability and convergence properties, and offers a unified approach applicable to diverse PDE classes.

Abstract: In this work we introduce a viscosity-based notion of solution for general approximation schemes associated with partial differential equations, such as dynamic programming principles~(DPPs). A key feature of our approach is that it bypasses any measurability requirement on solutions of the DPP, an assumption that is often difficult to verify and may even fail in relevant examples. We establish a comparison principle between classical strict supersolutions and viscosity subsolutions of the DPP, which yields stability results under minimal and natural hypotheses. As a consequence, we prove existence of viscosity solutions of the DPP and their convergence to viscosity solutions of a PDE that is consistent with the underlying approximation scheme. Moreover, we show that solutions of the limiting PDE admit an asymptotic expansion encoded by the approximation operator. Finally, we demonstrate that a broad class of local, nonlocal, and nonlinear partial differential equations fits into our framework, recovering known examples in the literature and completing gaps in the existing literature.

</details>


### [29] [Quantitative estimates for the forced Navier-Stokes equations and applications](https://arxiv.org/abs/2602.09951)
*Tobias Barker,Henry Popkin*

Main category: math.AP

TL;DR: The paper proves a localized supercritical regularity criterion for 3D Navier-Stokes equations, refining recent progress on Tao's conjecture, with applications to Boussinesq equations.


<details>
  <summary>Details</summary>
Motivation: To refine the recent partial positive answer to Tao's conjecture about regularity criteria for 3D Navier-Stokes equations, and to develop quantitative estimates for critically bounded solutions with forcing terms.

Method: Uses Carleman inequalities with additional forcing terms, supplemented by Caccioppoli-type estimates to handle low regularity forcing. Develops new quantitative estimates for critically bounded solutions of forced Navier-Stokes equations.

Result: Proves a localized supercritical (Orlicz) regularity criterion for 3D Navier-Stokes equations. As a by-product, obtains quantitative blow-up rate for the critical L³ norm of velocity in Boussinesq equations.

Conclusion: The paper successfully refines progress on Tao's conjecture through localized regularity criteria and develops new quantitative techniques for handling forced Navier-Stokes equations with applications to related fluid models.

Abstract: In this paper, we prove a localisation of a slightly supercritical (Orlicz) regularity criterion for the 3D incompressible Navier-Stokes equations. This is a refinement to the recent partial positive answer to Tao's conjecture [Tao21] as given in [BP21b]. The proof requires new quantitative estimates for critically bounded solutions of the forced Navier-Stokes equations, where the forcing is induced by the localisation. A by-product of these new estimates is an application to the Boussinesq equations, where we prove a quantitative blow-up rate for the critical $L^3$ norm of the velocity. We prove these quantitative estimates using Carleman inequalities as in [Tao21], and subsequently in [BP21a], with an additional forcing term. An obstacle to doing this is that, in the Carleman inequalities, the forcing term is amplified on large scales. Additionally, the low regularity of the forcing requires the addition of Caccioppoli-type estimates to deal with the Carleman inequalities appropriately.

</details>


### [30] [Stability and bifurcation analysis in a mechanochemical model of pattern formation](https://arxiv.org/abs/2602.09998)
*Szymon Cygan,Anna Marciniak-Czochra,Finn Münnich,Dietmar Oelz*

Main category: math.AP

TL;DR: Mechanochemical model of tissue regeneration shows how mechanical feedback enables single-peaked pattern formation without needing a second diffusible inhibitor.


<details>
  <summary>Details</summary>
Motivation: To understand how mechanochemical feedback (mechanical stretching affecting morphogen production and vice versa) can generate robust pattern formation in regenerating tissue spheroids, potentially explaining how biological systems achieve patterning without complex chemical inhibitor networks.

Method: Developed a mechanochemical model coupling morphogen dynamics with tissue mechanics via positive feedback loop, with global strain conservation providing nonlocal inhibition. Used variational formulation for exponential elasticity-morphogen coupling, performed linear stability analysis, and conducted bifurcation analysis of steady states.

Result: Proved existence of nonconstant steady states for small diffusion and uniqueness of homogeneous state for large diffusion. Showed only unimodal patterns are stable while multimodal solutions are unstable. Found subcritical and supercritical pitchfork bifurcations with fold bifurcations creating bistable regimes.

Conclusion: Mechanochemical feedback provides a robust mechanism for single-peaked pattern formation that doesn't require a second diffusible inhibitor, offering a simpler alternative to traditional activator-inhibitor models in biological pattern formation.

Abstract: We analyze the stability and bifurcation structure of steady states in a mechanochemical model of pattern formation in regenerating tissue spheroids. The model couples morphogen dynamics with tissue mechanics via a positive feedback loop: mechanical stretching enhances morphogen production, while morphogen concentration modulates tissue elasticity. Global strain conservation implements a nonlocal inhibitory effect, realizing a mechanochemical variant of the local activation--long-range inhibition mechanism. For exponential elasticity-morphogen coupling, the system admits a variational formulation. We prove existence of nonconstant steady states for small diffusion and uniqueness of the homogeneous state for large diffusion. Linear stability analysis shows that only unimodal patterns are stable, while multimodal solutions are unstable. Bifurcation analysis reveals subcritical and supercritical pitchforks, with fold bifurcations generating bistable regimes. Our results demonstrate that mechanochemical feedback provides a robust mechanism for single-peaked pattern formation without requiring a second diffusible inhibitor.

</details>


### [31] [Convergence to equilibrium for a class of coagulation-fragmentation equations without detailed balance](https://arxiv.org/abs/2602.10059)
*Apratim Bhattacharya,Sebastian Throm*

Main category: math.AP

TL;DR: Convergence to equilibrium for coagulation-fragmentation equations without detailed balance, focusing on perturbations of constant rate kernels with explicit convergence rates and uniqueness of stationary states.


<details>
  <summary>Details</summary>
Motivation: Many coagulation-fragmentation equations require detailed balance conditions for equilibrium analysis. This work addresses systems that don't satisfy this condition, expanding the class of treatable models.

Method: Analysis of perturbations of constant rate kernels in coagulation-fragmentation equations. The approach likely involves functional analytic methods and perturbation theory to study convergence properties.

Result: Proves convergence to equilibrium with explicit convergence rates for the considered class of kernels. Also establishes uniqueness of stationary states for these systems.

Conclusion: The paper extends equilibrium convergence results to coagulation-fragmentation equations without detailed balance, providing both convergence rates and uniqueness guarantees for perturbed constant rate kernels.

Abstract: We prove convergence to equilibrium for a class of coagulation-fragmentation equations that do not satisfy a detailed balance condition. More precisely, we consider perturbations of constant rate kernels. Our result provides in particular explicit convergence rates. Uniqueness of the stationary states is proven as well for the considered class of kernels.

</details>


### [32] [Confinement results near point vortices on the rotating sphere](https://arxiv.org/abs/2602.10061)
*Martin Donati,Emeric Roulley*

Main category: math.AP

TL;DR: Study of Euler equations on rotating sphere with sharply concentrated vorticity, showing vortex collision improbability, logarithmic confinement, optimality, and power-law confinement configurations.


<details>
  <summary>Details</summary>
Motivation: Extend vorticity confinement results from planar Euler equations to rotating sphere geometry, addressing new challenges posed by spherical geometry.

Method: Follow literature on planar Euler vorticity confinement, adapt to rotating sphere, provide unified self-contained proofs with improved exposition.

Result: Proved: 1) improbability of point-vortex collisions, 2) logarithmic absolute vorticity confinement, 3) optimality of logarithmic bound, 4) existence of power-law long confinement configurations.

Conclusion: Successfully extended planar vorticity confinement results to rotating sphere with comprehensive proofs, revealing geometry-specific confinement behaviors.

Abstract: We study the Euler equation on the rotating sphere in the case where the absolute vorticity is initially sharply concentrated around several points. We follow the literature already concerning vorticity confinement for the planar Euler equations, and obtain similar results on the rotating sphere, with new challenges due to the geometry. More precisely, we show the improbability of collisions for point-vortices, logarithmic in time absolute vorticity confinement for general configurations, the optimality of this last result in general, and the existence of configurations with power-law long confinement. We take this opportunity to write a unified, self-contained, and improved version of all the proofs, previously scattered across multiple papers on the planar case, with detailed exposition for pedagogical clarity.

</details>


### [33] [An eigenvalue problem for a generalized polyharmonic operator in Orlicz-Sobolev spaces without the $Δ_2$-condition](https://arxiv.org/abs/2602.10077)
*Ignacio Ceresa Dussel,Julián Fernández Bonder,Pablo Ochoa*

Main category: math.AP

TL;DR: Generalized polyharmonic eigenvalue problem in Orlicz-Sobolev spaces has infinite eigenfunctions with eigenvalues tending to infinity, without requiring Δ₂-condition on Orlicz functions.


<details>
  <summary>Details</summary>
Motivation: To study generalized polyharmonic eigenvalue problems in higher-order Orlicz-Sobolev spaces, extending classical results to more general operators and function spaces without restrictive growth conditions like the Δ₂-condition.

Method: Combines pseudomonotone operator theory with complementary systems to prove existence of eigenfunctions. Uses De Giorgi's iteration scheme for regularity analysis of eigenfunctions.

Result: Proves the eigenvalue problem has infinite number of eigenfunctions, with corresponding eigenvalues tending to infinity. Establishes first regularity results for eigenfunctions.

Conclusion: The generalized polyharmonic eigenvalue problem in Orlicz-Sobolev spaces is well-posed with infinite spectrum, even without the restrictive Δ₂-condition on Orlicz functions, and eigenfunctions possess regularity properties.

Abstract: In this paper, we consider a generalized polyharmonic eigenvalue problem of the form $A(u)= λh(u)$ in a bounded smooth domain with Dirichlet boundary conditions in the setting of higher-order Orlicz-Sobolev spaces. Here, $A$ is a very general operator depending on $u$ and arbitrary higher-order derivatives of $u$, whose growth is governed by an Orlicz function, and $h$ is a lower order term. Combining the theories of pseudomonotone operators with complementary systems, we prove that this eigenvalue problem has an infinite number of eigenfunctions and that the corresponding sequence of eigenvalues tends to infinity. We point out that the $Δ_2$-condition is not assumed for the involved Orlicz functions. Finally, we prove a first regularity result for eigenfunctions by following a De Giorgi's iteration scheme.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [34] [UniPhy: Unifying Riemannian-Clifford Geometry and Biorthogonal Dynamics for Planetary-Scale Continuous Weather Modeling](https://arxiv.org/abs/2602.09030)
*Ruiqing Yan,Haoyu Deng,Yuhang Shao,Xingbo Du,Jingyuan Wang,Zhengyi Yang*

Main category: physics.comp-ph

TL;DR: UniPhy is a continuous-time non-Hermitian neural SPDE solver that addresses limitations of current data-driven weather models by capturing multi-scale continuous dynamics and thermodynamic openness through geometric transformations, dynamic operators, and computational optimizations.


<details>
  <summary>Details</summary>
Motivation: Current data-driven weather models rely on discrete-time mappings and closed-system assumptions, failing to capture the multi-scale continuous dynamics and thermodynamic openness of the atmosphere, which limits their physical completeness and accuracy.

Method: 1) Geometric: Riemannian-Clifford gauge transformations to flatten planetary heterogeneity for globally consistent operations. 2) Dynamic: Non-Hermitian biorthogonal spectral operators with global flux tracker to capture transient energy growth and open-system exchange. 3) Computational: Reformulate adaptive physical integration as parallel prefix-sum problem using algebraic associativity of analytic solution for log-linear sequence parallelism.

Result: UniPhy establishes a physically complete foundation model architecture that unifies geometric adaptivity, thermodynamic consistency, and computational efficiency, providing a continuous-time solution for atmospheric dynamics.

Conclusion: UniPhy addresses fundamental limitations of current weather models by providing a continuous-time, thermodynamically consistent framework that captures multi-scale atmospheric dynamics while maintaining computational efficiency through innovative geometric and algorithmic approaches.

Abstract: While data-driven weather models have achieved remarkable deterministic accuracy, they fundamentally rely on discrete-time mappings and closed-system assumptions, failing to capture the multi-scale continuous dynamics and thermodynamic openness of the atmosphere. To address these limitations, we propose UniPhy, a continuous-time non-Hermitian neural stochastic partial differential equation (SPDE) solver. Geometrically, we employ Riemannian-Clifford gauge transformations to flatten planetary heterogeneity, enabling globally consistent operations. Dynamically, we construct non-Hermitian biorthogonal spectral operators integrated with a global flux tracker to capture transient energy growth and open-system exchange. Computationally, by identifying the algebraic associativity of the analytic solution, we reformulate adaptive physical integration as a parallel prefix-sum problem, achieving log-linear sequence parallelism. UniPhy establishes a physically complete foundation model architecture that unifies geometric adaptivity, thermodynamic consistency, and computational efficiency. Our code is available at <https://github.com/yrqUni/UniPhy>.

</details>


### [35] [A complete phase-field fracture model for brittle materials subjected to thermal shocks](https://arxiv.org/abs/2602.09031)
*Bo Zeng,John E. Dolbow*

Main category: physics.comp-ph

TL;DR: Complete phase-field fracture model for thermo-mechanical problems that independently specifies material properties, strength, and fracture toughness, validated across various thermal shock scenarios.


<details>
  <summary>Details</summary>
Motivation: Brittle materials under thermal shocks experience temperature gradients causing mechanical stresses that can induce fracture. Classical approaches have limitations in predicting fracture under extreme thermal environments.

Method: Developed a complete phase-field fracture model for coupled thermo-mechanical problems where bulk material properties, material strength, and fracture toughness are specified independently. The model was assessed across various thermo-mechanical fracture scenarios.

Result: Model successfully captured experimentally observed crack patterns in glass plates under controlled quenching, reproduced straight cracks in notched ceramic disks and branching in intact specimens under infrared radiation, and explained experimental transitions from intact to fractured ceramic pellets under rapid power pulses.

Conclusion: The complete phase-field model unifies treatment of distinct fracture scenarios under thermal shock, surpassing classical approaches and enabling more reliable prediction of brittle fracture in extreme environments.

Abstract: Brittle materials subjected to thermal shocks experience strong temperature gradients that in turn give rise to mechanical stresses that can be large enough to induce fracture. This work presents a complete model for phase-field fracture for coupled thermo-mechanical problems, wherein the bulk material properties, the material strength, and the fracture toughness are specified independently. The capabilities of the model are assessed across a wide span of scenarios in thermo-mechanical fracture, from the propagation of large pre-existing cracks to crack nucleation under spatially uniform states of stress. In particular, we revisit the controlled quenching of glass plates, and demonstrate how the model captures experimentally observed crack patterns across a range of thermal loads. Ceramic disks subjected to infrared radiation are also examined, with the model reproducing both straight cracks in notched specimens and branching in intact specimens. Finally, ceramic pellets subjected to rapid power pulses are examined, with the model explaining experimental transitions from intact to fractured pellets and the important role of material strength. The results demonstrate that the complete phase-field model unifies the treatment of distinct fracture scenarios under thermal shock, surpassing classical approaches and enabling more reliable prediction of brittle fracture in extreme environments.

</details>


### [36] [A single-stage high-order compact gas-kinetic scheme in arbitrary Lagrangian-Eulerian formulation](https://arxiv.org/abs/2602.09482)
*Yue Zhang,Xing Ji,Yibing Chen,Fengxiang Zhao,Kun Xu*

Main category: physics.comp-ph

TL;DR: A compact gas-kinetic scheme with ALE formulation for structured meshes achieves high-order accuracy with reduced computational cost through third-order gas-kinetic flux and simplified fourth-order compact reconstruction.


<details>
  <summary>Details</summary>
Motivation: ALE formulation effectively tracks flow discontinuities like shock waves, but mesh motion increases computational costs. Need to reduce costs while maintaining accuracy in ALE framework.

Method: 1) Use gas-kinetic scheme to construct third-order gas-kinetic flux (instead of Runge-Kutta) for single reconstruction/flux per time step, enabling direct updates of flow variables and gradients. 2) Simplified fourth-order compact reconstruction using small matrix to avoid recalculating reconstruction matrix at each time step due to mesh changes. 3) Generalized ENO (GENO) method for handling discontinuities.

Result: Reconstruction is 2.4x to 3.0x faster than previous methods. Numerical tests (Riemann problem, Sedov problem, Noh problem, Saltzmann problem) demonstrate robustness and accuracy of the method.

Conclusion: The combination of fourth-order spatial reconstruction and third-order time-accurate flux evolution ensures both high resolution and computational efficiency in ALE framework for tracking flow discontinuities.

Abstract: This study presents the development of a compact gas-kinetic scheme using an arbitrary Lagrangian-Eulerian (ALE) formulation for structured meshes. Unlike the Eulerian formulation, the ALE approach effectively tracks flow discontinuities, such as shock waves and contact discontinuities. However, mesh motion alters the geometry and increases computational costs. To address this, two key strategies were introduced to reduce costs and enhance accuracy. The first strategy is to use the gas-kinetic scheme to construct a third-order gas-kinetic flux, rather than the Runge-Kutta method to achieve high-order time accuracy, which allows a single reconstruction and flux calculation per time step. This approach enables direct updates of both cell-averaged flow variables and their gradients using a time-accurate flux function, facilitating compact reconstruction. Second, the significant computational expense is spent on reconstruction, which requires recalculating the reconstruction matrix at each time step due to mesh changes. A simplified fourth-order compact reconstruction using a small matrix was used to mitigate this cost. The combination of fourth-order spatial reconstruction and third-order time-accurate flux evolution ensures both high resolution and computational efficiency in the ALE framework. The tests shows that the current reconstruction is 2.4x to 3.0x faster than the previous reconstruction. Additionally, a generalized ENO(GENO) method for handling discontinuities enhances the scheme's robustness. The numerical test cases, such as the Riemann problem, Sedov problem, Noh problem, and Saltzmann problem, demonstrated the robustness and accuracy of our method.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [37] [Development of a Reduced Multi-Fluid Equilibrium Model and Its Application to Proton-Boron Spherical Tokamaks](https://arxiv.org/abs/2602.09205)
*Huasheng Xie,Xingyu Li,Jiaqi Dong,Zhiwei Ma,Yunfeng Liang,Yuejiang Shi,Wenjun Liu,Yueng-Kay Martin Peng,Lai Wei,Zhengxiong Wang,Hanyue Zhao*

Main category: physics.plasm-ph

TL;DR: A reduced multi-fluid model for proton-boron fusion in spherical tokamaks shows that strong rotation causes significant boron accumulation and electrostatic potential, requiring multi-fluid modeling for reactor design.


<details>
  <summary>Details</summary>
Motivation: Standard single-fluid MHD models fail to capture complex multi-fluid effects in proton-boron fusion reactors where strong toroidal rotation and large mass disparity between protons and boron ions drive centrifugal species separation and electrostatic polarization.

Method: Developed a reduced multi-fluid model balancing physical fidelity with computational robustness by retaining dominant toroidal rotation and self-consistent potential while neglecting poloidal inertia and pressure anisotropy. The model couples a generalized Grad-Shafranov equation with species-specific Bernoulli relations and a quasi-neutrality constraint.

Result: Equilibrium modifications are governed by ion Mach number (M). At low rotation (M < 0.5), multi-fluid effects are weak and solutions approach single-fluid limit. At high rotation (M > 2), strong centrifugal forces drive significant boron accumulation at low-field side and generate internal electrostatic potential on the order of 10 kV.

Conclusion: Multi-fluid modeling is necessary for accurate proton-boron reactor design, and the reduced model establishes a theoretical foundation for future investigations into stability, transport, and free-boundary dynamics.

Abstract: Proton-Boron fusion requires extreme ion temperatures and robust confinement, making Spherical Tokamaks (ST) with high-power neutral beam injection primary candidates. In these devices, strong toroidal rotation and the large mass disparity between protons and boron ions drive complex multi-fluid effects - specifically centrifugal species separation and electrostatic polarization - that standard single-fluid magnetohydrodynamic (MHD) models fail to capture. While comprehensive multi-fluid models are often numerically stiff, we develop a reduced model balancing physical fidelity with computational robustness. By retaining dominant toroidal rotation and self-consistent potential while neglecting poloidal inertia and pressure anisotropy, the model couples a generalized Grad-Shafranov equation with species-specific Bernoulli relations and a quasi-neutrality constraint. The model is applied to two representative p-B ST configurations: the experimental EHL-2 and reactor-scale EHL-3B. Simulation results demonstrate that equilibrium modifications are governed by the ion Mach number ($M$). In the low-rotation regime ($M < 0.5$), multi-fluid effects are weak and solutions approach the single-fluid limit. However, at $M > 2$, strong centrifugal forces drive significant boron accumulation at the low-field side (LFS) and generate an internal electrostatic potential on the order of 10 kV. These findings confirm the necessity of multi-fluid modeling for accurate p-$^{11}$B reactor design and establish a theoretical foundation for future investigations into stability, transport, and free-boundary dynamics.

</details>


### [38] [Simulation of the Space-Charge-Limited Current Density for Time-Variant Pulsed Injection](https://arxiv.org/abs/2602.09399)
*H. Huang,Y. Liu*

Main category: physics.plasm-ph

TL;DR: Numerical investigation of space-charge-limited electron flow with time-varying injection profiles, showing potential for transport enhancement in short-pulse conditions.


<details>
  <summary>Details</summary>
Motivation: While space-charge-limited current density for time-invariant injection is well understood, the role of time-varying current density for injection remains unknown, especially how it affects maximum transportable density in different pulse conditions.

Method: Used particle-in-cell simulation to study SCL electron flow with time-variant injection, enforcing four different time-variant profiles for electron injection and determining maximum current densities for various pulse lengths.

Result: Found that time-variant injection density can contribute to transport enhancement in short-pulse conditions, potentially allowing higher current densities than traditional time-invariant limits.

Conclusion: Time-varying injection profiles offer a pathway to overcome traditional space-charge limitations, particularly in short-pulse regimes, enabling higher electron transport densities than previously thought possible.

Abstract: Space-charge-limited (SCL) current density for time-invariant injection (under long-pulse condition) via the diode cathode is the maximum transportable density, while it can be leveraged higher when the injection pulselength becomes shorter than the transmit time for electrons (i.e., under short-pulse condition). However, both limits mentioned above apply for the time-invariant injection condition and the role of time-varying current density for injection remains elusive. In this paper, we numerically investigate the SCL electron flow with time-variant injection. Using particle-in-cell simulation, four different time-variant profiles for electron injection are enforced, and the maximum current densities are determined resulting from the space charge effect for various pulse lengths. We speculate that the time-variant density of injection via the diode cathode will contribute to transport enhancement in the short-pulse condition.

</details>


### [39] [Scaling laws for the cutoff wavenumber of the short-wavelength ion-temperature-gradient mode in a Z-pinch](https://arxiv.org/abs/2602.09827)
*O. Gupta,M. Barnes,F. I. Parra,L. Podavini,A. Zocco,T. Adkins,P. G. Ivanov*

Main category: physics.plasm-ph

TL;DR: The paper develops a heuristic fluid model to predict cutoff wave number scaling for SWITG modes and derives ITG heat flux scalings using turbulent flux estimates and critical balance.


<details>
  <summary>Details</summary>
Motivation: To understand how the cutoff wave number for short-wavelength ion temperature gradient (SWITG) modes depends on key plasma parameters (ion density gradient, ITG, ion-electron temperature ratio) and predict turbulent heat flux scalings.

Method: Developed a heuristic fluid model to predict cutoff wave number scaling, validated with direct numerical solutions of gyrokinetic dispersion relation using a purpose-built solver, then combined with simple diffusive estimate for turbulent fluxes and critical balance conjecture.

Result: Predicted linear increase of cutoff wave number with ITG for large ITG values (confirmed numerically), found weaker power-law scaling for intermediate ITG, derived scaling predictions for ITG heat flux in SWITG-driven turbulence and aspect ratio of turbulent eddies.

Conclusion: The heuristic model successfully predicts SWITG cutoff wave number scalings, enabling derivation of turbulent heat flux predictions that can inform understanding of plasma transport in fusion devices.

Abstract: We use a heuristic fluid model to predict the dependence of the cutoff wave number for the short-wavelength ion temperature gradient (SWITG) mode on ion density gradient, ion temperature gradient (ITG) and ion-electron temperature ratio. In particular, we predict that the cutoff wave number increases linearly with increasing ITG for sufficiently large values of the ITG. Direct numerical solutions of the gyrokinetic dispersion relation using a purpose-built solver confirm the predicted scalings at large ITG values and find a weaker power-law scaling for intermediate ITG values. Combining these wave number scalings with a simple diffusive estimate for turbulent fluxes produces a scaling prediction for the ITG heat flux in SWITG-driven turbulence. Applying the critical balance conjecture additionally provides scalings for the aspect ratio of the SWITG turbulent eddies.

</details>


### [40] [Deflation Techniques for Stellarator Equilibrium and Optimization](https://arxiv.org/abs/2602.09957)
*Dario Panici,Byoungchan Jang,Rory Conlin,Daniel Dudt,Yigit Gunsur Elmacioglu,Egemen Kolemen*

Main category: physics.plasm-ph

TL;DR: Novel application of deflation methods to stellarator optimization, enabling discovery of multiple distinct local minima by penalizing already-found solutions.


<details>
  <summary>Details</summary>
Motivation: Stellarator optimization is multi-objective, non-convex with many local minima, sensitive to initial conditions and optimization setup. Current methods often fail to find physically distinct minima despite parameter scans.

Method: Deflation methods that modify the objective function to penalize already-found solutions, encouraging exploration of new minima while using single initial guess and optimization setup.

Result: Discovery of families of global equilibria with similar core characteristics; convergence to helical core equilibria without prescient initial guesses; production of multiple high-quality, distinct solutions in stellarator and coil optimization.

Conclusion: Deflation methods effectively explore complex optimization landscapes in stellarator design, producing multiple distinct solutions with ease of use and establishing method's efficacy.

Abstract: Stellarator optimization is a multi-objective, non-convex problem characterized by a complex objective landscape containing many local minima. The solution resulting from a single optimization is highly sensitive to factors such as the initial guess, objective weights, and the optimization method employed. However, merely varying these factors does not guarantee that a physically distinct minimum will be found; optimizations often fail to converge to good minima or simply return to the same or very similar local minima despite large-scale parameter scans. This paper presents a novel application of deflation methods to effectively explore this landscape. By modifying the objective function to penalize and "deflate" away already-found solutions, this technique encourages the optimizer towards attractive, distinct new minima while using a single initial guess and optimization setup. We provide a primer on deflation for nonlinear systems and non-convex optimization before applying it to non-axisymmetric equilibrium and stellarator optimization problems. Key results include the discovery of families of global equilibria with similar core characteristics and the convergence to helical core equilibria without prescient initial guesses. Furthermore, we demonstrate that augmenting stage-one stellarator and stage-two coil optimization with deflation constraints readily produces multiple high-quality, distinct solutions, establishing the method's efficacy and ease of use.

</details>


### [41] [Design of experiments characterising heat conduction in magnetised, weakly collisional plasma](https://arxiv.org/abs/2602.10041)
*T. A. Vincent,P. Ariyathilaka,L. Creaser,C. Danson,D. Lamb,J. Meinecke,C. A. J. Palmer,S. Pitt,H. Poole,C. Spindloe,P. Thomas,E. Tubman,L. Wilson,W. J. Garbett,G. Gregori,P. Tzeferacos,T. Hodge,A. F. A. Bott*

Main category: physics.plasm-ph

TL;DR: New experimental platform on Orion laser produces weakly collisional high-beta plasma to study whistler heat-flux instability and measure thermal conductivity suppression.


<details>
  <summary>Details</summary>
Motivation: Heat conduction in weakly collisional magnetized plasma is difficult to model due to complex electron physics and microinstabilities. Current kinetic simulations are computationally expensive, requiring experimental approaches to understand thermal transport in systems like galaxy clusters and inertial confinement fusion.

Method: Developed new experimental platform on Orion laser that produces weakly collisional high-beta plasma susceptible to whistler heat-flux instability. Platform design assessed using radiation-magnetohydrodynamics simulations with FLASH code, comparing three thermal conduction models.

Result: Simulations predict conductivity suppression by over an order of magnitude relative to Spitzer value at whistler saturation, demonstrating the platform's efficacy for studying whistler-regulated thermal conductivity.

Conclusion: The new experimental platform enables characterization of whistler-regulated thermal conductivity, providing experimental constraints to overcome computational limitations in modeling heat transport in weakly collisional magnetized plasmas.

Abstract: Heat conduction in weakly collisional, magnetised plasma is challenging to model accurately due to multifaceted physics governing heat-carrying electrons, including microinstabilities that scatter electrons and modify heat transport. Capturing these effects requires multidimensional kinetic theory simulations, which are computationally expensive. Experimental constraints overcome this issue, resulting in improved understanding of thermal transport in systems such as the intra-cluster medium of galaxy clusters, and the hot-spot in inertial confinement fusion. In this paper, we present a new experimental platform that produces a weakly collisional high-\b{eta} plasma expected to be susceptible to the whistler heat-flux instability. This platform, to be fielded on the Orion laser, enables characterisation of whistler-regulated thermal conductivity. The platform design is assessed using radiation-magnetohydrodynamics simulations with the code FLASH. Simulations using three thermal conduction models predict conductivity suppression by over an order of magnitude relative to the Spitzer value at whistler saturation, demonstrating the efficacy of the platform.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [42] [Asymptotic analysis of the Gaussian kernel matrix for partially noisy data in high dimensions](https://arxiv.org/abs/2602.09762)
*Kensuke Aishima*

Main category: math.ST

TL;DR: The paper presents a consistent estimator for Gaussian kernel matrices in high dimensions by combining Karoui's asymptotic analysis with constrained low-rank approximation methods.


<details>
  <summary>Details</summary>
Motivation: The Gaussian kernel is widely used but faces challenges in high-dimensional settings with noisy data, where naive estimators become inconsistent. There's a need for consistent estimators that work well under statistical models with partial noise.

Method: Combines Karoui's asymptotic analysis of Gaussian kernel matrices with constrained low-rank matrix approximation procedures. Uses the smallest eigenvalue and applies optimization methods for low-rank approximations with constraints to overcome inconsistency issues.

Result: Develops a new estimator that achieves strong consistency in rank-deficient cases, overcoming the inconsistency of naive estimators. The method works when the target kernel matrix tends to low rank in the asymptotic regime.

Conclusion: The proposed constrained low-rank approximation approach successfully addresses inconsistency problems in high-dimensional Gaussian kernel matrix estimation under noisy data conditions, providing a consistent estimator for practical applications.

Abstract: The Gaussian kernel is one of the most important kernels, applicable to many research fields, including scientific computing and data science. In this paper, we present asymptotic analysis of the Gaussian kernel matrix in high dimension under a statistical model of noisy data. The main result is a nice combination of Karoui's asymptotic analysis with procedures of constrained low rank matrix approximations. More specifically, Karouli clarified an important asymptotic structure of the Gaussian kernel matrix, leading to strong consistency of the eigenvectors, though the eigenvalues are inconsistent. This paper focuses on the above results and presents a consistent estimator with the use of the smallest eigenvalue, whenever the target kernel matrix tends to low rank in the asymptotic regime. Importantly, asymptotic analysis is given under a statistical model representing partial noise. Although a naive estimator is inconsistent, applying an optimization method for low rank approximations with constraints, we overcome the difficulty caused by the inconsistency, resulting in a new estimator with strong consistency in rank deficient cases.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [43] [Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks](https://arxiv.org/abs/2602.09980)
*Enzo Nicolas Spotorno,Josafat Ribeiro Leal,Antonio Augusto Frohlich*

Main category: cs.LG

TL;DR: TAPINN: Topology-Aware PINN using supervised metric regularization to handle parameterized dynamical systems with sharp transitions like bifurcations, avoiding spectral bias and mode collapse.


<details>
  <summary>Details</summary>
Motivation: Standard PINNs struggle with parameterized dynamical systems having sharp regime transitions (e.g., bifurcations), suffering from spectral bias/mode collapse where networks average distinct physical behaviors instead of capturing discontinuous changes.

Method: Proposes Topology-Aware PINN (TAPINN) that structures latent space via Supervised Metric Regularization. Instead of mapping physical parameters directly to solutions, conditions solver on latent state optimized for metric-based separation between regimes. Uses phase-based Alternating Optimization schedule to manage gradient conflicts between metric and physics objectives.

Result: Achieves ~49% lower physics residual (0.082 vs 0.160) compared to baselines. Shows stable convergence with 2.18x lower gradient variance than multi-output Sobolev Error baseline, and uses 5x fewer parameters than hypernetwork-based alternative. On Duffing Oscillator, avoids spectral bias that affects standard PINNs and overfitting that affects high-capacity hypernetworks.

Conclusion: TAPINN effectively mitigates spectral bias in parameterized dynamical systems with sharp transitions by structuring latent space with metric regularization and using alternating optimization, achieving better physics compliance with fewer parameters and more stable training.

Abstract: Standard Physics-Informed Neural Networks (PINNs) often face challenges when modeling parameterized dynamical systems with sharp regime transitions, such as bifurcations. In these scenarios, the continuous mapping from parameters to solutions can result in spectral bias or "mode collapse", where the network averages distinct physical behaviors. We propose a Topology-Aware PINN (TAPINN) that aims to mitigate this challenge by structuring the latent space via Supervised Metric Regularization. Unlike standard parametric PINNs that map physical parameters directly to solutions, our method conditions the solver on a latent state optimized to reflect the metric-based separation between regimes, showing ~49% lower physics residual (0.082 vs. 0.160). We train this architecture using a phase-based Alternating Optimization (AO) schedule to manage gradient conflicts between the metric and physics objectives. Preliminary experiments on the Duffing Oscillator demonstrate that while standard baselines suffer from spectral bias and high-capacity Hypernetworks overfit (memorizing data while violating physics), our approach achieves stable convergence with 2.18x lower gradient variance than a multi-output Sobolev Error baseline, and 5x fewer parameters than a hypernetwork-based alternative.

</details>


### [44] [From Adam to Adam-Like Lagrangians: Second-Order Nonlocal Dynamics](https://arxiv.org/abs/2602.09101)
*Carlos Heredia*

Main category: cs.LG

TL;DR: Accelerated continuous-time formulation of Adam as second-order integro-differential system with stability analysis and variational viewpoint.


<details>
  <summary>Details</summary>
Motivation: To develop a continuous-time formulation of Adam optimization algorithm that captures its acceleration properties and provides theoretical understanding through dynamical systems and variational perspectives.

Method: Model Adam as second-order integro-differential dynamical system, relate to existing first-order Adam flow via α-refinement limit, perform Lyapunov-based stability analysis, and introduce Adam-inspired nonlocal Lagrangian formulation for variational viewpoint.

Result: Derived accelerated continuous-time formulation of Adam, established connections between inertial nonlocal model and existing Adam flow, provided convergence analysis, and demonstrated agreement with discrete Adam on Rosenbrock-type examples.

Conclusion: The paper successfully develops a continuous-time dynamical systems framework for Adam optimization, providing theoretical foundations through stability analysis and variational perspectives while maintaining practical agreement with discrete Adam.

Abstract: In this paper, we derive an accelerated continuous-time formulation of Adam by modeling it as a second-order integro-differential dynamical system. We relate this inertial nonlocal model to an existing first-order nonlocal Adam flow through an $α$-refinement limit, and we provide Lyapunov-based stability and convergence analyses. We also introduce an Adam-inspired nonlocal Lagrangian formulation, offering a variational viewpoint. Numerical simulations on Rosenbrock-type examples show agreement between the proposed dynamics and discrete Adam.

</details>


### [45] [Empirical Stability Analysis of Kolmogorov-Arnold Networks in Hard-Constrained Recurrent Physics-Informed Discovery](https://arxiv.org/abs/2602.09988)
*Enzo Nicolas Spotorno,Josafat Leal Filho,Antonio Augusto Medeiros Frohlich*

Main category: cs.LG

TL;DR: KANs integrated into hard-constrained recurrent physics-informed architectures show competitive performance on simple polynomial residuals but suffer from hyperparameter fragility, instability in deeper configurations, and failure on multiplicative terms, generally underperforming compared to standard MLPs.


<details>
  <summary>Details</summary>
Motivation: Motivated by the Kolmogorov-Arnold representation theorem and preliminary gray-box results, researchers hypothesized that KANs would enable efficient recovery of unknown terms in oscillatory systems compared to MLPs.

Method: Integration of Kolmogorov-Arnold Networks (KANs) into hard-constrained recurrent physics-informed architectures (HRPINN) with sensitivity analysis on configuration sensitivity, parameter scale, and training paradigm, tested on univariate polynomial residuals (Duffing) and multiplicative terms (Van der Pol).

Result: Small KANs are competitive on univariate polynomial residuals (Duffing) but exhibit severe hyperparameter fragility, instability in deeper configurations, and consistent failure on multiplicative terms (Van der Pol), generally outperformed by standard MLPs.

Conclusion: The additive inductive bias in the original KAN formulation has limitations for state coupling, providing preliminary empirical evidence of inductive bias limitations for future hybrid modeling approaches.

Abstract: We investigate the integration of Kolmogorov-Arnold Networks (KANs) into hard-constrained recurrent physics-informed architectures (HRPINN) to evaluate the fidelity of learned residual manifolds in oscillatory systems. Motivated by the Kolmogorov-Arnold representation theorem and preliminary gray-box results, we hypothesized that KANs would enable efficient recovery of unknown terms compared to MLPs. Through initial sensitivity analysis on configuration sensitivity, parameter scale, and training paradigm, we found that while small KANs are competitive on univariate polynomial residuals (Duffing), they exhibit severe hyperparameter fragility, instability in deeper configurations, and consistent failure on multiplicative terms (Van der Pol), generally outperformed by standard MLPs. These empirical challenges highlight limitations of the additive inductive bias in the original KAN formulation for state coupling and provide preliminary empirical evidence of inductive bias limitations for future hybrid modeling.

</details>


### [46] [Stabilizing Physics-Informed Consistency Models via Structure-Preserving Training](https://arxiv.org/abs/2602.09303)
*Che-Chia Chang,Chen-Yang Dai,Te-Sheng Lin,Ming-Chih Lai,Chieh-Hsin Lai*

Main category: cs.LG

TL;DR: Physics-informed consistency modeling for fast PDE solving via few-step generative inference with stability improvements


<details>
  <summary>Details</summary>
Motivation: Address stability challenges in physics-constrained consistency training where PDE residuals can drive models toward trivial/degenerate solutions, degrading learned data distributions

Method: Structure-preserving two-stage training that decouples distribution learning from physics enforcement (freezing coefficient decoder during fine-tuning) + two-step residual objective enforcing physical consistency on refined generative trajectories

Result: Enables stable, high-fidelity inference for unconditional generation and forward problems; forward solutions via projection-based zero-shot inpainting achieve diffusion baseline accuracy with orders of magnitude computational cost reduction

Conclusion: Proposed framework provides stable physics-informed consistency modeling for fast PDE solving with computational efficiency while maintaining accuracy

Abstract: We propose a physics-informed consistency modeling framework for solving partial differential equations (PDEs) via fast, few-step generative inference. We identify a key stability challenge in physics-constrained consistency training, where PDE residuals can drive the model toward trivial or degenerate solutions, degrading the learned data distribution. To address this, we introduce a structure-preserving two-stage training strategy that decouples distribution learning from physics enforcement by freezing the coefficient decoder during physics-informed fine-tuning. We further propose a two-step residual objective that enforces physical consistency on refined, structurally valid generative trajectories rather than noisy single-step predictions. The resulting framework enables stable, high-fidelity inference for both unconditional generation and forward problems. We demonstrate that forward solutions can be obtained via a projection-based zero-shot inpainting procedure, achieving consistent accuracy of diffusion baselines with orders of magnitude reduction in computational cost.

</details>


### [47] [Adaptive recurrent flow map operator learning for reaction diffusion dynamics](https://arxiv.org/abs/2602.09487)
*Huseyin Tunc*

Main category: cs.LG

TL;DR: DDOL-ART is a data-driven neural operator with adaptive recurrent training that learns stable flow-map surrogates for reaction-diffusion systems without physics-based residuals, achieving strong generalization and training efficiency.


<details>
  <summary>Details</summary>
Motivation: Neural operators for reaction-diffusion systems suffer from error accumulation in autoregressive rollouts and poor generalization to out-of-distribution conditions. Physics-based regularization adds complexity, assumptions, and computational cost.

Method: DDOL-ART uses adaptive recurrent training with lightweight validation milestones that early-exit unproductive rollout segments and redirect optimization. Trained only on short-horizon in-distribution data from a single toroidal Gaussian family.

Result: Learns one-step operators that remain stable under long rollouts and generalize zero-shot to strong morphology shifts across FitzHugh-Nagumo, Gray-Scott, and Lambda-Omega systems. Several-fold faster than physics-based NLOL while maintaining competitive accuracy.

Conclusion: Feedback-controlled recurrent training generates robust flow-map surrogates without PDE residuals, maintaining competitiveness with physics-based methods at significantly reduced training costs, with adaptivity strengthening validation-to-test error correlation.

Abstract: Reaction-diffusion (RD) equations underpin pattern formation across chemistry, biology, and physics, yet learning stable operators that forecast their long-term dynamics from data remains challenging. Neural-operator surrogates provide resolution-robust prediction, but autoregressive rollouts can drift due to the accumulation of error, and out-of-distribution (OOD) initial conditions often degrade accuracy. Physics-based numerical residual objectives can regularize operator learning, although they introduce additional assumptions, sensitivity to discretization and loss design, and higher training cost. Here we develop a purely data-driven operator learner with adaptive recurrent training (DDOL-ART) using a robust recurrent strategy with lightweight validation milestones that early-exit unproductive rollout segments and redirect optimization. Trained only on a single in-distribution toroidal Gaussian family over short horizons, DDOL-ART learns one-step operators that remain stable under long rollouts and generalize zero-shot to strong morphology shifts across FitzHugh-Nagumo (FN), Gray-Scott (GS), and Lambda-Omega (LO) systems. Across these benchmarks, DDOL-ART delivers a strong accuracy and cost trade-off. It is several-fold faster than a physics-based numerical-loss operator learner (NLOL) under matched settings, and it remains competitive on both in-distribution stability and OOD robustness. Training-dynamics diagnostics show that adaptivity strengthens the correlation between validation error and OOD test error performance, acting as a feedback controller that limits optimization drift. Our results indicate that feedback-controlled recurrent training of DDOL-ART generates robust flow-map surrogates without PDE residuals, while simultaneously maintaining competitiveness with NLOL at significantly reduced training costs.

</details>


### [48] [Learning to Discover Iterative Spectral Algorithms](https://arxiv.org/abs/2602.09530)
*Zihang Liu,Oleg Balabanov,Yaoqing Yang,Michael W. Mahoney*

Main category: cs.LG

TL;DR: AutoSpec is a neural network framework that discovers iterative spectral algorithms for numerical linear algebra and optimization by learning recurrence coefficients for matrix polynomials tailored to specific tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop automated methods for discovering efficient iterative algorithms for large-scale numerical linear algebra problems, moving beyond hand-designed classical methods to leverage machine learning for algorithm discovery.

Method: AutoSpec uses self-supervised neural networks that adapt to input operators using coarse spectral information (eigenvalue estimates, residual norms). The architecture implements executable numerical linear algebra recurrences, is trained on small synthetic problems with transfer to large-scale operators, and uses task-defined objectives for desired approximation/preconditioning behavior.

Result: On real-world matrices, AutoSpec delivers orders-of-magnitude improvements in accuracy and/or reductions in iteration count compared to basic baselines. The learned procedures show connections to classical theory, with induced polynomials exhibiting near-equiripple, near-minimax behavior characteristic of Chebyshev polynomials.

Conclusion: AutoSpec successfully demonstrates that neural networks can discover effective iterative spectral algorithms for numerical linear algebra tasks, achieving significant performance improvements while revealing connections to established mathematical theory.

Abstract: We introduce AutoSpec, a neural network framework for discovering iterative spectral algorithms for large-scale numerical linear algebra and numerical optimization. Our self-supervised models adapt to input operators using coarse spectral information (e.g., eigenvalue estimates and residual norms), and they predict recurrence coefficients for computing or applying a matrix polynomial tailored to a downstream task. The effectiveness of AutoSpec relies on three ingredients: an architecture whose inference pass implements short, executable numerical linear algebra recurrences; efficient training on small synthetic problems with transfer to large-scale real-world operators; and task-defined objectives that enforce the desired approximation or preconditioning behavior across the range of spectral profiles represented in the training set. We apply AutoSpec to discovering algorithms for representative numerical linear algebra tasks: accelerating matrix-function approximation; accelerating sparse linear solvers; and spectral filtering/preconditioning for eigenvalue computations. On real-world matrices, the learned procedures deliver orders-of-magnitude improvements in accuracy and/or reductions in iteration count, relative to basic baselines. We also find clear connections to classical theory: the induced polynomials often exhibit near-equiripple, near-minimax behavior characteristic of Chebyshev polynomials.

</details>


### [49] [Physics-informed diffusion models in spectral space](https://arxiv.org/abs/2602.09708)
*Davide Gallon,Philippe von Wurstemberger,Patrick Cheridito,Arnulf Jentzen*

Main category: cs.LG

TL;DR: A method combining latent diffusion models with physics-informed ML to solve parametric PDEs from partial observations, using spectral representations for dimensionality reduction and enforcing physics constraints during inference.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient approach for solving forward and inverse PDE problems with sparse observations, overcoming limitations of grid-based diffusion models while ensuring mathematical consistency with PDE operators.

Method: Learn joint distribution of PDE parameters/solutions via diffusion in latent spectral space, use diffusion posterior sampling with physics-informed constraints and Adam-based updates at each step, enabling dimensionality reduction while maintaining function regularity.

Result: Demonstrated improved accuracy and computational efficiency on Poisson, Helmholtz, and Navier-Stokes equations compared to state-of-the-art diffusion-based PDE solvers for sparse observations.

Conclusion: The spectral latent diffusion approach effectively solves parametric PDEs from partial observations, offering mathematical consistency, computational efficiency, and superior performance over existing methods.

Abstract: We propose a methodology that combines generative latent diffusion models with physics-informed machine learning to generate solutions of parametric partial differential equations (PDEs) conditioned on partial observations, which includes, in particular, forward and inverse PDE problems. We learn the joint distribution of PDE parameters and solutions via a diffusion process in a latent space of scaled spectral representations, where Gaussian noise corresponds to functions with controlled regularity. This spectral formulation enables significant dimensionality reduction compared to grid-based diffusion models and ensures that the induced process in function space remains within a class of functions for which the PDE operators are well defined. Building on diffusion posterior sampling, we enforce physics-informed constraints and measurement conditions during inference, applying Adam-based updates at each diffusion step. We evaluate the proposed approach on Poisson, Helmholtz, and incompressible Navier--Stokes equations, demonstrating improved accuracy and computational efficiency compared with existing diffusion-based PDE solvers, which are state of the art for sparse observations. Code is available at https://github.com/deeplearningmethods/PISD.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [50] [Optimising Microwave Cavities for nonzero Helicity with Machine Learning](https://arxiv.org/abs/2602.09037)
*Emma Paterson,Jeremy Bourhill,Maxim Goryachev*

Main category: physics.optics

TL;DR: ML-driven inverse design framework for 3D microwave cavities that maximize electromagnetic helicity using shape optimization and gradient-free algorithms.


<details>
  <summary>Details</summary>
Motivation: To systematically engineer 3D microwave cavity resonators supporting modes with nonzero electromagnetic helicity, moving beyond heuristic design approaches that are limited in exploring complex shape parameter spaces.

Method: Formulated helicity maximization as boundary-shape optimization problem. Applied framework to multiple cavity families (globally twisted cavities, orthogonal prism intersections, sphere-subtracted cylinders, parametrized surfaces). Used two gradient-free optimization strategies: genetic algorithm and Bayesian optimization to explore design parameters. Evaluated helicity via finite-element eigenmode analysis.

Result: Successfully identified high-helicity cavity designs that are difficult to predict using heuristic rules alone. Quantified robustness to manufacturing tolerances by applying Gaussian geometric perturbations and evaluating statistical robustness metrics.

Conclusion: The ML-driven inverse design framework enables systematic exploration of complex cavity geometries and identification of optimal helicity designs with quantified manufacturing robustness, advancing beyond traditional heuristic approaches.

Abstract: We present a machine-learning-driven inverse design framework for systematically engineering three-dimensional microwave cavity resonators that support modes with nonzero electromagnetic helicity. In contrast to heuristic approaches to cavity design, helicity maximisation is formulated as a boundary-shape optimisation problem, enabling systematic exploration of complex boundary-shape parameter spaces and the identification of high-helicity designs that are difficult to predict using heuristic design rules alone. We applied this framework to several cavity families composed of smooth, edge-free components, including globally twisted cavities with control-point-defined cross-sections realised in both linear and ring configurations, cavities defined by the intersection of orthogonal prisms, sphere-subtracted cylindrical cavities, and parametrised surface resonators. Two gradient-free optimisation strategies, a genetic algorithm and Bayesian optimisation, were independently employed to explore compact sets of design parameters for these geometries and to optimise a scaled-helicity figure of merit for the dominant helical mode, evaluated via finite-element eigenmode analysis. Robustness to manufacturing tolerances was quantified by applying Gaussian geometric perturbations to the optimised cavities and evaluating statistical robustness metrics that penalise sensitivity to geometric variation.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [51] [Toeplitz Based Spectral Methods for Data-driven Dynamical Systems](https://arxiv.org/abs/2602.09791)
*Vladimir R. Kostic,Karim Lounici,Massimiliano Pontil*

Main category: math.DS

TL;DR: Toeplitz-based framework for data-driven spectral estimation of linear evolution operators from equilibrium trajectories without equations of motion.


<details>
  <summary>Details</summary>
Motivation: Need for data-driven methods to estimate spectral properties of linear evolution operators (transfer/Koopman operators) from trajectory data without access to underlying equations, especially when structural priors like self-adjointness or skew-symmetry are known.

Method: Uses Toeplitz filters applied to infinitesimal generator to extract eigenvalues, eigenfunctions, and spectral measures. Incorporates structural prior knowledge by design. Leverages both primal and dual algorithms from statistical learning for computational efficiency.

Result: Method is statistically consistent and computationally efficient. Numerical experiments on deterministic and chaotic systems show recovery of spectral properties beyond standard data-driven methods.

Conclusion: Toeplitz-based framework provides effective data-driven approach for spectral estimation of linear evolution operators, handling structural priors and outperforming existing methods on complex systems.

Abstract: We introduce a Toeplitz-based framework for data-driven spectral estimation of linear evolution operators in dynamical systems. Focusing on transfer and Koopman operators from equilibrium trajectories without access to the underlying equations of motion, our method applies Toeplitz filters to the infinitesimal generator to extract eigenvalues, eigenfunctions, and spectral measures. Structural prior knowledge, such as self-adjointness or skew-symmetry, can be incorporated by design. The approach is statistically consistent and computationally efficient, leveraging both primal and dual algorithms commonly used in statistical learning. Numerical experiments on deterministic and chaotic systems demonstrate that the framework can recover spectral properties beyond the reach of standard data-driven methods.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [52] [Elliptic Multiple Polylogarithms with Arbitrary Arguments in \textsc{GiNaC}](https://arxiv.org/abs/2602.09956)
*Claude Duhr,Florian Lorkowski,Robin Marzucca,Sofia Mauc,Stefan Weinzierl*

Main category: hep-ph

TL;DR: Algorithm for numerical evaluation of elliptic multiple polylogarithms with arbitrary arguments to arbitrary precision using q-series representations with ordinary multiple polylogarithm coefficients.


<details>
  <summary>Details</summary>
Motivation: Need for computational tools to evaluate elliptic multiple polylogarithms to high precision for arbitrary arguments, as no public package currently exists for this purpose.

Method: Develop q-series representation of elliptic multiple polylogarithms with coefficients expressed as ordinary multiple polylogarithms, plus preparation steps to map into regions of rapid convergence.

Result: First public implementation in GiNaC framework capable of evaluating elliptic multiple polylogarithms to high precision for arbitrary argument values.

Conclusion: Provides practical computational tool for evaluating elliptic multiple polylogarithms, filling important gap in mathematical software for high-precision calculations.

Abstract: We present an algorithm for the numerical evaluation of elliptic multiple polylogarithms for arbitrary arguments and to arbitrary precision. The cornerstone of our approach is a procedure to obtain a convergent $q$-series representation of elliptic multiple polylogarithms. Its coefficients are expressed in terms of ordinary multiple polylogarithms, which can be evaluated efficiently using existing libraries. In a series of preparation steps the elliptic polylogarithms are mapped into a region where the $q$-series converges rapidly. We also present an implementation of our algorithm into the \texttt{GiNaC} framework. This release constitutes the first public package capable of evaluating elliptic multiple polylogarithms to high precision and for arbitrary values of the arguments.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [53] [Geometric eigenvalue estimates of Kuttler-Sigillito type on differential forms](https://arxiv.org/abs/2602.09876)
*Rodolphe Abou Assali*

Main category: math.DG

TL;DR: The paper introduces a new biharmonic Steklov problem for differential forms with Dirichlet boundary conditions, proves its ellipticity and existence of discrete spectrum, provides variational characterizations, and establishes Kuttler-Sigillito type eigenvalue inequalities connecting eigenvalues to manifold curvature.


<details>
  <summary>Details</summary>
Motivation: To extend Steklov eigenvalue theory to differential forms and establish connections between spectral properties of differential forms and geometric quantities like curvature on manifolds.

Method: Introduces a biharmonic Steklov problem for differential forms with Dirichlet boundary conditions, proves ellipticity using PDE theory, establishes existence of discrete spectrum through variational methods, and derives eigenvalue estimates via analytical techniques.

Result: The problem is shown to be elliptic, has a discrete spectrum, variational characterizations for eigenvalues are provided, and Kuttler-Sigillito type inequalities are established connecting eigenvalues of different problems on differential forms with curvature quantities on the manifold.

Conclusion: The paper successfully extends Steklov eigenvalue theory to differential forms, providing a complete spectral theory framework with connections to geometric properties of the underlying manifold through curvature-dependent eigenvalue bounds.

Abstract: We introduce a new biharmonic Steklov problem on differential forms with Dirichlet-type boundary conditions and show that it is elliptic. We prove the existence of a discrete spectrum for this problem and give variational characterizations for eigenvalues associated to it. We establish eigenvalue estimates known as Kuttler-Sigillito inequalities, that connect the eigenvalues of different problems on differential forms with curvature quantities on the manifold.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [54] [Wave Particle Turbulent Simulation of Spatially Developing Round Jets Using a Non Equilibrium Transport Model with a Mixing Length Characteristic Time Closure](https://arxiv.org/abs/2602.09759)
*Xiaojian Yang,Kun Xu*

Main category: physics.flu-dyn

TL;DR: WPTS turbulence modeling approach coupled with mixing-length-based characteristic-time closure accurately predicts round jet similarity solutions at Re=5k and 20k.


<details>
  <summary>Details</summary>
Motivation: To develop a practical, unified turbulence modeling framework that can represent both laminar and turbulent regimes while overcoming limitations of conventional equilibrium-based eddy-viscosity models.

Method: Couples WPTS (wave-particle turbulent simulation) with a turbulence characteristic-time closure derived from Prandtl mixing-length hypothesis. WPTS uses Lagrangian particles for turbulent regions and Eulerian wave-like representation for background flow, with particle fraction governed by modeled turbulence characteristic time.

Result: The WPTS framework accurately reproduces jet similarity solutions and characteristic features at Reynolds numbers of 5,000 and 20,000 for spatially developing round jets.

Conclusion: WPTS shows promise as a practical tool for turbulence modeling and simulation, successfully bridging mixing-length concepts with non-equilibrium transport mechanisms in a unified framework.

Abstract: In this paper, the wave-particle turbulent simulation (WPTS), a recently developed multiscale, non-equilibrium turbulence modeling approach, is coupled with a turbulence characteristic-time closure derived from Prandtl mixing-length hypothesis and applied to spatially developing round jets. In WPTS, fluid elements in strongly turbulent regions are represented by Lagrangian particles that travel a finite distance before interacting with the background flow field represented in a wave-like (Eulerian) form. This mechanism bears conceptual similarity to the discrete fluid parcels invoked in the Prandtl mixing-length picture. WPTS differs from conventional mixing-length-based turbulence models in two key respects. First, particle evolution follows a non-equilibrium transport mechanism, rather than the equilibrium assumptions typically embedded in eddy-viscosity closures. Second, WPTS advances the wave and particle components in a coupled manner, with the particle fraction governed primarily by the modeled turbulence characteristic time, enabling laminar and turbulent regimes to be represented within a unified framework. Because spatially developing jets provide a canonical test case with well-established similarity behavior, they are used here for evaluation. Specifically, this work (1) develops a mixing-length-based characteristic-time model tailored to jet flows and (2) incorporates it into WPTS to assess predictive performance. The resulting WPTS framework accurately reproduces the jet similarity solution and other characteristic features at Reynolds numbers of 5,000 and 20,000, demonstrating the promise of WPTS as a practical tool for turbulence modeling and simulation.

</details>


### [55] [From oblique-wave forcing to streak reinforcement: A perturbation-based frequency-response framework](https://arxiv.org/abs/2602.09137)
*Dušan Božić,Anubhav Dwivedi,Mihailo R. Jovanović*

Main category: physics.flu-dyn

TL;DR: Develops a perturbation-based frequency-response framework to analyze amplification mechanisms in subcritical transition of wall-bounded shear flows, connecting linear resolvent analysis with nonlinear interactions.


<details>
  <summary>Details</summary>
Motivation: To understand amplification mechanisms in subcritical transition routes in wall-bounded shear flows, and to establish connections between linear resolvent analysis and nonlinear interactions that drive transition.

Method: Perturbation-based frequency-response framework expanding input-output dynamics about laminar base flow with respect to forcing amplitude. Uses systematic expansion to connect linear resolvent analysis with higher-order nonlinear interactions, analyzing quadratic interactions of oblique waves generating streaks via lift-up mechanism.

Result: At second order, quadratic interactions of oblique waves generate steady streaks captured by second output singular function of streamwise-constant resolvent operator. Higher-order nonlinear coupling yields additional streak components whose relative phase governs reinforcement/attenuation. Identifies critical forcing amplitude marking breakdown of weakly nonlinear regime, coinciding with onset of secondary instability.

Conclusion: The framework provides a mechanistically transparent and computationally efficient description of transition that unifies non-modal amplification, streak formation, and modal instability within a single formulation derived from Navier-Stokes equations.

Abstract: We develop a perturbation-based frequency-response framework for analyzing amplification mechanisms that are central to subcritical routes to transition in wall-bounded shear flows. By systematically expanding the input-output dynamics of fluctuations about the laminar base flow with respect to forcing amplitude, we establish a rigorous correspondence between linear resolvent analysis and higher-order nonlinear interactions. At second order, quadratic interactions of unsteady oblique waves generate steady streamwise streaks via the lift-up mechanism. We demonstrate that the spatial structure of these streaks is captured by the second output singular function of the streamwise-constant resolvent operator. At higher orders, nonlinear coupling between oblique waves and induced streaks acts as structured forcing of the laminar linearized dynamics, yielding additional streak components whose relative phase governs reinforcement or attenuation of the leading-order streak response. Our analysis identifies a critical forcing amplitude marking the breakdown of the weakly nonlinear regime, beyond which direct numerical simulations exhibit sustained unsteadiness. We show that this breakdown coincides with the onset of secondary instability, revealing that the nonlinear interactions responsible for streak formation also drive the modal growth central to classical transition theory. The resulting framework provides a mechanistically transparent and computationally efficient description of transition that unifies non-modal amplification, streak formation, and modal instability within a single formulation derived directly from the Navier-Stokes equations.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [56] [The Unruh state for bosonic Teukolsky fields on subextreme Kerr spacetimes](https://arxiv.org/abs/2602.09796)
*Dietrich Häfner,Christiane K. M. Klein*

Main category: math-ph

TL;DR: Quantization of Teukolsky scalars (spin 0, ±1, ±2) using algebraic QFT approach, constructing Unruh state on Kerr spacetime that is Hadamard up to inner horizon.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous quantization framework for Teukolsky fields on Kerr spacetime and demonstrate existence of Hadamard states, particularly extending the Unruh state construction to bosonic Teukolsky fields where such results were previously lacking.

Method: Algebraic approach to quantum field theory: first analyzing classical phase space, constructing corresponding algebra to identify conjugate fields, then constructing Unruh state specifically for Kerr spacetime.

Result: Successfully constructed Unruh state for Teukolsky theory on Kerr that is Hadamard on both black hole exterior and interior up to the inner horizon, proving existence of Hadamard states for this theory.

Conclusion: The work provides rigorous quantization of Teukolsky fields on Kerr spacetime and extends existence of Hadamard Unruh state to bosonic Teukolsky fields, filling previous gap in literature.

Abstract: We perform the quantization of Teukolsky scalars of spin $0$, $\pm 1$, and $\pm 2$ within the algebraic approach to quantum field theory. We first discuss the classical phase space, from which we subsequently construct the algebra. This sheds light on which fields are conjugates of each other. Further, we construct the Unruh state for this theory on Kerr and show that it is Hadamard on the black hole exterior and the interior up to the inner horizon. This shows not only that Hadamard states exist for this theory, but also extends the existence and Hadamard property of the Unruh state to (bosonic) Teukolsky fields on Kerr, where such a result was previously missing.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [57] [Long-Range Machine Learning of Electron Density for Twisted Bilayer Moiré Materials](https://arxiv.org/abs/2602.09938)
*Zekun Lou,Alan M. Lewis,Mariana Rossi*

Main category: cond-mat.mtrl-sci

TL;DR: Machine learning model trained on small bilayer structures predicts electron densities for large moiré superlattices, enabling accurate electronic property calculations without full DFT.


<details>
  <summary>Details</summary>
Motivation: Ab initio modeling of moiré superlattices is computationally prohibitive, and existing machine learning methods often rely on locality assumptions that may not capture long-range effects in these systems.

Method: Train Gaussian process regression SALTED model on electron densities of small displaced bilayer structures, then extrapolate to predict densities for large supercells representing small twist angles. Use long-range descriptors to capture non-local geometric information.

Result: Long-range descriptors are necessary for reliable band structures and electrostatic properties. The choice of descriptor affects residual density error distribution and downstream electronic properties. Successfully applied to twisted bilayer graphene, hBN, and TMDs, predicting flat bands, bandwidth narrowing, domain-wall electric fields, and spin-orbit coupling effects.

Conclusion: This approach provides a general methodology for electronic structure prediction in large-scale systems with substantial long-range phenomena, extending beyond moiré materials to systems with non-local geometric information.

Abstract: Moiré superlattices in two-dimensional (2D) materials exhibit rich quantum phenomena, but ab initio modelling of these systems remains computationally prohibitive. Existing machine learning methods for accelerating density-functional theory (DFT) can target the prediction of different quantities and often rely on the locality assumption. Here we train a Gaussian process regression SALTED model exclusively on the electron densities of small displaced bilayer structures and then extrapolate electron density prediction to the large supercells required to describe small twist angles between these bilayers. We show the necessity of long-range descriptors to yield reliable band structures and electrostatic properties of large twisted bilayer structures, when these are derived from predicted densities. We demonstrate that the choice of descriptor determines the distribution of residual density errors, which in turn affects the downstream electronic properties. We apply our models to twisted bilayer graphene, hexagonal boron nitride, and transition metal dichalcogenides, focusing on the model's capacity to predict complex phenomena, including flat band formation, bandwidth narrowing, domain-wall electric fields, and spin-orbit coupling effects. Beyond moiré materials, this approach provides a general methodology for electronic structure prediction in large-scale systems with substantial long-range phenomena related to non-local geometric information.

</details>


### [58] [Fixed-grid sharp-interface numerical solutions to the three-phase spherical Stefan problem](https://arxiv.org/abs/2602.09077)
*Yavkreet Swami,Jacob Barajas,Amneet Pal Singh Bhalla*

Main category: cond-mat.mtrl-sci

TL;DR: This paper develops a numerical solution for the three-phase Stefan problem in spherical coordinates for finite-sized particles, addressing simultaneous melting, solidification, boiling, and condensation with density-change effects.


<details>
  <summary>Details</summary>
Motivation: Traditional Stefan problems neglect density-change effects and typically handle only two phases. Real metal manufacturing involves multiple simultaneous phase changes (melting, boiling, vaporization) with density variations, especially important for nanoparticle applications.

Method: Fixed-grid sharp-interface method with second-order spatio-temporal accuracy, using small-time analytical solution for initial temperature and interface predictions. Validated against existing two-phase nanoparticle melting results.

Result: Successfully solved three-phase Stefan problems numerically, showing kinetic energy terms are crucial for nanoparticle phase change but diminish for larger (micron+) particles.

Conclusion: The developed method effectively handles complex three-phase Stefan problems in spherical coordinates, revealing important size-dependent effects where kinetic energy terms significantly impact nanoparticle phase change behavior.

Abstract: Many metal manufacturing processes involve phase change phenomena, which include melting, boiling, and vaporization. These phenomena often occur concurrently. A prototypical 1D model for understanding the phase change phenomena is the Stefan problem. There is a large body of literature discussing the analytical solution to the two-phase Stefan problem that describes only the melting or boiling of phase change materials (PCMs) with one moving interface. Density-change effects that induce additional fluid flow during phase change are generally neglected in the literature to simplify the math of the Stefan problem. In our recent work [1], we provide analytical and numerical solutions to the three-phase Stefan problem with simultaneous occurrences of melting, solidification, boiling, and condensation in Cartesian coordinates. Our current work builds on our previous work to solve a more challenging problem: the three-phase Stefan problem in spherical coordinates for finite-sized particles. There are three moving interfaces in this system: the melt front, the boiling front, and the outer boundary which is in contact with the atmosphere. Although an analytical solution could not be found for this problem, we solved the governing equations using a fixed-grid sharp-interface method with second-order spatio-temporal accuracy. Using a small-time analytical solution, we predict a reasonably accurate estimate of temperature (in the three phases) and interface positions and velocities at the start of the simulation. Our numerical method is validated by reproducing the two-phase nanoparticle melting results of Font et al. [2]. Lastly, we solve the three-phase Stefan problems numerically to demonstrate the importance of kinetic energy terms during phase change of smaller (nano) particles. In contrast, these effects diminish for large particles (microns and larger).

</details>


### [59] [PySlice: Routine Vibrational Electron Energy Loss Spectroscopy Prediction with Universal Interatomic Potentials](https://arxiv.org/abs/2602.10064)
*Harrison A. Walker,Thomas W. Pfeifer,Paul M. Zeiger,Jordan A. Hachtel,Sokrates T. Pantelides,Eric R. Hoglund*

Main category: cond-mat.mtrl-sci

TL;DR: PySlice is the first public implementation of TACAW method for automated prediction of vibrational electron energy-loss spectra from atomic structures, integrating machine learning potentials to eliminate per-system development bottlenecks.


<details>
  <summary>Details</summary>
Motivation: Current vibrational spectroscopy prediction in electron microscopy requires fragmented workflows and specialized expertise, making routine prediction inaccessible despite its potential for nanometer spatial resolution phonon analysis.

Method: PySlice implements Time Autocorrelation of Auxiliary Wavefunction (TACAW) method, integrating universal machine learning interatomic potentials to automate workflow from atomic structures to momentum- and energy-resolved vibrational spectra through molecular dynamics, GPU-accelerated electron scattering, and frequency-domain analysis.

Result: PySlice provides a unified workflow that produces phonon dispersions, spectral diffraction patterns, and spectrum images directly from atomic structures, demonstrated on canonical materials science systems, while also supporting conventional electron microscopy simulations.

Conclusion: PySlice makes vibrational spectroscopy prediction routine rather than specialized, enabling computational screening for experimental design, systematic exploration of phonon physics, and high-throughput generation of simulated data for training machine learning models.

Abstract: Vibrational spectroscopy in the electron microscope can reveal phonon excitations with nanometer spatial resolution, yet routine prediction remains out of reach due to fragmented workflows requiring specialized expertise. Here we introduce PySlice, the first publicly available implementation of the Time Autocorrelation of Auxiliary Wavefunction (TACAW) method, providing an automated framework that produces momentum- and energy-resolved vibrational electron energy-loss spectra directly from atomic structures. By integrating universal machine learning interatomic potentials with TACAW, PySlice eliminates the bottleneck of per-system potential development. Users input atomic structures and obtain phonon dispersions, spectral diffraction patterns, and spectrum images through a unified workflow spanning molecular dynamics, GPU-accelerated electron scattering, and frequency-domain analysis. We outline the formulation behind the code, demonstrate its application to canonical systems in materials science, and discuss its use for advanced analysis and materials exploration. The modular Python architecture additionally supports conventional electron microscopy simulations, providing a general-purpose platform for imaging and diffraction calculations. PySlice makes vibrational spectroscopy prediction routine rather than specialized, enabling computational screening for experimental design, systematic exploration of phonon physics across materials families, and high-throughput generation of simulated data for training of future machine learning models.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [60] [Stability and Concentration in Nonlinear Inverse Problems with Block-Structured Parameters: Lipschitz Geometry, Identifiability, and an Application to Gaussian Splatting](https://arxiv.org/abs/2602.09415)
*Joe-Mei Feng,Hsin-Hsiung Kao*

Main category: cs.CV

TL;DR: Operator-theoretic framework for stability and concentration in nonlinear inverse problems with block-structured parameters, yielding algorithm-independent error bounds and demonstrating a stability-resolution tradeoff.


<details>
  <summary>Details</summary>
Motivation: To develop a unified theoretical framework for analyzing stability and statistical concentration in high-dimensional nonlinear inverse problems with block-structured parameters, which are common in modern imaging and differentiable rendering applications.

Method: Develops an operator-theoretic framework combining blockwise Lipschitz geometry, local identifiability, and sub-Gaussian noise assumptions. Establishes deterministic stability inequalities, global Lipschitz bounds for least-squares misfit functionals, and nonasymptotic concentration estimates.

Result: Derives high-probability parameter error bounds intrinsic to the forward operator (algorithm-independent). Verifies that Gaussian Splatting rendering operator satisfies the assumptions and obtains explicit constants for Lipschitz continuity and resolution-dependent observability. Reveals a fundamental stability-resolution tradeoff where estimation error is constrained by the ratio between image resolution and model complexity.

Conclusion: The analysis characterizes operator-level limits for a broad class of high-dimensional nonlinear inverse problems in modern imaging and differentiable rendering, providing fundamental theoretical understanding of stability and concentration properties independent of specific reconstruction algorithms.

Abstract: We develop an operator-theoretic framework for stability and statistical concentration in nonlinear inverse problems with block-structured parameters. Under a unified set of assumptions combining blockwise Lipschitz geometry, local identifiability, and sub-Gaussian noise, we establish deterministic stability inequalities, global Lipschitz bounds for least-squares misfit functionals, and nonasymptotic concentration estimates. These results yield high-probability parameter error bounds that are intrinsic to the forward operator and independent of any specific reconstruction algorithm. As a concrete instantiation, we verify that the Gaussian Splatting rendering operator satisfies the proposed assumptions and derive explicit constants governing its Lipschitz continuity and resolution-dependent observability. This leads to a fundamental stability--resolution tradeoff, showing that estimation error is inherently constrained by the ratio between image resolution and model complexity. Overall, the analysis characterizes operator-level limits for a broad class of high-dimensional nonlinear inverse problems arising in modern imaging and differentiable rendering.

</details>


### [61] [Allure of Craquelure: A Variational-Generative Approach to Crack Detection in Paintings](https://arxiv.org/abs/2602.09730)
*Laura Paul,Holger Rauhut,Martin Burger,Samira Kabri,Tim Roith*

Main category: cs.CV

TL;DR: A hybrid approach combining deep generative models with variational methods for automated crack detection in digitized paintings, addressing challenges from complex scenery and crack-like artistic features.


<details>
  <summary>Details</summary>
Motivation: Automated detection of craquelure (cracks) in digitized paintings is crucial for assessing degradation and guiding restoration, but remains challenging due to complex scenery and visual similarity between cracks and crack-like artistic features like brush strokes or hair.

Method: Models crack detection as an inverse problem, decomposing an observed image into crack-free painting and crack components. Uses a deep generative model as prior for the underlying artwork, and a Mumford-Shah-type variational functional with crack prior to capture crack structures. Joint optimization yields pixel-level crack localization maps.

Result: The approach enables automated, pixel-level detection of cracks in digitized paintings by separating them from artistic features, supporting artwork documentation and conservation.

Conclusion: The hybrid approach combining deep learning with variational methods effectively addresses the challenge of crack detection in paintings by leveraging complementary strengths of both techniques for accurate crack localization.

Abstract: Recent advances in imaging technologies, deep learning and numerical performance have enabled non-invasive detailed analysis of artworks, supporting their documentation and conservation. In particular, automated detection of craquelure in digitized paintings is crucial for assessing degradation and guiding restoration, yet remains challenging due to the possibly complex scenery and the visual similarity between cracks and crack-like artistic features such as brush strokes or hair. We propose a hybrid approach that models crack detection as an inverse problem, decomposing an observed image into a crack-free painting and a crack component. A deep generative model is employed as powerful prior for the underlying artwork, while crack structures are captured using a Mumford--Shah-type variational functional together with a crack prior. Joint optimization yields a pixel-level map of crack localizations in the painting.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [62] [Optical Signatures of a Schwarzschild Black Hole in a Dehnen-Type Dark Matter Halo](https://arxiv.org/abs/2602.09168)
*Javokhir Sharipov,Jonibek Khasanov,Pankaj Sheoran,Sanjar Shaymatov,Bobomurat Ahmedov*

Main category: gr-qc

TL;DR: Study explores optical effects near Schwarzschild-like black holes with Dehnen-type dark matter halos, analyzing photon spheres, deflection angles, shadows, and gravitational lensing in plasma media.


<details>
  <summary>Details</summary>
Motivation: To understand how dark matter halo properties and plasma characteristics jointly influence observable optical phenomena around black holes, including gravitational lensing signatures and shadow formation.

Method: 1) Derive photon sphere radius and analytical deflection angle in weak-field regime using Gauss-Bonnet theorem; 2) Perform ray-tracing calculations for strong-field regime to examine light trajectories and orbit numbers; 3) Compute black hole shadow and gravitational lensing in plasma medium; 4) Extend analysis to weak gravitational lensing in plasma environments with uniform and singular isothermal sphere distributions.

Result: Obtained analytical expressions for deflection angles in both weak-field regime and plasma presence, examined how dark matter halo parameters and plasma characteristics alter lensing signatures, and provided constraints from dark matter halo parameters.

Conclusion: Dark matter halo properties and plasma characteristics significantly modify observable optical effects around black holes, jointly altering gravitational lensing signatures and providing important constraints for astrophysical observations.

Abstract: In this paper, the optical effects that occur near a Schwarzschild-like black hole (BH) with a Dehnen-type $(1,4,2)$ dark matter (DM) halo are explored. We first derive the photon sphere radius and obtain an analytical expression for the deflection angle in the weak-field regime by applying the Gauss-Bonnet theorem (GBT). For the strong-field regime, we perform ray-tracing calculations to examine the behavior of light trajectories and determine the corresponding number of orbits. We further compute the BH shadow and gravitational lensing in a plasma medium and provide constraints arising from the DM halo parameters. We also extend our analysis to weak gravitational lensing within plasma environments, considering both uniform and singular isothermal sphere (SIS) distributions. We find the analytical expressions for the deflection angle in the presence of plasma and examine the resulting effects on image magnification. The overall results highlight how DM halo properties and plasma characteristics jointly alter observable lensing signatures.

</details>
