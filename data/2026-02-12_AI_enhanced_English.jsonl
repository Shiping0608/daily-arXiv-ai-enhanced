{"id": "2602.10247", "pdf": "https://arxiv.org/pdf/2602.10247", "abs": "https://arxiv.org/abs/2602.10247", "authors": ["Daniela Calvetti", "Erkki Somersalo"], "title": "Discretization-free Bayesian inverse problems in distribution spaces", "categories": ["math.NA"], "comment": null, "summary": "The Bayesian approach to inverse problems provides a practical way to solve ill-posed problems by augmenting the observation model with prior information. Due to the measure-theoretic underpinnings, the approach has raised theoretical interest, leading to a rather comprehensive description in infinite-dimensional function spaces. The goal of this article is to bridge the infinite-dimensional theory for linear inverse problems in distribution spaces and associated computational inverse problems without resorting to a discrete approximation of the forward model. We will shown that under certain assumptions, discretization of the unknown of interest is not necessary for the numerical treatment of the problem, the only approximations required being numerical quadratures that are independent of any discrete representation of the unknown. An analysis of the connection between the proposed approach and discretization-based ones is also provided.", "AI": {"tldr": "Bridging infinite-dimensional Bayesian inverse problems theory with computational implementation without discretizing the unknown, using only numerical quadratures independent of discrete representation.", "motivation": "To connect infinite-dimensional theory for linear inverse problems in distribution spaces with practical computational implementation without requiring discrete approximation of the forward model or unknown.", "method": "Proposes an approach that avoids discretization of the unknown, requiring only numerical quadratures that are independent of any discrete representation of the unknown, and analyzes connection with discretization-based methods.", "result": "Shows that under certain assumptions, discretization of the unknown is unnecessary for numerical treatment; only independent numerical quadratures are needed.", "conclusion": "Provides a bridge between infinite-dimensional Bayesian inverse problems theory and computational practice without resorting to discrete approximations of the forward model or unknown."}}
{"id": "2602.10248", "pdf": "https://arxiv.org/pdf/2602.10248", "abs": "https://arxiv.org/abs/2602.10248", "authors": ["Jiawen Lyu", "Maria Han Veiga"], "title": "Low-rank approximation of Rippa method for RBF interpolation", "categories": ["math.NA"], "comment": "19 pages, 20 figures", "summary": "We study the problem of selecting the shape parameter in Radial Basis function (RBF) interpolation using leave-one-out-cross-validation (LOOCV). Since the classical LOOCV formula requires repeated solves with a dense $N \\times N$ kernel matrix, we combine a Nystr\u00f6m approximation with the Woodbury identity to obtain an efficient surrogate objective that avoids large matrix inversions. Based on this reduced form, we compare a grid-based search with a gradient descent strategy and examine their behavior across different dimensions. Numerical experiments are performed in 1D, 2D, and 3D using the Inverse Multiquadratic RBF to illustrate the computational advantages of the approximation as well as the situations in which it may introduce additional sensitivity. These results show that the proposed acceleration makes LOOCV-based parameter tuning practical for larger datasets while preserving the qualitative behavior of the full method.", "AI": {"tldr": "Efficient LOOCV for RBF shape parameter selection using Nystr\u00f6m approximation and Woodbury identity to avoid expensive matrix inversions.", "motivation": "Traditional LOOCV for RBF interpolation requires repeated solves with dense N\u00d7N kernel matrices, which is computationally expensive for larger datasets.", "method": "Combine Nystr\u00f6m approximation with Woodbury identity to create efficient surrogate objective function, then compare grid-based search and gradient descent strategies across different dimensions.", "result": "Numerical experiments in 1D, 2D, and 3D show computational advantages while preserving qualitative behavior of full method, though approximation may introduce additional sensitivity in some cases.", "conclusion": "Proposed acceleration makes LOOCV-based parameter tuning practical for larger datasets while maintaining accuracy of full method."}}
{"id": "2602.10268", "pdf": "https://arxiv.org/pdf/2602.10268", "abs": "https://arxiv.org/abs/2602.10268", "authors": ["Haifeng Wang", "Xiaoming Wang", "Min Zhang"], "title": "Unconditionally Long-Time Stable Variable-Step Second-Order Exponential Time-Differencing Schemes for the Incompressible NSE", "categories": ["math.NA"], "comment": null, "summary": "We develop an efficient, unconditionally stable, variable step second order exponential time differencing scheme for the incompressible Navier Stokes equations in two and three spatial dimensions under periodic boundary conditions, together with an embedded adaptive time stepping variant. The scheme is unconditionally uniform in time stable in the sense that the numerical solution admits a time uniform bound in Linfinity over time with values in L2 to the power d whenever the external forcing term is uniformly bounded in time in L2, for all Reynolds numbers and for arbitrary choices of time step sizes.\n  At each time step, the method requires the solution of two time dependent Stokes problems, which can be evaluated explicitly in the periodic setting using Fourier techniques, along with the solution of a single scalar cubic algebraic equation. Beyond the standard exponential time differencing framework, the proposed scheme incorporates two recently developed ingredients. The first is a dynamic second order scalar auxiliary variable correction, which is essential for achieving second order temporal accuracy. The second is a mean reverting scalar auxiliary variable multistep formulation, which plays a central role in ensuring long time stability.\n  The proposed methods overcome key limitations of existing approaches for the Navier Stokes equations. Classical Runge Kutta schemes generally lack provable long time stability, while IMEX and scalar auxiliary variable based BDF methods typically do not admit unconditional stability guarantees in the variable step setting. Numerical experiments in two spatial dimensions confirm second order temporal accuracy, uniform long time stability, and effective error control provided by the adaptive strategy. Rigorous convergence analysis and a systematic investigation of long time statistical properties will be pursued in future work.", "AI": {"tldr": "A second-order exponential time differencing scheme for incompressible Navier-Stokes equations with unconditional stability and adaptive time stepping.", "motivation": "Existing methods for Navier-Stokes equations have limitations: classical Runge-Kutta lacks provable long-time stability, while IMEX and scalar auxiliary variable BDF methods don't guarantee unconditional stability with variable time steps.", "method": "Unconditionally stable variable-step second-order exponential time differencing scheme with two key innovations: dynamic second-order scalar auxiliary variable correction for temporal accuracy, and mean-reverting scalar auxiliary variable multistep formulation for long-time stability.", "result": "Numerical experiments in 2D confirm second-order temporal accuracy, uniform long-time stability, and effective error control with adaptive strategy. The method requires solving two time-dependent Stokes problems and one scalar cubic equation per time step.", "conclusion": "The proposed method overcomes key limitations of existing approaches, providing unconditional stability for all Reynolds numbers and arbitrary time steps. Future work will include rigorous convergence analysis and investigation of long-time statistical properties."}}
{"id": "2602.10335", "pdf": "https://arxiv.org/pdf/2602.10335", "abs": "https://arxiv.org/abs/2602.10335", "authors": ["Shalmali Bandyopadhyay", "F. Ay\u00e7a \u00c7etinkaya", "Tom Cuchta"], "title": "Nonlinear elliptic Dirichlet boundary value problems on time scales", "categories": ["math.AP", "math.SP"], "comment": null, "summary": "We establish existence and uniqueness results for nonlinear elliptic Dirichlet boundary value problems on n-dimensional time scale domains. Time scales provide a unified framework that encompasses continuous, discrete, and hybrid settings. Under a Lipschitz condition on the nonlinearity bounded by the first eigenvalue, we prove existence and uniqueness using the contraction mapping theorem. Under a weaker one-sided growth condition, we establish existence using the Leray--Schauder fixed point theorem. To apply these functional analytic methods, we reformulate the problem as an operator equation, which requires developing the spectral theory for the Dirichlet Laplacian with mixed nabla-delta derivatives. We establish self-adjointness, positivity, and completeness of eigenfunctions, and the product eigenfunctions form a complete orthonormal basis in the n-dimensional setting.", "AI": {"tldr": "Existence and uniqueness results for nonlinear elliptic Dirichlet problems on n-dimensional time scale domains using functional analytic methods.", "motivation": "To develop a unified framework for solving nonlinear elliptic Dirichlet boundary value problems that works across continuous, discrete, and hybrid settings using time scales theory.", "method": "1. Reformulate the problem as an operator equation; 2. Develop spectral theory for Dirichlet Laplacian with mixed nabla-delta derivatives; 3. Prove existence/uniqueness under Lipschitz condition using contraction mapping theorem; 4. Prove existence under weaker one-sided growth condition using Leray-Schauder fixed point theorem.", "result": "1. Established self-adjointness, positivity, and completeness of eigenfunctions for the Dirichlet Laplacian; 2. Product eigenfunctions form a complete orthonormal basis in n-dimensional setting; 3. Proved existence and uniqueness under Lipschitz condition; 4. Proved existence under weaker one-sided growth condition.", "conclusion": "Successfully developed a unified framework for nonlinear elliptic Dirichlet problems on time scale domains with rigorous existence and uniqueness results using functional analytic methods and spectral theory."}}
{"id": "2602.10277", "pdf": "https://arxiv.org/pdf/2602.10277", "abs": "https://arxiv.org/abs/2602.10277", "authors": ["Randy Bartels", "Olivier Pinaud"], "title": "Blind source separation for imaging", "categories": ["math.NA", "physics.optics"], "comment": null, "summary": "This work is concerned with the problem of blind source separation and its applications to imaging. We first establish a theoretical result that we stated in our previous article on imaging in diffusive environments. This result is a generalization of separability criteria found in the literature to arbitrary correlated complex-valued sources with additive noise. In a second step, we verify these separability conditions in two propagation regimes frequently encountered in imaging: the speckle regime and the random geometrical optics regime. Finally, we propose a new imaging method based on the blind source separation problem that improves on images obtained with the classical decomposition of the time reversal operator method.", "AI": {"tldr": "The paper establishes theoretical separability criteria for blind source separation of correlated complex-valued sources with noise, verifies them in speckle and random geometrical optics regimes, and proposes an improved imaging method based on BSS.", "motivation": "To address blind source separation problems in imaging applications, particularly in diffusive environments, by establishing theoretical foundations and developing practical imaging methods.", "method": "1) Theoretical generalization of separability criteria to arbitrary correlated complex-valued sources with additive noise; 2) Verification of separability conditions in speckle and random geometrical optics propagation regimes; 3) Development of new imaging method based on blind source separation.", "result": "Established theoretical separability criteria for complex-valued correlated sources, verified these conditions in two important imaging propagation regimes, and demonstrated improved imaging performance compared to classical time reversal operator decomposition methods.", "conclusion": "Blind source separation provides a solid theoretical framework for imaging in diffusive environments, with practical applications in speckle and random geometrical optics regimes, offering improved image quality over conventional methods."}}
{"id": "2602.10463", "pdf": "https://arxiv.org/pdf/2602.10463", "abs": "https://arxiv.org/abs/2602.10463", "authors": ["Abdelrazek Dieb", "Remi Yvant Temgoua"], "title": "Fractional Hardy inequalities on $C^{1,1}$ open sets", "categories": ["math.AP"], "comment": null, "summary": "Let $\u03a9$ be a bounded open set of class $C^{1,1}$ in $\\mathbb{R}^N$ and $s\\in(\\frac{1}{2}, 1)$. We study a family of fractional Hardy-type inequalities \\begin{equation} \\frac{c_{N,s}}{2}\\displaystyle\\iint_{\u03a9\\times\u03a9}\\frac{(u(x)-u(y))^2}{|x-y|^{N+2s}}\\ dxdy-\\displaystyle\u03bb\\int_\u03a9u^2\\ dx\\geq C\\displaystyle\\int_\u03a9\\frac{u^2}{\u03b4^{2s}}\\ dx,~~~\\quad\\forall\u03bb\\in\\mathbb{R},~~~~~~~(0.1) \\end{equation} with $u\\in C_c^\\infty(\u03a9)$ and $C=C(\u03a9,s,N,\u03bb)>0$. We show that the best constant in $(0.1)$ is achieved if and only if $\u03bb>\u03bb^*(s,\u03a9)$, for some $\u03bb^*(s,\u03a9)\\in\\mathbb{R}$. As a by-product, we derive in particular that the best constant in Hardy inequality $\u03bc_{N,s}(\u03a9)$ is achieved if and only if $\u03bc_{N,s}(\u03a9)<\\mathfrak{h}_{N,s}$, with $\\mathfrak{h}_{N,s}$ being the best constant for the fractional Hardy inequality in the half space. Moreover, if $\u03a9$ is a convex open set, we obtain a lower bound for $\u03bb^*(s,\u03a9)$ in terms of the volume of $\u03a9$. Specifically, we prove that $\u03bb^*(s,\u03a9)\\geq a(N,s)|\u03a9|^{-\\frac{2s}{N}}$ with an explicit constant $a(N,s)>0$. For general bounded $C^{1,1}$ open sets, we prove instead that $\u03bb^*(s,\u03a9)\\geq0$ when $s$ is close to $\\frac{1}{2}$. The aforementioned result is proved after showing that $\u03bc_{N,s}(\u03a9)=\\mathfrak{h}_{N,s}$ for $s$ close to $\\frac{1}{2}$. In particular, we deduce that, whenever $s$ is sufficiently close to $\\frac{1}{2}$, the Hardy constant $\u03bc_{N,s}(\u03a9)$ is never achieved, hence, behaves differently from that in the local case. This result is completely new in the fractional setting, and was known only for convex open sets for the full range $s\\in(\\frac{1}{2}, 1)$.", "AI": {"tldr": "This paper studies fractional Hardy-type inequalities on bounded domains, establishing conditions for achieving best constants and deriving lower bounds for critical parameters.", "motivation": "To understand when fractional Hardy-type inequalities achieve their best constants, particularly comparing behavior to local cases and establishing connections between domain geometry and critical parameters.", "method": "Analyzes fractional Hardy inequalities using variational methods, studies the best constant problem, establishes connections between domain properties and critical parameters \u03bb*(s,\u03a9), and derives lower bounds for convex and general domains.", "result": "Shows best constant is achieved iff \u03bb > \u03bb*(s,\u03a9); for convex domains, \u03bb*(s,\u03a9) \u2265 a(N,s)|\u03a9|^{-2s/N}; for general domains near s=1/2, \u03bb*(s,\u03a9) \u2265 0 and \u03bc_{N,s}(\u03a9) = \ud835\udd25_{N,s} (not achieved), revealing different behavior from local case.", "conclusion": "Fractional Hardy inequalities behave differently from local cases, with achievement of best constants depending on domain geometry and parameter ranges, particularly showing non-achievement near s=1/2 for general domains."}}
{"id": "2602.10132", "pdf": "https://arxiv.org/pdf/2602.10132", "abs": "https://arxiv.org/abs/2602.10132", "authors": ["C\u00e9cile Rousseau", "Samuel Jackson", "Rodrigo H. Ordonez-Hurtado", "Nicola C. Amorisco", "Tobia Boschi", "George K. Holt", "Andrea Loreti", "Eszter Sz\u00e9kely", "Alexander Whittle", "Adriano Agnello", "Stanislas Pamela", "Alessandra Pascale", "Robert Akers", "Juan Bernabe Moreno", "Sue Thorne", "Mykhaylo Zayats"], "title": "TokaMark: A Comprehensive Benchmark for MAST Tokamak Plasma Models", "categories": ["physics.plasm-ph", "cs.AI"], "comment": null, "summary": "Development and operation of commercially viable fusion energy reactors such as tokamaks require accurate predictions of plasma dynamics from sparse, noisy, and incomplete sensors readings. The complexity of the underlying physics and the heterogeneity of experimental data pose formidable challenges for conventional numerical methods, while simultaneously highlights the promise of modern data-native AI approaches. A major obstacle in realizing this potential is, however, the lack of curated, openly available datasets and standardized benchmarks. Existing fusion datasets are scarce, fragmented across institutions, facility-specific, and inconsistently annotated, which limits reproducibility and prevents a fair and scalable comparison of AI approaches. In this paper, we introduce TokaMark, a structured benchmark to evaluate AI models on real experimental data collected from the Mega Ampere Spherical Tokamak (MAST). TokaMark provides a comprehensive suite of tools designed to (i) unify access to multi-modal heterogeneous fusion data (ii) harmonize formats, metadata, temporal alignment and evaluation protocols to enable consistent cross-model and cross-task comparisons. The benchmark includes a curated list of 14 tasks spanning a range of physical mechanisms, exploiting a variety of diagnostics and covering multiple target use cases. A baseline model is provided to facilitate transparent comparison and validation within a unified framework. By establishing a unified benchmark for both the fusion and AI-for-science communities, TokaMark aims to accelerate progress in data-driven plasma AI modeling, contributing to the broader goal of achieving sustainable and stable fusion energy. The benchmark, documentation, and tooling will be fully open sourced upon acceptance to encourage community adoption and contribution.", "AI": {"tldr": "TokaMark is an open-source benchmark for AI models on real fusion plasma data from MAST tokamak, providing standardized tasks and tools for reproducible evaluation.", "motivation": "Fusion energy development needs accurate plasma predictions from sparse sensor data, but lacks curated datasets and standardized benchmarks. Existing fusion data is fragmented, facility-specific, and inconsistently annotated, limiting reproducibility and fair AI model comparisons.", "method": "Introduces TokaMark benchmark with: (1) unified access to multi-modal heterogeneous fusion data, (2) harmonized formats, metadata, temporal alignment and evaluation protocols, (3) 14 curated tasks covering various physical mechanisms and diagnostics, (4) baseline model for transparent comparison.", "result": "Provides a comprehensive benchmark suite for evaluating AI models on real experimental data from MAST tokamak, enabling consistent cross-model and cross-task comparisons in fusion plasma AI research.", "conclusion": "TokaMark aims to accelerate data-driven plasma AI modeling by establishing a unified benchmark for both fusion and AI-for-science communities, contributing to sustainable fusion energy development. The benchmark will be fully open-sourced upon acceptance."}}
{"id": "2602.10301", "pdf": "https://arxiv.org/pdf/2602.10301", "abs": "https://arxiv.org/abs/2602.10301", "authors": ["Alaa Ahmed"], "title": "Impact of Separation Distance on the Performance and Annual Energy Production of a Dual-Flap Oscillating Surge Wave Energy Converter", "categories": ["math.NA", "physics.flu-dyn"], "comment": null, "summary": "Among the different concepts for wave energy conversion, oscillating surge wave energy converters have been shown to have a high capture width ratio. The primary wave capture structure consists of a flap hinged at the seabed or to a floating platform. Different flap configurations, including single and dual-flap, have been investigated. The separation distance between the oscillating surge wave energy converters can have an impact on their response when deployed in arrays. We consider the case of a dual-flap oscillating surge wave energy converter and investigate the impact of the separation distance between them on the performance of each flap. We estimate the absorbed wave energy and the annual energy production by the two flaps when deployed at the PacWave South site. Inviscid numerical simulations were conducted to predict the response of the oscillating surge wave energy converters. The simulations are validated with experimental measurements of a 1:10 scaled model in a wave tank. The results show that for a short separation distance, the interaction between the oscillating surge wave energy converters has a destructive and constructive effect depending on the wave frequency. However, these effects tend to balance each other out when considering the broad range of wave excitations. For longer separation distances, the interaction always results in a constructive effect. The results reveal that the separation distance has an insignificant impact on annual energy production when considering all wave frequencies and amplitudes.", "AI": {"tldr": "Study shows separation distance between dual-flap oscillating surge wave energy converters has minimal impact on annual energy production at PacWave South site.", "motivation": "To investigate how separation distance between dual-flap oscillating surge wave energy converters affects their performance and energy production in array deployments.", "method": "Used inviscid numerical simulations validated with experimental measurements of a 1:10 scaled model in a wave tank to analyze dual-flap oscillating surge wave energy converters at PacWave South site.", "result": "Short separation distances cause both destructive and constructive interference depending on wave frequency, but effects balance out. Longer distances always produce constructive effects. Overall, separation distance has insignificant impact on annual energy production.", "conclusion": "Separation distance between dual-flap oscillating surge wave energy converters has minimal effect on annual energy production when considering the full spectrum of wave conditions, suggesting flexibility in array spacing design."}}
{"id": "2602.10509", "pdf": "https://arxiv.org/pdf/2602.10509", "abs": "https://arxiv.org/abs/2602.10509", "authors": ["Fuping Zhang", "Ruijun Wu"], "title": "Stationary periodic solutions to Nonlinear Dirac equations with non-coercive potentials", "categories": ["math.AP"], "comment": "nonlinear Dirac equation, periodic solution, stationary solution, linking, perturbation", "summary": "We obtain periodic solutions for nonlinear Dirac equations with a nonlinear term that is not necessarily coercive.\n  This amounts to study the equation on a three-dimensional torus.\n  The Palais-Smale condition is enhanced by involving a coercive perturbation.\n  Uniform estimates for the critical levels as well as the Sobolev norms for the perturbed solutions are obtained, making it possible to pass to a limit which gives a nontrivial solution.", "AI": {"tldr": "Periodic solutions for nonlinear Dirac equations with non-coercive nonlinearity on 3D torus using coercive perturbation to enhance Palais-Smale condition.", "motivation": "To obtain periodic solutions for nonlinear Dirac equations where the nonlinear term lacks coercivity, which is a challenging mathematical problem requiring specialized techniques.", "method": "Study the equation on a three-dimensional torus, enhance Palais-Smale condition using coercive perturbation, obtain uniform estimates for critical levels and Sobolev norms of perturbed solutions, then pass to limit.", "result": "Successfully obtain nontrivial periodic solutions for nonlinear Dirac equations with non-coercive nonlinearity through the perturbation and limiting process.", "conclusion": "The coercive perturbation technique combined with careful estimates enables existence of periodic solutions for nonlinear Dirac equations even when the nonlinear term is not coercive."}}
{"id": "2602.10447", "pdf": "https://arxiv.org/pdf/2602.10447", "abs": "https://arxiv.org/abs/2602.10447", "authors": ["X. Liu", "D. Wu", "J. Zhang"], "title": "Bridging the Kinetic-Fluid Gap: Ion-Driven Magnetogenesis to Prime Cosmic Dynamos", "categories": ["physics.plasm-ph", "astro-ph.GA"], "comment": null, "summary": "The origin of cosmic magnetic fields is widely attributed to the amplification of weak seed fields by turbulent dynamos. However, a critical understanding gap remains between the microscopic generation of these seeds and the macroscopic onset of the dynamo. Current kinetic models, often constrained to electron scales, predict premature saturation via magnetic trapping, leaving the generated fields potentially too weak and small-scale to effectively prime magnetohydrodynamic (MHD) processes. Here, using high-resolution kinetic simulations with a realistic mass ratio, we reveal the physics of this unexplored ion-kinetic regime. Under generalized continuous shear driving, used to simulate ubiquitous macroscopic flows, we demonstrate that the saturation of electron instabilities is not the endpoint but a precursor to a distinct, ion-dominated evolution. Massive ions, sustaining the velocity shear, trigger a subsequent filamentation instability that accesses the vast ion kinetic energy reservoir. This mechanism amplifies the magnetic energy by orders of magnitude beyond the electron-saturation limit, expanding the field coherence to ion scales. Our results establish ion kinetics as the essential ''missing link'' that bridges the divide between microscopic plasma instabilities and macroscopic cosmic dynamos.", "AI": {"tldr": "Ion kinetics bridges microscopic plasma instabilities to macroscopic cosmic dynamos by amplifying magnetic fields beyond electron-scale saturation limits.", "motivation": "There's a critical gap between microscopic seed field generation and macroscopic dynamo onset. Current kinetic models limited to electron scales predict premature saturation, leaving fields too weak/small-scale to prime MHD processes.", "method": "Used high-resolution kinetic simulations with realistic mass ratio to study ion-kinetic regime under generalized continuous shear driving (simulating ubiquitous macroscopic flows).", "result": "Electron instability saturation is a precursor to ion-dominated evolution. Massive ions sustain velocity shear, triggering filamentation instability that accesses ion kinetic energy reservoir, amplifying magnetic energy orders of magnitude beyond electron-saturation limit and expanding field coherence to ion scales.", "conclusion": "Ion kinetics serves as the essential \"missing link\" bridging microscopic plasma instabilities and macroscopic cosmic dynamos."}}
{"id": "2602.11006", "pdf": "https://arxiv.org/pdf/2602.11006", "abs": "https://arxiv.org/abs/2602.11006", "authors": ["Tobias H\u00fclser", "Sebastian Matera"], "title": "Noise-balanced multilevel on-the-fly sparse grid surrogates for coupling Monte Carlo models into continuum models with application to heterogeneous catalysis", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "math.NA"], "comment": "28 pages, 7 figures", "summary": "Multiscale simulations utilizing high-fidelity, microscopic Monte Carlo models to provide the nonlinear response for continuum models can easily become computationally intractable. Surrogate models for the high-fidelity Monte Carlo models can overcome this but come with some challenges. One such challenges arise by the sampling noise in the underlying Monte Carlo data, which leads to uncontrolled errors possibly corrupting the surrogate even though it would be highly accurate in the case of noise-free data. Another challenge arises by the 'curse of dimensionality' when the response depends on many macro-variables. These points are addressed by a novel noise-balanced sparse grids interpolation approach which, in a quasi-optimal fashion, controls the amount of Monte Carlo sampling for each data point. The approach is complemented by a multilevel on-the-fly construction during the multiscale simulation. Besides its efficiency, a particularly appealing feature is the ease of use of the approach with only a single hyperparameter controlling the whole surrogate construction - from the surrogate's accuracy with guaranteed convergence to which data needs to be created with which accuracy. The approach is demonstrated on challenging examples from heterogeneous catalysis, coupling microscopic kinetic Monte Carlo models into macroscopic reactor simulations.", "AI": {"tldr": "Novel noise-balanced sparse grids interpolation approach for multiscale simulations that controls Monte Carlo sampling noise and addresses curse of dimensionality with single hyperparameter control.", "motivation": "Multiscale simulations using microscopic Monte Carlo models become computationally intractable due to high computational costs. Surrogate models face challenges from sampling noise in Monte Carlo data (leading to uncontrolled errors) and the curse of dimensionality when response depends on many macro-variables.", "method": "A noise-balanced sparse grids interpolation approach that quasi-optimally controls Monte Carlo sampling for each data point, complemented by multilevel on-the-fly construction during multiscale simulation. Uses only a single hyperparameter controlling surrogate construction, accuracy with guaranteed convergence, and data creation requirements.", "result": "The approach is demonstrated on challenging examples from heterogeneous catalysis, successfully coupling microscopic kinetic Monte Carlo models into macroscopic reactor simulations.", "conclusion": "The method provides an efficient, easy-to-use solution for multiscale simulations with guaranteed convergence properties, addressing both sampling noise and dimensionality challenges through a unified framework with minimal parameter tuning."}}
{"id": "2602.10424", "pdf": "https://arxiv.org/pdf/2602.10424", "abs": "https://arxiv.org/abs/2602.10424", "authors": ["Zhongxiao Jia", "Xinyuan Wan"], "title": "A Numerical Analysis of Sketched Linear Squares Problems and Stopping Criteria for Iterative Solvers", "categories": ["math.NA"], "comment": "26 pages, 15 figures", "summary": "Randomized subspace embedding methods have had a great impact on the solution of a linear least squares (LS) problem by reducing its row dimension, leading to a randomized or sketched LS (sLS) problem, and use the solution of the sLS problem as an approximate solution of the LS problem. This work makes a numerical analysis on the sLS problem, establishes its numerous theoretical properties, and show their crucial roles on the most effective and efficient use of iterative solvers. We first establish a compact bound on the norm of the residual difference between the solutions of the LS and sLS problems, which is the first key result towards understanding the rationale of the sLS problem. Then from the perspective of backward errors, we prove that the solution of the sLS problem is the one of a certain perturbed LS problem with minimal backward error, and quantify how the embedded quality affects the residuals, solution errors, and the relative residual norms of normal equations of the LS and sLS problems. These theoretical results enable us to propose new novel and reliable general-purpose stopping criteria for iterative solvers for the sLS problem, which dynamically monitor stabilization patterns of iterative solvers for the LS problem itself and terminate them at the earliest iteration. Numerical experiments justify the theoretical bounds and demonstrate that the new stopping criteria work reliably and result in a tremendous reduction in computational cost without sacrificing attainable accuracy.", "AI": {"tldr": "This paper analyzes randomized subspace embedding methods for linear least squares problems, establishes theoretical bounds on solution quality, and proposes novel stopping criteria for iterative solvers that significantly reduce computational cost.", "motivation": "Randomized sketching methods reduce the dimension of linear least squares problems, but there's a need to better understand the theoretical properties of sketched LS problems and develop reliable stopping criteria for iterative solvers to maximize computational efficiency.", "method": "The authors conduct numerical analysis of sketched LS problems, establish theoretical bounds on residual differences, analyze backward errors, and propose new stopping criteria that monitor stabilization patterns of iterative solvers for the original LS problem.", "result": "The paper establishes compact bounds on residual differences, proves that sketched LS solutions minimize backward error for perturbed LS problems, and demonstrates that the new stopping criteria work reliably, achieving tremendous computational cost reduction without sacrificing accuracy.", "conclusion": "The theoretical analysis provides crucial insights into sketched LS problems, and the proposed stopping criteria enable efficient use of iterative solvers by terminating them at the earliest possible iteration while maintaining solution quality."}}
{"id": "2602.10591", "pdf": "https://arxiv.org/pdf/2602.10591", "abs": "https://arxiv.org/abs/2602.10591", "authors": ["Wenting Huang", "Zekai Luo", "Ying Sun", "Xiaojing Xu"], "title": "Stability threshold for 3D Boussinesq equations with rotation near the Couette flow and stratified temperature", "categories": ["math.AP"], "comment": null, "summary": "This paper examines the stability threshold at high Reynolds numbers $\\textbf{Re}$ for the three-dimensional Boussinesq equations with rotation on the domain $\u03a9=\\{(x,\\,y,\\,z)\\in \\mathbb{T} \\times \\mathbb{R} \\times \\mathbb{T}\\}$ around the Couette flow $(y,0,0)$ and the vertically stratified temperature $\u0398_s=1+\u03b1^2 z$. For the linear system without rotation, stratification not only suppresses the lift-up effect but also exhibits certain dispersion effects, except for some points where degradation occurs, which will bring essential difficulties to nonlinear estimates. In contrast, when rotation is taken into account, we observe that this degeneracy in dispersion effects disappears; furthermore, we can derive dispersive estimates for the second and third components of the simple-zero mode within the velocity field. Additionally, we develop three good unknowns to minimize linear coupling terms as much as possible while mitigating growth induced by linear stretching terms; through constructing a series of multipliers, we achieve enhanced dissipation and inviscid damping effects. In our analysis of the nonlinear system aimed at establishing an improved stability threshold, we utilize quasi-linearization methods to rectify deficiencies in dispersive estimates related to both the first component of velocity and temperature, as well as address regularity issues along vertical directions caused by buoyancy forces and stratification. Consequently, we demonstrate that if initial perturbations in velocity and temperature satisfy $\\left\\|u_{\\mathrm{in}}\\right\\|_{H^{N+2}\\cap W^{N+3,1}}+\\left\\|\u03b8_{\\mathrm{in}}\\right\\|_{H^{N+1}\\cap W^{N+3,1}}<\u03b4\\mathbf{Re}^{-\\frac{14}{15}}$, for any $N\\geq 11$ and some $\u03b4>0$ independent of $\\mathbf{Re}$, then the solution to the 3D Boussinesq equations with rotation is nonlinearly stable without transitioning away from the steady state.", "AI": {"tldr": "The paper establishes an improved stability threshold for 3D Boussinesq equations with rotation around Couette flow and stratified temperature at high Reynolds numbers, showing that rotation eliminates degeneracy in dispersion effects and enables enhanced dissipation.", "motivation": "To understand the stability threshold for 3D Boussinesq equations with rotation at high Reynolds numbers, particularly examining how rotation affects dispersion effects and stability compared to the non-rotating case where stratification causes degeneracy in dispersion.", "method": "Uses quasi-linearization methods to address deficiencies in dispersive estimates, introduces three good unknowns to minimize linear coupling terms, constructs multipliers to achieve enhanced dissipation and inviscid damping effects, and analyzes linear system with/without rotation.", "result": "Shows that rotation eliminates degeneracy in dispersion effects present in non-rotating case, enables dispersive estimates for velocity components, and establishes nonlinear stability if initial perturbations satisfy $\\|u_{\\mathrm{in}}\\|_{H^{N+2}\\cap W^{N+3,1}}+\\|\u03b8_{\\mathrm{in}}\\|_{H^{N+1}\\cap W^{N+3,1}}<\u03b4\\mathbf{Re}^{-\\frac{14}{15}}$ for $N\\geq 11$.", "conclusion": "The 3D Boussinesq equations with rotation exhibit improved stability properties compared to the non-rotating case, with rotation eliminating degeneracy in dispersion effects and enabling establishment of a refined stability threshold at high Reynolds numbers."}}
{"id": "2602.10642", "pdf": "https://arxiv.org/pdf/2602.10642", "abs": "https://arxiv.org/abs/2602.10642", "authors": ["Shi-Jie Zhang", "Lei Chang", "Zhao-Ju Bo", "Zhi-Song Qu", "Ilya Zadiriev", "Elena Kralkina", "Shogo Isayama", "Sin-Jae You", "Zi-Chen Kan", "Ji-Kai Sun", "Jing-Jing Ma"], "title": "Fully nonlinear phenomenology of the bump-on-tail (BOT) instability with drag, diffusion and Krook relaxation", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Energetic-particle-driven modes in magnetically confined fusion plasmas often exhibit nonlinear frequency sweeping, reflecting complex wave-particle interactions near marginal stability. While the bump-on-tail (BOT) instability within the Berk-Breizman framework has served as a canonical model for understanding such phenomena, a unified nonlinear description remains incomplete when drag, diffusion, and Krook relaxation act simultaneously. In this work, we present a comprehensive numerical investigation of the BOT instability that explicitly retains all three collision operators together with external wave damping. Using a validated characteristic-based BOT code, we systematically scan the multi-dimensional collision parameter space and construct nonlinear regime maps and bifurcation diagrams. To organize the rich dynamics, we introduce a two-level categorization that combines global wave-energy evolution with chirping subtypes identified from spectral morphology. We find that diffusion and Krook relaxation regularize the nonlinear dynamics and promote ordered transitions from chaotic behaviors to periodic oscillations and steady saturation as collision strength increases, with the saturation level decreasing approximately exponentially with external damping. In contrast, drag alone does not admit steady solutions and instead drives persistent or chaotic chirping through convective deformation of resonant phase-space structures. When drag is combined with diffusion or Krook relaxation, clear transition sequences emerge: increasing drag breaks hole-clump symmetry, broadens the effective resonance region, and drives systematic transitions from transient to intermittent and persistent chirping.", "AI": {"tldr": "Numerical study of bump-on-tail instability with drag, diffusion, and Krook collisions reveals systematic transitions in nonlinear dynamics, with drag driving persistent chirping while diffusion/Krook promote ordered saturation.", "motivation": "Energetic-particle-driven modes in fusion plasmas show nonlinear frequency sweeping, but a unified description is incomplete when drag, diffusion, and Krook relaxation act simultaneously. The Berk-Breizman bump-on-tail model needs comprehensive investigation with all three collision operators.", "method": "Comprehensive numerical investigation using validated characteristic-based BOT code, systematically scanning multi-dimensional collision parameter space. Introduced two-level categorization combining global wave-energy evolution with chirping subtypes from spectral morphology.", "result": "Diffusion and Krook relaxation regularize nonlinear dynamics, promoting transitions from chaotic to periodic oscillations and steady saturation. Drag alone drives persistent/chaotic chirping. Combined drag with diffusion/Krook shows systematic transitions from transient to intermittent to persistent chirping.", "conclusion": "The study provides a unified framework for understanding nonlinear dynamics of bump-on-tail instability with multiple collision mechanisms, revealing how different collision operators shape wave-particle interactions and frequency chirping behavior in fusion plasmas."}}
{"id": "2602.10316", "pdf": "https://arxiv.org/pdf/2602.10316", "abs": "https://arxiv.org/abs/2602.10316", "authors": ["Jiefu Tian", "David Montiel", "Kaihua Ji", "Trevor Lyons", "Jason Landini", "Katsuyo Thornton", "Alain Karma"], "title": "Benchmarking of Massively Parallel Phase-Field Codes for Directional Solidification", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We present a detailed benchmark comparing two state-of-the-art phase-field implementations for simulating alloy solidification under experimentally relevant conditions. The study investigates the directional solidification of Al-3wt%Cu under additive manufacturing conditions and SCN-0.46wt% camphor under microgravity conditions from National Aeronautics and Space Administration (NASA) DECLIC-DSI-R experiments. Both codes, one employing finite-difference discretization with uniform mesh and GPU-acceleration and the other one employing finite-element discretization with adaptive-mesh and CPU-parallelization, solve the same quantitative phase-field formulation that incorporates an anti-trapping current for the solidification of dilute alloys. We evaluate the predictions of each code for dendritic morphology, primary spacing, and tip dynamics in both 2D and 3D, as well as their numerical convergence and computational performance. While existing benchmark problems have primarily focused on simplified or small-scale simulations, they do not reflect the computational and modeling challenges posed by employing experimentally relevant time and length scales. Our results provide a practical framework for assessing phase-field code performance as well as validating and facilitating their application in integrated computational materials engineering (ICME) workflows that require integration with realistic experimental data.", "AI": {"tldr": "Benchmark comparison of two state-of-the-art phase-field implementations for alloy solidification under experimental conditions, evaluating dendritic morphology, spacing, tip dynamics, and computational performance.", "motivation": "Existing benchmark problems focus on simplified or small-scale simulations that don't reflect computational challenges of experimentally relevant time and length scales. Need practical framework for assessing phase-field code performance in real-world ICME workflows.", "method": "Compare two phase-field implementations: one uses finite-difference discretization with uniform mesh and GPU-acceleration, the other uses finite-element discretization with adaptive-mesh and CPU-parallelization. Both solve same quantitative phase-field formulation with anti-trapping current for dilute alloys. Study directional solidification of Al-3wt%Cu under additive manufacturing conditions and SCN-0.46wt% camphor under NASA microgravity conditions.", "result": "Evaluate predictions for dendritic morphology, primary spacing, and tip dynamics in 2D and 3D, plus numerical convergence and computational performance. Results provide practical framework for code assessment.", "conclusion": "Benchmark provides framework for assessing phase-field code performance and validating their application in ICME workflows requiring integration with realistic experimental data."}}
{"id": "2602.10440", "pdf": "https://arxiv.org/pdf/2602.10440", "abs": "https://arxiv.org/abs/2602.10440", "authors": ["Zhiwei Yang", "Yikan Liu"], "title": "Identifying the source term in a viscoelastic membrane with a Riemann-Liouville time derivative by the partial interior observation", "categories": ["math.NA"], "comment": "16 pages, 2 figures, 3 tables", "summary": "This paper studies an inverse source problem for a viscoelastic membrane, where the material's memory effect is characterized by the Riemann-Liouville fractional derivative. The problem is to recover the unknown source term from the limited interior observation data. We propose an optimal control framework to address this ill-posed inverse problem. The first-order optimality condition leads to a coupled system of forward and backward fractional partial differential equations. A numerical algorithm combining the finite element method and a conjugate gradient iterative scheme is then developed for the reconstruction of the source term. Several numerical examples are provided to demonstrate the effectiveness and robustness of the proposed method.", "AI": {"tldr": "Inverse source recovery for viscoelastic membrane using fractional derivative model solved via optimal control and FEM-CG algorithm.", "motivation": "To address the ill-posed inverse problem of recovering unknown source terms in viscoelastic membranes with memory effects, where limited interior observation data is available.", "method": "Optimal control framework leading to coupled forward/backward fractional PDEs, solved numerically with finite element method and conjugate gradient iterative scheme.", "result": "Developed effective numerical algorithm for source term reconstruction, demonstrated through several numerical examples showing method effectiveness and robustness.", "conclusion": "The proposed optimal control approach combined with FEM and conjugate gradient provides a practical solution for inverse source problems in fractional viscoelastic systems."}}
{"id": "2602.10612", "pdf": "https://arxiv.org/pdf/2602.10612", "abs": "https://arxiv.org/abs/2602.10612", "authors": ["Debraj Kar"], "title": "Optimal in tail H\u00f6lder estimates for weak solutions of the nonlocal parabolic p-Laplace equations on the Heisenberg group", "categories": ["math.AP"], "comment": null, "summary": "We prove the H\u00f6lder continuity for weak solutions to parabolic p-Laplace equations on the Heisenberg group. We deduce this result while considering an optimal tail condition.", "AI": {"tldr": "The paper proves H\u00f6lder continuity for weak solutions to parabolic p-Laplace equations on the Heisenberg group under optimal tail conditions.", "motivation": "The motivation is to extend regularity theory for parabolic p-Laplace equations to the non-Euclidean setting of the Heisenberg group, which has important applications in sub-Riemannian geometry and related PDEs.", "method": "The authors use techniques from regularity theory for degenerate parabolic equations, adapting methods to the Heisenberg group framework while considering optimal tail conditions for the solutions.", "result": "The main result establishes H\u00f6lder continuity for weak solutions to parabolic p-Laplace equations on the Heisenberg group under optimal tail conditions.", "conclusion": "This work extends classical regularity results to the sub-Riemannian setting of the Heisenberg group, providing important regularity properties for solutions to parabolic p-Laplace equations in this geometric context."}}
{"id": "2602.10709", "pdf": "https://arxiv.org/pdf/2602.10709", "abs": "https://arxiv.org/abs/2602.10709", "authors": ["Baptiste Groussin", "Philipp Sikorski", "Aodhan McIlvenny", "Kosta Oubrerie", "Pierre Bartoli", "Lieselotte Obst-Huebl", "Anthony Vazquez", "Lulu Russell", "Tirtha Mandal", "Kei Nakamura", "Anthony J. Gonsalves", "Cameron G. R. Geddes", "Luca Fedeli", "Henri Vincenti", "Adrien Leblanc"], "title": "Generation and control of Doppler harmonics approaching $10^{22}\\textrm{W/cm}^2$ on plasma mirrors", "categories": ["physics.plasm-ph"], "comment": null, "summary": "In this letter, we report Doppler harmonic generation with a relativistic plasma mirror at unprecedented intensities $>10^{21} ~\\textrm{W/cm}^2$ using a PetaWatt-class laser. We show that beyond a few $10^{21} ~\\textrm{W/cm}^2$ a precise control of the laser contrast at the sub-picosecond time scale becomes essential to drive the efficient generation of high-order harmonics. Such control is paramount for deploying plasma mirrors in high-field applications at PetaWatt-class laser facilities, including, for instance, their use as intensity boosters in the pursuit of the strong-field regime of quantum electrodynamics.", "AI": {"tldr": "Doppler harmonic generation with relativistic plasma mirror at >10\u00b2\u00b9 W/cm\u00b2 intensities using PetaWatt laser, showing contrast control is essential for efficient high-order harmonics.", "motivation": "To explore Doppler harmonic generation at unprecedented intensities (>10\u00b2\u00b9 W/cm\u00b2) using PetaWatt-class lasers, and to understand the requirements for efficient high-order harmonic generation in relativistic plasma mirror systems.", "method": "Used a PetaWatt-class laser to drive Doppler harmonic generation with a relativistic plasma mirror at intensities >10\u00b2\u00b9 W/cm\u00b2, with precise control of laser contrast at sub-picosecond timescales.", "result": "Showed that beyond a few 10\u00b2\u00b9 W/cm\u00b2, precise control of laser contrast at sub-picosecond time scale becomes essential for efficient generation of high-order harmonics.", "conclusion": "Such contrast control is paramount for deploying plasma mirrors in high-field applications at PetaWatt-class laser facilities, including their use as intensity boosters for pursuing the strong-field regime of quantum electrodynamics."}}
{"id": "2602.10451", "pdf": "https://arxiv.org/pdf/2602.10451", "abs": "https://arxiv.org/abs/2602.10451", "authors": ["Jinkyo Han", "Bahador Bahmani"], "title": "A Multimodal Conditional Mixture Model with Distribution-Level Physics Priors", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Many scientific and engineering systems exhibit intrinsically multimodal behavior arising from latent regime switching and non-unique physical mechanisms. In such settings, learning the full conditional distribution of admissible outcomes in a physically consistent and interpretable manner remains a challenge. While recent advances in machine learning have enabled powerful multimodal generative modeling, their integration with physics-constrained scientific modeling remains nontrivial, particularly when physical structure must be preserved or data are limited. This work develops a physics-informed multimodal conditional modeling framework based on mixture density representations. Mixture density networks (MDNs) provide an explicit and interpretable parameterization of multimodal conditional distributions. Physical knowledge is embedded through component-specific regularization terms that penalize violations of governing equations or physical laws. This formulation naturally accommodates non-uniqueness and stochasticity while remaining computationally efficient and amenable to conditioning on contextual inputs. The proposed framework is evaluated across a range of scientific problems in which multimodality arises from intrinsic physical mechanisms rather than observational noise, including bifurcation phenomena in nonlinear dynamical systems, stochastic partial differential equations, and atomistic-scale shock dynamics. In addition, the proposed method is compared with a conditional flow matching (CFM) model, a representative state-of-the-art generative modeling approach, demonstrating that MDNs can achieve competitive performance while offering a simpler and more interpretable formulation.", "AI": {"tldr": "Physics-informed mixture density networks for multimodal conditional modeling in scientific systems with intrinsic non-uniqueness and regime switching.", "motivation": "Many scientific systems exhibit multimodal behavior from latent regime switching and non-unique physical mechanisms, but existing ML approaches struggle to preserve physical structure while learning full conditional distributions, especially with limited data.", "method": "Develops physics-informed multimodal conditional modeling using mixture density networks (MDNs) with component-specific regularization terms that penalize violations of governing equations or physical laws.", "result": "The framework is evaluated on scientific problems with intrinsic multimodality (nonlinear dynamical systems, stochastic PDEs, atomistic shock dynamics) and shows competitive performance compared to conditional flow matching while offering simpler, more interpretable formulation.", "conclusion": "MDNs provide an effective physics-informed approach for multimodal conditional modeling that preserves physical structure, accommodates non-uniqueness, and offers computational efficiency and interpretability advantages over more complex generative models."}}
{"id": "2602.10541", "pdf": "https://arxiv.org/pdf/2602.10541", "abs": "https://arxiv.org/abs/2602.10541", "authors": ["Antonin Sulc"], "title": "Solving PDEs in One Shot via Fourier Features with Exact Analytical Derivatives", "categories": ["math.NA", "cs.LG"], "comment": "9 pages, 1 figure, ICLR 2026 Workshop on AI and Partial Differential Equations", "summary": "Recent random feature methods for solving partial differential equations (PDEs) reduce computational cost compared to physics-informed neural networks (PINNs) but still rely on iterative optimization or expensive derivative computation. We observe that sinusoidal random Fourier features possess a cyclic derivative structure: the derivative of any order of $\\sin(\\mathbf{W}\\cdot\\mathbf{x}+b)$ is a single sinusoid with a monomial prefactor, computable in $O(1)$ operations. Alternative activations such as $\\tanh$, used in prior one-shot methods like PIELM, lack this property: their higher-order derivatives grow as $O(2^n)$ terms, requiring automatic differentiation for operator assembly. We propose FastLSQ, which combines frozen random Fourier features with analytical operator assembly to solve linear PDEs via a single least-squares call, and extend it to nonlinear PDEs via Newton--Raphson iteration where each linearized step is a FastLSQ solve. On a benchmark of 17 PDEs spanning 1 to 6 dimensions, FastLSQ achieves relative $L^2$ errors of $10^{-7}$ in 0.07\\,s on linear problems, three orders of magnitude more accurate and significantly faster than state-of-the-art iterative PINN solvers, and $10^{-8}$ to $10^{-9}$ on nonlinear problems via Newton iteration in under 9s.", "AI": {"tldr": "FastLSQ uses frozen random Fourier features with analytical derivative computation to solve PDEs via single least-squares call for linear problems and Newton iteration for nonlinear ones, achieving high accuracy and speed.", "motivation": "Existing random feature methods for PDEs still require iterative optimization or expensive derivative computation. Sinusoidal random Fourier features have a special cyclic derivative structure that enables efficient analytical computation, unlike activations like tanh used in prior methods.", "method": "FastLSQ combines frozen random Fourier features with analytical operator assembly. For linear PDEs, it solves via a single least-squares call. For nonlinear PDEs, it uses Newton-Raphson iteration where each linearized step is a FastLSQ solve.", "result": "On 17 PDE benchmarks spanning 1-6 dimensions: linear problems achieve 10^-7 relative L^2 errors in 0.07s (3 orders more accurate and significantly faster than state-of-the-art iterative PINN solvers); nonlinear problems achieve 10^-8 to 10^-9 errors via Newton iteration in under 9s.", "conclusion": "FastLSQ leverages the cyclic derivative structure of sinusoidal random Fourier features to enable efficient analytical operator assembly, providing a fast and accurate alternative to iterative PINN methods for solving both linear and nonlinear PDEs."}}
{"id": "2602.10617", "pdf": "https://arxiv.org/pdf/2602.10617", "abs": "https://arxiv.org/abs/2602.10617", "authors": ["Yong Liu"], "title": "Free boundary regularity in obstacle problems with a degenerate forcing term", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we consider the properties of a special free boundary point in the following obstacle problem: The Laplacian of u equals f(x) multiplied by the characteristic function of the set where u is positive within the two-dimensional unit ball, where $f(x)=|x|$ is a degenerate forcing term. The key challenge stems from the degeneracy of $f(x)$, which leads to a more complex structure of the free boundary compared to the classical setting. To analyze it, we introduce the epiperimetric inequality developed by Weiss (Invent Math 138:23-50, 1999). Although this powerful tool was firstly introduced for the classical obstacle problem characterized by $f(x)>0$ in B_1, it also proves effective in our degenerate setting. This allows us to first obtain the decay rate of the Weiss energy for all blow-ups at the origin, which in turn implies the uniqueness of the blow-up profiles. With this uniqueness established, we then prove a very weak directional monotonicity properties satisfied by the solutions. This finally yields the regularity of the free boundary at the origin if the origin is a regular point.", "AI": {"tldr": "The paper analyzes a degenerate obstacle problem with f(x)=|x| in 2D, proving free boundary regularity at the origin using Weiss's epiperimetric inequality and establishing uniqueness of blow-up profiles.", "motivation": "To understand the properties of free boundary points in degenerate obstacle problems where the forcing term f(x)=|x| vanishes at the origin, which creates more complex free boundary structures than classical non-degenerate cases.", "method": "Uses Weiss's epiperimetric inequality adapted to the degenerate setting, analyzes Weiss energy decay for blow-ups at the origin, proves uniqueness of blow-up profiles, establishes weak directional monotonicity properties of solutions.", "result": "Obtains decay rate of Weiss energy for all blow-ups at origin, proves uniqueness of blow-up profiles, establishes weak directional monotonicity properties, and shows free boundary regularity at origin when origin is a regular point.", "conclusion": "Weiss's epiperimetric inequality remains effective for degenerate obstacle problems, enabling analysis of free boundary regularity at special points despite the degeneracy of the forcing term."}}
{"id": "2602.11053", "pdf": "https://arxiv.org/pdf/2602.11053", "abs": "https://arxiv.org/abs/2602.11053", "authors": ["Torsten En\u00dflin", "Christoph Pfrommer"], "title": "Collisionless relaxation as the origin of the anisotropic, non-thermal, and multi-temperature momentum distributions observed in space plasmas", "categories": ["physics.plasm-ph", "astro-ph.HE"], "comment": "16 pages, 1 figure", "summary": "Anisotropic, non-thermal, and multi-temperature distributed particle momenta are commonly observed in collisionless space plasmas, such as the solar wind. Using Liouville's theorem, we argue that anisotropic compression or expansion of the plasma, followed by a relaxation of the resulting anisotropic stress must lead to non-equilibrium states that are either anisotropic, non-thermal distribution functions, different electron and ion temperatures, or a combination of these effects. We present arguments showing that a plasma in thermal equilibrium undergoing anisotropic compression or expansion cannot return to thermal equilibrium in the absence of particle collisions. Since most astrophysical plasmas are practically collisionless and experience significant anisotropic compression or expansion, we expect anisotropic, non-thermal, and multi-temperature particle distributions to be ubiquitous, in agreement with solar wind measurements.", "AI": {"tldr": "Plasma compression/expansion without collisions leads to anisotropic, non-thermal distributions, explaining solar wind observations.", "motivation": "To explain why collisionless space plasmas like solar wind commonly exhibit anisotropic, non-thermal, and multi-temperature particle distributions despite expectations of thermal equilibrium.", "method": "Using Liouville's theorem to analyze plasma behavior during anisotropic compression/expansion, showing that without collisions, relaxation of anisotropic stress cannot restore thermal equilibrium.", "result": "Demonstrates that anisotropic compression/expansion followed by stress relaxation must produce non-equilibrium states (anisotropy, non-thermal distributions, or temperature differences between species).", "conclusion": "Anisotropic, non-thermal, and multi-temperature distributions should be ubiquitous in astrophysical plasmas due to collisionless anisotropic compression/expansion, consistent with solar wind measurements."}}
{"id": "2602.10611", "pdf": "https://arxiv.org/pdf/2602.10611", "abs": "https://arxiv.org/abs/2602.10611", "authors": ["Nicol\u00e1s Becerra-Zuniga", "Lucas Lacasa", "Eusebio Valero", "Gonzalo Rubio"], "title": "On the Role of Consistency Between Physics and Data in Physics-Informed Neural Networks", "categories": ["cs.LG", "physics.comp-ph", "stat.ML"], "comment": "24 pages, 7 Figures, 3 Tables", "summary": "Physics-informed neural networks (PINNs) have gained significant attention as a surrogate modeling strategy for partial differential equations (PDEs), particularly in regimes where labeled data are scarce and physical constraints can be leveraged to regularize the learning process. In practice, however, PINNs are frequently trained using experimental or numerical data that are not fully consistent with the governing equations due to measurement noise, discretization errors, or modeling assumptions. The implications of such data-to-PDE inconsistencies on the accuracy and convergence of PINNs remain insufficiently understood. In this work, we systematically analyze how data inconsistency fundamentally limits the attainable accuracy of PINNs. We introduce the concept of a consistency barrier, defined as an intrinsic lower bound on the error that arises from mismatches between the fidelity of the data and the exact enforcement of the PDE residual. To isolate and quantify this effect, we consider the 1D viscous Burgers equation with a manufactured analytical solution, which enables full control over data fidelity and residual errors. PINNs are trained using datasets of progressively increasing numerical accuracy, as well as perfectly consistent analytical data. Results show that while the inclusion of the PDE residual allows PINNs to partially mitigate low-fidelity data and recover the dominant physical structure, the training process ultimately saturates at an error level dictated by the data inconsistency. When high-fidelity numerical data are employed, PINN solutions become indistinguishable from those trained on analytical data, indicating that the consistency barrier is effectively removed. These findings clarify the interplay between data quality and physics enforcement in PINNs providing practical guidance for the construction and interpretation of physics-informed surrogate models.", "AI": {"tldr": "PINNs face accuracy limits from data-PDE inconsistencies; a \"consistency barrier\" emerges as intrinsic error bound when training data mismatches exact PDE enforcement.", "motivation": "PINNs are widely used for PDE modeling with scarce data, but real-world data often contains noise, discretization errors, or modeling assumptions that create inconsistencies with governing equations. The impact of these data-to-PDE inconsistencies on PINN accuracy and convergence remains poorly understood.", "method": "Systematic analysis of data inconsistency effects on PINNs using the 1D viscous Burgers equation with manufactured analytical solution. PINNs are trained with datasets of varying numerical accuracy (progressively increasing fidelity) and perfectly consistent analytical data to isolate and quantify the consistency barrier.", "result": "PINNs can partially mitigate low-fidelity data using PDE residuals and recover dominant physical structure, but training eventually saturates at an error level dictated by data inconsistency. When high-fidelity numerical data is used, PINN solutions become indistinguishable from those trained on analytical data, effectively removing the consistency barrier.", "conclusion": "Data-to-PDE inconsistencies fundamentally limit PINN accuracy through a \"consistency barrier.\" The work clarifies the interplay between data quality and physics enforcement in PINNs, providing practical guidance for constructing and interpreting physics-informed surrogate models."}}
{"id": "2602.10550", "pdf": "https://arxiv.org/pdf/2602.10550", "abs": "https://arxiv.org/abs/2602.10550", "authors": ["Huangxin Chen", "Yuxiang Chen", "Jisheng Kou", "Shuyu Sun"], "title": "An Energy-Stable, Bound-Preserving and Locally Conservative Numerical Framework for Multicomponent Gas Flow in Poroelastic Media", "categories": ["math.NA"], "comment": null, "summary": "In this paper, we propose a robust and efficient numerical framework for simulating multicomponent gas flow in poroelastic media, with a focus on preserving fundamental thermodynamic principles and ensuring computational reliability. The model captures the complex nonlinear coupling between multicomponent transport and solid deformation, while addressing critical numerical challenges such as mass conservation, energy stability, and molar density boundedness. To achieve this, we develop a stabilized discretization approach that guarantees the preservation of the original energy dissipation law and ensures the boundedness of each gas component's molar density. Furthermore, the proposed method incorporates an adaptive time-stepping strategy that dynamically adjusts the time step size based on the system's dynamics, significantly enhancing computational efficiency without compromising stability or accuracy. For spatial discretization, a mixed finite element method combined with an upwind scheme is employed for the flow and transport equations to ensure local mass conservation, while a discontinuous Galerkin (DG) method is utilized for discretizing the momentum equation of poroelasticity to effectively overcome numerical locking phenomena. Numerical experiments are presented to demonstrate the performance, robustness, and applicability of the method in simulating multicomponent gas flow under various scenarios.", "AI": {"tldr": "A robust numerical framework for simulating multicomponent gas flow in poroelastic media that preserves thermodynamic principles, ensures mass conservation, energy stability, and molar density boundedness through stabilized discretization and adaptive time-stepping.", "motivation": "To address the complex nonlinear coupling between multicomponent transport and solid deformation in poroelastic media while overcoming numerical challenges like mass conservation, energy stability, and molar density boundedness that are critical for reliable simulations.", "method": "Developed a stabilized discretization approach that preserves original energy dissipation law and ensures molar density boundedness. Uses adaptive time-stepping strategy for efficiency, mixed finite element method with upwind scheme for flow/transport equations, and discontinuous Galerkin method for poroelasticity momentum equation to overcome numerical locking.", "result": "Numerical experiments demonstrate the method's performance, robustness, and applicability in simulating multicomponent gas flow under various scenarios, showing enhanced computational efficiency without compromising stability or accuracy.", "conclusion": "The proposed framework provides a reliable and efficient numerical approach for simulating multicomponent gas flow in poroelastic media that preserves fundamental thermodynamic principles and addresses key numerical challenges through innovative discretization and adaptive strategies."}}
{"id": "2602.10636", "pdf": "https://arxiv.org/pdf/2602.10636", "abs": "https://arxiv.org/abs/2602.10636", "authors": ["Youjun Deng", "Ching-Lung Lin", "Gen Nakamura"], "title": "Explicit form of relaxation tensor for isotropic extended Burgers model and its spectral inversion", "categories": ["math.AP"], "comment": null, "summary": "Concerning the anelastic nature of Earth, the quasi-static extended Burgers model (abbreviated by q-EBM), an integro-differential system, is used to study the free oscillation of Earth (abbreviated by FOE). In this paper, we first provide a general method to obtain an explicit form of the relaxation tensor for inhomogeneous isotropic q-EBM. Then, we apply it to compute the eigenvalues of the free oscillation of Earth, assuming that Earth is a unit ball modeled as a homogeneous and isotropic q-EBM. So far, an analytical and systematic way to compute the eigenvalues of the FOE has been missing when modeling Earth as a q-EBM. In particular, we compute some clusters of eigenvalues (abbreviated by C-ev's). To be more precise, integrating by parts with respect to time of the q-EBM under the assumption that the initial strain is zero, the q-EBM becomes the sum of two terms. The first term, called the instantaneous term, doesn't have any integration with respect to time, but the second term, called the memory term, has such an integration. Then, consider the eigenvalues of the instantaneous part of the q-EBM. The eigenfunctions of C-ev's share the same eigenfunctions of the instantaneous part. However, the C-ev's may be shifted from the eigenvalues of the instantaneous part. Further, we analyze the structure of C-ev's and provide an inversion formula identifying the q-EBM from the C-ev's.", "AI": {"tldr": "The paper develops a method to compute eigenvalues for Earth's free oscillations using the quasi-static extended Burgers model (q-EBM), providing analytical solutions for eigenvalue clusters and an inversion formula to identify q-EBM parameters from these eigenvalues.", "motivation": "There has been no analytical and systematic way to compute eigenvalues of Earth's free oscillations when modeling Earth as a q-EBM, despite its importance for understanding Earth's anelastic nature.", "method": "First derives an explicit form of the relaxation tensor for inhomogeneous isotropic q-EBM. Then applies this to compute eigenvalues for a homogeneous isotropic q-EBM unit ball model. Uses integration by parts to separate instantaneous and memory terms, analyzes eigenvalue clusters that share eigenfunctions with the instantaneous part.", "result": "Develops a general method to obtain relaxation tensor for q-EBM, computes eigenvalue clusters for Earth's free oscillations, analyzes their structure, and provides an inversion formula to identify q-EBM parameters from eigenvalue data.", "conclusion": "The paper provides the first analytical framework for computing eigenvalues of Earth's free oscillations using q-EBM, with practical applications for identifying Earth's anelastic properties through eigenvalue inversion."}}
{"id": "2602.10836", "pdf": "https://arxiv.org/pdf/2602.10836", "abs": "https://arxiv.org/abs/2602.10836", "authors": ["Ugo Boscain", "Wadim Gerner"], "title": "Charged particle motion in a strong magnetic field: The first order expansion", "categories": ["math-ph", "math.CA", "physics.plasm-ph"], "comment": "20 pages, 1 figure", "summary": "We provide a mathematically rigorous derivation of the first order expansion of the motion of a charged particle in a strong magnetic field. In contrast to the derivations that can be found in the physics literature we solely assume throughout that the magnetic field is strong. In particular we do not need to make any structural assumptions on the particle motion, such as the gyroradius being small in comparison to the magnetic length scale. Instead, some of the additional assumptions which are usually made in the physics literature turn out to be an a posteriori consequence in our approach. Our approach further justifies the utilisation of the guiding centre approximation at \"bounce points\" within magnetic mirrors, a situation which violates the usual assumptions which are made in the physics literature when deriving the guiding centre approximation.", "AI": {"tldr": "Mathematically rigorous derivation of first-order expansion for charged particle motion in strong magnetic fields without structural assumptions on particle motion.", "motivation": "To provide a mathematically rigorous derivation of the guiding centre approximation for charged particle motion in strong magnetic fields, addressing limitations in existing physics literature approaches.", "method": "Uses mathematical rigor to derive first-order expansion, solely assuming strong magnetic field without additional structural assumptions on particle motion like small gyroradius relative to magnetic length scale.", "result": "Derivation shows that additional assumptions typically made in physics literature are a posteriori consequences, and justifies using guiding centre approximation at bounce points in magnetic mirrors where usual assumptions are violated.", "conclusion": "The approach provides rigorous mathematical foundation for guiding centre approximation in strong magnetic fields, extending applicability to bounce points in magnetic mirrors where traditional derivations fail."}}
{"id": "2602.11097", "pdf": "https://arxiv.org/pdf/2602.11097", "abs": "https://arxiv.org/abs/2602.11097", "authors": ["David A. Barajas-Solano"], "title": "Statistical Learning Analysis of Physics-Informed Neural Networks", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "We study the training and performance of physics-informed learning for initial and boundary value problems (IBVP) with physics-informed neural networks (PINNs) from a statistical learning perspective. Specifically, we restrict ourselves to parameterizations with hard initial and boundary condition constraints and reformulate the problem of estimating PINN parameters as a statistical learning problem. From this perspective, the physics penalty on the IBVP residuals can be better understood not as a regularizing term bus as an infinite source of indirect data, and the learning process as fitting the PINN distribution of residuals $p(y \\mid x, t, w) q(x, t) $ to the true data-generating distribution $\u03b4(0) q(x, t)$ by minimizing the Kullback-Leibler divergence between the true and PINN distributions. Furthermore, this analysis show that physics-informed learning with PINNs is a singular learning problem, and we employ singular learning theory tools, namely the so-called Local Learning Coefficient (Lau et al., 2025) to analyze the estimates of PINN parameters obtained via stochastic optimization for a heat equation IBVP. Finally, we discuss implications of this analysis on the quantification of predictive uncertainty of PINNs and the extrapolation capacity of PINNs.", "AI": {"tldr": "PINNs for IBVPs analyzed from statistical learning perspective, showing physics penalty acts as infinite indirect data source, and PINN learning is a singular learning problem analyzed using Local Learning Coefficient.", "motivation": "To understand physics-informed neural networks (PINNs) for initial and boundary value problems (IBVPs) from a statistical learning theory perspective, moving beyond the conventional view of physics penalty as regularization.", "method": "Reformulate PINN parameter estimation as statistical learning problem with hard constraints, analyze physics penalty as infinite source of indirect data, use Kullback-Leibler divergence minimization between true and PINN residual distributions, and apply singular learning theory tools (Local Learning Coefficient) to analyze parameter estimates.", "result": "Physics penalty in PINNs is better understood as infinite indirect data rather than regularization, PINN learning is a singular learning problem, and Local Learning Coefficient analysis provides insights into parameter estimation for heat equation IBVP.", "conclusion": "Statistical learning perspective provides new understanding of PINNs, with implications for predictive uncertainty quantification and extrapolation capacity, and singular learning theory tools offer analytical framework for PINN parameter analysis."}}
{"id": "2602.10590", "pdf": "https://arxiv.org/pdf/2602.10590", "abs": "https://arxiv.org/abs/2602.10590", "authors": ["Diana Al Zareef", "Ahmad El Hajj", "Antoine Zurek"], "title": "Convergence of a scheme for a two dimensional nonlocal system of transport equations", "categories": ["math.NA"], "comment": null, "summary": "In this paper, we numerically study a two-dimensional system modeling the dynamics of dislocation densities. This system is hyperbolic, but not strictly hyperbolic, and couples two non-local transport equations. It is characterized by weak regularity in both the velocity and the initial data. We propose a semi-explicit finite difference (IMEX) numerical scheme for the discretization of this system, after regularizing the singular velocity using a Fej\u00e9r kernel. We show that this scheme preserves, at the discrete level, an entropy estimate on the gradient, which then allows us to establish the convergence of the discrete solution to the continuous solution. To our knowledge, this is the first convergence result obtained for this type of system. We conclude with some numerical illustrations highlighting the performance of the proposed scheme.", "AI": {"tldr": "First convergence result for a 2D hyperbolic system modeling dislocation densities using an IMEX scheme with Fej\u00e9r kernel regularization and entropy-preserving discretization.", "motivation": "The paper addresses the challenge of numerically studying a two-dimensional hyperbolic system modeling dislocation densities, which has weak regularity in both velocity and initial data, and lacks prior convergence results for such systems.", "method": "Proposes a semi-explicit finite difference (IMEX) numerical scheme that regularizes the singular velocity using a Fej\u00e9r kernel, preserving an entropy estimate on the gradient at the discrete level.", "result": "Establishes convergence of the discrete solution to the continuous solution - the first convergence result obtained for this type of system, with numerical illustrations demonstrating scheme performance.", "conclusion": "The proposed IMEX scheme with Fej\u00e9r kernel regularization successfully handles the weak regularity of the dislocation density system and provides the first proven convergence result, validated by numerical experiments."}}
{"id": "2602.10678", "pdf": "https://arxiv.org/pdf/2602.10678", "abs": "https://arxiv.org/abs/2602.10678", "authors": ["Buddhika Priyasad", "S\u00e9rgio S. Rodrigues"], "title": "Stabilization of nonautonomous Navier-Stokes flows under dynamic slip boundary conditions", "categories": ["math.AP", "math.OC"], "comment": "26 pages, 2 figures", "summary": "Exponential stabilizability of the incompressible Navier-Stokes equations under dynamic slip boundary conditions toward arbitrary time-dependent trajectories is proven. The feedback control law is constructed explicitly using oblique projections and realized through a finite number of spatially localized interior actuators, without requiring spectral assumptions. The approach extends to various slip boundary condition types (Navier, vorticity-type, and Neumann) and applies to multi-connected domains. Weak solution existence and exponential decay estimates are established, with the stabilization rate depending on the boundary dynamics parameters.", "AI": {"tldr": "Exponential stabilization of incompressible Navier-Stokes equations using finite interior actuators and dynamic slip boundary conditions without spectral assumptions.", "motivation": "To achieve exponential stabilization of incompressible Navier-Stokes equations toward arbitrary time-dependent trajectories using practical control methods that work with various slip boundary conditions and multi-connected domains.", "method": "Constructs explicit feedback control law using oblique projections, realized through finite spatially localized interior actuators. No spectral assumptions required. Extends to Navier, vorticity-type, and Neumann slip boundary conditions.", "result": "Proves exponential stabilizability, establishes weak solution existence, provides exponential decay estimates with stabilization rate depending on boundary dynamics parameters.", "conclusion": "The approach successfully achieves exponential stabilization of incompressible Navier-Stokes equations using finite interior actuators under various slip boundary conditions, applicable to multi-connected domains without spectral assumptions."}}
{"id": "2602.10605", "pdf": "https://arxiv.org/pdf/2602.10605", "abs": "https://arxiv.org/abs/2602.10605", "authors": ["Peichen Xie"], "title": "Evaluating Numerical Accuracy in Mixed-Precision Computing by Dual-Delta Testing", "categories": ["math.NA", "cs.SE"], "comment": null, "summary": "Mixed-precision computing has become increasingly important in modern high-performance computing and machine learning applications. When implementing custom mixed-precision functions -- such as fused operators, optimized GPU kernels, or quantized inference paths -- it is critical to verify their numerical accuracy. Traditional approaches typically compare the custom implementation against a reference using a single error metric. However, this single-delta approach provides limited insight into whether the observed errors are inherent to the precision level or specific to the implementation. This paper introduces \\textit{Dual-Delta Testing}, a systematic methodology that evaluates two error distributions against a high-precision oracle, enabling rigorous comparison between a custom implementation and a baseline reference. We present the mathematical framework, algorithmic formulation, statistical analysis techniques, and practical examples demonstrating the methodology's effectiveness in evaluating numerical accuracy.", "AI": {"tldr": "Dual-Delta Testing is a new methodology for evaluating numerical accuracy of mixed-precision implementations by comparing two error distributions against a high-precision oracle, providing better insight than traditional single-error approaches.", "motivation": "Traditional approaches for verifying numerical accuracy of custom mixed-precision functions (like fused operators, GPU kernels, or quantized inference) use single error metrics that provide limited insight into whether errors are inherent to the precision level or specific to the implementation.", "method": "Dual-Delta Testing systematically evaluates two error distributions against a high-precision oracle, enabling rigorous comparison between a custom implementation and a baseline reference. The paper presents mathematical framework, algorithmic formulation, and statistical analysis techniques.", "result": "The methodology is demonstrated through practical examples showing its effectiveness in evaluating numerical accuracy of mixed-precision implementations.", "conclusion": "Dual-Delta Testing provides a more comprehensive approach than traditional single-error methods for verifying numerical accuracy in mixed-precision computing, offering better insight into error sources and implementation quality."}}
{"id": "2602.10700", "pdf": "https://arxiv.org/pdf/2602.10700", "abs": "https://arxiv.org/abs/2602.10700", "authors": ["Xiangdi Huang", "Yongteng Gu", "Muxi Lei"], "title": "Global strong solutions with large initial data for the Cauchy problem of the multi-dimensional compressible Navier-Stokes-Korteweg system", "categories": ["math.AP"], "comment": "31 pages", "summary": "In this paper, we establish global strong solutions for arbitrarily large initial data to the 2D and 3D compressible Navier-Stokes-Korteweg system, also referred to as the quantum Navier-Stokes equations, originally derived by Dunn and Serrin [Arch. Ration. Mech. Anal. 88(2):95-133, 1985]. Specifically, we prove the existence of global strong solutions for arbitrarily large initial data in the case $N=2$ when $\u03b3\\ge 1$, and $N=3$ with $1 \\le \u03b3< 8/3$ for the associated Cauchy problem. By employing techniques from Littlewood-Paley theory, range truncation analysis, refined Nash-Moser and De Giorgi iteration methods, we derive positive upper and lower bounds for the density. As a consequence, we are able to treat the whole-space case with strictly positive far-field density. To the best of our knowledge, this is the first result that establishes global strong solutions for physically relevant compressible Navier-Stokes equations in the whole space, without imposing any symmetry or special geometric assumptions on the initial data.", "AI": {"tldr": "Global strong solutions for 2D/3D compressible Navier-Stokes-Korteweg system with arbitrarily large initial data, establishing first such result without symmetry assumptions.", "motivation": "To establish global strong solutions for physically relevant compressible Navier-Stokes equations in whole space without imposing symmetry or special geometric assumptions on initial data, addressing a long-standing open problem.", "method": "Employ Littlewood-Paley theory, range truncation analysis, refined Nash-Moser and De Giorgi iteration methods to derive positive upper and lower bounds for density.", "result": "Proved existence of global strong solutions for arbitrarily large initial data: 2D case with \u03b3\u22651, and 3D case with 1\u2264\u03b3<8/3 for the Cauchy problem.", "conclusion": "First result establishing global strong solutions for physically relevant compressible Navier-Stokes equations in whole space without symmetry assumptions, enabling treatment of whole-space case with strictly positive far-field density."}}
{"id": "2602.10689", "pdf": "https://arxiv.org/pdf/2602.10689", "abs": "https://arxiv.org/abs/2602.10689", "authors": ["Changjian Xie", "Yingxi Miao", "Haocheng Yang"], "title": "An Efficient Energy Stable Structure Preserving Method for The Landau-Lifshitz Equation", "categories": ["math.NA"], "comment": null, "summary": "One of the main difficulties in micromagnetics simulation is the norm preserving constraints $\\|\\mathbf{m}\\|=1$ at the continuous or the discrete level. Another difficulty is the stability with the time step constraint. Using standard explicit integrators leads to a physical time step of sub-pico seconds, which is often two orders of magnitude smaller than the fastest physical time scales. Direct implicit integrators require solving complicated, coupled systems. Another major difficulty with the projection method in this field is the lack of rigorous theoretical guarantees regarding its stability of the projection step. In this paper, we introduce a first order method. Such a method is structure preserving based on a combination of a Gauss-Seidel iteration, a double diffusion iteration and a Crank-Nicolson iteration to preserve the norm constraints.", "AI": {"tldr": "A first-order structure-preserving method for micromagnetics simulation that addresses norm constraints and stability issues using Gauss-Seidel, double diffusion, and Crank-Nicolson iterations.", "motivation": "Micromagnetics simulation faces three main difficulties: 1) norm-preserving constraints (|m|=1), 2) severe time step limitations with explicit integrators (sub-picosecond steps), and 3) lack of rigorous stability guarantees for projection methods.", "method": "A first-order structure-preserving method combining Gauss-Seidel iteration, double diffusion iteration, and Crank-Nicolson iteration to preserve the norm constraints while maintaining stability.", "result": "The paper introduces a novel method that addresses the norm constraint preservation and stability issues in micromagnetics simulation, though specific numerical results are not provided in the abstract.", "conclusion": "The proposed method provides a structure-preserving approach to overcome key challenges in micromagnetics simulation, particularly the norm constraints and stability limitations of existing methods."}}
{"id": "2602.10726", "pdf": "https://arxiv.org/pdf/2602.10726", "abs": "https://arxiv.org/abs/2602.10726", "authors": ["Mathis Hardion", "Th\u00e9o Lacombe"], "title": "The Wasserstein gradient flow of the Sinkhorn divergence between Gaussian distributions", "categories": ["math.AP", "math.OC"], "comment": null, "summary": "We study the Wasserstein gradient flow of the Sinkhorn divergence when both the source and the target are Gaussian distributions. We prove the existence of a flow that stays in the class of Gaussian distributions, and is unique in the larger class of measures with strongly-concave and smooth log-densities. We prove that the flow globally converges toward the target measure when the source's covariance matrix is not singular, and provide counter-examples to global convergence when it is, giving a first answer to an open question raised in [Carlier et al. 2024, \\S4.2]. When the covariance matrix of the source distribution commutes with that of the target, we derive more quantitative results that showcase exponential convergence toward the target when the source and the target share their support, but dropping to linear rates (O(t^{-1})) if the target is concentrated on a strict subspace of the source's support.", "AI": {"tldr": "The paper studies Wasserstein gradient flow of Sinkhorn divergence for Gaussian distributions, proving existence of Gaussian-preserving flow, convergence results, and rate analysis.", "motivation": "To understand the behavior of Wasserstein gradient flow of Sinkhorn divergence when both source and target distributions are Gaussian, addressing an open question about global convergence raised in prior work.", "method": "Analyzing the Wasserstein gradient flow of Sinkhorn divergence for Gaussian distributions, proving existence of flow that stays within Gaussian class, studying convergence properties with different covariance conditions.", "result": "Proved existence of unique Gaussian-preserving flow, global convergence when source covariance is non-singular, counter-examples when singular, and quantitative exponential/linear convergence rates depending on support conditions.", "conclusion": "The Wasserstein gradient flow of Sinkhorn divergence preserves Gaussianity, converges globally under non-singular conditions, and exhibits different convergence rates based on support relationships between source and target distributions."}}
{"id": "2602.10773", "pdf": "https://arxiv.org/pdf/2602.10773", "abs": "https://arxiv.org/abs/2602.10773", "authors": ["Tom\u00e1s Caraballo", "Macarena G\u00f3mez-M\u00e1rmol", "Ignacio Rold\u00e1n"], "title": "The Stochastic TR-BDF2 Scheme of Order 2", "categories": ["math.NA"], "comment": null, "summary": "Our main objective in this paper is to develop a second-order stochastic numerical method which generalizes the well-known deterministic TR-BDF2 scheme. Since most stochastic techniques used for approximating the solution of a stochastic differential equation may have lower order compared to the deterministic case, we have elaborated a scheme which not only preserves the second-order accuracy of the original scheme in the stochastic framework, but also its $A$-stability. Once we obtain the scheme and prove its second-order accuracy and $A$-stability, which is not a trivial task, we also state a result concerning its $MS$-stability. This concept is also analyzed for different parameter ranges in our scheme and the It{\u00f4}--Taylor approximation of order 2, revealing scenarios where, for certain time step sizes, the developed method is $MS$-stable while the It{\u00f4}--Taylor one is not. This concept is really useful to tackle slow-fast problems such as stiff ones, which we aim to explore further in future work. Finally, we validate the theoretical results with some academic test cases.", "AI": {"tldr": "A second-order stochastic numerical method is developed that generalizes the deterministic TR-BDF2 scheme, preserving both second-order accuracy and A-stability in stochastic differential equations, with analysis of MS-stability showing advantages over It\u00f4-Taylor methods.", "motivation": "To develop a stochastic numerical method that preserves the desirable properties of the deterministic TR-BDF2 scheme (second-order accuracy and A-stability) for solving stochastic differential equations, where most stochastic techniques typically have lower order compared to deterministic methods.", "method": "Generalization of the deterministic TR-BDF2 scheme to stochastic differential equations, with theoretical analysis proving second-order accuracy and A-stability, plus investigation of MS-stability properties across different parameter ranges and comparison with It\u00f4-Taylor order 2 approximations.", "result": "Successfully developed a stochastic scheme that preserves second-order accuracy and A-stability of the original TR-BDF2 method, with MS-stability analysis revealing scenarios where the new method is stable while It\u00f4-Taylor order 2 is not, particularly for certain time step sizes.", "conclusion": "The developed stochastic TR-BDF2 scheme successfully extends deterministic properties to stochastic framework, showing promise for tackling stiff and slow-fast problems, with theoretical results validated through academic test cases and potential for future applications in challenging stochastic problems."}}
{"id": "2602.10741", "pdf": "https://arxiv.org/pdf/2602.10741", "abs": "https://arxiv.org/abs/2602.10741", "authors": ["Fumihito Abe", "Ryo Muramatsu"], "title": "Wave front set of solutions to Schr\u00f6dinger equations with time-dependent magnetic fields", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we determine the wave front set of solutions to the Schr\u00f6dinger equation with time-dependent magnetic fields. We considered time-dependent and `not so small' magnetic fields through the method using the wave packet transform established by K. Kato, M. Kobayashi and S. Ito. Furthermore, we checked that the fundamental solution of the Schr\u00f6dinger equation in a spatially decaying magnetic field has no singularities as a consequence of our result.", "AI": {"tldr": "Determination of wave front sets for Schr\u00f6dinger equations with time-dependent magnetic fields using wave packet transform methods.", "motivation": "To analyze the propagation of singularities in solutions to Schr\u00f6dinger equations with time-dependent magnetic fields, particularly for non-small magnetic fields, which has applications in quantum mechanics and PDE theory.", "method": "Uses the wave packet transform method established by K. Kato, M. Kobayashi and S. Ito to handle time-dependent magnetic fields that are not necessarily small.", "result": "Determined the wave front set of solutions to the Schr\u00f6dinger equation with time-dependent magnetic fields, and showed that the fundamental solution in spatially decaying magnetic fields has no singularities.", "conclusion": "The wave packet transform method successfully handles time-dependent magnetic fields, providing insights into singularity propagation and showing absence of singularities in fundamental solutions for decaying magnetic fields."}}
{"id": "2602.10786", "pdf": "https://arxiv.org/pdf/2602.10786", "abs": "https://arxiv.org/abs/2602.10786", "authors": ["Jan Glaubitz", "Armin Iske", "Joshua Lampert", "Philipp \u00d6ffner"], "title": "Why summation by parts is not enough", "categories": ["math.NA"], "comment": null, "summary": "We investigate the construction and performance of summation-by-parts (SBP) operators, which offer a powerful framework for the systematic development of structure-preserving numerical discretizations of partial differential equations. Previous approaches for the construction of SBP operators have usually relied on either local methods or sparse differentiation matrices, as commonly used in finite difference schemes. However, these methods often impose implicit requirements that are not part of the formal SBP definition. We demonstrate that adherence to the SBP definition alone does not guarantee the desired accuracy, and we identify conditions for SBP operators to achieve both accuracy and stability. Specifically, we analyze the error minimization for an augmented basis, discuss the role of sparsity, and examine the importance of nullspace consistency in the construction of SBP operators. Furthermore, we show how these design criteria can be integrated into a recently proposed optimization-based construction procedure for function space SBP (FSBP) operators on arbitrary grids. Our findings are supported by numerical experiments that illustrate the improved accuracy for the numerical solution using the proposed SBP operators.", "AI": {"tldr": "The paper analyzes construction of summation-by-parts (SBP) operators, showing that formal SBP definition alone doesn't guarantee accuracy, and identifies conditions for achieving both accuracy and stability in SBP operators.", "motivation": "Previous SBP operator construction methods rely on local methods or sparse differentiation matrices with implicit requirements not part of formal SBP definition. The paper aims to identify conditions for SBP operators to achieve both accuracy and stability beyond just meeting the formal definition.", "method": "Analyzes error minimization for augmented basis, discusses role of sparsity, examines importance of nullspace consistency in SBP construction. Integrates these design criteria into optimization-based construction procedure for function space SBP (FSBP) operators on arbitrary grids.", "result": "Demonstrates that adherence to SBP definition alone doesn't guarantee desired accuracy. Identifies specific conditions for SBP operators to achieve both accuracy and stability. Numerical experiments show improved accuracy for numerical solutions using proposed SBP operators.", "conclusion": "The paper provides a comprehensive analysis of SBP operator construction, identifying key design criteria beyond formal definition that ensure both accuracy and stability, with practical implementation in optimization-based FSBP construction on arbitrary grids."}}
{"id": "2602.10772", "pdf": "https://arxiv.org/pdf/2602.10772", "abs": "https://arxiv.org/abs/2602.10772", "authors": ["Yuanyuan Lian"], "title": "Interior $BMO$ regularity for elliptic equations in divergence form", "categories": ["math.AP"], "comment": null, "summary": "In this note, we establish the interior $BMO$ regularity of weak solutions to uniformly elliptic equations in divergence form. Moreover, the assumptions on the coefficients are nearly optimal.", "AI": {"tldr": "The paper proves interior BMO regularity for weak solutions of uniformly elliptic divergence-form equations with nearly optimal coefficient assumptions.", "motivation": "Understanding the regularity properties of solutions to elliptic PDEs is fundamental in analysis. BMO (Bounded Mean Oscillation) regularity provides important information about solution behavior, and establishing such regularity under minimal coefficient assumptions has significant theoretical value.", "method": "The authors use techniques from elliptic PDE theory, likely involving estimates and regularity theory for divergence-form equations. The approach focuses on establishing BMO regularity in the interior of the domain under nearly optimal conditions on the coefficients.", "result": "The main result establishes interior BMO regularity for weak solutions to uniformly elliptic equations in divergence form. The coefficient assumptions are shown to be nearly optimal, meaning the regularity result holds under conditions that are close to the minimal possible requirements.", "conclusion": "Weak solutions to uniformly elliptic divergence-form equations enjoy interior BMO regularity under nearly optimal coefficient conditions, extending our understanding of solution regularity for this important class of PDEs."}}
{"id": "2602.10803", "pdf": "https://arxiv.org/pdf/2602.10803", "abs": "https://arxiv.org/abs/2602.10803", "authors": ["Huangxin Chen", "Yuxiang Chen", "Jisheng Kou", "Shuyu Sun"], "title": "bound-preserving Adaptive Time-Stepping Method with Energy Stability for Simulating Compressible Gas Flow in Poroelastic Media", "categories": ["math.NA"], "comment": null, "summary": "In this paper, we present an efficient numerical method to address a thermodynamically consistent gas flow model in porous media involving compressible gas and deformable rock. The accurate modeling of gas flow in porous media often poses significant challenges due to their inherent nonlinearity, the coupling between gas and rock dynamics, and the need to preserve physical principles such as mass conservation, energy dissipation and molar density boundedness. The system is further complicated by the need to balance computational efficiency with the accuracy and stability of the numerical scheme. To tackle these challenges, we adopt a stabilization approach that is able to preserve the original energy dissipation while achieving linear energy-stable numerical schemes. We also prove the convergence of the adopted linear iterative method. At each time step, the stabilization parameter is adaptively updated using a simple and explicit formula to ensure compliance with the original energy dissipation law. The proposed method uses adaptive time stepping to improve computational efficiency while maintaining solution accuracy and boundedness. The adaptive time step size is calculated explicitly at each iteration, ensuring stability and allowing for efficient handling of highly dynamic scenarios. A mixed finite element method combined with an upwind scheme is employed as spatial discretization to ensure mass conservation and stability. Finally, we conduct a series of numerical experiments to validate the performance and robustness of the proposed numerical method.", "AI": {"tldr": "An efficient numerical method for thermodynamically consistent gas flow in deformable porous media that preserves energy dissipation while maintaining computational efficiency through adaptive stabilization and time stepping.", "motivation": "Modeling gas flow in porous media is challenging due to nonlinearity, gas-rock coupling, and the need to preserve physical principles like mass conservation, energy dissipation, and molar density boundedness while balancing computational efficiency with accuracy and stability.", "method": "Stabilization approach preserving original energy dissipation with linear energy-stable schemes; adaptive stabilization parameter updated explicitly; adaptive time stepping with explicit step size calculation; mixed finite element method with upwind scheme for spatial discretization.", "result": "Proposed method achieves thermodynamically consistent modeling with preserved energy dissipation, proven convergence of linear iterative method, and efficient handling of dynamic scenarios through adaptive techniques.", "conclusion": "The numerical method successfully addresses challenges in gas flow modeling through energy-stable schemes, adaptive stabilization and time stepping, and proper spatial discretization, validated by numerical experiments showing performance and robustness."}}
{"id": "2602.10822", "pdf": "https://arxiv.org/pdf/2602.10822", "abs": "https://arxiv.org/abs/2602.10822", "authors": ["Diego Alonso-Or\u00e1n", "Rafael Granero-Belinch\u00f3n"], "title": "A fluid-solid interaction problem in porous media", "categories": ["math.AP", "physics.flu-dyn"], "comment": null, "summary": "In this work, we derive asymptotic interface models for an elastic Muskat free boundary problem describing Darcy flow beneath an elastic membrane. In a weakly nonlinear regime of small interface steepness, we obtain nonlocal evolution equations that capture the free-boundary dynamics up to quadratic order. In the long-wave thin-film regime, we rewrite the kinematic condition in flux form, flatten the moving domain, and derive a lubrication-type equation. Moreover, we establish well-posedness for these models in suitable Wiener spaces.", "AI": {"tldr": "Derivation of asymptotic interface models for elastic Muskat free boundary problem in weakly nonlinear and long-wave regimes, with well-posedness results.", "motivation": "To develop simplified asymptotic models for the complex elastic Muskat free boundary problem, which describes Darcy flow beneath an elastic membrane, making the dynamics more tractable for analysis.", "method": "Two asymptotic approaches: 1) Weakly nonlinear regime (small interface steepness) yielding nonlocal evolution equations up to quadratic order; 2) Long-wave thin-film regime using kinematic condition in flux form, domain flattening, and derivation of lubrication-type equation.", "result": "Derived asymptotic interface models capturing free-boundary dynamics in different regimes, and established well-posedness for these models in suitable Wiener spaces.", "conclusion": "Successfully developed simplified asymptotic models for the elastic Muskat problem that are mathematically tractable while preserving essential physics of the free-boundary dynamics."}}
{"id": "2602.10890", "pdf": "https://arxiv.org/pdf/2602.10890", "abs": "https://arxiv.org/abs/2602.10890", "authors": ["Daniele Di Pietro", "Aurelio Spadotto"], "title": "Hybrid Methods for Friedrichs Systems with Application to Scalar and Vector Diffusion-Advection Problems", "categories": ["math.NA"], "comment": null, "summary": "In this work we study arbitrary-order hybrid discretizations of Friedrichs systems. Friedrichs systems provide a framework that goes beyond the standard classification of partial differential equations into hyperbolic or elliptic, and are thus particularly suited for problems that include both diffusive and advective terms. The family of numerical schemes proposed in this work hinge on hybrid spaces with unknowns located at elements and faces. They support general meshes, are locally conservative and, compared with traditional Discontinuous Galerkin discretizations, lead to smaller algebraic systems once static condensation has been applied. We carry out a complete stability and convergence analysis, which appears to be the first of its kind. The performance of the method is illustrated on scalar and vector three-dimensional diffusion-advection-reaction problems.", "AI": {"tldr": "Hybrid discretizations for Friedrichs systems supporting arbitrary order, general meshes, local conservation, and smaller algebraic systems than DG after static condensation.", "motivation": "Friedrichs systems provide a unified framework beyond traditional hyperbolic/elliptic classification, particularly suitable for problems with both diffusive and advective terms. There's a need for numerical schemes that can handle these mixed-type problems efficiently.", "method": "Arbitrary-order hybrid discretizations using hybrid spaces with unknowns located at elements and faces. The method supports general meshes, is locally conservative, and leads to smaller algebraic systems than traditional Discontinuous Galerkin after static condensation.", "result": "Complete stability and convergence analysis (first of its kind) is provided. The method's performance is demonstrated on scalar and vector three-dimensional diffusion-advection-reaction problems.", "conclusion": "The proposed hybrid discretization scheme provides an effective numerical approach for Friedrichs systems, offering advantages over traditional DG methods in terms of reduced system size after static condensation while maintaining desirable properties like local conservation and mesh flexibility."}}
{"id": "2602.10918", "pdf": "https://arxiv.org/pdf/2602.10918", "abs": "https://arxiv.org/abs/2602.10918", "authors": ["Marco Cicalese", "Leonaard Kreutz", "Imteyaz Mansoor"], "title": "Discrete Quantitative Isocapacitary Inequality: Fluctuation Estimates", "categories": ["math.AP"], "comment": null, "summary": "The classical isocapacitary inequality states that, among all sets of fixed volume, the ball uniquely minimizes the capacity. While this result holds in the continuum, it fails in the discrete setting, where the isocapacitary problem may admit multiple minimizers. In this paper we establish quantitative fluctuation estimates for the discrete isocapacitary problem on subsets of $\\mathbb{Z}^d$\n  as their cardinality diverges. Our approach relies on a careful extension of the associated variational problem from the discrete to the continuum setting, combined with sharp (continuum) quantitative isocapacitary inequalities.", "AI": {"tldr": "Quantitative fluctuation estimates for discrete isocapacitary problem on subsets of \u2124^d as cardinality diverges, bridging discrete and continuum settings.", "motivation": "The classical isocapacitary inequality (ball minimizes capacity for fixed volume) holds in continuum but fails in discrete setting where multiple minimizers may exist. Need to understand quantitative behavior of discrete isocapacitary problem as system size grows.", "method": "Careful extension of variational problem from discrete to continuum setting, combined with sharp continuum quantitative isocapacitary inequalities to establish fluctuation estimates.", "result": "Established quantitative fluctuation estimates for discrete isocapacitary problem on subsets of \u2124^d as their cardinality diverges, showing how discrete behavior approaches continuum limit.", "conclusion": "Successfully bridged discrete and continuum isocapacitary problems, providing quantitative control on fluctuations in discrete setting as system size grows, explaining how discrete multiple minimizers relate to continuum uniqueness."}}
{"id": "2602.11109", "pdf": "https://arxiv.org/pdf/2602.11109", "abs": "https://arxiv.org/abs/2602.11109", "authors": ["Xiao Qi", "Yue Wu", "Yubin Yan"], "title": "Drift-Randomized Milstein-Galerkin Finite Element Method for Semilinear Stochastic Evolution Equations", "categories": ["math.NA", "math.PR"], "comment": null, "summary": "Kruse and Wu [Math. Comp. 88 (2019) 2793--2825] proposed a fully discrete randomized Galerkin finite element method for semilinear stochastic evolution equations (SEEs) driven by additive noise and showed that this method attains a temporal strong convergence rate exceeding order $\\frac{1}{2}$ without imposing any differentiability assumptions on the drift nonlinearity. They further discussed a potential extension of the randomized method to SEEs with multiplicative noise and introduced the so-called drift-randomized Milstein-Galerkin finite element fully discrete scheme, but without providing a corresponding strong convergence analysis.\n  This paper aims to fill this gap by rigorously analyzing the strong convergence behavior of the drift-randomized Milstein-Galerkin finite element scheme. By avoiding the use of differentiability assumptions on the nonlinear drift term, we establish strong convergence rates in both space and time for the proposed method. The obtained temporal convergence rate is $O(\u0394t^{1-\\varepsilon_0})$, where $\u0394t$ denotes the time step size and $\\varepsilon_0$ is an arbitrarily small positive number. Numerical experiments are reported to validate the theoretical findings.", "AI": {"tldr": "This paper provides a rigorous strong convergence analysis for the drift-randomized Milstein-Galerkin finite element scheme for semilinear stochastic evolution equations with multiplicative noise, achieving temporal convergence rate O(\u0394t^{1-\u03b5\u2080}) without requiring differentiability of the drift nonlinearity.", "motivation": "The motivation is to fill the gap left by Kruse and Wu (2019), who proposed the drift-randomized Milstein-Galerkin finite element scheme for SEEs with multiplicative noise but did not provide a strong convergence analysis. This paper aims to rigorously analyze the convergence behavior of this method.", "method": "The paper analyzes the drift-randomized Milstein-Galerkin finite element fully discrete scheme for semilinear stochastic evolution equations with multiplicative noise. The method avoids using differentiability assumptions on the nonlinear drift term while establishing strong convergence rates in both space and time.", "result": "The main result is establishing strong convergence rates for the proposed method. The obtained temporal convergence rate is O(\u0394t^{1-\u03b5\u2080}), where \u0394t is the time step size and \u03b5\u2080 is an arbitrarily small positive number. Numerical experiments validate the theoretical findings.", "conclusion": "The paper successfully fills the gap by providing a rigorous strong convergence analysis for the drift-randomized Milstein-Galerkin finite element scheme, achieving near-optimal temporal convergence without requiring differentiability of the drift nonlinearity, with numerical validation supporting the theoretical results."}}
{"id": "2602.10990", "pdf": "https://arxiv.org/pdf/2602.10990", "abs": "https://arxiv.org/abs/2602.10990", "authors": ["Meng Yang"], "title": "Cutoff Sobolev inequalities for local and non-local $p$-energies on metric measure spaces", "categories": ["math.AP", "math.FA", "math.MG", "math.PR"], "comment": "68 pages", "summary": "For $p>1$, we study subordination phenomena for local and non-local regular $p$-energies on metric measure spaces. Under suitable geometric assumptions, we show that if a local regular $p$-energy satisfies a Poincar\u00e9 inequality together with a cutoff Sobolev inequality with scaling function $\u03a8$, then all associated stable-like non-local $p$-energies with scaling functions strictly below $\u03a8$ are regular and satisfy the corresponding non-local cutoff Sobolev inequalities. Moreover, if a stable-like non-local regular $p$-energy with scaling function $\u03a8$ satisfies the corresponding non-local cutoff Sobolev inequality, then the same conclusion holds for all associated stable-like non-local $p$-energies with scaling functions below $\u03a8$. These results provide a non-linear extension of the classical subordination principle beyond the Dirichlet form framework.", "AI": {"tldr": "The paper establishes subordination principles for local and non-local p-energies on metric measure spaces, showing that Sobolev inequalities for local energies imply similar inequalities for associated non-local energies with smaller scaling functions.", "motivation": "To extend the classical subordination principle from linear Dirichlet forms to the non-linear setting of p-energies, establishing relationships between local and non-local Sobolev-type inequalities in metric measure spaces.", "method": "The authors study subordination phenomena for local and non-local regular p-energies on metric measure spaces under suitable geometric assumptions. They analyze Poincar\u00e9 inequalities and cutoff Sobolev inequalities with scaling functions to establish relationships between different types of energies.", "result": "Two main results: (1) If a local regular p-energy satisfies Poincar\u00e9 and cutoff Sobolev inequalities with scaling function \u03a8, then associated stable-like non-local p-energies with scaling functions strictly below \u03a8 are regular and satisfy corresponding non-local cutoff Sobolev inequalities. (2) If a stable-like non-local regular p-energy with scaling function \u03a8 satisfies the corresponding non-local cutoff Sobolev inequality, then the same holds for all associated stable-like non-local p-energies with scaling functions below \u03a8.", "conclusion": "The results provide a non-linear extension of the classical subordination principle beyond the Dirichlet form framework, establishing systematic relationships between local and non-local p-energies and their associated Sobolev inequalities in metric measure spaces."}}
{"id": "2602.10120", "pdf": "https://arxiv.org/pdf/2602.10120", "abs": "https://arxiv.org/abs/2602.10120", "authors": ["Mason Mault", "Ray Treinen"], "title": "Comparison of the potential energy for different equilibrium configurations of symmetric and asymmetric floating drops", "categories": ["physics.flu-dyn", "math-ph", "math.NA"], "comment": null, "summary": "We provide a numerical method for computing solutions to a free boundary problem arising from the equilibrium state of a floating drop. This numerical method is based on a Newton's method for the underlying nonlinear boundary value problems, and at each iterative step a Chebyshev spectral collocation method is employed. The problems considered here are those that can be described by using generating curves, and include problems in $\\mathbb{R}^2$ and $\\mathbb{R}^3$.\n  The resulting nine-dimensional space of physical parameters is explored, and examples are given that highlight the potential energy of centrally located drops, wall-bound drops, and asymmetrical configurations in $\\mathbb{R}^2$. Non-uniqueness of solutions to the corresponding Euler-Lagrange equations is displayed, and also strong evidence of non-uniqueness of energy minimizers is given.", "AI": {"tldr": "Numerical method using Newton's method with Chebyshev spectral collocation to solve free boundary problems for floating drops, exploring 9D parameter space and showing non-uniqueness of solutions.", "motivation": "To develop an efficient numerical method for computing equilibrium states of floating drops, which involve free boundary problems that are challenging to solve analytically.", "method": "Combines Newton's method for nonlinear boundary value problems with Chebyshev spectral collocation at each iterative step, applied to problems described by generating curves in \u211d\u00b2 and \u211d\u00b3.", "result": "Successfully explores the 9-dimensional parameter space, provides examples of centrally located drops, wall-bound drops, and asymmetrical configurations in \u211d\u00b2, and demonstrates non-uniqueness of both Euler-Lagrange solutions and energy minimizers.", "conclusion": "The proposed numerical framework effectively solves complex free boundary problems for floating drops and reveals important non-uniqueness properties in the solution space, with implications for understanding drop equilibrium states."}}
{"id": "2602.10150", "pdf": "https://arxiv.org/pdf/2602.10150", "abs": "https://arxiv.org/abs/2602.10150", "authors": ["Yilong Dai", "Shengyu Chen", "Xiaowei Jia", "Peyman Givi", "Runlong Yu"], "title": "PEST: Physics-Enhanced Swin Transformer for 3D Turbulence Simulation", "categories": ["physics.flu-dyn", "cs.AI", "math.AP"], "comment": null, "summary": "Accurate simulation of turbulent flows is fundamental to scientific and engineering applications. Direct numerical simulation (DNS) offers the highest fidelity but is computationally prohibitive, while existing data-driven alternatives struggle with stable long-horizon rollouts, physical consistency, and faithful simulation of small-scale structures. These challenges are particularly acute in three-dimensional (3D) settings, where the cubic growth of spatial degrees of freedom dramatically amplifies computational cost, memory demand, and the difficulty of capturing multi-scale interactions. To address these challenges, we propose a Physics-Enhanced Swin Transformer (PEST) for 3D turbulence simulation. PEST leverages a window-based self-attention mechanism to effectively model localized PDE interactions while maintaining computational efficiency. We introduce a frequency-domain adaptive loss that explicitly emphasizes small-scale structures, enabling more faithful simulation of high-frequency dynamics. To improve physical consistency, we incorporate Navier--Stokes residual constraints and divergence-free regularization directly into the learning objective. Extensive experiments on two representative turbulent flow configurations demonstrate that PEST achieves accurate, physically consistent, and stable autoregressive long-term simulations, outperforming existing data-driven baselines.", "AI": {"tldr": "PEST: Physics-Enhanced Swin Transformer for 3D turbulence simulation using window-based self-attention, frequency-domain adaptive loss, and Navier-Stokes constraints for accurate, stable long-term predictions.", "motivation": "DNS is computationally prohibitive for 3D turbulence, while existing data-driven methods struggle with stable long-horizon rollouts, physical consistency, and faithful simulation of small-scale structures due to cubic growth of spatial degrees of freedom in 3D settings.", "method": "Proposes Physics-Enhanced Swin Transformer (PEST) with window-based self-attention for localized PDE interactions, frequency-domain adaptive loss for small-scale structures, and incorporates Navier-Stokes residual constraints and divergence-free regularization into learning objective.", "result": "PEST achieves accurate, physically consistent, and stable autoregressive long-term simulations on two representative turbulent flow configurations, outperforming existing data-driven baselines.", "conclusion": "PEST effectively addresses challenges in 3D turbulence simulation by combining transformer architecture with physics-informed constraints, enabling efficient and accurate modeling of turbulent flows while maintaining physical consistency and stability."}}
{"id": "2602.10374", "pdf": "https://arxiv.org/pdf/2602.10374", "abs": "https://arxiv.org/abs/2602.10374", "authors": ["Yiwen Chen"], "title": "Relationships between full-space and subspace quadratic interpolation models and simplex derivatives", "categories": ["math.OC", "math.NA"], "comment": null, "summary": "Quadratic interpolation models and simplex derivatives are fundamental tools in numerical optimization, particularly in derivative-free optimization. When constructed in suitably chosen affine subspaces, these tools have been shown to be especially effective for high-dimensional derivative-free optimization problems, where full-space model construction is often impractical. In this paper, we analyze the relationships between full-space and subspace formulations of these tools. In particular, we derive explicit conversion formulas between full-space and subspace models, including minimum-norm models, minimum Frobenius norm models, least Frobenius norm updating models, as well as models constructed via generalized simplex gradients and Hessians. We show that the full-space and subspace models coincide on the affine subspace and, in general, along directions in the orthogonal complement. Overall, our results provide a theoretical framework for understanding subspace approximation techniques and offer insight into the design and analysis of derivative-free optimization methods.", "AI": {"tldr": "The paper analyzes relationships between full-space and subspace quadratic interpolation models and simplex derivatives in derivative-free optimization, providing explicit conversion formulas and showing when these models coincide.", "motivation": "Subspace models are effective for high-dimensional derivative-free optimization where full-space construction is impractical, but the theoretical relationships between full-space and subspace formulations need better understanding.", "method": "Derived explicit conversion formulas between full-space and subspace models, including minimum-norm models, minimum Frobenius norm models, least Frobenius norm updating models, and models using generalized simplex gradients and Hessians.", "result": "Showed that full-space and subspace models coincide on the affine subspace and generally along directions in the orthogonal complement, establishing theoretical equivalence under certain conditions.", "conclusion": "Provides a theoretical framework for understanding subspace approximation techniques and offers insight for designing and analyzing derivative-free optimization methods."}}
{"id": "2602.10227", "pdf": "https://arxiv.org/pdf/2602.10227", "abs": "https://arxiv.org/abs/2602.10227", "authors": ["Elena Medvedeva", "Raphael Assier", "Anastasia Kisil"], "title": "Wave scattering by a transversal defect in a discrete waveguide", "categories": ["math-ph", "math.AP", "math.CV"], "comment": null, "summary": "We study wave scattering by a finite transversal strip in a discrete square-lattice waveguide with Dirichlet boundary conditions imposed on the strip and the waveguide walls. The setting is motivated as a discrete analogue of the classical continuous waveguide problem with a screen. The corresponding Wiener--Hopf formulation leads to an equation with a $4 \\times 4$ matrix kernel, which reduces to a $2 \\times 2$ matrix kernel under some symmetry assumptions. The factorisation prospects of this kernel are discussed, but this route is not followed. Instead, an exact analytical solution is obtained using the pole removal technique. This contrasts with the continuous case, where only approximate solutions are currently available. The reflection and transmission coefficients resulting from an incident duct mode are computed with an accuracy up to $10^{-13}$, showing consistency with theoretical predictions from continuous waveguide theory. In particular, full reflection and zero transmission are recovered as the frequency approaches the cut-off value for the incident mode. Finally, the solution is validated against a numerical computation of the diffraction problem via the Boundary Algebraic Equations method with a tailored lattice Green's function.", "AI": {"tldr": "Exact analytical solution for wave scattering by a finite strip in a discrete square-lattice waveguide using pole removal technique, achieving high accuracy and recovering continuous waveguide theory predictions.", "motivation": "To study wave scattering in a discrete waveguide as an analogue to classical continuous waveguide problems with screens, where only approximate solutions exist in continuous cases.", "method": "Uses Wiener-Hopf formulation leading to 4\u00d74 matrix kernel (reducible to 2\u00d72 under symmetry), then applies pole removal technique for exact analytical solution instead of kernel factorization.", "result": "Obtained reflection and transmission coefficients with accuracy up to 10\u207b\u00b9\u00b3, showing consistency with continuous waveguide theory predictions, including full reflection and zero transmission at cut-off frequencies.", "conclusion": "Successfully developed exact analytical solution for discrete waveguide scattering problem, validated against numerical computations, contrasting with continuous case where only approximate solutions exist."}}
{"id": "2602.10544", "pdf": "https://arxiv.org/pdf/2602.10544", "abs": "https://arxiv.org/abs/2602.10544", "authors": ["Wuyang Zhang", "Zhen Luo", "Chuqiao Gu", "Jianming Ma", "Yebo Cao", "Wangming Yuan", "Yinzhi Jin"], "title": "Bridging the Compression-Precision Paradox: A Hybrid Architecture for Clinical EEG Report Generation with Guaranteed Measurement Accuracy", "categories": ["cs.LG", "math.NA"], "comment": "7 pages", "summary": "Automated EEG monitoring requires clinician-level precision for seizure detection and reporting. Clinical EEG recordings exceed LLM context windows, requiring extreme compression (400:1+ ratios) that destroys fine-grained temporal precision. A 0.5 Hz error distinguishes absence epilepsy from Lennox-Gastaut syndrome. LLMs lack inherent time-series comprehension and rely on statistical associations from compressed representations. This dual limitation causes systems to hallucinate clinically incorrect measurement values.\n  We separate measurement extraction from text generation. Our hybrid architecture computes exact clinical values via signal processing before compression, employs a cross-modal bridge for EEG-to-language translation, and uses parameter-efficient fine-tuning with constrained decoding around frozen slots. Multirate sampling maintains long-range context while preserving event-level precision. Evaluation on TUH and CHB-MIT datasets achieves 60% fewer false alarms, 50% faster detection, and sub-clinical measurement precision. This is the first system guaranteeing clinical measurement accuracy in automated EEG reports.", "AI": {"tldr": "Hybrid EEG analysis system separates signal processing from text generation to achieve clinical-level accuracy in automated EEG reports, solving LLM limitations with extreme compression and time-series comprehension.", "motivation": "Current automated EEG monitoring systems using LLMs face two critical problems: 1) Clinical EEG recordings exceed LLM context windows, requiring extreme compression (400:1+ ratios) that destroys fine-grained temporal precision needed for clinical diagnosis, and 2) LLMs lack inherent time-series comprehension and rely on statistical associations from compressed representations, causing hallucinations of clinically incorrect measurement values.", "method": "Hybrid architecture that separates measurement extraction from text generation. Key components: 1) Computes exact clinical values via signal processing before compression, 2) Employs a cross-modal bridge for EEG-to-language translation, 3) Uses parameter-efficient fine-tuning with constrained decoding around frozen slots, and 4) Multirate sampling to maintain long-range context while preserving event-level precision.", "result": "Evaluation on TUH and CHB-MIT datasets shows: 60% fewer false alarms, 50% faster detection, and sub-clinical measurement precision. This is the first system guaranteeing clinical measurement accuracy in automated EEG reports.", "conclusion": "The proposed hybrid architecture successfully addresses the dual limitations of LLMs in EEG analysis by separating measurement extraction from text generation, achieving clinical-level accuracy while maintaining computational efficiency through multirate sampling and constrained decoding."}}
{"id": "2602.10263", "pdf": "https://arxiv.org/pdf/2602.10263", "abs": "https://arxiv.org/abs/2602.10263", "authors": ["Hadi Susanto"], "title": "New logarithmic power nonlinear Schr\u00f6dinger equations with super-Gaussons", "categories": ["nlin.PS", "math.AP"], "comment": null, "summary": "We introduce a new class of nonlinear Schr\u00f6dinger equations with a logarithmic-power nonlinearity that admits exact localized solutions of super-Gaussian form. The resulting stationary states possess flat-top profiles with sharp edges and are referred to as super-Gaussons, in analogy with the Gaussian Gaussons of the classical logarithmic NLS (log-NLS). The model, which we call the logarithmic-power NLS (logp-NLS), is parameterized by an exponent $p\\geq1$ that controls the degree of flatness of the soliton core and the sharpness of its decay. Mathematically, $p$ interpolates between the standard log-NLS ($p=1$) and increasingly flat-top profiles as $p$ increases, while physically it governs the stiffness of an underlying logarithmic-power compressibility law. The proposed equation is constructed so as to admit super-Gaussian stationary states and can be interpreted a posteriori within a generalized pressure-law framework, thereby extending the log-NLS. We investigate the dynamics of super-Gaussons in one spatial dimension through numerical simulations for various values of $p$, demonstrating how this parameter regulates both the internal structure of the soliton and its collision dynamics. The logp-NLS thus generalizes the standard log-NLS by admitting a broader family of localized states with distinctive structural and dynamical properties, suggesting its relevance for flat-top solitons in nonlinear optics, Bose-Einstein condensates, and related nonlinear media.", "AI": {"tldr": "Introduces logp-NLS equations with logarithmic-power nonlinearity that admit exact super-Gaussian localized solutions called super-Gaussons, generalizing the standard log-NLS to produce flat-top solitons with controllable sharpness.", "motivation": "To extend the classical logarithmic NLS (log-NLS) to admit a broader family of localized states with flat-top profiles, addressing limitations of standard Gaussian profiles and enabling control over soliton flatness and edge sharpness.", "method": "Introduces logarithmic-power NLS (logp-NLS) parameterized by exponent p\u22651, constructed to admit exact super-Gaussian stationary states. Analyzes stationary states and investigates dynamics through numerical simulations in 1D for various p values.", "result": "The logp-NLS admits exact super-Gaussian localized solutions (super-Gaussons) with flat-top profiles and sharp edges. Parameter p controls soliton flatness and decay sharpness, interpolating between standard log-NLS (p=1) and increasingly flat-top profiles as p increases. Numerical simulations show p regulates both internal structure and collision dynamics.", "conclusion": "The logp-NLS generalizes standard log-NLS by admitting a broader family of localized states with distinctive structural and dynamical properties, suggesting relevance for flat-top solitons in nonlinear optics, Bose-Einstein condensates, and related nonlinear media."}}
{"id": "2602.10589", "pdf": "https://arxiv.org/pdf/2602.10589", "abs": "https://arxiv.org/abs/2602.10589", "authors": ["Alessandro Andrea Zecchi", "Claudio Sanavio", "Luca Cappelli", "Simona Perotto", "Alessandro Roggero", "Sauro Succi"], "title": "Block encoding of sparse matrices with a periodic diagonal structure", "categories": ["quant-ph", "math.NA"], "comment": null, "summary": "Block encoding is a successful technique used in several powerful quantum algorithms. In this work we provide an explicit quantum circuit for block encoding a sparse matrix with a periodic diagonal structure. The proposed methodology is based on the linear combination of unitaries (LCU) framework and on an efficient unitary operator used to project the complex exponential at a frequency $\u03c9$ multiplied by the computational basis into its real and imaginary components. We demonstrate a distinct computational advantage with a $\\mathcal{O}(\\text{poly}(n))$ gate complexity, where $n$ is the number of qubits, in the worst-case scenario used for banded matrices, and $\\mathcal{O}(n)$ when dealing with a simple diagonal matrix, compared to the exponential scaling of general-purpose methods for dense matrices. Various applications for the presented methodology are discussed in the context of solving differential problems such as the advection-diffusion-reaction (ADR) dynamics, using quantum algorithms with optimal scaling, e.g., quantum singular value transformation (QSVT). Numerical results are used to validate the analytical formulation.", "AI": {"tldr": "This paper presents an efficient quantum circuit for block encoding sparse matrices with periodic diagonal structure using LCU framework, achieving polynomial gate complexity compared to exponential scaling for dense matrices.", "motivation": "Block encoding is crucial for many quantum algorithms, but general methods for dense matrices scale exponentially. There's a need for efficient block encoding of sparse matrices with specific structures to enable practical quantum algorithms for solving differential equations.", "method": "The method uses linear combination of unitaries (LCU) framework with an efficient unitary operator that projects complex exponentials at frequency \u03c9 into real and imaginary components. It specifically targets sparse matrices with periodic diagonal structure.", "result": "Achieves O(poly(n)) gate complexity for banded matrices and O(n) for simple diagonal matrices, compared to exponential scaling for dense matrices. The approach is validated numerically and applied to solving advection-diffusion-reaction problems using QSVT.", "conclusion": "The proposed method provides efficient block encoding for structured sparse matrices, enabling practical quantum algorithms for differential equations with optimal scaling, particularly useful for quantum singular value transformation applications."}}
{"id": "2602.10913", "pdf": "https://arxiv.org/pdf/2602.10913", "abs": "https://arxiv.org/abs/2602.10913", "authors": ["Andrew M. Roberts"], "title": "Low energy $\\varepsilon$-harmonic maps into the round sphere", "categories": ["math.DG", "math.AP"], "comment": "23 pages", "summary": "In this paper we classify the low energy $\\varepsilon$-harmonic maps from the surfaces of constant curvature with positive genus into the round sphere. We find that all such maps with degree $\\pm1$ are all quantitively close to a bubble configuration with bubbles forming at special points on the domain with bubbling radius proportional to $\\varepsilon^{1/4}$.", "AI": {"tldr": "Classifies low energy \u03b5-harmonic maps from constant curvature surfaces with positive genus to spheres, showing degree \u00b11 maps are quantitatively close to bubble configurations with bubbles forming at special points with radius ~\u03b5^{1/4}.", "motivation": "To understand the structure and behavior of low energy \u03b5-harmonic maps from surfaces of positive genus to spheres, particularly focusing on maps with degree \u00b11 and their bubbling phenomena.", "method": "Mathematical analysis and classification of \u03b5-harmonic maps from constant curvature surfaces with positive genus to round spheres, examining bubbling configurations and their quantitative properties.", "result": "All degree \u00b11 \u03b5-harmonic maps are quantitatively close to bubble configurations where bubbles form at special points on the domain with bubbling radius proportional to \u03b5^{1/4}.", "conclusion": "The paper establishes precise quantitative relationships between low energy \u03b5-harmonic maps and bubble configurations, revealing the specific scaling behavior (\u03b5^{1/4}) of bubbling radius for degree \u00b11 maps."}}
{"id": "2602.10963", "pdf": "https://arxiv.org/pdf/2602.10963", "abs": "https://arxiv.org/abs/2602.10963", "authors": ["Srishti Siddharth", "Vivek Natarajan", "Ravi N. Banavar"], "title": "Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation", "categories": ["eess.SY", "cs.RO", "math.NA"], "comment": "Submitted to: Computers and Mathematics with Applications", "summary": "In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system.", "AI": {"tldr": "A discrete Cosserat rod model with cross-sectional deformation using Lie group variational integrator that conserves volume, preserves rotational configuration, and maintains energy with bounded error.", "motivation": "To develop a geometrically exact rod model that incorporates both rotational motion and cross-sectional deformation while maintaining desirable physical properties like volume conservation and energy preservation in discrete simulations.", "method": "Derived continuous space-time equations for 3D Cosserat rod with planar cross-sectional deformation, then applied Lie group variational integrator technique to obtain discrete model with volume conservation via local dilatation factor.", "result": "The discrete model successfully conserves volume of elements, preserves rotational configuration, maintains energy with bounded error, and replicates physics of the system across various initial conditions.", "conclusion": "The Lie group variational integrator approach effectively creates a discrete Cosserat rod model that incorporates cross-sectional deformation while maintaining key physical conservation properties and accurately simulating rod dynamics."}}
{"id": "2602.10914", "pdf": "https://arxiv.org/pdf/2602.10914", "abs": "https://arxiv.org/abs/2602.10914", "authors": ["Andrew M. Roberts"], "title": "The generalised energy identity and length of necks for $\\varepsilon$-harmonic maps", "categories": ["math.DG", "math.AP"], "comment": "9 pages", "summary": "In this paper we find analogues for $\\varepsilon$-harmonic maps to the generalised energy identity and the existence of geodesic necks result discovered by Yuxiang Li and Youde Wang for $\u03b1$-harmonic maps. In particular there exist specific quantities depending only on $\\varepsilon$ and the bubbling radius which entirely determine if the full energy identity holds and if a neck forms. In the case these fail we can calculate the energy lost and the length of the geodesic neck based on only these quantities and the biharmonic energy of the bubble.", "AI": {"tldr": "The paper establishes analogues for \u03b5-harmonic maps of known results for \u03b1-harmonic maps, specifically the energy identity and existence of geodesic necks, with quantities depending on \u03b5 and bubbling radius determining these phenomena.", "motivation": "To extend the understanding of bubbling phenomena from \u03b1-harmonic maps to \u03b5-harmonic maps, particularly regarding energy concentration and geometric structures that form during bubbling processes.", "method": "The authors develop analogues of the generalised energy identity and geodesic neck existence results for \u03b5-harmonic maps, building on previous work by Li and Wang for \u03b1-harmonic maps. They identify specific quantities depending on \u03b5 and the bubbling radius that govern these phenomena.", "result": "The paper shows that for \u03b5-harmonic maps, there exist specific quantities (depending only on \u03b5 and bubbling radius) that determine whether the full energy identity holds and whether a geodesic neck forms. When these fail, the energy lost and neck length can be calculated using these quantities and the biharmonic energy of the bubble.", "conclusion": "The study provides a complete characterization of bubbling behavior for \u03b5-harmonic maps, establishing precise conditions for energy conservation and neck formation, with explicit formulas for energy loss and neck geometry when these conditions fail."}}
{"id": "2602.10920", "pdf": "https://arxiv.org/pdf/2602.10920", "abs": "https://arxiv.org/abs/2602.10920", "authors": ["Benedikt Kaltenbach", "Christian Aarset", "Tram Thi Ngoc Nguyen"], "title": "Data assimilation via model reference adaptation for linear and nonlinear dynamical systems", "categories": ["math.OC", "math.AP", "math.DS"], "comment": null, "summary": "We address data assimilation for linear and nonlinear dynamical systems via the so-called \\emph{model reference adaptive system}. Continuing our theoretical developments in \\cite{Tram_Kaltenbacher_2021}, we deliver the first practical implementation of this approach for online parameter identification with time series data. Our semi-implicit scheme couples a modified state equation with a parameter evolution law that is driven by model-data residuals. We demonstrate four benchmark problems of increasing complexity: the Darcy flow, the Fisher-KPP equation, a nonlinear potential equation and finally, an Allen-Cahn type equation. Across all cases, explicit model reference adaptive system construction, verified assumptions and numerically stable reconstructions underline our proposed method as a reliable, versatile tool for data assimilation and real-time inversion.", "AI": {"tldr": "First practical implementation of model reference adaptive system for online parameter identification with time series data, demonstrated on four benchmark problems.", "motivation": "To develop a practical, reliable tool for data assimilation and real-time inversion in dynamical systems, building on previous theoretical work.", "method": "Semi-implicit scheme coupling modified state equation with parameter evolution law driven by model-data residuals, using model reference adaptive system approach.", "result": "Successful demonstration on four benchmark problems of increasing complexity: Darcy flow, Fisher-KPP equation, nonlinear potential equation, and Allen-Cahn type equation.", "conclusion": "The proposed method is a reliable, versatile tool for data assimilation and real-time inversion with numerically stable reconstructions."}}
{"id": "2602.11108", "pdf": "https://arxiv.org/pdf/2602.11108", "abs": "https://arxiv.org/abs/2602.11108", "authors": ["Jocelyn T. Chi"], "title": "Large Scale High-Dimensional Reduced-Rank Linear Discriminant Analysis", "categories": ["stat.CO", "math.NA"], "comment": null, "summary": "Reduced-rank linear discriminant analysis (RRLDA) is a foundational method of dimension reduction for classification that has been useful in a wide range of applications. The goal is to identify an optimal subspace to project the observations onto that simultaneously maximizes between-group variation while minimizing within-group differences. The solution is straight forward when the number of observations is greater than the number of features but computational difficulties arise in both the high-dimensional setting, where there are more features than there are observations, and when the data are very large. Many works have proposed solutions for the high-dimensional setting and frequently involve additional assumptions or tuning parameters. We propose a fast and simple iterative algorithm for both classical and high-dimensional RRLDA on large data that is free from these additional requirements and that comes with guarantees. We also explain how RRLDA-RK provides implicit regularization towards the least norm solution without explicitly incorporating penalties. We demonstrate our algorithm on real data and highlight some results.", "AI": {"tldr": "A fast iterative algorithm for reduced-rank linear discriminant analysis (RRLDA) that works in both classical and high-dimensional settings without additional assumptions or tuning parameters, with implicit regularization properties.", "motivation": "RRLDA is widely used for dimension reduction in classification but faces computational difficulties in high-dimensional settings (more features than observations) and with large datasets. Existing solutions often require additional assumptions or tuning parameters.", "method": "Proposes a fast and simple iterative algorithm for RRLDA that works in both classical and high-dimensional settings without additional requirements. The algorithm (RRLDA-RK) provides implicit regularization towards the least norm solution without explicit penalties.", "result": "The algorithm comes with theoretical guarantees and is demonstrated on real data with highlighted results showing its effectiveness.", "conclusion": "A practical solution for RRLDA that overcomes computational challenges in high-dimensional and large-scale settings while maintaining simplicity and theoretical guarantees."}}
{"id": "2602.11115", "pdf": "https://arxiv.org/pdf/2602.11115", "abs": "https://arxiv.org/abs/2602.11115", "authors": ["Benedito Leandro", "Ilton Menezes", "Rafael Novais"], "title": "Solution for the Einstein-Maxwell equations invariant under an $(n - 1)$-dimensional group of dilations", "categories": ["math.DG", "math-ph", "math.AP"], "comment": null, "summary": "We consider an electrostatic system whose spatial factor is conformal to an $n$-dimensional Euclidean space. We provide a complete characterization of the most general ansatz, thereby reducing the associated electrostatic system of partial differential equations to an ordinary differential equation system. We prove that there are only two possibilities: either the cosmological constant is nonzero, in which case the solutions are necessarily invariant under rotations or translations, or the cosmological constant vanishes, and the solutions belong to the Majumdar-Papapetrou class with a degree of freedom associated with an invariant $(n-1)$-dimensional subgroup. As a result, we introduce a new solution to the electrovacuum system in the Majumdar-Papapetrou class that is invariant under an $(n-1)$-dimensional group of dilations.", "AI": {"tldr": "The paper analyzes electrostatic systems in n-dimensional conformally Euclidean spaces, showing they reduce to ODEs with only two solution classes: rotation/translation invariant solutions with nonzero cosmological constant, or Majumdar-Papapetrou solutions with (n-1)-dimensional subgroup invariance when cosmological constant vanishes.", "motivation": "To understand the general structure of electrostatic systems in conformally Euclidean spaces and classify all possible solutions, particularly examining how cosmological constant affects solution symmetries.", "method": "Developed a complete characterization of the most general ansatz for electrostatic systems in n-dimensional conformally Euclidean spaces, reducing the PDE system to ODEs, then proved classification theorems based on cosmological constant value.", "result": "Found only two possibilities: 1) Nonzero cosmological constant leads to rotation or translation invariant solutions; 2) Vanishing cosmological constant yields Majumdar-Papapetrou class solutions with (n-1)-dimensional subgroup invariance. Introduced new dilation-invariant solution in Majumdar-Papapetrou class.", "conclusion": "The cosmological constant fundamentally determines solution symmetries in electrostatic conformally Euclidean systems, with a sharp dichotomy between rotation/translation invariance (nonzero \u039b) and Majumdar-Papapetrou solutions with higher-dimensional subgroup invariance (\u039b=0)."}}
